{"Data":{"GitHub":{"Issues":[{"Id":"361983639","IsPullRequest":true,"CreatedAt":"2018-09-20T01:24:32","Actor":"zeahmed","Number":"961","RawContent":null,"Title":"Converted LpNorm, GcNorm and Whitening transforms into transformers/estimators…","State":"open","Body":"This PR fixes #959 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/961","RelatedDescription":"Open PR \"Converted LpNorm, GcNorm and Whitening transforms into transformers/estimators…\" (#961)"},{"Id":"361983424","IsPullRequest":true,"CreatedAt":"2018-09-20T01:23:13","Actor":"Zruty0","Number":"960","RawContent":null,"Title":"WIP API overview and samples","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/960","RelatedDescription":"Open PR \"WIP API overview and samples\" (#960)"},{"Id":"361983370","IsPullRequest":false,"CreatedAt":"2018-09-20T01:22:51","Actor":"zeahmed","Number":"959","RawContent":null,"Title":"Convert LpNorm, GcNorm and Whitening Transforms to transformers/estimators.","State":"open","Body":"\r\nIn this work item, following transforms will be converted into transformer/estimators.\r\n\r\n- LpNormNormalizerTransform\r\n- GcnTransform\r\n- WhiteningTransform","Url":"https://github.com/dotnet/machinelearning/issues/959","RelatedDescription":"Open issue \"Convert LpNorm, GcNorm and Whitening Transforms to transformers/estimators.\" (#959)"},{"Id":"361970644","IsPullRequest":false,"CreatedAt":"2018-09-20T00:04:26","Actor":"wschin","Number":"958","RawContent":null,"Title":"ONNX Conversion Framework Needs a Way to Create Tensors as ONNX Graph's Initializers","State":"open","Body":"As title. Currently, we're not able to create elements in [this field](https://github.com/onnx/onnx/blob/c0ec417e219ff4ce22b94998bbe570e9b9b0c34a/onnx/onnx-ml.proto#L256).","Url":"https://github.com/dotnet/machinelearning/issues/958","RelatedDescription":"Open issue \"ONNX Conversion Framework Needs a Way to Create Tensors as ONNX Graph's Initializers\" (#958)"},{"Id":"361956442","IsPullRequest":true,"CreatedAt":"2018-09-19T22:50:10","Actor":"artidoro","Number":"957","RawContent":null,"Title":"WIP: Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators","State":"open","Body":"Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators by deriving the base class LbfgsTrainerBase from TrainerEstimatorBase.\r\n\r\nWorking on testing the converted classes using TestEstimatorCore. ","Url":"https://github.com/dotnet/machinelearning/pull/957","RelatedDescription":"Open PR \"WIP: Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators\" (#957)"},{"Id":"361956023","IsPullRequest":false,"CreatedAt":"2018-09-19T22:48:11","Actor":"artidoro","Number":"956","RawContent":null,"Title":"Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators","State":"open","Body":"Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators by deriving the base class LbfgsTrainerBase from TrainerEstimatorBase.","Url":"https://github.com/dotnet/machinelearning/issues/956","RelatedDescription":"Open issue \"Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators\" (#956)"},{"Id":"361949146","IsPullRequest":false,"CreatedAt":"2018-09-19T22:18:09","Actor":"wschin","Number":"955","RawContent":null,"Title":"Experimental Exporter of CopyColumnTransform to ONNX","State":"open","Body":"Following the same strategy of converting ConvertTransform, we should be able export CopyColumnTransform to ONNX as well. #952 demonstrates a possible approach. Note that we assume that somehow the ONNX runtime used can recognize the unofficial operator we're producing.","Url":"https://github.com/dotnet/machinelearning/issues/955","RelatedDescription":"Open issue \"Experimental Exporter of CopyColumnTransform to ONNX\" (#955)"},{"Id":"361943367","IsPullRequest":true,"CreatedAt":"2018-09-19T21:57:20","Actor":"Anipik","Number":"954","RawContent":null,"Title":"different config files for train and predict benchmarks","State":"open","Body":"- different Config files for train and test\r\n- solves problem of long running time\r\n- train benchmarks contain only one iteration as it gives more idea on how the users will use. (with no warmup iteration)\r\n- predict config is the original version\r\n\r\ncc @danmosemsft @eerhardt @adamsitnik @justinormont \r\n","Url":"https://github.com/dotnet/machinelearning/pull/954","RelatedDescription":"Open PR \"different config files for train and predict benchmarks\" (#954)"},{"Id":"361930678","IsPullRequest":true,"CreatedAt":"2018-09-19T21:15:32","Actor":"zeahmed","Number":"953","RawContent":null,"Title":"Converted listed text transforms into transformers/estimators.","State":"open","Body":"This PR fixes #950.\r\n\r\nThe following transforms were converted in this PR.\r\n\r\n- Stopwords Remover Transform\r\n- Text Normalizer Transform \r\n- Word Bag Transform\r\n- Word Hash Bag Transform \r\n- Ngram Transform \r\n- Ngram Hash Transform \r\n","Url":"https://github.com/dotnet/machinelearning/pull/953","RelatedDescription":"Open PR \"Converted listed text transforms into transformers/estimators.\" (#953)"},{"Id":"361927915","IsPullRequest":true,"CreatedAt":"2018-09-19T21:06:59","Actor":"wschin","Number":"952","RawContent":null,"Title":"Export CopyColumnTransform to (unofficial) ONNX operator","State":"open","Body":"1. Add exporter for CopyColumnTransform\r\n2. Remove duplicate definitions in ONNX graph\r\n3. Some changes for adding constant tensors are included.","Url":"https://github.com/dotnet/machinelearning/pull/952","RelatedDescription":"Open PR \"Export CopyColumnTransform to (unofficial) ONNX operator\" (#952)"},{"Id":"361924820","IsPullRequest":false,"CreatedAt":"2018-09-19T20:57:52","Actor":"zeahmed","Number":"951","RawContent":null,"Title":"Develop a POC for training tensorflow model using TF#.","State":"open","Body":"There are couple of hurdles in implementing a transfer learning scenario (where tf model is actually modified) using TF#.\r\n\r\n- There is no way to serialized TF model back to file using TF C-API (also TF#).\r\n- It seems impossible to load checkpoint models using C-API (also TF#) because the graph saved with checkpoint models is saved in meta_graph format for which straightforward API is currently missing to load/save.\r\n- When using model created for the purpose of serving e.g. frozen model or un-frozen model ( saved with simple_save method in python) for training, there are no training ops like optimizations or loss operations.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/951","RelatedDescription":"Open issue \"Develop a POC for training tensorflow model using TF#.\" (#951)"},{"Id":"361919430","IsPullRequest":false,"CreatedAt":"2018-09-19T20:42:19","Actor":"zeahmed","Number":"950","RawContent":null,"Title":"Convert all text transforms into transformers/estimators.","State":"open","Body":"Following is the list of transforms that will converted in this work item.\r\n\r\n- Stopwords Remover Transform\r\n- Text Normalizer Transform \r\n- Word Bag Transform\r\n- Word Hash Bag Transform \r\n- Ngram Transform \r\n- Ngram Hash Transform \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/950","RelatedDescription":"Open issue \"Convert all text transforms into transformers/estimators.\" (#950)"},{"Id":"361903092","IsPullRequest":false,"CreatedAt":"2018-09-19T19:54:48","Actor":"TomFinley","Number":"949","RawContent":null,"Title":"API: Binary Classification Training Context","State":"open","Body":"There seems to be something appealing about a convenience object whose purpose is to help \"guide\" people on the path to a successful experiment. So for example, someone might have a pipeline where they featurize, then learn, then evaluate on a test set. Each of these is of course naturally implemented in separate classes, which is good. But it also means that the ingredients necessary to compose a successful experiment are naturally spread hither and yon.\r\n\r\nYou might imagine that in addition to the components, there might be some sort of \"task context\" object, like for example, a `BinaryClassifierContext`. This might have common facilities: for example, a common way to \"browse\" binary classifier trainers, and to evaluate binary classification outputs.\r\n\r\nThere is something appealing about doing this:\r\n\r\n```csharp\r\nvar data = ...\r\nvar ctx = new BinaryClassificationContext();\r\nvar prediction = ctx.Trainers.FastTree(data, ...);\r\nvar metrics = ctx.Evaluate(prediction, ...);\r\n```\r\n\r\nvs. this\r\n\r\n```csharp\r\nvar data = ...\r\nvar prediction = new FastTreeBinaryClassifierEstimator(data, ...);\r\nvar eval = new BinaryClasifierEvaluator(...);\r\nvar metrics = eval.Evaluate(prediction, ...)\r\n```\r\n\r\nThe latter case is certainly no less powerful, but if I imagine someone tooling around in intellisense, the sheer number of things you'll get by including the key namespaces and saying `new` is absolutely dizzying, vs. this context which can be very, very focused.\r\n\r\nIn the case of static pipelines the story is a little bit better, \"we provide extension methods on `Scalar<bool>`\", which is OK *if you know that*, but if you don't happen to know that, I see no reasonable way you could discover that without reading documentation and samples. (Of course for that matter I see ). But requiring knowledge at the level of, \"if you want to do something related to binary classifiers, please say `new BinaryClassifierContext`\" or something, that seems kind of reasonable to me.\r\n\r\nThis hypothetical `Context` object would contain at least two things: the first is a property. (It must be an actual instance because the only way external assemblies could \"add\" their learners to it would be via extension methods.) The second is one or more `Evaluate` methods to produce metrics.\r\n\r\nThese \"objects\" do have state in the sense that they must have an `IHostEnvironment` more or less like \"namespaces,\" with the important difference possibly that you can't have a top level function as a namespace. (Though perhaps we don't care about doing functions.) There was some thought that if we also defined pipelines through them we could avoid having environments in the dynamic pipelines altogether (as we already do for static pipelines), but how this would be accomplished is not clear to me.\r\n\r\nAlso because the only reasonable way things can add themselves is via an extension method, this `Trainers` object would have to be an actual instance... now then, it needn't actually be instantiable -- one can call extension methods on the `null` of an object as well as anything so long as we don't want to get any information out of it -- but that is a little awkward. If we could just put extension methods on, say, a static class or something that would be nice, but we can't.\r\n\r\n# Work Item\r\n\r\nThe first thing I will do is create a binary classification training context object, as an exploration of the idea. If we like the idea, we can extend it to the other tasks as well.","Url":"https://github.com/dotnet/machinelearning/issues/949","RelatedDescription":"Open issue \"API: Binary Classification Training Context\" (#949)"},{"Id":"361876572","IsPullRequest":false,"CreatedAt":"2018-09-19T18:40:39","Actor":"wschin","Number":"948","RawContent":null,"Title":"Public space for accumulating knowledge about ML.NET","State":"open","Body":"Do we have any places like a Wiki? I'd like to have a place to share some small knowledge related to ML.NET. Here is an example.\r\nToday, I changed the signature of SaveOnnx and then got two tests failed, TestGeneratedCSharpAPI and EntryPointCatalog. The solution is very straightforward, when you know the answer.\r\n\r\nSolution:\r\n\r\n1. Open Microsoft.ML.sln under Visual Studio\r\n2. Go to Test Explorer\r\n3. Find the test code of `RegenerateEntryPointCatalog()` in TestEntryPoints.cs and change its `[Fact(Skip = \".....\")]` to `[Fact()]`' and then run it. Then, you will see (via `git diff`) core_mainfest.json gets changed. Include those changes into your commit. Note that with the existence of `Skip =`, Test Explorer may not execute your test anyway.\r\n4. Find the test code of `RegenerateCSharpApi()` in CSharpCodeGen.cs and change its `[Fact(skip = \".....\")]` to `[Fact()]` and also commit the changes (CSharpApi.cs) induced by running this test.\r\n\r\nI personally like GitHub issues with a better tag name such as \"knowledge\" so that we have one place for all.","Url":"https://github.com/dotnet/machinelearning/issues/948","RelatedDescription":"Open issue \"Public space for accumulating knowledge about ML.NET\" (#948)"},{"Id":"361861172","IsPullRequest":true,"CreatedAt":"2018-09-19T17:59:13","Actor":"wschin","Number":"947","RawContent":null,"Title":"Save ConvertTransform as ONNX Operator and Control the Use of Experimental Features with a Flag","State":"open","Body":"1. Introduce a new argument to SaveOnnx, which is OnnxVersion.\r\n   Two values are currently allowed, \"Latest\" and \"Experimental\".\r\n   Note that \"Latest\" means that the produced ONNX model meets\r\n   the latest ONNX release while \"Experimental\" may produce\r\n   things not officially supported in ONNX.\r\n2. For (1), the interface of saving ONNX is slightly changed. Now,\r\n   CanSaveOnnx requires an OnnxContext as its input argument,\r\n   because if a model can be saved to ONNX depends on the targeted\r\n   ONNX version now.\r\n3. Add exporter for ConvertTransform. It doesn't use standard\r\n   ONNX operator.","Url":"https://github.com/dotnet/machinelearning/pull/947","RelatedDescription":"Open PR \"Save ConvertTransform as ONNX Operator and Control the Use of Experimental Features with a Flag\" (#947)"},{"Id":"361856168","IsPullRequest":false,"CreatedAt":"2018-09-19T17:51:51","Actor":"wschin","Number":"946","RawContent":null,"Title":"Is NATransform still onnxable?","State":"closed","Body":"Just notice that the code of exporting NAReplaceTransform to ONNX is missing comparing with the version pointed by internal TLC. The root reason is that OneToOneTransformerBase doesn't have ITransformCanSaveOnnx anymore.","Url":"https://github.com/dotnet/machinelearning/issues/946","RelatedDescription":"Closed issue \"Is NATransform still onnxable?\" (#946)"},{"Id":"361849014","IsPullRequest":false,"CreatedAt":"2018-09-19T17:24:51","Actor":"wschin","Number":"945","RawContent":null,"Title":"Experimental Conversion of ConvertTransform to ONNX format","State":"open","Body":"We're experimenting for exporting more transforms to ONNX. ConvertTransform is the first one we're working on. #947 ","Url":"https://github.com/dotnet/machinelearning/issues/945","RelatedDescription":"Open issue \"Experimental Conversion of ConvertTransform to ONNX format\" (#945)"},{"Id":"361842957","IsPullRequest":true,"CreatedAt":"2018-09-19T17:07:02","Actor":"Ivanidzo4ka","Number":"944","RawContent":null,"Title":"Hash estimator","State":"open","Body":"@Zruty0  you can pick up this one","Url":"https://github.com/dotnet/machinelearning/pull/944","RelatedDescription":"Open PR \"Hash estimator\" (#944)"},{"Id":"361525181","IsPullRequest":true,"CreatedAt":"2018-09-19T14:32:20","Actor":"shmoradims","Number":"941","RawContent":null,"Title":"[WIP] Added Onnx Transform","State":"closed","Body":"WIP PR for implementing issue #695.","Url":"https://github.com/dotnet/machinelearning/pull/941","RelatedDescription":"Closed or merged PR \"[WIP] Added Onnx Transform\" (#941)"},{"Id":"361541130","IsPullRequest":true,"CreatedAt":"2018-09-19T01:20:37","Actor":"jwood803","Number":"943","RawContent":null,"Title":"WIP: Update private and constant variable names","State":"open","Body":"Fix for issue #829 \r\n\r\n@briancylui @safern These are the changes I've found so far. Marked as WIP since I'd like to go through once more to make sure I didn't miss anything.","Url":"https://github.com/dotnet/machinelearning/pull/943","RelatedDescription":"Open PR \"WIP: Update private and constant variable names\" (#943)"},{"Id":"361527281","IsPullRequest":true,"CreatedAt":"2018-09-19T00:00:47","Actor":"jignparm","Number":"942","RawContent":null,"Title":"[WIP] Add OnnxTransform for scoring Onnx 1.2 models - integrates Microsoft.ML.Scoring/Sonoma Library","State":"open","Body":"Fixes issue #695 \r\nFixes issue #892\r\n\r\nThis adds a new transform  for scoring Onnx v1.2 models, leveraging an updated version of the scoring library at the link below.\r\n\r\nhttps://www.nuget.org/packages/Microsoft.ML.Scoring/\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/942","RelatedDescription":"Open PR \"[WIP] Add OnnxTransform for scoring Onnx 1.2 models - integrates Microsoft.ML.Scoring/Sonoma Library\" (#942)"},{"Id":"361517769","IsPullRequest":true,"CreatedAt":"2018-09-18T23:11:27","Actor":"Zruty0","Number":"940","RawContent":null,"Title":"Added the GetColumn functionality to dynamic API","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/940","RelatedDescription":"Open PR \"Added the GetColumn functionality to dynamic API\" (#940)"},{"Id":"361516003","IsPullRequest":true,"CreatedAt":"2018-09-18T23:03:46","Actor":"Anipik","Number":"939","RawContent":null,"Title":"Enabled Multiclass Logistic Regression Tests","State":"open","Body":"\r\n","Url":"https://github.com/dotnet/machinelearning/pull/939","RelatedDescription":"Open PR \"Enabled Multiclass Logistic Regression Tests\" (#939)"},{"Id":"361515350","IsPullRequest":false,"CreatedAt":"2018-09-18T23:00:55","Actor":"artidoro","Number":"938","RawContent":null,"Title":"Find a new regression dataset","State":"open","Body":"Some regression tests rely on a machine generated regression dataset (Gaussian noise on top of a linear function of a vector input). The file was introduced by #937.\r\n\r\nWe should replace this dataset with a real dataset. Justin @justinormont suggested to find something from [data.gov](https://catalog.data.gov/dataset), for example predicting the SF employee pay: https://catalog.data.gov/dataset/employee-compensation-53987\r\n","Url":"https://github.com/dotnet/machinelearning/issues/938","RelatedDescription":"Open issue \"Find a new regression dataset\" (#938)"},{"Id":"361505359","IsPullRequest":true,"CreatedAt":"2018-09-18T22:44:29","Actor":"artidoro","Number":"937","RawContent":null,"Title":"Substituted Wine Quality dataset with machine generated dataset","State":"closed","Body":"Fixes #936.\r\nFixes #889.\r\n\r\nI substituted the UCI Wine Quality dataset with a machine generated regression dataset (linear function of a vector input with added Gaussian noise). I had to update the test outputs for all affected tests.\r\n\r\nNote that this is a temporary change, and that we are looking into finding a real dataset to substitute this machine generated one.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/937","RelatedDescription":"Closed or merged PR \"Substituted Wine Quality dataset with machine generated dataset\" (#937)"},{"Id":"361500432","IsPullRequest":false,"CreatedAt":"2018-09-18T22:44:29","Actor":"artidoro","Number":"936","RawContent":null,"Title":"Substituting UCI Wine Quality dataset with machine generated dataset","State":"closed","Body":"There are two problems with the UCI Wine Quality dataset:\r\n\r\n- it is not reachable (which breaks the build)\r\n- it is intended to be used for research purposes only\r\n\r\nIt should be substituted with another regression dataset.","Url":"https://github.com/dotnet/machinelearning/issues/936","RelatedDescription":"Closed issue \"Substituting UCI Wine Quality dataset with machine generated dataset\" (#936)"},{"Id":"361389167","IsPullRequest":false,"CreatedAt":"2018-09-18T16:37:04","Actor":"Zruty0","Number":"935","RawContent":null,"Title":"Fix separators for word tokenizer","State":"open","Body":"Currently, the separators property for `WordTokenizer` is a string, that is parsed as a comma-separated list of characters. It was appropriate for command-line parsing, but not appropriate for API use.\r\n\r\nA better solution is to have a `char[]`.","Url":"https://github.com/dotnet/machinelearning/issues/935","RelatedDescription":"Open issue \"Fix separators for word tokenizer\" (#935)"},{"Id":"361267055","IsPullRequest":false,"CreatedAt":"2018-09-18T11:52:47","Actor":"lefig","Number":"934","RawContent":null,"Title":"Release 0.5 feedback","State":"open","Body":"Firstly, a very big thank you and congratulations to all involved with the latest release. I am, particularly looking forward to exploring the new API and specifically accessing model feature selection/scores.\r\n\r\nIn the meantime, we have incomplete MI generated and am not sure if this is related to the changes. ..\r\nDisplayng metrics for Momentum Model Regression\r\nNot adding a normalizer.\r\nMaking per-feature arrays\r\nChanging data from row-wise to column-wise\r\nProcessed 423 instances\r\nBinning and forming Feature objects\r\nReserved memory for tree learner: 363168 bytes\r\nStarting to train ...\r\nNot training a calibrator because it is not needed.\r\n*************************************************\r\n*       Metrics for Fast Tree\r\n*------------------------------------------------\r\n*       R2 Score: -1.05\r\n*       Absolute loss:\r\n*       Squared loss:\r\n*       RMS loss:\r\n*************************************************\r\nNot adding a normalizer.\r\nMaking per-feature arrays\r\nChanging data from row-wise to column-wise\r\nProcessed 423 instances\r\nBinning and forming Feature objects\r\nReserved memory for tree learner: 363168 bytes\r\nStarting to train ...\r\nNot training a calibrator because it is not needed.\r\n*************************************************\r\n*       Metrics for Fast Forest\r\n*------------------------------------------------\r\n*       R2 Score: 0.05\r\n*       Absolute loss:\r\n*       Squared loss:\r\n*       RMS loss:\r\n*************************************************\r\n\r\nI have a theory though - that this is related to some data points being not sufficiently linear. Could this be correct?","Url":"https://github.com/dotnet/machinelearning/issues/934","RelatedDescription":"Open issue \"Release 0.5 feedback\" (#934)"},{"Id":"361072980","IsPullRequest":false,"CreatedAt":"2018-09-17T22:49:22","Actor":"TomFinley","Number":"933","RawContent":null,"Title":"De-transformation of samplers, filters","State":"open","Body":"As we transition the code from being exclusively for a tool to being more appropriate for an API, one of the most crucial parts of the work is that summarized in #581 where we take the concept `IDataTransform` and split it into three concepts `IEstimator`/`ITransformer`/`IDataView` -- currently, an [`IDataTranform` fills all three roles](https://github.com/dotnet/machinelearning/blob/4e0800c652e981d12a04099262aadea1181aa76a/src/Microsoft.ML.Data/Data/IDataLoader.cs#L91) (it is both the transforming model and an `IDataView`), which leads to a great deal of confusion when using this as an API.\r\n\r\nThe working assumption is that most things that are `IDataTranform` will transition to being this triad of estimator, transformer, and data-view. There are however some probably desirable exceptions that we do not want to *fully* convert:\r\n\r\n* All row filter transforms (skip, take, NA filter),\r\n* The shuffle transform,\r\n* The bootstrap sampler transform.\r\n\r\nCurrently they are `IDataTransform`, because everything that transforms data in this fashion is an `IDataTransform`. However this means that there is a data model associated with it, and it is serialized just alongside every other transform.\r\n\r\nPeople have historically found this confusing. For example, people want to train and test based on the same dataset, so they apply bootstrap sampling transform in their transform list -- but then the same is done to their test set so the results are all screwed up. Or, they want to train on only some of it, so they apply the `Take` filter -- but then their test set evaluation happens only over the first however many. There are lots of examples like this that I've seen over the years. My belief is that generally this sort of row-wise filtering/sampling being part of the data pipeline really does more harm than good.\r\n\r\nNow that we have the estimator/transformer/data triad of #581, we can make these operations exclusively as `IDataView`s, *not* actual fully blown `ITransformer` implementors (where someone might make the mistake of serializing them to a data pipeline).\r\n\r\nIt does ***technically*** represent a loss of capability, but I am not aware that I have ever seen a valid usecase where any of these entities was used as a data-model component deliberately, and it is very difficult for me to imagine a case where people would want to do so. Every usecase I have ever seen has been accidental and ultimately deeply harmful to the integrity of the user's experiments.\r\n\r\nWe will also need to decide what to do when we deserialize these models, when we deserialize what had been an `IDataTransform` into the new `ITransformer`. My own preference would be that they be replaced with a no-op transformer, since again I've never seen anything valid done with them.\r\n\r\nThis will also incidentally mean less work as we perform the conversion work.","Url":"https://github.com/dotnet/machinelearning/issues/933","RelatedDescription":"Open issue \"De-transformation of samplers, filters\" (#933)"},{"Id":"361069105","IsPullRequest":false,"CreatedAt":"2018-09-17T22:31:34","Actor":"artidoro","Number":"932","RawContent":null,"Title":"ComponentCatalogue: private constructors for estimators","State":"open","Body":"Only one constructor per estimator should be **public** and presented to the end user. The constructor should require the arguments that are needed to initialize the estimator.\r\n\r\nWe also need to have another constructor with arguments (IHostEnvironment env, Arguments args) for MAML to work. This constructor should be **private**, so that it does not appear as an option to the end user.\r\n\r\nCurrently the ComponentCatalogue does not recognize any private constructors. ","Url":"https://github.com/dotnet/machinelearning/issues/932","RelatedDescription":"Open issue \"ComponentCatalogue: private constructors for estimators\" (#932)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-09-20T05:30:35.8682521Z","RunDurationInMilliseconds":921}