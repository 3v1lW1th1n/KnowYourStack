{"Data":{"GitHub":{"Issues":[{"Id":"357036296","IsPullRequest":false,"CreatedAt":"2018-09-05T01:55:12","Actor":"briancylui","Number":"836","RawContent":null,"Title":"Double-compute input elements in hardware intrinsics","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\nAfter implementing \"double-compute\", it is expected to make hardware intrinsics more efficient.\r\n\r\n## Details (mostly from @tannergooding)\r\n- In `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs` and `src\\Microsoft.ML.CpuMath\\AvxIntrinsics.cs`, change the last loop of the existing 3-loop code pattern into the following:\r\n    1. Saving the stored result (`dstVector`) from the last iteration of the vectorized code\r\n    2. Moving `pDstCurrent` back such that `pDstCurrent + elementsPerIteration == pEnd`\r\n    3. Doing a single iteration for the remaining elements\r\n    4. Mix the saved result from the last iteration of the vectorized code with the result from the remaining elements\r\n    5. Write the result\r\n\r\nThis generally results in more performant code, depending on the exact algorithm and number of remaining elements\r\n\r\n-  On handling unpadded parts in AVX intrinsics:\r\n\r\nFor some algorithms (like `Sum`), it is possible to “double-compute” a few elements in the beginning and end to have better overall performance. See the following pseudo-code:\r\n```\r\nif addr not aligned\r\n              tmp = unaligned load from addr\r\n              tmp &= mask which zero's elements after the first aligned address\r\n              result = tmp\r\n              move addr forward to the first aligned address \r\n\r\nwhile addr is aligned and remaining bits >= 128\r\n              result += aligned load\r\n              addr += 128-bits\r\n\r\nif any remaining\r\n              addr = endAddr - 128\r\n              tmp = unaligned load from addr\r\n              tmp &= mask which zero's elements already processed\r\n              result += tmp\r\n\r\nSum the elements in result (using \"horizontal add\" or \"shuffle and add\")\r\n```\r\n\r\nSo, your overall algorithm will probably look like:\r\n```\r\nif (Avx.IsSupported && (Length >= AvxLimit))\r\n{\r\n    // Process 256-bits, we have a limit since 256-bit \r\n    // AVX instructions can cause a downclock in the CPU\r\n    // Algorithm would be similar to the SSE pseudo-code\r\n}\r\nelse if (Sse.IsSupported && (Length >= SseLimit))\r\n{\r\n    // Pseudo-code algorithm given above\r\n\r\n    // 128-bit instructions operate at full frequency\r\n    // and don't downclock the CPU, we can only use\r\n    // them for more than 128-bits so we don't AV\r\n}\r\nelse\r\n{\r\n    // Software Implementation\r\n}\r\n```\r\n\r\nIf you can’t “double-compute” for some reason, then you generally do the “software” processing for the beginning (to become aligned) and end (to catch stray elements).\r\n•\t`AvxLimit` is generally a number that takes into account the “downclocking” that can occur for heavy 256-bit instruction usage\r\n•\t`SseLimit` is generally 128-bits for algorithms where you can “double-compute” and some profiled number for other algorithms\r\n\r\n\r\ncc: @tannergooding since he suggested this approach.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/836","RelatedDescription":"Open issue \"Double-compute input elements in hardware intrinsics\" (#836)"},{"Id":"357035453","IsPullRequest":false,"CreatedAt":"2018-09-05T01:49:59","Actor":"briancylui","Number":"835","RawContent":null,"Title":"Make bound checking of loops in hardware intrinsics more efficient","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs` and `src\\Microsoft.ML.CpuMath\\AvxIntrinsics.cs`, changing `while (pDstCurrent + 4 <= pDstEnd)` for the loop bound checking into `while (pDstCurrent <= pDstEnd - 4)` to save an instruction (ref: https://github.com/dotnet/machinelearning/pull/668#issuecomment-412121893)\r\n- It may probably be a CoreCLR issue","Url":"https://github.com/dotnet/machinelearning/issues/835","RelatedDescription":"Open issue \"Make bound checking of loops in hardware intrinsics more efficient\" (#835)"},{"Id":"357035024","IsPullRequest":false,"CreatedAt":"2018-09-05T01:47:27","Actor":"briancylui","Number":"834","RawContent":null,"Title":"Add unit tests for software fallbacks of hardware intrinsics","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  Add unit tests for software fallback implementations, particularly for `MatTimesSrc`.\r\n\r\nReference:\r\n- The software fallback implementations are in `src\\Microsoft.ML.CpuMath\\CpuMathUtils.netcoreapp.cs`, encapsulated in the following switching paradigm:\r\n``` log\r\nif (Avx.IsSupported)\r\n{\r\n    // AvxIntrinsics\r\n}\r\nelse if (Sse.IsSupported)\r\n{\r\n    // SseIntrinsics\r\n}\r\nelse\r\n{\r\n    // Software fallback\r\n}\r\n```\r\n\r\n- Unit tests are implemented in `test\\Microsoft.ML.CpuMath.UnitTests.netcoreapp/UnitTests.cs`\r\n- To turn on the software fallback implementation in unit tests, you may have to turn off the environment variable `COMPlus_FeatureSimd`.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/834","RelatedDescription":"Open issue \"Add unit tests for software fallbacks of hardware intrinsics\" (#834)"},{"Id":"357034000","IsPullRequest":false,"CreatedAt":"2018-09-05T01:41:19","Actor":"briancylui","Number":"833","RawContent":null,"Title":"Optimize codegen of inlining in hardware intrinsics APIs","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  (from Intel partners) In the original code of `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs`, even though `VectorSum` is inlined, the codegen is not optimized due to register spill and reload. It seems JIT has optimization opportunity over there. Do you mind opening an issue to discuss about it on CoreCLR github repo?\r\n\r\ncc: @tannergooding since you might already have addressed this issue.","Url":"https://github.com/dotnet/machinelearning/issues/833","RelatedDescription":"Open issue \"Optimize codegen of inlining in hardware intrinsics APIs\" (#833)"},{"Id":"357031811","IsPullRequest":false,"CreatedAt":"2018-09-05T01:27:45","Actor":"briancylui","Number":"832","RawContent":null,"Title":"Use FusedMultiplyAdd in hardware intrinsics APIs","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs`, Use `FusedMultiplyAdd` to replace `srcVector = Sse.Multiply(srcVector, scaleVector);` in `AddScaleU`.  It would be part of any AVX related code-work.","Url":"https://github.com/dotnet/machinelearning/issues/832","RelatedDescription":"Open issue \"Use FusedMultiplyAdd in hardware intrinsics APIs\" (#832)"},{"Id":"357031545","IsPullRequest":false,"CreatedAt":"2018-09-05T01:26:05","Actor":"briancylui","Number":"831","RawContent":null,"Title":"Accelerate loops in hardware intrinsics implementation","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  Make while loops more efficient in `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs` and `src\\Microsoft.ML.CpuMath\\AvxIntrinsics.cs` with modified bound checking:\r\n``` log\r\nvar remainder = count % elementsPerIteration;\r\nfloat* pEnd = pdst + (count - remainder);\r\nwhile (pDstCurrent < pEnd)\r\n{ … }\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/831","RelatedDescription":"Open issue \"Accelerate loops in hardware intrinsics implementation\" (#831)"},{"Id":"357031155","IsPullRequest":false,"CreatedAt":"2018-09-05T01:23:35","Actor":"briancylui","Number":"830","RawContent":null,"Title":"Preamble for hardware intrinsics implementation","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  Do \"preamble\" for the implementation of SSE/AVX intrinsics in `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs` and `src\\Microsoft.ML.CpuMath\\AvxIntrinsics.cs`:\r\n\r\n[Preamble](https://github.com/dotnet/coreclr/blob/b896dd14830b600043a99c2626ea848ad679fb4f/src/System.Private.CoreLib/shared/System/SpanHelpers.Char.cs#L96-L102): \r\n1. while (!aligned) { do scalar operation; } // preamble\r\n2. Do vectorized operation using Read**Aligned**\r\n3. while (!end) { do scalar operation; }\r\nFor large arrays, especially those that cross cache line or page boundaries, doing this should save some measurable amount of time. \r\n\r\nReference: https://github.com/dotnet/machinelearning/pull/562/files/f0f81a5019a3c8cbd795a970e40d633e9e1770c1#r204061074","Url":"https://github.com/dotnet/machinelearning/issues/830","RelatedDescription":"Open issue \"Preamble for hardware intrinsics implementation\" (#830)"},{"Id":"357030705","IsPullRequest":false,"CreatedAt":"2018-09-05T01:20:53","Actor":"briancylui","Number":"829","RawContent":null,"Title":"Fix naming of non-constant privates in perf tests for hardware intrinsics","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `test\\Microsoft.ML.CpuMath.PerformanceTests\\PerformanceTests.cs`, regarding the line `private float[] src, dst, original, src1, src2;`, all these **non-constant privates** should be prefixed with `_` but it can be updated in the future PR.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/829","RelatedDescription":"Open issue \"Fix naming of non-constant privates in perf tests for hardware intrinsics\" (#829)"},{"Id":"357030008","IsPullRequest":false,"CreatedAt":"2018-09-05T01:16:42","Actor":"briancylui","Number":"828","RawContent":null,"Title":"Add Debug.Assert to check matching lengths of arguments to SSE/AVX intrinsics","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `src\\Microsoft.ML.CpuMath\\SseIntrinsics.cs`, it may make sense to add some `Debug.Asserts` to check the `src` and `dst` Lengths match. However, these are internal functions that are only called from functions that guarantee the arguments are checked, so it might not be a blocking issue. It just may be some nice documentation on the expectations of these methods. And in case they get new callsites in the future.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/828","RelatedDescription":"Open issue \"Add Debug.Assert to check matching lengths of arguments to SSE/AVX intrinsics\" (#828)"},{"Id":"357029201","IsPullRequest":false,"CreatedAt":"2018-09-05T01:12:00","Actor":"briancylui","Number":"827","RawContent":null,"Title":"Remove any unnecessary Contracts.Assert covered by Span<T> in hardware intrinsics APIs","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n-  In `src\\Microsoft.ML.CpuMath\\CpuMathUtils.netcoreapp.cs`, `Span<T>` might already do the checks (`Contracts.Assert`) in the public functions.  Reference:\r\nhttps://github.com/dotnet/machinelearning/blob/e443e2afcd39a8a363321d423e087c0569c0d4af/src/Microsoft.ML.CpuMath/CpuMathUtils.netcoreapp.cs#L237-L245","Url":"https://github.com/dotnet/machinelearning/issues/827","RelatedDescription":"Open issue \"Remove any unnecessary Contracts.Assert covered by Span<T> in hardware intrinsics APIs\" (#827)"},{"Id":"357029132","IsPullRequest":false,"CreatedAt":"2018-09-05T01:11:31","Actor":"codemzs","Number":"826","RawContent":null,"Title":"remove trailing dot from the OnnxNodeImpl.cs","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/issues/826","RelatedDescription":"Open issue \"remove trailing dot from the OnnxNodeImpl.cs\" (#826)"},{"Id":"357028945","IsPullRequest":true,"CreatedAt":"2018-09-05T01:10:18","Actor":"shauheen","Number":"825","RawContent":null,"Title":"Cherrypick to update release for 0.5","State":"open","Body":"Cherrypick into release for 0.5","Url":"https://github.com/dotnet/machinelearning/pull/825","RelatedDescription":"Open PR \"Cherrypick to update release for 0.5\" (#825)"},{"Id":"357009721","IsPullRequest":true,"CreatedAt":"2018-09-05T01:05:40","Actor":"shauheen","Number":"816","RawContent":null,"Title":"Cherrypick to update release for 0.5 - NO MERGE","State":"closed","Body":"Cherrypick into release for 0.5","Url":"https://github.com/dotnet/machinelearning/pull/816","RelatedDescription":"Closed or merged PR \"Cherrypick to update release for 0.5 - NO MERGE\" (#816)"},{"Id":"356907205","IsPullRequest":true,"CreatedAt":"2018-09-05T01:04:37","Actor":"GalOshri","Number":"808","RawContent":null,"Title":"Add release notes for ML.NET 0.5","State":"closed","Body":"This adds release notes for ML.NET 0.5.","Url":"https://github.com/dotnet/machinelearning/pull/808","RelatedDescription":"Closed or merged PR \"Add release notes for ML.NET 0.5\" (#808)"},{"Id":"357027619","IsPullRequest":false,"CreatedAt":"2018-09-05T01:01:06","Actor":"briancylui","Number":"824","RawContent":null,"Title":"Rename input arguments of CpuMath SSE/AVX intrinsics","State":"open","Body":"Style changes needed to solve part of https://github.com/dotnet/machinelearning/issues/823\r\n\r\n## Details\r\n- Rename input arguments of methods in `src\\Microsoft.ML.CpuMath\\CpuMathUtils.netcoreapp.cs` and `src\\Microsoft.ML.CpuMath\\Sse.cs`, to make them more informative, e.g.:\r\n* for `MatTimesSrc`, change `tran` into `transpose`\r\n\r\n* for `a` and `b`, change them into `src` and `dst`\r\n","Url":"https://github.com/dotnet/machinelearning/issues/824","RelatedDescription":"Open issue \"Rename input arguments of CpuMath SSE/AVX intrinsics\" (#824)"},{"Id":"357026910","IsPullRequest":false,"CreatedAt":"2018-09-05T00:56:59","Actor":"briancylui","Number":"823","RawContent":null,"Title":"Suggestions on CpuMath Enhancement","State":"open","Body":"Listed below are CpuMath enhancement suggestions raised during PR reviews for SSE and AVX intrinsics but only documented for future follow-up.\r\n\r\nThe individual issue pages that expand each issue are https://github.com/dotnet/machinelearning/issues/824 and #827 - #836.\r\n\r\n## Style\r\n- [ ] Big-scale renaming of input arguments of Microsoft.ML.CpuMath\\Sse.cs and CpuMathUtils.netcoreapp.cs, e.g. for `MatTimesSrc`, change `tran` into `transpose`.\r\n- [x] Change `0 < count` into `count > 0` and `offset < dst.Length - count` into `offset < (dst.Length - count)`\r\n- [x] Split `&&` asserts into two separate asserts\r\n- [ ] In `CpuMathUtils.netcoreapp.cs`, `Span<T>` might already do the checks (`Contracts.Assert`) in the public functions.\r\n- [ ] (minor) In `SseIntrinsics.cs`, it may make sense to add some `Debug.Asserts` to check the `src` and `dst` Lengths match. However, these are internal functions that are only called from functions that guarantee the arguments are checked, so I don't believe it is a blocking issue. It just may be some nice documentation on the expectations of these methods. And in case they get new callsites in the future.\r\n- [ ] In `SsePerformanceTests.cs`, regarding the line `private float[] src, dst, original, src1, src2;`, all these non-constant privates should be prefixed with `_` but it can be updated in the next PR to not block the current one.\r\n\r\n## Functionality\r\n- [ ] [Preamble](https://github.com/dotnet/coreclr/blob/b896dd14830b600043a99c2626ea848ad679fb4f/src/System.Private.CoreLib/shared/System/SpanHelpers.Char.cs#L96-L102): \r\n1. while (!aligned) { do scalar operation; } // preamble\r\n2. Do vectorized operation using Read**Aligned**\r\n3. while (!end) { do scalar operation; }\r\nFor large arrays, especially those that cross cache line or page boundaries, doing this should save some measurable amount of time. \r\nReference: https://github.com/dotnet/machinelearning/pull/562/files/f0f81a5019a3c8cbd795a970e40d633e9e1770c1#r204061074\r\n- [ ] In 'SseIntrinsics.cs', do the following two things to make while loops more efficient:\r\n* Bound checking:\r\n`var remainder = count % elementsPerIteration;` and then `float* pEnd = pdst + (count - remainder);`. Your loop check then just does `while (pDstCurrent < pEnd)`\r\n\r\n* Double-computing:\r\nFinish off the remaining indices one of two ways.\r\n1. drop down to a scalar algorithm or, \r\n2. \"double compute\" a couple of the indices, that involves:\r\n\r\n- Saving the stored result (`dstVector`) from the last iteration of the vectorized code\r\n- Moving `pDstCurrent` back such that `pDstCurrent + elementsPerIteration == pEnd`\r\n- Doing a single iteration for the remaining elements\r\n- Mix the saved result from the last iteration of the vectorized code with the result from the remaining elements\r\n- Write the result\r\nThis generally results in more performant code, depending on the exact algorithm and number of remaining elements\r\n\r\n- [ ] In `SseIntrinsics.cs`, Use `FusedMultiplyAdd` to replace `srcVector = Sse.Multiply(srcVector, scaleVector);` in `AddScaleU`.  It would be part of any AVX related code-work.\r\n\r\n- [ ] In the original code of `SseIntrinsics.cs`, even though `VectorSum` is inlined, the codegen is not optimized due to register spill and reload. It seems JIT has optimization opportunity over there. Do you mind opening an issue to discuss about it on CoreCLR github repo? (from Intel partners)\r\n\r\n- [x] (probably) Try the default static void Main(string[] args) => BenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args); in Program.cs of perf tests.  It will work, but we will need to decide how to parse arguments from the command line.\r\n\r\n- [ ] Add unit tests for software fallback implementations, particularly for `MatTimesSrc`.\r\n\r\n- [ ] Change `while (pDstCurrent + 4 <= pDstEnd)` for the loop bound checking into `while (pDstCurrent <= pDstEnd - 4)` to save an instruction (ref: https://github.com/dotnet/machinelearning/pull/668#issuecomment-412121893).\r\n\r\n- [ ] (@tannergooding) On handling unpadded parts in AVX intrinsics:\r\nIt can be that simple, but that is often not the best way to handle it.\r\n\r\nFor some algorithms (like `Sum`), it is possible to “double-compute” a few elements in the beginning and end to have better overall performance. See the following pseudo-code:\r\n```\r\nif addr not aligned\r\n              tmp = unaligned load from addr\r\n              tmp &= mask which zero's elements after the first aligned address\r\n              result = tmp\r\n              move addr forward to the first aligned address \r\n\r\nwhile addr is aligned and remaining bits >= 128\r\n              result += aligned load\r\n              addr += 128-bits\r\n\r\nif any remaining\r\n              addr = endAddr - 128\r\n              tmp = unaligned load from addr\r\n              tmp &= mask which zero's elements already processed\r\n              result += tmp\r\n\r\nSum the elements in result (using \"horizontal add\" or \"shuffle and add\")\r\n```\r\n\r\nSo, your overall algorithm will probably look like:\r\n```\r\nif (Avx.IsSupported && (Length >= AvxLimit))\r\n{\r\n    // Process 256-bits, we have a limit since 256-bit \r\n    // AVX instructions can cause a downclock in the CPU\r\n    // Algorithm would be similar to the SSE pseudo-code\r\n}\r\nelse if (Sse.IsSupported && (Length >= SseLimit))\r\n{\r\n    // Pseudo-code algorithm given above\r\n\r\n    // 128-bit instructions operate at full frequency\r\n    // and don't downclock the CPU, we can only use\r\n    // them for more than 128-bits so we don't AV\r\n}\r\nelse\r\n{\r\n    // Software Implementation\r\n}\r\n```\r\n\r\nIf you can’t “double-compute” for some reason, then you generally do the “software” processing for the beginning (to become aligned) and end (to catch stray elements).\r\n•\t`AvxLimit` is generally a number that takes into account the “downclocking” that can occur for heavy 256-bit instruction usage\r\n•\t`SseLimit` is generally 128-bits for algorithms where you can “double-compute” and some profiled number for other algorithms","Url":"https://github.com/dotnet/machinelearning/issues/823","RelatedDescription":"Open issue \"Suggestions on CpuMath Enhancement\" (#823)"},{"Id":"357024980","IsPullRequest":true,"CreatedAt":"2018-09-05T00:44:00","Actor":"briancylui","Number":"822","RawContent":null,"Title":"Fix bounding checking error of SSE SumU intrinsic","State":"open","Body":"Added an \"=\" sign to a bound check inside the SSE SumU intrinsic to fix a previous typo and make it consistent with all other intrinsics' implementations - look forward to green light!\r\n\r\ncc: @eerhardt @tannergooding @safern ","Url":"https://github.com/dotnet/machinelearning/pull/822","RelatedDescription":"Open PR \"Fix bounding checking error of SSE SumU intrinsic\" (#822)"},{"Id":"357024331","IsPullRequest":true,"CreatedAt":"2018-09-05T00:39:40","Actor":"briancylui","Number":"821","RawContent":null,"Title":"Change bound checking in SSE/AVX intrinsics to avoid integer overflow","State":"open","Body":"Suggested by @ahsonkhan to avoid integer overflow in bound checking inside SSE/AVX intrinsics implementation, i.e. change all `while (pCurrent + 8 OR 4 <= pEnd)` into `while (pEnd - pCurrent >= 8 OR 4)`.\r\n\r\nPerf tests results before and after the change are shown below:\r\n## Before the change:\r\n``` ini\r\nBenchmarkDotNet=v0.11.1, OS=Windows 10.0.17134.228 (1803/April2018Update/Redstone4)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=3.0.100-alpha1-20180720-2\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                   Type | Method |     Mean |    Error |    StdDev |\r\n|----------------------- |------- |---------:|---------:|----------:|\r\n|    AvxPerformanceTests |   SumU | 159.4 us | 1.104 us | 0.9784 us |\r\n| NativePerformanceTests |   SumU | 283.5 us | 5.492 us | 4.8687 us |\r\n|    SsePerformanceTests |   SumU | 281.2 us | 1.472 us | 1.3045 us |\r\n|    AvxPerformanceTests |   AddU | 276.1 us | 3.018 us | 2.520 us |\r\n| NativePerformanceTests |   AddU | 330.1 us | 3.585 us | 3.178 us |\r\n|    SsePerformanceTests |   AddU | 325.6 us | 6.883 us | 7.926 us |\r\n\r\n## After the change:\r\n``` ini\r\nBenchmarkDotNet=v0.11.1, OS=Windows 10.0.17134.228 (1803/April2018Update/Redstone4)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\n.NET Core SDK=3.0.100-alpha1-20180720-2\r\n  [Host] : .NET Core 3.0.0-preview1-26710-03 (CoreCLR 4.6.26710.05, CoreFX 4.6.26708.04), 64bit RyuJIT\r\n\r\nToolchain=InProcessToolchain\r\n```\r\n|                   Type | Method |     Mean |    Error |   StdDev |\r\n|----------------------- |------- |---------:|---------:|---------:|\r\n|    AvxPerformanceTests |   SumU | 183.5 us | 3.621 us | 3.023 us |\r\n| NativePerformanceTests |   SumU | 281.6 us | 5.261 us | 4.921 us |\r\n|    SsePerformanceTests |   SumU | 294.1 us | 2.080 us | 1.946 us |\r\n|    AvxPerformanceTests |   AddU | 296.3 us | 5.185 us | 4.850 us |\r\n| NativePerformanceTests |   AddU | 335.1 us | 3.053 us | 2.707 us |\r\n|    SsePerformanceTests |   AddU | 345.0 us | 2.155 us | 1.800 us |\r\n\r\nBoth SSE and AVX implementations are slower by 10-20% after this change.\r\n\r\nIn my opinion, after seeing the perf results, I may not recommend merging this PR.  I may wait until the alternative suggested by @tannergooding in an earlier PR review has been implemented (2nd item under \"Functionality\" in https://github.com/briancylui/machinelearning/issues/2):\r\n``` log\r\nvar remainder = count % elementsPerIteration;\r\nfloat* pEnd = pdst + (count - remainder);\r\nwhile (pDstCurrent < pEnd)\r\n{ … }\r\n```\r\n\r\nAnother question I have is: would `pDstCurrent + 8 OR 4` ever have the possibility to result in integer overflow?  According to my knowledge, `pEnd` is initialized as `pDstCurrent + count`, and there are `Contract.Asserts` in the wrapper class to check that `count` does not exceed the original array length.  I'm not sure, and am open to any PR comments and advice.\r\n\r\ncc: @danmosemsft @eerhardt @tannergooding @ahsonkhan \r\n","Url":"https://github.com/dotnet/machinelearning/pull/821","RelatedDescription":"Open PR \"Change bound checking in SSE/AVX intrinsics to avoid integer overflow\" (#821)"},{"Id":"357023041","IsPullRequest":true,"CreatedAt":"2018-09-05T00:31:12","Actor":"Anipik","Number":"820","RawContent":null,"Title":"Added Benchmark performance tests for wikidetoxData","State":"open","Body":"This PR adds BenchMark tests for AveragePreceptron and LightGBM classifier on wikiDetox Dataset.\r\n\r\n\r\ncc @eerhardt @danmosemsft @sfilipi ","Url":"https://github.com/dotnet/machinelearning/pull/820","RelatedDescription":"Open PR \"Added Benchmark performance tests for wikidetoxData\" (#820)"},{"Id":"357022872","IsPullRequest":false,"CreatedAt":"2018-09-05T00:30:13","Actor":"Zruty0","Number":"819","RawContent":null,"Title":"Bring back Supervised binning normalizer","State":"open","Body":"This is a unique kind of normalizer that requires label column. We should have a component for it in the new API.","Url":"https://github.com/dotnet/machinelearning/issues/819","RelatedDescription":"Open issue \"Bring back Supervised binning normalizer\" (#819)"},{"Id":"357016535","IsPullRequest":true,"CreatedAt":"2018-09-04T23:53:17","Actor":"codemzs","Number":"818","RawContent":null,"Title":"remove dot from the file name.","State":"open","Body":"fixes #826 ","Url":"https://github.com/dotnet/machinelearning/pull/818","RelatedDescription":"Open PR \"remove dot from the file name.\" (#818)"},{"Id":"357014087","IsPullRequest":true,"CreatedAt":"2018-09-04T23:40:11","Actor":"eerhardt","Number":"817","RawContent":null,"Title":"Remove SubComponent usage from ML.PipelineInference.","State":"open","Body":"Working towards #585\r\n","Url":"https://github.com/dotnet/machinelearning/pull/817","RelatedDescription":"Open PR \"Remove SubComponent usage from ML.PipelineInference.\" (#817)"},{"Id":"357004212","IsPullRequest":true,"CreatedAt":"2018-09-04T23:13:41","Actor":"shauheen","Number":"815","RawContent":null,"Title":"Cherrypick to update release for 0.5 - NO MERGE","State":"closed","Body":"Cherrypick into release for 0.5","Url":"https://github.com/dotnet/machinelearning/pull/815","RelatedDescription":"Closed or merged PR \"Cherrypick to update release for 0.5 - NO MERGE\" (#815)"},{"Id":"357002744","IsPullRequest":true,"CreatedAt":"2018-09-04T22:44:22","Actor":"zeahmed","Number":"814","RawContent":null,"Title":" Enabled option to get multiple outputs from TF graphs","State":"open","Body":"This PR fixes #712.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/814","RelatedDescription":"Open PR \" Enabled option to get multiple outputs from TF graphs\" (#814)"},{"Id":"356965893","IsPullRequest":true,"CreatedAt":"2018-09-04T21:09:56","Actor":"safern","Number":"813","RawContent":null,"Title":"Update badges to new definition name","State":"closed","Body":"Renamed the build def right after my PR got merged. \r\n\r\n@eerhardt and I chatted offline that the CI name should be something more descriptive, rather than \"public-CI\". So renamed it to MachineLearning-CI.","Url":"https://github.com/dotnet/machinelearning/pull/813","RelatedDescription":"Closed or merged PR \"Update badges to new definition name\" (#813)"},{"Id":"356936320","IsPullRequest":true,"CreatedAt":"2018-09-04T20:04:00","Actor":"safern","Number":"811","RawContent":null,"Title":"Update README badges to point to dnceng","State":"closed","Body":"cc: @eerhardt @shauheen ","Url":"https://github.com/dotnet/machinelearning/pull/811","RelatedDescription":"Closed or merged PR \"Update README badges to point to dnceng\" (#811)"},{"Id":"356950539","IsPullRequest":true,"CreatedAt":"2018-09-04T19:46:04","Actor":"sfilipi","Number":"812","RawContent":null,"Title":" WIP: Pigsty examples","State":"open","Body":"I will not merge this branch as is, because  its history is polluted from the merge/updates to master. \r\nSending out a PR to get some feedback, while i resolve the history problem. \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/812","RelatedDescription":"Open PR \" WIP: Pigsty examples\" (#812)"},{"Id":"356931777","IsPullRequest":false,"CreatedAt":"2018-09-04T18:47:41","Actor":"artidoro","Number":"810","RawContent":null,"Title":"Tests failing when repository in folder named 'source'","State":"open","Body":"### System information\r\n\r\n- OS: Windows 10\r\n- .NET Version: \r\n```\r\n.NET Core SDK (reflecting any global.json):\r\nVersion:   2.1.401\r\nCommit:    91b1c13032\r\n\r\nRuntime Environment:\r\nOS Name:     Windows\r\nOS Version:  10.0.17134\r\nOS Platform: Windows\r\nRID:         win10-x64\r\nBase Path:   C:\\Program Files\\dotnet\\sdk\\2.1.401\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.3\r\n  Commit:  124038c13e\r\n```\r\n\r\n### Issue\r\n\r\n- I ran all tests after successfully building ML.NET\r\n- I had errors in several tests\r\n- Since the code passed all automated tests online, I was expecting the same to happen on my machine locally\r\n\r\nWith the help of @codemzs we found out that the name of the folder in which I had cloned my repository was causing the errors. I used the **default path** that Visual Studio gave me:\r\n`C:\\Users\\myUsername\\source\\repos\\artidoro-machinelearning`\r\n\r\n### Source code / logs\r\n\r\nExample with LogisticRegression-bin-norm-CV-breast-cancer unit test in Microsoft.ML.Predictor.Tests:\r\n\r\n- Here is the file path in the output of my unit test:\r\n`dout=%Source%\\repos\\artidoro-machinelearning\\bin\\AnyCPU.Debug\\Microsoft.ML.Predictor.Tests\\netcoreapp2.1\\TestOutput\\LogisticRegression\\LogisticRegression-bin-norm-CV-breast-cancer.txt`\r\n\r\n- Vs what the test was expecting:\r\n`dout=%Output%`\r\n\r\nThe code that normalizes file paths in the output files of unit tests picked up on the folder name `source` and replaced it with `%Source%` instead of replacing the entire file path correctly. This introduces a difference with the expected output. \r\n\r\nHere is the function that performs the path normalization:\r\nhttps://github.com/dotnet/machinelearning/blob/622e0283f70ed53af4e17bffd730807789641ab1/test/Microsoft.ML.TestFramework/BaseTestBaseline.cs#L285-L305\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/810","RelatedDescription":"Open issue \"Tests failing when repository in folder named 'source'\" (#810)"},{"Id":"356911003","IsPullRequest":true,"CreatedAt":"2018-09-04T17:43:46","Actor":"Ivanidzo4ka","Number":"809","RawContent":null,"Title":"Some pigsty examples","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/809","RelatedDescription":"Open PR \"Some pigsty examples\" (#809)"},{"Id":"356769394","IsPullRequest":false,"CreatedAt":"2018-09-04T11:34:27","Actor":"xclud","Number":"807","RawContent":null,"Title":"Help needed with Multi-label string classification","State":"open","Body":"### Issue\r\nI am new to ML (and i don't know if i chose a correct subject for the issue) and I need some help classifying some text into several emotion labels. My model has 6 emotions (anger, disgust, fear, happiness, sadness, and surprise) and i want to label many sentences/strings by these emotions to train the model. Later i will need check some string against the model to predict the emotions within the text. The data looks like this:\r\n\r\n```\r\n\"Sentence #1\" : Sad (10%), Fear (90%), Disgust (0%), Anger (0%), ...\r\n\"Sentense #2: : Happy (60%), Surprised (40%), Disgust (0%), Anger (0%), ...\r\n```\r\n\r\nI don't know which learner to start with and how to build my input class (class as in a `public class InData`). The \"Features\" and \"Label\" things look magics to me.\r\n\r\nI will be happy to contribute a sample after i get my sample working.","Url":"https://github.com/dotnet/machinelearning/issues/807","RelatedDescription":"Open issue \"Help needed with Multi-label string classification\" (#807)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-09-05T05:30:34.73989Z","RunDurationInMilliseconds":1044}