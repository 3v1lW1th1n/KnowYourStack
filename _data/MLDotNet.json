{"Data":{"GitHub":{"Issues":[{"Id":"580904660","IsPullRequest":true,"CreatedAt":"2020-03-14T00:46:43","Actor":"Lynx1820","Number":"4942","RawContent":null,"Title":"Fixes KMeans scoring differences between ORT and OnnxRunner","State":"closed","Body":"The KMeans ORT score predictions were off because batches were not being handled correctly. \r\nThere is still an issue because Nimbus produces int32 predictions, when they should be uint32, since ML.NET returns key values, but I plan on working on that separately, since it's probably a Nimbus bug. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4942","RelatedDescription":"Closed or merged PR \"Fixes KMeans scoring differences between ORT and OnnxRunner\" (#4942)"},{"Id":"580931672","IsPullRequest":true,"CreatedAt":"2020-03-13T23:33:31","Actor":"mstfbl","Number":"4943","RawContent":null,"Title":"Fixed CheckValidDownload in ResourceManagerUtils.cs","State":"open","Body":"Fixed the helper function ResourceManagerUtils.CheckValidDownload. \r\n\r\nThe function was not correctly warning that the HTML of www.microsoft.com was downloaded (instead of an intended data file) as the size of the website is bigger than 4 kilobytes, and the site should have the sub-strings <head and <body (not <head> and <body>).","Url":"https://github.com/dotnet/machinelearning/pull/4943","RelatedDescription":"Open PR \"Fixed CheckValidDownload in ResourceManagerUtils.cs\" (#4943)"},{"Id":"580804713","IsPullRequest":true,"CreatedAt":"2020-03-13T20:26:22","Actor":"najeeb-kazmi","Number":"4941","RawContent":null,"Title":"Add see also section to TensorFlowEstimator docs","State":"closed","Body":"Fixes #4932 ","Url":"https://github.com/dotnet/machinelearning/pull/4941","RelatedDescription":"Closed or merged PR \"Add see also section to TensorFlowEstimator docs\" (#4941)"},{"Id":"579215175","IsPullRequest":false,"CreatedAt":"2020-03-13T20:26:22","Actor":"vslynko","Number":"4932","RawContent":null,"Title":"TensorFlowEstimator initialization info is missing","State":"closed","Body":"`TensorFlowEstimator` is not static and has no public constructors. Therefore the link to the documentation on how to initialize `TensorFlowEstimator` is essential.\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 7366dd71-3899-63fb-690e-5e0d11a5bf13\r\n* Version Independent ID: 4e44da94-51eb-2617-135a-eb71186b4da9\r\n* Content: [TensorFlowEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowestimator?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/4932","RelatedDescription":"Closed issue \"TensorFlowEstimator initialization info is missing\" (#4932)"},{"Id":"579104390","IsPullRequest":true,"CreatedAt":"2020-03-13T19:01:59","Actor":"mstfbl","Number":"4931","RawContent":null,"Title":"Added hanging test mem dump feature","State":"closed","Body":"Added the option to automatically collect memory dumps on hanging and crashing tests through VSTest Tasks and ProcDump.\r\n\r\nAlso added a section in the developer guide explaining the process to collecting memory dumps from CI builds.","Url":"https://github.com/dotnet/machinelearning/pull/4931","RelatedDescription":"Closed or merged PR \"Added hanging test mem dump feature\" (#4931)"},{"Id":"580714924","IsPullRequest":true,"CreatedAt":"2020-03-13T18:19:08","Actor":"natke","Number":"4940","RawContent":null,"Title":"Fix xrefs in the LDSVM trainer docs","State":"closed","Body":"\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4940","RelatedDescription":"Closed or merged PR \"Fix xrefs in the LDSVM trainer docs\" (#4940)"},{"Id":"578330610","IsPullRequest":false,"CreatedAt":"2020-03-13T05:45:55","Actor":"artemiusgreat","Number":"4926","RawContent":null,"Title":"SdcaMaximumEntropy trainer goes into an infinite loop if it takes already transformed data view as an input","State":"closed","Body":"### System information\r\n\r\n- **OS version**: Windows 10 Pro x64\r\n- **.NET Version**: .NET Core 3.0\r\n- **ML.NET**: 1.5.0-preview\r\n\r\n### Issue\r\n\r\n**What I did**\r\n- create data-preparation pipeline \r\n- create trainer SdcaMaximumEntropy \r\n- execute pipeline, e.g. to debug transformed data view \r\n- add trainer to the pipeline and execute pipeline again, with the trainer included \r\n \r\n**What happened**\r\n\r\nIf I execute pipeline once, e.g. load from enumerables into data view and then execute entire transformation chain that includes transformations and trainer, everything works fine. \r\n\r\nIf I execute pipeline twice, first time - separately, then - as a part of entire transformation chain, it consumes 3GB of RAM memory out of 16GB available, then **training hangs indefinitely** and never ends. \r\nFixed this temporarily by changing this `MaximumNumberOfIterations` option, but not sure if it's a good idea...  \r\n\r\n**What I expect**\r\n\r\nI expect training to stop eventually, no matter how many times I execute pipeline. \r\n**Check the comment on the last line in the core below.**\r\n\r\n### Source code \r\n\r\nSource code is taken from this issue https://github.com/dotnet/machinelearning/issues/4903\r\n\r\n```C#\r\n\r\npublic IEstimator<ITransformer> GetPipeline(IEnumerable<string> columns)\r\n{\r\n  var pipeline = Context\r\n    .Transforms\r\n    .Conversion\r\n    .MapValueToKey(new[] { new InputOutputColumnPair(\"Label\", \"Strategy\") })\r\n    .Append(Context.Transforms.Concatenate(\"Combination\", columns.ToArray())) // merge \"dynamic\" colums into single property\r\n    .Append(Context.Transforms.NormalizeMinMax(new[] { new InputOutputColumnPair(\"Features\", \"Combination\") })) // normalize merged columns into Features\r\n    .Append(Context.Transforms.SelectColumns(new string[] { \"Label\", \"Features\" })); // remove everything from data view, except transformed columns\r\n\r\n  return pipeline;\r\n}\r\n\r\npublic IEstimator<ITransformer> GetEstimator()\r\n{\r\n  var options = new SdcaMaximumEntropyMulticlassTrainer.Options\r\n  {\r\n    // MaximumNumberOfIterations = 100  // uncomment this to fix the issue\r\n  };\r\n\r\n  var estimator = Context\r\n    .MulticlassClassification\r\n    .Trainers\r\n    .SdcaMaximumEntropy(options)\r\n    .Append(Context.Transforms.Conversion.MapKeyToValue(new[]\r\n    {\r\n      new InputOutputColumnPair(\"Prediction\", \"PredictedLabel\") // set trainer to use Prediction property as output\r\n    }));\r\n\r\n  return estimator;\r\n}\r\n\r\npublic void TrainModel(IEnumerable<string> columns, IEnumerable<InputModel> items)\r\n{\r\n  var estimator = GetEstimator();\r\n  var pipeline = GetPipeline(columns);\r\n  var inputs = Context.Data.LoadFromEnumerable(items);  // create view \r\n\r\n  // If I stop execution here, everything is ok\r\n\r\n  var model = pipeline.Append(estimator).Fit(inputs);  // works fine for the data view loaded from enumerables\r\n\r\n  // Data preparation pipeline is a part of a transformation chain, so I don't need next 2 lines, but I don't understand why it's causing the issue\r\n  \r\n  var pipelineModel = pipeline.Fit(inputs);  \r\n  var pipelineView = pipelineModel.Transform(inputs); // execute pipeline before the training\r\n  var model = pipeline.Append(estimator).Fit(pipelineView); // use transformed pipelineView instead of initial inputs and ... go into infinite loop ... why?\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4926","RelatedDescription":"Closed issue \"SdcaMaximumEntropy trainer goes into an infinite loop if it takes already transformed data view as an input\" (#4926)"},{"Id":"580137617","IsPullRequest":true,"CreatedAt":"2020-03-12T18:26:49","Actor":"harishsk","Number":"4939","RawContent":null,"Title":"Draft PR to debug tensorflow issues","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4939","RelatedDescription":"Open PR \"Draft PR to debug tensorflow issues\" (#4939)"},{"Id":"579681677","IsPullRequest":true,"CreatedAt":"2020-03-12T17:03:07","Actor":"harishsk","Number":"4936","RawContent":null,"Title":"Updated version to 1.5.0-preview3","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4936","RelatedDescription":"Closed or merged PR \"Updated version to 1.5.0-preview3\" (#4936)"},{"Id":"579736111","IsPullRequest":true,"CreatedAt":"2020-03-12T07:06:37","Actor":"mstfbl","Number":"4938","RawContent":null,"Title":"Added working version of checking whether file is available for access","State":"open","Body":"Recently AutoFitRegressionTest() and AutoFitBinaryTest() have been failing occasionally on our MachineLearning-Full CI builds with the error:\r\n\r\n> System.IO.IOException : The process cannot access the file 'D:\\a\\1\\s\\bin\\AnyCPU.Debug\\Microsoft.ML.AutoML.Tests\\netcoreapp2.1\\...dataset' because it is being used by another process.\r\n> \r\n> Stack trace\r\n>    at System.IO.FileStream.ValidateFileHandle(SafeFileHandle fileHandle)\r\n>    at System.IO.FileStream.CreateFileOpenHandle(FileMode mode, FileShare share, FileOptions options)\r\n>    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options)\r\n>    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share)\r\n>    at Microsoft.ML.AutoML.TextFileSample.CreateFromFullFile(String path) in D:\\a\\1\\s\\src\\Microsoft.ML.AutoML\\ColumnInference\\TextFileSample.cs:line 76\r\n>  ...\r\n\r\n(Specific errors for [AutoFitRegressionTest ](https://dev.azure.com/dnceng/public/_build/results?buildId=555337&view=logs&j=dd8eddb6-ecc6-5f65-73e6-df90e5693b94&t=5b4b90b5-382b-59ee-45ec-a64c47991239&l=202)and [AutoFitBinaryTest](https://dev.azure.com/dnceng/public/_build/results?buildId=545476&view=logs&j=41509eb4-74ce-5e57-61b4-bdf74b39e7c1&t=dbdc2969-5b98-5c39-1328-31d4a2fdc45e&l=286) from CI builds)\r\n\r\nThis indicates that the .dataset file that is trying to be reached still has a lock on it, and is not yet ready for accessing. The current method of checking whether this file is ready to be accessed (checking `new FileInfo(dataFile).Length > 0` is not sufficient. \r\n\r\nThe fix below remedies this by explicitly attempting to open the file, and returning true iff the file can be opened, and its stream later closed without throwing an exception.  ","Url":"https://github.com/dotnet/machinelearning/pull/4938","RelatedDescription":"Open PR \"Added working version of checking whether file is available for access\" (#4938)"},{"Id":"579653089","IsPullRequest":true,"CreatedAt":"2020-03-12T06:00:22","Actor":"frank-dong-ms","Number":"4935","RawContent":null,"Title":"Nightlybuild fix","State":"closed","Body":"several issue here:\r\n1. delete useless folder to avoid no disk space\r\n2. add missing dependency for nightly build\r\n3. fix LD_LIBRARY_PATH for CentOS to set proper native reference path\r\n4. increase build time, seems it takes more time now for net core 3.0 to build","Url":"https://github.com/dotnet/machinelearning/pull/4935","RelatedDescription":"Closed or merged PR \"Nightlybuild fix\" (#4935)"},{"Id":"579694210","IsPullRequest":false,"CreatedAt":"2020-03-12T05:01:15","Actor":"philiplai","Number":"4937","RawContent":null,"Title":"model.LastTransformer doesn't exist","State":"open","Body":"I was trying to implement Permutation Feature Importance (PFI) for Binary Classification.  But I was stuck on the following line of code.  This method simply doesn't exist.\r\n// Extract the predictor.\r\nvar linearPredictor = model.LastTransformer;\r\n\r\nI was following the example on https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet\r\n\r\nAny idea?\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 5ec45442-8e5f-a544-cc9a-58483a383513\r\n* Version Independent ID: 040169f9-d169-cbbd-099e-f04a7a5a6b3f\r\n* Content: [PermutationFeatureImportanceExtensions.PermutationFeatureImportance Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/4937","RelatedDescription":"Open issue \"model.LastTransformer doesn't exist\" (#4937)"},{"Id":"578821017","IsPullRequest":true,"CreatedAt":"2020-03-11T21:34:21","Actor":"Lynx1820","Number":"4928","RawContent":null,"Title":"Fix for MulticlassNaiveBayesTrainer export to Onnx","State":"closed","Body":"- Adding support for a batch input dimension\r\n- While ML.NET doesn't use this batch dimension, ORT does.  \r\n","Url":"https://github.com/dotnet/machinelearning/pull/4928","RelatedDescription":"Closed or merged PR \"Fix for MulticlassNaiveBayesTrainer export to Onnx\" (#4928)"},{"Id":"579469782","IsPullRequest":true,"CreatedAt":"2020-03-11T20:05:28","Actor":"najeeb-kazmi","Number":"4934","RawContent":null,"Title":"Improved documentation for LdSvmTrainer","State":"closed","Body":"Adds explanation of the algorithm, moves details to remarks, adds references to samples.","Url":"https://github.com/dotnet/machinelearning/pull/4934","RelatedDescription":"Closed or merged PR \"Improved documentation for LdSvmTrainer\" (#4934)"},{"Id":"579237248","IsPullRequest":false,"CreatedAt":"2020-03-11T12:44:08","Actor":"vslynko","Number":"4933","RawContent":null,"Title":"AccessViolationException PredictionEngine when 100-200 concurrent predictions running async","State":"open","Body":"### System information\r\n\r\n- Windows 10 64bit latest. 4 core CPU with hyperthreading.\r\n- Main app net48, that loads dependency in net472 that loads Microsoft.ML.Tensorflow 1.4: \r\n\r\n### Issue\r\n\r\n- Multiple concurrent tasks scheduled with `Task.WhenAll`. All tasks perform the same lambda, that involves calling PredictionEngineBase.Predict call. Number of tasks in parallel stacks window is about 100-200. \r\n- `AccessViolationException` thrown with message \"Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\"\r\n- As in case when number of tasks is not that big, ~30-50 I would expect no exception.\r\n\r\n### Source code / logs\r\nTwo different stack traces point to about same location in the code. The difference is that I rearrange a little async workflow by switch couple of async tasts around.\r\n```stacktrace\r\n   at System.SpanHelpers.CopyTo[T](T& dst, Int32 dstLength, T& src, Int32 srcLength)\r\n   at System.Span`1.TryCopyTo(Span`1 destination)\r\n   at Microsoft.ML.TensorFlow.TensorTypeExtensions.CopyTo[T](Tensor tensor, Span`1 values)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at InstaFlow.TensorFlow.Gp2.TfGpBaseV2`1.Predict(TfGpSeriesV2 series)\r\n   at InstaFlow.TensorFlow.Gp2.TfGpBaseV2`1.CorrectInternal(T model, TfInput input)\r\n   at InstaFlow.TensorFlow.TfEstimatorV2.TimerAction[T](Func`1 func)\r\n   at InstaFlow.TensorFlow.TfEstimatorV2.EstimateAndEvaluate(TfInput input)\r\n```\r\n\r\n```stacktrace\r\n   at Tensorflow.c_api.TF_TensorByteSize(IntPtr tensor)\r\n   at Tensorflow.Tensor.get_bytesize()\r\n   at Tensorflow.Tensor.get_size()\r\n   at Microsoft.ML.TensorFlow.TensorTypeExtensions.CopyTo[T](Tensor tensor, Span`1 values)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at InstaFlow.TensorFlow.Estimator.TfEstimatorBase.Predict(TfSeries series) in C:\\src\\instaflow\\dotnet\\InstaFlow.TensorFlow\\Estimator\\TfEstimatorBase.cs:line 101\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4933","RelatedDescription":"Open issue \"AccessViolationException PredictionEngine when 100-200 concurrent predictions running async\" (#4933)"},{"Id":"575840698","IsPullRequest":true,"CreatedAt":"2020-03-10T23:38:47","Actor":"antoniovs1029","Number":"4919","RawContent":null,"Title":"Update to Onnxruntime 1.2 and reenable its support for GPU","State":"closed","Body":"Update dependencies in ML.NET for Onnxruntime.Managed 1.2 and reenable GPU support.\r\n\r\nFrom now on OnnxTransformer will take a dependency on OnnxRuntime.Managed nuget, instead of OnnxRuntime. And users of ML.NET will have the ability to either use OnnxRuntime nuget (for CPU) or OnnxRuntime.Gpu nuget, depending if they want their onnx models to be applied using cpu or gpu.\r\n\r\nNotice that in # #4416 support for GPU was disabled because of changes in onnxruntime nugets, and in here that same code is reenabled.","Url":"https://github.com/dotnet/machinelearning/pull/4919","RelatedDescription":"Closed or merged PR \"Update to Onnxruntime 1.2 and reenable its support for GPU\" (#4919)"},{"Id":"578885494","IsPullRequest":true,"CreatedAt":"2020-03-10T23:31:46","Actor":"frank-dong-ms","Number":"4929","RawContent":null,"Title":"add back lightgbm crash mitigation","State":"closed","Body":"we are seeing several crash so there might be more issue there, will remove this mitigation if we root cause and fix other remaining issue within lightgbm test\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4929","RelatedDescription":"Closed or merged PR \"add back lightgbm crash mitigation\" (#4929)"},{"Id":"578891508","IsPullRequest":true,"CreatedAt":"2020-03-10T22:11:18","Actor":"mstfbl","Number":"4930","RawContent":null,"Title":"Debugging hanging tests [Draft, WIP]","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4930","RelatedDescription":"Open PR \"Debugging hanging tests [Draft, WIP]\" (#4930)"},{"Id":"578394306","IsPullRequest":true,"CreatedAt":"2020-03-10T20:07:02","Actor":"frank-dong-ms","Number":"4927","RawContent":null,"Title":"fix LdaWorkoutEstimatorCore","State":"closed","Body":"fix LdaWorkoutEstimatorCore test.\r\n\r\nresetRandomGenerator needs to be true here as multiple compare will be performed later. \r\nIn lda_engine, a queue of samples with size of (num_of_threads - 2) will be created at first, each time a compare is performed the internal status of one sample (random number: rng_) is changed, so if size of queue is smaller the number of compare performed (in local workstation we have 12 cores thus the issue is not reproduced), dirty data will be used again for calculation and cause issue. set resetRandomGenerator to true will reset the random number rng_ every time before lda calculation thus fix the issue.","Url":"https://github.com/dotnet/machinelearning/pull/4927","RelatedDescription":"Closed or merged PR \"fix LdaWorkoutEstimatorCore\" (#4927)"},{"Id":"576588062","IsPullRequest":true,"CreatedAt":"2020-03-10T07:53:11","Actor":"frank-dong-ms","Number":"4921","RawContent":null,"Title":"test LdaWorkoutEstimatorCore","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4921","RelatedDescription":"Closed or merged PR \"test LdaWorkoutEstimatorCore\" (#4921)"},{"Id":"578280343","IsPullRequest":true,"CreatedAt":"2020-03-10T01:30:25","Actor":"suxi-ms","Number":"4925","RawContent":null,"Title":"add root cause localization transformer","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4925","RelatedDescription":"Open PR \"add root cause localization transformer\" (#4925)"},{"Id":"578260111","IsPullRequest":true,"CreatedAt":"2020-03-10T00:14:12","Actor":"frank-dong-ms","Number":"4924","RawContent":null,"Title":"Tensorflow crash issue","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4924","RelatedDescription":"Open PR \"Tensorflow crash issue\" (#4924)"},{"Id":"575279610","IsPullRequest":false,"CreatedAt":"2020-03-09T22:07:10","Actor":"nighotatul","Number":"4915","RawContent":null,"Title":"how we can show confusion matrix of Permutation Feature Importance so end user easily identify?","State":"closed","Body":"@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\n\r\nhow we can show score,probability,confusion matrix of Permutation Feature Importance?","Url":"https://github.com/dotnet/machinelearning/issues/4915","RelatedDescription":"Closed issue \"how we can show confusion matrix of Permutation Feature Importance so end user easily identify?\" (#4915)"},{"Id":"576429602","IsPullRequest":false,"CreatedAt":"2020-03-09T17:16:56","Actor":"artemiusgreat","Number":"4920","RawContent":null,"Title":"Create DataView from IEnumerable<HashTable> or IEnumerable<IDictionary<string,dynamic>>","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro x64\r\n- **.NET Version**: .NET Core 3.0\r\n- **ML.NET Version**: 1.5.0-preview\r\n\r\n### Issue\r\n\r\n**What did you do?**\r\n\r\nTrying to create a data view from a list of IDictionary objects. \r\n\r\n- `IEnumerable<Expando>` or ...\r\n- `IEnumerable<HashTable>` or ...\r\n- `IEnumerable<Dictionary<string, object>>`\r\n- `IEnumerable<Dictionary<string, dynamic>>`\r\n\r\nIn this case, Keys would be used as column names, and Values as a data. \r\n\r\n**What happened?**\r\n\r\nWhen I add column names or implement ValueGetter, I need to specify a type of the column. \r\nThis code from ValueGetter gives an exception - could not cast type String to ReadOnlyMemory<char>\r\n\r\n```C#\r\n  return (ValueGetter<TValue>)_enumerator.Current[column.Name]\r\n```\r\n\r\nIn this code from data view constructor I don't know how to set column type as \"dynamic\". \r\n\r\n```C#\r\n  public DictionaryView(IEnumerable<HashTable> items)\r\n  {\r\n    Items = items;\r\n\r\n    var builder = new DataViewSchema.Builder();\r\n\r\n    foreach (var k in items.First().Keys)\r\n    {\r\n      builder.AddColumn(k, TextDataViewType.Instance); // not sure what data type to use here, because HashTable doesn't have type for its Values\r\n    }\r\n    \r\n    Schema = builder.ToSchema();\r\n  }\r\n```\r\n\r\n**What did you expect?**\r\n\r\n- how to define all columns as `object` or `dynamic` or ... \r\n- is it possible to implement custom column type for a data view, something like DataKind.MixedEnumerableFloatString or ... \r\n- define Switch-Case mapping between System.Type and DataView.Kind like in the pseudo-code below?\r\n\r\n```C#\r\npublic override ValueGetter<TValue> GetGetter<TValue>(DataViewSchema.Column column)\r\n{\r\n  // Ideally, would be good to have some generic delegate that could return some \"dynamic\" type instead of hardcoded type-casting \r\n  // If we iterate over data view collection using cursor, we don't need to know the type of the column \r\n\r\n  switch (column.GetType().Name)\r\n  {\r\n    case \"Float\": return (ValueGetter<float>)_enumerator.Current[column.Name];\r\n    case \"Boolean\": return (ValueGetter<bool>)_enumerator.Current[column.Name];\r\n    case \"String\": return (ValueGetter<ReadOnlyMemory<char>>)_enumerator.Current[column.Name];\r\n  }\r\n\r\n  if (column is IEnumerable) \r\n  {\r\n    return (ValueGetter<IEnumerable<float>>)_enumerator.Current[column.Name];\r\n  }\r\n\r\n  return (ValueGetter<TValue>)_enumerator.Current[column.Name];\r\n}\r\n```\r\n\r\n### Source code / logs\r\n\r\nUsing this guide as an example. \r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.idataview?view=ml-dotnet \r\n\r\n```C#\r\npublic class DictionaryView : IDataView\r\n{\r\n  public bool CanShuffle => false;\r\n  public long? GetRowCount() => 0;\r\n  public DataViewSchema Schema { get; }\r\n  public IEnumerable<HashTable> Items = null;\r\n\r\n  public DictionaryView(IEnumerable<HashTable> items)\r\n  {\r\n    Items = items;\r\n\r\n    var builder = new DataViewSchema.Builder();\r\n    builder.AddColumn(\"Label\", TextDataViewType.Instance); // add multiple properties dynamically from IDictionary or HashTable item \r\n    \r\n    //foreach (var k in items.First().Keys)\r\n    //{\r\n    //  builder.AddColumn(k, TextDataViewType.Instance); // not sure what data type to use here, because HashTable doesn't have type for its Values\r\n    //}\r\n    \r\n    //builder.AddColumn(\"Value\", TextDataViewType.Instance);\r\n    Schema = builder.ToSchema();\r\n  }\r\n\r\n  public DataViewRowCursor GetRowCursor(IEnumerable<DataViewSchema.Column> columns, Random seed = null) => new Cursor(this);\r\n  public DataViewRowCursor[] GetRowCursorSet(IEnumerable<DataViewSchema.Column> columns, int n, Random seed = null) => new[] { GetRowCursor(columns, seed) };\r\n\r\n  private sealed class Cursor : DataViewRowCursor\r\n  {\r\n    private long _position = -1;\r\n    private bool _inactive = false;\r\n    private readonly IEnumerator<HashTable> _enumerator = null;\r\n\r\n    public override long Batch => 0;\r\n    public override long Position => _position;\r\n    public override DataViewSchema Schema { get; } = null;\r\n    public override bool IsColumnActive(DataViewSchema.Column column) => true;\r\n    public override ValueGetter<DataViewRowId> GetIdGetter() => (ref DataViewRowId id) => id = new DataViewRowId();\r\n\r\n    public Cursor(DataViewManager view)\r\n    {\r\n      _position = -1;\r\n      _enumerator = view.Items.GetEnumerator();\r\n\r\n      //_getters = new Delegate[]\r\n      //{\r\n      //  (ValueGetter<ReadOnlyMemory<char>>)LabelGetterImplementation\r\n      //};\r\n\r\n      Schema = view.Schema;\r\n    }\r\n\r\n    //private readonly Delegate[] _getters;\r\n    //private void LabelGetterImplementation(ref ReadOnlyMemory<char> value) => value = $\"{ _enumerator.Current[\"Label\"] }\".AsMemory();\r\n\r\n    public override ValueGetter<TValue> GetGetter<TValue>(DataViewSchema.Column column)\r\n    {\r\n      if (_enumerator.Current == null)\r\n      {\r\n        MoveNext();\r\n      }\r\n\r\n      return (ValueGetter<TValue>)_enumerator.Current[column.Name]; // extract property by name from the current row of HashTable or IDictionary type\r\n\r\n      //return (ValueGetter<TValue>)_getters[column.Index];\r\n    }\r\n\r\n    protected override void Dispose(bool disposing)\r\n    {\r\n      if (_inactive)\r\n      {\r\n        return;\r\n      }\r\n\r\n      if (disposing)\r\n      {\r\n        _enumerator.Dispose();\r\n        _position = -1;\r\n      }\r\n\r\n      _inactive = true;\r\n\r\n      base.Dispose(disposing);\r\n    }\r\n\r\n    public override bool MoveNext()\r\n    {\r\n      if (_inactive)\r\n      {\r\n        return false;\r\n      }\r\n\r\n      if (_enumerator.MoveNext())\r\n      {\r\n        _position++;\r\n        return true;\r\n      }\r\n\r\n      Dispose();\r\n\r\n      return false;\r\n    }\r\n  }\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4920","RelatedDescription":"Closed issue \"Create DataView from IEnumerable<HashTable> or IEnumerable<IDictionary<string,dynamic>>\" (#4920)"},{"Id":"577382791","IsPullRequest":false,"CreatedAt":"2020-03-07T18:42:48","Actor":"artemiusgreat","Number":"4923","RawContent":null,"Title":"How Transformer converts structured or custom data view type into a feature value?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro x64\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.0\r\n- **ML.NET Version**: 1.5.0-preview\r\n\r\n### Question\r\n\r\nWhen implementing a custom data view type, how does transformer know what to use as a \"value\" of this type? Does it use `GetHashCode()` method for this?\r\n\r\n### Source code \r\n\r\nConsidering, we have this custom image type with properties Width and Height. \r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.ImageAnalytics/ImageType.cs \r\n\r\nThen, we have this transformer code that merges several columns into one called `Features`. \r\nOne of these columns has type `ImageType`. \r\n\r\n```C#\r\n  var pipeline = Context\r\n    .Transforms\r\n    .Conversion\r\n    .Append(Context.Transforms.Concatenate(\"Features\", new[] { \"ImageColumn\", \"Points\" }));\r\n```\r\n\r\nAs far as I understand, for ML engine to learn something from the provided data, `Features` should be an array of float values. So, the question is, how `ImageColumn` and `Points` will be converted to floats? \r\n\r\nAnother example that I found is this test for custom type registration. \r\nIt's also using GetHashCode method. \r\nhttps://github.com/dotnet/machinelearning/blob/release/1.5-preview/test/Microsoft.ML.Core.Tests/UnitTests/TestCustomTypeRegister.cs\r\n\r\n**I'd like somebody to confirm that whatever is returned from GetHashCode method will be used in training the model.**\r\n\r\n```C#\r\npublic override int GetHashCode() // unique value for ImageType\r\n{\r\n    return Hashing.CombineHash(Height.GetHashCode(), Width.GetHashCode());\r\n}\r\n```\r\n\r\nI'm asking because, e.g. OnnxMapType or OnnxSequenceType are completely different animals, whose GetHashCode method returns value based on a data type, not its value.\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.OnnxTransformer/OnnxMapType.cs\r\n\r\n```C#\r\npublic override int GetHashCode() // uniquer value for OnnxMapType\r\n{\r\n    return RawType.GetHashCode();\r\n}\r\n```\r\n\r\n**Does it mean that ONNX types cannot be used for training because their hash code is based on a System.Type instead of actual observation?**","Url":"https://github.com/dotnet/machinelearning/issues/4923","RelatedDescription":"Open issue \"How Transformer converts structured or custom data view type into a feature value?\" (#4923)"},{"Id":"577092182","IsPullRequest":true,"CreatedAt":"2020-03-06T18:46:08","Actor":"LittleLittleCloud","Number":"4922","RawContent":null,"Title":"Add hasHeader flag in ColumnInference function","State":"closed","Body":"### This change will only affect the internal API.\r\n\r\nwhen hasHeader is true, AutoML will use the column name from dataset's header to indicate label/userId/itemId. else, it will use the default column name `col{i}` to indicate those information","Url":"https://github.com/dotnet/machinelearning/pull/4922","RelatedDescription":"Closed or merged PR \"Add hasHeader flag in ColumnInference function\" (#4922)"},{"Id":"575481194","IsPullRequest":false,"CreatedAt":"2020-03-06T13:43:41","Actor":"tomasfalt","Number":"4917","RawContent":null,"Title":"Error loading LightGBM model","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .Net Standard 2.0\r\n- **ML.Net version**: 1.4\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nBuild and trained a model with FastTree, saved it and finally load it and all worked. Changed to LightGBM and got an error when I try to load it.\r\n\r\nThe error is following:\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\n### Source code / logs\r\n\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Error during class instantiation\r\n  Source=Microsoft.ML.Core\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(String filePath, DataViewSchema& inputSchema)\r\n  \r\n\r\n  This exception was originally thrown at this call stack:\r\n\tMicrosoft.ML.Runtime.ComponentCatalog.TryGetIniters(System.Type, System.Type, System.Type[], out System.Reflection.MethodInfo, out System.Reflection.ConstructorInfo, out System.Reflection.MethodInfo, out bool)\r\n\tMicrosoft.ML.Runtime.ComponentCatalog.RegisterAssembly(System.Reflection.Assembly, bool)\r\n\tMicrosoft.ML.ModelLoadContext.EnsureLoaderAssemblyIsRegistered(Microsoft.ML.Runtime.ComponentCatalog)\r\n\tMicrosoft.ML.ModelLoadContext.TryLoadModelCore<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, object[])\r\n\tMicrosoft.ML.ModelLoadContext.TryLoadModel<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, Microsoft.ML.Repository.Entry, string, object[])\r\n\tMicrosoft.ML.ModelLoadContext.LoadModel<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, Microsoft.ML.Repository.Entry, string, object[])\r\n\tMicrosoft.ML.ModelLoadContext.LoadModelOrNull<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, string, object[])\r\n\r\nInner Exception 1:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 2:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nInner Exception 3:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 4:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nInner Exception 5:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 6:\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4917","RelatedDescription":"Closed issue \"Error loading LightGBM model\" (#4917)"},{"Id":"575808706","IsPullRequest":true,"CreatedAt":"2020-03-05T20:46:00","Actor":"frank-dong-ms","Number":"4918","RawContent":null,"Title":"LightGBM Crash issue","State":"closed","Body":"https://github.com/microsoft/LightGBM/issues/2820\r\n\r\nLightGBM has dependency on OpenMP multi-threading library. In our tests we are setting number of threads to be 1 for LightGBM and LightGBM also sets OpenMP to use only 1 thread. While OpenMP is also used by other native libraries and they also tend to set number of threads for OpenMP to use (by default this is number of cores, in our case it is 2 as we are using https://docs.microsoft.com/en-us/azure/virtual-machines/dv2-dsv2-series#dsv2-series). This setting(number of threads) is global in process and cause LightGBM referencing OpenMP from single threads to multi-threads. LightGBM is using number of threads for indexing and thus cause index out of range in native code and crash the process.\r\n\r\nBy this fix, we are not force single threading when run LightGBM related tests thus default behavior is applied and all the libraries use same number of threads for OpenMP.\r\n\r\nIdealy LightGBM better not to rely number of threads to do indexing as this setting is global and likely be override by other library.","Url":"https://github.com/dotnet/machinelearning/pull/4918","RelatedDescription":"Closed or merged PR \"LightGBM Crash issue\" (#4918)"},{"Id":"575301003","IsPullRequest":false,"CreatedAt":"2020-03-05T07:14:55","Actor":"nighotatul","Number":"4916","RawContent":null,"Title":"how we show score,probability associated with Permutation Feature Importance (PFI) so end user can easily identify?","State":"closed","Body":"@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\nreferences link:\r\n[how we show permutation slot associated with feature so end user easily identify? #4739](url)\r\n\r\nhow we can get score,probability of PFI?\r\nwe have get globally score and probability but we cannot get at PFI. how we can achieve this?","Url":"https://github.com/dotnet/machinelearning/issues/4916","RelatedDescription":"Closed issue \"how we show score,probability associated with Permutation Feature Importance (PFI) so end user can easily identify?\" (#4916)"},{"Id":"575074859","IsPullRequest":false,"CreatedAt":"2020-03-04T01:32:46","Actor":"crvkumar","Number":"4914","RawContent":null,"Title":"WeakReference<IHost> memory leak?","State":"open","Body":"### System information\r\n\r\n- **ML.NET Version**: 1.4.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\n1. Created a pipeline of ImageLoadingEstimator + ImageResizingEstimator + ImagePixelExtractingEstimator + OnnxScoringEstimator.\r\n2. Create a ITransformer object by fitting the pipeline.\r\n3. Performed ITransformer.Transform multiple times.\r\n\r\nPS: Creating a PredictionEngine and performing PredictionEngine.Predict seems to lock the image as mentioned in issue [4585](https://github.com/dotnet/machinelearning/issues/4585 )\r\n\r\n- **What happened?** \r\n\r\nWeakReference<IHost> objects seems to accumulate.\r\n\r\nThe number of objects does not change even after performing GC.Collect()\r\n\r\nIs this possibly a memory leak?\r\nThe application is built is Release configuration.\r\n\r\n![image](https://user-images.githubusercontent.com/2994809/75835713-f44f3a80-5e02-11ea-8454-abea45097ecc.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4914","RelatedDescription":"Open issue \"WeakReference<IHost> memory leak?\" (#4914)"}],"ResultType":"GitHubIssue"}},"RunOn":"2020-03-14T05:30:40.5275015Z","RunDurationInMilliseconds":722}