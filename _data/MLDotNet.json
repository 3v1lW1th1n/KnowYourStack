{"Data":{"GitHub":{"Issues":[{"Id":"453305449","IsPullRequest":false,"CreatedAt":"2019-06-07T01:43:25","Actor":"daholste","Number":"3838","RawContent":null,"Title":"Enable Binary Classification Metric Calculation on Huge Datasets","State":"open","Body":"From experimenting, it seems like calculating binary classification metrics does not scale to huge datasets. Taking a heap dump to examine the high memory usage (before the program runs out of memory), I see a list of floats used by `UnweightedAucAggregator`. It looks like, to calculate AUC, every prediction is kept in memory. It also looks like there is already substantial logic to account for this scenario -- there's logic to reservoir sample predictions, and then calculate AUC on the sample. However, it looks like the size of the internal parameter `MaxAucExamples` to control the size of this reservoir sample is always set to -1, and not exposed to the end user?https://github.com/dotnet/machinelearning/blob/610ffcb67083c2e5e6e1a14884ba24b1da0384c7/src/Microsoft.ML.Data/Evaluators/BinaryClassifierEvaluator.cs#L45 \r\nPerhaps we should somehow expose this parameter to enable binary metric calculation on huge datasets, or set the parameter to some reasonable default\r\n@justinormont, @vinodshanbhag ","Url":"https://github.com/dotnet/machinelearning/issues/3838","RelatedDescription":"Open issue \"Enable Binary Classification Metric Calculation on Huge Datasets\" (#3838)"},{"Id":"453293558","IsPullRequest":true,"CreatedAt":"2019-06-07T00:33:03","Actor":"wschin","Number":"3837","RawContent":null,"Title":"Bump ONNXRuntime version","State":"open","Body":"Toward #3836. We will have to increase the number of tests to have higher code coverage.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3837","RelatedDescription":"Open PR \"Bump ONNXRuntime version\" (#3837)"},{"Id":"453293411","IsPullRequest":false,"CreatedAt":"2019-06-07T00:32:10","Actor":"wschin","Number":"3836","RawContent":null,"Title":"ONNXTransformer can be upgraded","State":"open","Body":"ONNXRuntime has released 0.4.0 version, so ML.NET needs to be upgraded to include newly added features.\r\n\r\nWorking items:\r\n- Add new types to enable ONNX dictionary and sequence.\r\n- Enrich tests.","Url":"https://github.com/dotnet/machinelearning/issues/3836","RelatedDescription":"Open issue \"ONNXTransformer can be upgraded\" (#3836)"},{"Id":"453271903","IsPullRequest":true,"CreatedAt":"2019-06-06T22:54:34","Actor":"shmoradims","Number":"3835","RawContent":null,"Title":"Explain MLContext seed parameter","State":"open","Body":"Fixes #3048.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3835","RelatedDescription":"Open PR \"Explain MLContext seed parameter\" (#3835)"},{"Id":"452037688","IsPullRequest":false,"CreatedAt":"2019-06-06T21:27:35","Actor":"PeterPann23","Number":"3817","RawContent":null,"Title":"how will you know this at the time of coding...","State":"closed","Body":"I guess it would be appropriate to set this value at runtime as a developer can hardly know what runtime value will be in effect without knowing the data.\n\n---\n#### Document Details\n\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\n\n* ID: 8d7b6ec7-078a-9f61-3250-ceba1a3a1846\n* Version Independent ID: 13902a2a-592f-a075-a68e-b09002f8e714\n* Content: [LightGbmBinaryTrainer.Options.WeightOfPositiveExamples Field (Microsoft.ML.Trainers.LightGbm)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lightgbm.lightgbmbinarytrainer.options.weightofpositiveexamples?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmBinaryTrainer+Options.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers.LightGbm/LightGbmBinaryTrainer+Options.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/3817","RelatedDescription":"Closed issue \"how will you know this at the time of coding...\" (#3817)"},{"Id":"453168729","IsPullRequest":true,"CreatedAt":"2019-06-06T18:09:46","Actor":"codemzs","Number":"3834","RawContent":null,"Title":"Move Time Series, TensorFlow and OnnxConverter nugets to stable project","State":"open","Body":"fixes #3833\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3834","RelatedDescription":"Open PR \"Move Time Series, TensorFlow and OnnxConverter nugets to stable project\" (#3834)"},{"Id":"453168427","IsPullRequest":false,"CreatedAt":"2019-06-06T18:08:58","Actor":"codemzs","Number":"3833","RawContent":null,"Title":"Move Time Series, TensorFlow and OnnxConverter nugets to stable project.","State":"open","Body":"We plan to GA them in 1.2 release.","Url":"https://github.com/dotnet/machinelearning/issues/3833","RelatedDescription":"Open issue \"Move Time Series, TensorFlow and OnnxConverter nugets to stable project.\" (#3833)"},{"Id":"452666106","IsPullRequest":true,"CreatedAt":"2019-06-06T12:14:33","Actor":"shmoradims","Number":"3831","RawContent":null,"Title":"Add default and missing value definitions for ML.NET types","State":"closed","Body":"Fixes #3443.\r\n\r\nThis PR has two related parts:\r\n\r\n1) Add default and missing values definitions. DataKind page, seems the best place to have all of that information in one place. The documented definitions come from [IsNa region](https://github.com/dotnet/machinelearning/blob/2960b273ee0eda1d3a285a4b46a58a4d6d7b6926/src/Microsoft.ML.Data/Data/Conversion.cs#L739) and [IsDefault region](https://github.com/dotnet/machinelearning/blob/2960b273ee0eda1d3a285a4b46a58a4d6d7b6926/src/Microsoft.ML.Data/Data/Conversion.cs#L749).\r\n\r\n2) Fix the docs of CountFeatureSelectingEstimator to include missing value in addition to default value. Previously, we incorrectly thought only non-default values matter. But digging into [the code](https://github.com/dotnet/machinelearning/blob/5163413f3cfab430e49f6fb2a690c160fde46b58/src/Microsoft.ML.Transforms/CountFeatureSelection.cs#L433), it's clear that the check is for non-default AND non-missing.","Url":"https://github.com/dotnet/machinelearning/pull/3831","RelatedDescription":"Closed or merged PR \"Add default and missing value definitions for ML.NET types\" (#3831)"},{"Id":"452239328","IsPullRequest":true,"CreatedAt":"2019-06-06T00:32:09","Actor":"daholste","Number":"3823","RawContent":null,"Title":"[AutoML] Enable style cop rules & resolve errors","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3823","RelatedDescription":"Closed or merged PR \"[AutoML] Enable style cop rules & resolve errors\" (#3823)"},{"Id":"452731072","IsPullRequest":false,"CreatedAt":"2019-06-05T21:43:53","Actor":"shmoradims","Number":"3832","RawContent":null,"Title":"Add an example for key type's missing value","State":"open","Body":"Related to #3831. Add an in-memory example to explain key type's missing value 0.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3832","RelatedDescription":"Open issue \"Add an example for key type's missing value\" (#3832)"},{"Id":"452176125","IsPullRequest":true,"CreatedAt":"2019-06-05T19:32:07","Actor":"daholste","Number":"3821","RawContent":null,"Title":"Add AutoML as a best friend assembly to Microsoft.ML.Core","State":"closed","Body":"This resolves https://github.com/dotnet/machinelearning/issues/3813 for AutoML","Url":"https://github.com/dotnet/machinelearning/pull/3821","RelatedDescription":"Closed or merged PR \"Add AutoML as a best friend assembly to Microsoft.ML.Core\" (#3821)"},{"Id":"451719517","IsPullRequest":false,"CreatedAt":"2019-06-05T19:32:07","Actor":"daholste","Number":"3813","RawContent":null,"Title":"Can we make NeedCalibration property of TrainerInfo public?","State":"closed","Body":"Could we make the `NeedCalibration` property in `TrainerInfo` public?\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7ca768a8740c5c873c7f26f2c71e0fa3ea28ea40/src/Microsoft.ML.Core/Prediction/TrainerInfo.cs#L30\r\n\r\nThis would help AutoML know when & when not to calibrate","Url":"https://github.com/dotnet/machinelearning/issues/3813","RelatedDescription":"Closed issue \"Can we make NeedCalibration property of TrainerInfo public?\" (#3813)"},{"Id":"452659656","IsPullRequest":false,"CreatedAt":"2019-06-05T18:43:22","Actor":"Ianpwest","Number":"3830","RawContent":null,"Title":"Fit() never returns when running in an ASP.NET MVC Full .NET Framework 4.6.1 / 4.7.2","State":"open","Body":"When running the sentiment analysis sample this line never returns. No exception is thrown.\r\n`// STEP 4: Train the model fitting to the DataSet\r\n            ITransformer trainedModel = trainingPipeline.Fit(trainingData);`\r\n\r\nThis is not the case in .net core web apps or .NET Framework 4.6.1 console apps. Only MVC.\r\n\r\nYou can recreate the issue by creating a brand new ASP.NET MVC .NET Framework 4.6.1 Web Application. Changing to target x64. Installing the Microsoft.ML nuget and running the sentiment analysis code.\r\n\r\nThanks.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3830","RelatedDescription":"Open issue \"Fit() never returns when running in an ASP.NET MVC Full .NET Framework 4.6.1 / 4.7.2\" (#3830)"},{"Id":"452587012","IsPullRequest":false,"CreatedAt":"2019-06-05T16:03:50","Actor":"baruchiro","Number":"3829","RawContent":null,"Title":"Support dynamic types when working with IDataView","State":"open","Body":"### Issue\r\n\r\nI want to read my data from the `.csv` file. I think it may be done without strongly-typing my objects. In C#, we have two potential abilities: [_Anonymous Types_](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/anonymous-types) and [_Dynamic Types_](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/types/using-type-dynamic). \r\n\r\nI tried to check how the existing code could be adapted, but I could not fully understand the code.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3829","RelatedDescription":"Open issue \"Support dynamic types when working with IDataView\" (#3829)"},{"Id":"452399201","IsPullRequest":false,"CreatedAt":"2019-06-05T09:24:31","Actor":"modios","Number":"3828","RawContent":null,"Title":"Provide access to eigenvalues used for PCA transformation","State":"open","Body":"In PcaTransformer.cs, class TransformInfo has an eigenvectors field. I assume it stores the eigenvectors retrieved from the SVD decomposition. Can we have access to the eigenvalues that the SVD provided.\r\n\r\nI think it might be useful to store and provide the eigenvalues used during the PCA. Is this possible?\r\ni.e I see in Accord you can do something like pca.Eigenvalues. \r\nhttp://accord-framework.net/docs/html/T_Accord_Statistics_Analysis_PrincipalComponentAnalysis.htm\r\n\r\nThank you!\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3828","RelatedDescription":"Open issue \"Provide access to eigenvalues used for PCA transformation\" (#3828)"},{"Id":"452270117","IsPullRequest":true,"CreatedAt":"2019-06-05T01:01:01","Actor":"eerhardt","Number":"3827","RawContent":null,"Title":" Add Microsoft.Extensions.ML integration package.","State":"open","Body":"This package makes it easier to use ML.NET with app models that support Microsoft.Extensions - i.e. ASP.NET and Azure Functions.\r\n\r\nSpecifically it contains functionality for:\r\n\r\n- Dependency Injection\r\n- Pooling PredictionEngines\r\n- Reloading models when the file or URI has changed\r\n- Hooking ML.NET logging to Microsoft.Extensions.Logging\r\n\r\nFix #3239\r\n\r\ncc @glennc - Note that the only major change I made to your code was to remove the `IPredictionEnginePoolBuilder` interface in favor of using a simple class instead.\r\n\r\nAfter this is merged to master, we can remove the `features/IntegrationPackage` branch.","Url":"https://github.com/dotnet/machinelearning/pull/3827","RelatedDescription":"Open PR \" Add Microsoft.Extensions.ML integration package.\" (#3827)"},{"Id":"452254954","IsPullRequest":true,"CreatedAt":"2019-06-05T00:51:15","Actor":"codemzs","Number":"3825","RawContent":null,"Title":"Update readme.","State":"closed","Body":"\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3825","RelatedDescription":"Closed or merged PR \"Update readme.\" (#3825)"},{"Id":"452259513","IsPullRequest":false,"CreatedAt":"2019-06-05T00:07:05","Actor":"Anipik","Number":"3826","RawContent":null,"Title":"String column being getting converted to int","State":"open","Body":"My dataset looks something like this\r\n\r\n```\r\nID\tArea\tTitle\tDescription\r\n\"7\"\tarea-System.Runtime.InteropServices\t\"Splitting XLinq classes into separate files, after rebasing the commits.\"\t\"\"\r\n\"12\"\tarea-System.Runtime.InteropServices\t\"Remove or cache some unnecessary allocations\"\t\"I noticed a few places where allocations were occurring unnecessary: - Across several of the immutable and XML collection types, the ICollection.CopyTo implementations were calling Array.SetValue in a loop; the second parameter to SetValue is a params array, so each iteration of the loop was resulting in allocating a new array... I've lifted that implicit allocation out to be an explicit one before the loop. - In a couple of places in the XML library and the metadata reader, string.Trim\\* was being used, either with an array of the same characters unnecessarily being allocated each time, or an implicitly allocated array of constant chars to fill a params array parameter.  I've replaced those with statically cached arrays. - In a couple of places in the XML library, a string was being constructed around a single character via creating a new char array; I've replaced that with usage of string's ctor that takes a character and a count, avoiding the unnecessary char[] allocation. \"\r\n\"13\"\tarea-System.Runtime.InteropServices\t\"Remove unnecessary unsafe code flag.\"\t\"The Immutable PCL targets platforms that include those that don't support unsafe code. Opening the solution in VS2015 results in a warning in the error list about this. But features that required unsafe code were recently removed so we don't need this flag any more. \"\r\n\"17\"\tarea-System.Xml\t\"Some XPath.XDocument tests are failing\"\t\"Some XPath.XDocument queries have different results than other XPath navigators. This might be an old behavior or newly introduced bug.  Failing tests: build /p=IncludeTraits=ActiveIssue=17 \"\r\n\"20\"\tarea-System.Xml\t\"2 XPath.XDocument tests fail because of lacking feature\"\t\"XPath.XDocument navigator doesn't support MoveToId(string).  Verify if this was ever supported. If it was, verify if we want to support it in the future. If it wasn't move the tests to a different file and remove them from XPath.XDocument.Tests project.  Failing tests: NodeSetFunctionsTest2267 MatchesTest2352  <!--- @huboard:{\"order\":20.0,\"milestone_order\":20,\"custom_state\":\"\"} --> \"\r\n\"22\"\tarea-System.Numerics\t\"Two Numerics Tests are failing only on our CI server\"\t\"Two of the tests in our System.Numerics.Vectors suite are failing only on our CI build server, and potentially only intermittently:  Vector2NormalizeTest1 Vector4NormalizeTest2  Given that these are very similar to other tests which cover a similar edge-case (especially the Vector3 normalization tests, which aren't failing), we will need to investigate why these tests in particular are failing on our build server. This may have been a point-in-time issue as we brought up our build infrastructure, and may not re-surface again. \"\r\n\"36\"\tarea-System.Numerics\t\"SIMD test failures on non-ENU configurations.\"\t\"After pulling both of @adamralph 's pull requests #31 and #32, I'm continuing to see test failures for SIMD on a DEU (German) test environment.  Here's a representative error: d:\\oss\\corefx\\src\\System.Numerics.Vectors\\tests\\GenericVectorTests.cs(545): error : System.Numerics.Tests.GenericVe ctorTests.ToStringCurrencySByte: Assert.Equal() Failure\\r\\nPosition: First difference is at position 8\\r\\nExpected:  <97,00 ?, -108,00 ?, 22,00 ?, 29,00 ?, 49,00 ?, 60,00 ?, 103,00 ?, 58,00 ?, -62,00 ?, -124,00 ?, -117,00 ?, 48,00 ?, 15,00 ?, -35,00 ?, -13,00 ?, -34,00 ?>\\r\\nActual:   <97,00 ?. -108,00 ?. 22,00 ?. 29,00 ?. 49,00 ?. 60,00 ?. 103 ,00 ?. 58,00 ?. -62,00 ?. -124,00 ?. -117,00 ?. 48,00 ?. 15,00 ?. -35,00 ?. -13,00 ?. -34,00 ?> [D:\\oss\\corefx\\bin\\ tools\\fxbuild.proj]  Observe that expected separates elements with a comma, actual separates elements with a dot. \"\r\n\"41\"\tarea-System.Numerics\t\"Quaternion operator overloads should be using the respective methods\"\t\"Quaternion declares a handful of methods to perform addition, subtraction and multiplication, and provides the respective overloads for these operations.  However, instead of re-using the `Add`, `Multiply` etc. methods, the code is re-written in the operator overloads. The operators should be using their respective methods rather than re-declaring the same code.  This is under the assumption that the JIT inlines the methods when they are used in the operator overloads. \"\r\n\"49\"\tarea-Infrastructure\t\"Add Linux/Mac build script\"\t\"A `build.sh` should be added alongside `build.cmd` to build corefx on Linux/Mac. \"\r\n```\r\n\r\n\r\nI want the auto-ml bot to consider the first column as a string but it is always converting it to float column\r\nIt would be nice to have some way of specifying the column types.\r\n\r\ncc @danmosemsft @eerhardt @daholste ","Url":"https://github.com/dotnet/machinelearning/issues/3826","RelatedDescription":"Open issue \"String column being getting converted to int\" (#3826)"},{"Id":"452253218","IsPullRequest":true,"CreatedAt":"2019-06-05T00:06:15","Actor":"codemzs","Number":"3824","RawContent":null,"Title":"Update API compat version number to 1.1.0 for stable release packages","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3824","RelatedDescription":"Closed or merged PR \"Update API compat version number to 1.1.0 for stable release packages\" (#3824)"},{"Id":"452216686","IsPullRequest":false,"CreatedAt":"2019-06-04T21:29:04","Actor":"najeeb-kazmi","Number":"3822","RawContent":null,"Title":"LightGbm default evaluation metrics in ML.NET do not conform to standalone LightGbm","State":"open","Body":"Found while investigating fix for #3761 \r\n\r\nIn ML.NET LightGbm wrapper, the default EvaluationMetric is set to EvaluateMetricType.Error for multiclass, EvaluationMetricType.LogLoss for binary, and so on. On the other hand, in standalone LightGbm, the default evaluation metric is \"\", which means that LightGbm will automatically select the default metric for the given objective function.\r\n\r\nThis leads to inconsistent behavior from the user's perspective: If a user specified EvaluationMetric = EvaluateMetricType.Default, the parameter passed to LightGbm would be the empty string \"\" but if they do not specify EvaluationMetric at all, the parameter passed to LightGbm would be Error for multiclass, LogLoss for binary, and so on.\r\n\r\nWe need to investigate whether these metrics are indeed the defaults for the respective objective functions in LightGbm, and if they are not, then change the defaults in ML.NET to conform to standalone LightGbm. Note that this would be a breaking change.","Url":"https://github.com/dotnet/machinelearning/issues/3822","RelatedDescription":"Open issue \"LightGbm default evaluation metrics in ML.NET do not conform to standalone LightGbm\" (#3822)"},{"Id":"452151777","IsPullRequest":true,"CreatedAt":"2019-06-04T20:59:39","Actor":"codemzs","Number":"3819","RawContent":null,"Title":"NativeAssemblyReference Include \"MklProxyNative\" in Samples project.","State":"closed","Body":"fixes #3818\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3819","RelatedDescription":"Closed or merged PR \"NativeAssemblyReference Include \"MklProxyNative\" in Samples project.\" (#3819)"},{"Id":"452151473","IsPullRequest":false,"CreatedAt":"2019-06-04T20:59:39","Actor":"codemzs","Number":"3818","RawContent":null,"Title":"NativeAssemblyReference Include \"MklProxyNative\" in Samples project.","State":"closed","Body":"Need to the above dependency to have some timer series samples work that use MKL ","Url":"https://github.com/dotnet/machinelearning/issues/3818","RelatedDescription":"Closed issue \"NativeAssemblyReference Include \"MklProxyNative\" in Samples project.\" (#3818)"},{"Id":"451720642","IsPullRequest":true,"CreatedAt":"2019-06-04T19:14:52","Actor":"daholste","Number":"3814","RawContent":null,"Title":"Expose NeedCalibration property of TrainerInfo","State":"closed","Body":"Closes https://github.com/dotnet/machinelearning/issues/3813","Url":"https://github.com/dotnet/machinelearning/pull/3814","RelatedDescription":"Closed or merged PR \"Expose NeedCalibration property of TrainerInfo\" (#3814)"},{"Id":"452158821","IsPullRequest":true,"CreatedAt":"2019-06-04T19:05:45","Actor":"daholste","Number":"3820","RawContent":null,"Title":"For binary classification, discard cross validation splits where there is not at least one true & one false label in the validation set","State":"open","Body":"For binary classification, discard cross validation splits where there is not at least one true & one false label in the validation set. Otherwise, scoring the dataset crashes because AUC cannot be computed like in https://github.com/dotnet/machinelearning/issues/3800","Url":"https://github.com/dotnet/machinelearning/pull/3820","RelatedDescription":"Open PR \"For binary classification, discard cross validation splits where there is not at least one true & one false label in the validation set\" (#3820)"},{"Id":"451946297","IsPullRequest":false,"CreatedAt":"2019-06-04T11:37:53","Actor":"cemicel","Number":"3816","RawContent":null,"Title":"System.ArgumentException: 'Length of memory  must match product of dimensions.","State":"open","Body":"- windows 10\r\n- 4.7.NET Version  \r\n- ML dotnet 1.0\r\n- Visual Studio 15.9.12\r\n\r\nIssue:\r\n\r\nI'm quite new to .net, however I'm trying to replicate CRNN model developed on keras to ML dotnet. I successfully converted the model to onnx format. But when I try to make a prediction I'm getting this:\r\n _System.ArgumentException: 'Length of memory (9600) must match product of dimensions (3200).'_\r\nI didn't find any issue or something so that is way I'm writing here.\r\n\r\nI can assume that the problem might be somewhere in image transformation. My model is built for grayscale images with the shape of (1, 1, 32, 100) and there I have this conflict between:\r\n1x32x100 = 3200 (should be)  vs  3x32x100 = 9600 (actually is)\r\n\r\nI've tried to transform images to grayscale, but it doesn't work (perhaps I do it in a wrong way).\r\n\r\nThis is my snipped code for building the pipeline:\r\n\r\n`\r\n\r\n        int imageHeight = 32;\r\n        int imageWidth = 100;\r\n        bool ChannelsLast = false;\r\n        string ModelInput = \"conv2d_1_input_01\";\r\n        string ModelOutput = \"dense_1_add_0\";\r\n\r\n\r\n        var pipeline = mLContext.Transforms.LoadImages(outputColumnName: \"conv2d_1_input_01\",\r\n                                                           imageFolder: imagesLocation,\r\n                                                           inputColumnName: nameof(ImageData.ImagePath))\r\n            .Append(mLContext.Transforms.ResizeImages(outputColumnName: \"conv2d_1_input_01\",\r\n                                                            imageWidth: imageWidth,\r\n                                                            imageHeight: imageHeight))\r\n            .Append(mLContext.Transforms.ConvertToGrayscale(outputColumnName:\r\n                                                            \"conv2d_1_input_01\"))\r\n            .Append(mLContext.Transforms.ExtractPixels(outputColumnName: \"conv2d_1_input_01\", interleavePixelColors: ImageSettings.ChannelsLast))\r\n            .Append(mLContext.Transforms.ApplyOnnxModel(modelFile: modelLocation,\r\n                                                            outputColumnNames: new[] { ModelOutput },\r\n                                                            inputColumnNames: new[] { ModelInput }));\r\n`\r\n\r\nI would appreciate any help or comments.","Url":"https://github.com/dotnet/machinelearning/issues/3816","RelatedDescription":"Open issue \"System.ArgumentException: 'Length of memory  must match product of dimensions.\" (#3816)"},{"Id":"451744537","IsPullRequest":true,"CreatedAt":"2019-06-04T00:28:35","Actor":"najeeb-kazmi","Number":"3815","RawContent":null,"Title":"Fix the treatment of LightGbm Evaluation Metric parameters in ML.NET …","State":"open","Body":"…and make them conform to LightGbm\r\n\r\nFixes #3761 plus some related issues discovered during investigation\r\n\r\n1. There was a bug in LightGbm `EvaluateMetricType` where if a user specified `EvaluateMetricType.Default`, the metric would not get added to the options Dictionary, and `LightGbmWrappedTraining` would throw because of that. \r\n\r\n2. Secondly, `EvaluateMetricType.Default` in LightGbm is supposed to be an empty string \"\" and LightGbm chooses the default metric according to the problem type when this is specified. This was not present in ML.NET parameter name mappings. `EvaluateMetricType.None` is supposed to be \"None\" in LightGbm but was \"\" in ML.NET parameter name mappings.\r\n\r\n3. [**Update: REVERTED**] Third, in ML.NET, the default `EvaluationMetric` is set to `EvaluateMetricType.Error` for multiclass, `EvaluationMetricType.LogLoss` for binary, and so on. This leads to inconsistent behavior from the user's perspective: If a user specified `EvaluationMetric = EvaluateMetricType.Default`, the parameter passed to LightGbm would be the empty string \"\" but if they do not specify `EvaluationMetric` at all, the parameter passed to LightGbm would be Error for multiclass, LogLoss for binary, and so on.\r\n\r\nThis PR does the following:\r\n- Fixes the bug in (1)\r\n- Addresses (2) by adding all the parameters to the options dictionary with the correct values (i.e. conforming to LightGbm [docs](https://lightgbm.readthedocs.io/en/latest/Parameters.html#metric-parameters)\r\n- [**Update: REVERTED**] Addresses (3) by changing the default `EvaluationMetric` in ML.NET to `EvaluationMetricType.Default`\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3815","RelatedDescription":"Open PR \"Fix the treatment of LightGbm Evaluation Metric parameters in ML.NET …\" (#3815)"},{"Id":"451649636","IsPullRequest":true,"CreatedAt":"2019-06-03T22:59:29","Actor":"abgoswam","Number":"3809","RawContent":null,"Title":"Check for number of input columns in concat transform","State":"closed","Body":"Fixes #3061 \r\n\r\nThe PR makes the following changes:\r\n- Follows Solution A mentioned in the issue\r\n- Added a unit test \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3809","RelatedDescription":"Closed or merged PR \"Check for number of input columns in concat transform\" (#3809)"},{"Id":"451712771","IsPullRequest":true,"CreatedAt":"2019-06-03T22:13:25","Actor":"wschin","Number":"3812","RawContent":null,"Title":"Tree-based featurization","State":"open","Body":"Fix #2482. Generating features using tree structure has been a popular technique in data mining. This PR exposes this internal-only feature to the public.\r\n\r\nSince I don't have enough time to handle multiple different assignments at the same time, please don't put nit comments and create new issues instead. Thanks a lot.","Url":"https://github.com/dotnet/machinelearning/pull/3812","RelatedDescription":"Open PR \"Tree-based featurization\" (#3812)"},{"Id":"451702484","IsPullRequest":false,"CreatedAt":"2019-06-03T22:08:12","Actor":"nicolehaugen","Number":"3811","RawContent":null,"Title":"CreateTextLoader isn't respecting the KeyType attribute","State":"closed","Body":"### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.503\r\n Commit:    4c506e0f35\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.14393\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.503\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.7\r\n  Commit:  cca5d72d48\r\n\r\n.NET Core SDKs installed:\r\n  2.1.503 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n\r\n### Issue\r\n\r\nI used LoadFromTextFile to load data where the loaded poco object has the KeyType attribute applied as follows:\r\n\r\n   private class DataPoint\r\n        {\r\n            [LoadColumn(0), KeyType(5)]\r\n            public uint Label { get; set; }\r\n            [LoadColumn(1), KeyType(100)]\r\n            public uint GroupId { get; set; }\r\n            [LoadColumn(2,52), VectorType(50)]\r\n            public float[] Features { get; set; }\r\n        }\r\n\r\nWhen I call Fit using the LightGbm algorithm, I see the following exception because the KeyType attribute isn't being respected when loading from a text file:\r\n\r\nSystem.ArgumentOutOfRangeException  HResult=0x80131502\r\n  Message=Schema mismatch for label column 'Label': expected Single or Key, got UInt32\r\nParameter name: labelCol\r\n  Source=Microsoft.ML.LightGbm\r\n  StackTrace:\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer.<>c__DisplayClass9_0.<CheckLabelCompatible>b__0() in E:\\A\\_work\\449\\s\\src\\Microsoft.ML.LightGbm\\LightGbmRankingTrainer.cs:line 240\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer.CheckLabelCompatible(Column labelCol) in E:\\A\\_work\\449\\s\\src\\Microsoft.ML.LightGbm\\LightGbmRankingTrainer.cs:line 246\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.CheckInputSchema(SchemaShape inputSchema)\r\n\r\nInstead, the KeyType attribute should be respected when loading from a text file.\r\n\r\n### Source code / logs\r\nRun the attached code which uses the attached data.\r\n[SampleKeyRepro.txt](https://github.com/dotnet/machinelearning/files/3249574/SampleKeyRepro.txt)\r\n\r\n[MyTestData.txt](https://github.com/dotnet/machinelearning/files/3249578/MyTestData.txt)\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3811","RelatedDescription":"Closed issue \"CreateTextLoader isn't respecting the KeyType attribute\" (#3811)"},{"Id":"451661805","IsPullRequest":false,"CreatedAt":"2019-06-03T19:57:36","Actor":"prathyusha12345","Number":"3810","RawContent":null,"Title":"why sampling key column is being added while Loading IDataView from Dataset stored Database ","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n### Issue\r\n\r\n- I am trying to create a sample to load data stored in SQL Server database. while loading data from database using mlContext.Data.TrainTestSplit(dataView) method, it adds a column called **SamplingKeyColumn**.  But this column is not added while **loading data from file**. \r\n\r\nI want to understand why this **SamplingKeyColumn** column is being added while loading from **Database**  but not while loading from file.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3810","RelatedDescription":"Open issue \"why sampling key column is being added while Loading IDataView from Dataset stored Database \" (#3810)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-06-07T05:30:37.848781Z","RunDurationInMilliseconds":786}