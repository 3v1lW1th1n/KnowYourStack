{"Data":{"GitHub":{"Issues":[{"Id":"490566509","IsPullRequest":true,"CreatedAt":"2019-09-07T00:14:25","Actor":"harishsk","Number":"4188","RawContent":null,"Title":"Added Onnx export functionality to PCATransformer","State":"open","Body":"Fixes #4186 ","Url":"https://github.com/dotnet/machinelearning/pull/4188","RelatedDescription":"Open PR \"Added Onnx export functionality to PCATransformer\" (#4188)"},{"Id":"490566314","IsPullRequest":true,"CreatedAt":"2019-09-07T00:13:06","Actor":"bpstark","Number":"4187","RawContent":null,"Title":"Modified how DataViewTypes are registered","State":"open","Body":"The DataViewManager registers DataViewTypes to determine how to\r\nrepresent the the data within ML.Net. However, there was a bug in how\r\ntypes were being queried. Types that were being registered via an\r\nAttribute were being added to the manager with only that Attribute.\r\nHowever, when queried from the manager all custom Attributes were being\r\npassed.\r\nTo solve this we need to only pass custom Attributes that are relevant\r\nto the Manager. All Type attributes now inherit from a single\r\nTypeAttribute class such that we can filter custom attributes for\r\nrelevant types.\r\n\r\nFixes #4121\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4187","RelatedDescription":"Open PR \"Modified how DataViewTypes are registered\" (#4187)"},{"Id":"490566177","IsPullRequest":false,"CreatedAt":"2019-09-07T00:12:00","Actor":"harishsk","Number":"4186","RawContent":null,"Title":"PCA Transformer does not support exporting to Onnx","State":"open","Body":"- **What did you do?**\r\nCreated a pipeline from with PCATranfsform and tried to export it to Onnx with - ConvertToOnnxProtobuf.\r\n\r\n- **What happened?**\r\nThe transform wasn't saved in the onnx graph\r\n\r\n- **What did you expect?**\r\nThe transform should be saved in the onnx graph\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4186","RelatedDescription":"Open issue \"PCA Transformer does not support exporting to Onnx\" (#4186)"},{"Id":"487288045","IsPullRequest":true,"CreatedAt":"2019-09-06T22:11:45","Actor":"harishsk","Number":"4161","RawContent":null,"Title":"Added onnx export functionality for LpNormNormalizingTransformer","State":"closed","Body":"Fixes #4159 ","Url":"https://github.com/dotnet/machinelearning/pull/4161","RelatedDescription":"Closed or merged PR \"Added onnx export functionality for LpNormNormalizingTransformer\" (#4161)"},{"Id":"487283571","IsPullRequest":false,"CreatedAt":"2019-09-06T22:11:45","Actor":"harishsk","Number":"4159","RawContent":null,"Title":"LpNormNormalizingTransformer does not support exporting to Onnx","State":"closed","Body":"- **What did you do?**\r\nCreated a pipeline from NormalizeLpNorm and tried to export it to Onnx with ConvertToOnnxProtobuf. \r\n\r\n- **What happened?**\r\nThe transform wasn't saved in the onnx graph\r\n\r\n- **What did you expect?**\r\nThe transform should be saved in the onnx graph\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4159","RelatedDescription":"Closed issue \"LpNormNormalizingTransformer does not support exporting to Onnx\" (#4159)"},{"Id":"490490534","IsPullRequest":false,"CreatedAt":"2019-09-06T19:36:54","Actor":"nicolehaugen","Number":"4185","RawContent":null,"Title":"Checkpoint method should be renamed to SaveCheckpoint","State":"open","Body":"ML.NET 1.3\r\n\r\nWhen working with Time Series\\SSA Forecasting, the method that is used for saving a model is called \"Checkpoint\":\r\n\r\n```Csharp\r\nforecastEngine.CheckPoint(mlContext, outputModelPath);\r\n```\r\n\r\nInstead, this method would be more intuitive if it were named according to a verb\\action - such as SaveCheckpoint().\r\n\r\nNote that this is also feedback from Cesar.","Url":"https://github.com/dotnet/machinelearning/issues/4185","RelatedDescription":"Open issue \"Checkpoint method should be renamed to SaveCheckpoint\" (#4185)"},{"Id":"490486888","IsPullRequest":false,"CreatedAt":"2019-09-06T19:26:45","Actor":"nicolehaugen","Number":"4184","RawContent":null,"Title":"Time Series - SSA Forecasting: Need to add API for performing calculations for comparing real vs. forecasted values","State":"open","Body":"ML.NET 1.3\r\n\r\nCurrently ML.NET doesn't provide any methods in the API for calculating accuracy of forecasted values compared to real observed values - this is when doing Time Series forecasting using SSA.\r\n\r\nIn looking at the [existing TLC documentation](https://microsoft.sharepoint.com/teams/TLC/SitePages/Time-series/Methodology.aspx), it provided the following calculations - ML.NET should do something similar:\r\n\r\n‚ÄãError Calculat‚Äãor\r\nOnce the expected value is produced by the time-series modeler component, it is compared against the actual observed value for the series at the time step to compute the amount of deviation. This calculation is done by the error calculator component and the result is called the Raw Score. The implicit assumption here is that the higher the absolute value of raw score at a timestamp, the more likely it is that the time-series is exhibiting an anomalous behavior at that timestamp. In TLC, we have implemented 5 error calculation functions that can be chosen by the user depending on the application.‚Äã‚Äã\r\n\r\nSigned Difference\r\nThe difference between the expected value and the observed value (this is the default error calculation function).\r\n \r\nAbsolute Difference\r\nThe absolute difference between the expected value and the observed value.\r\n\r\nSigned Proportion\r\nThe proportional difference between the expected value and the observed value.\r\n\r\nAbsolute Proportion\r\nThe absolute proportional difference between the expected value and the observed value.\r\n\r\nSquared Difference\r\nThe squared difference between the expected value and the observed value.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4184","RelatedDescription":"Open issue \"Time Series - SSA Forecasting: Need to add API for performing calculations for comparing real vs. forecasted values\" (#4184)"},{"Id":"490440860","IsPullRequest":false,"CreatedAt":"2019-09-06T17:50:27","Actor":"aslotte","Number":"4183","RawContent":null,"Title":"Forced shutdown during DNN training","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 version 1803\r\n- **.NET Version (eg., dotnet --info)**: .NET Core v2.2\r\n\r\n### Issue\r\nWhen training a DNN on classifying sounds based on audio spectrograms, with the Resetnet architecture, my computer shutdown. This has happened twice, but not every time I'm training the model. I have a Dell XPS15 with 32 gb of RAM. The only thing I can think of is that my fan cannot keep up (CPU is hitting 100% for 20 min), but I wanted to log it here as an issue in case this is a theme.\r\n\r\n- **What did you do?** I was training a DNN using the MultiClassifier with the Resnet architecture of audio spectrograms\r\n- **What happened?** My computer shutdown (twice)\r\n- **What did you expect?** My computer not to shutdown\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4183","RelatedDescription":"Closed issue \"Forced shutdown during DNN training\" (#4183)"},{"Id":"490440587","IsPullRequest":false,"CreatedAt":"2019-09-06T17:32:15","Actor":"CESARDELATORRE","Number":"4182","RawContent":null,"Title":"[DatabaseLoader] Create higher level convenient methods for DatabaseLoader","State":"open","Body":"As mentioned by Diego, these additions would help by simplifying the API usage for users even further and it should be pretty easy to implement for us: üëç \r\n\r\n@divega commented: https://github.com/dotnet/machinelearning-samples/pull/617#pullrequestreview-284597248\r\n\r\n@CESARDELATORRE, I did a deferred review. The experience seems pretty good. \r\n\r\n1:\r\nAnd I agree with you that it could be even better with some sugar method that loads directly from the arguments of DatabaseSource.\r\n\r\n2:\r\nI can also see other possible shortcuts of similar nature. For example, although DbProviderFactory is the all encompassing root concept if you need everything from an ADO.NET provider, a DbConnection can give you everything but DbConnectionStringBuilder, and it is a much more familiar abstraction for most users than the DbProviderFactory. So, unless you need to manipulate connection strings in a provider agnostic way (not commonly an useful thing to do), you could make the sugar Load method generic on the provider's DbConnection type.\r\nAll in all, I would would love to meet with you and the devs and walk trough the product code and API. It is likely that more things like this will come up.\r\n ","Url":"https://github.com/dotnet/machinelearning/issues/4182","RelatedDescription":"Open issue \"[DatabaseLoader] Create higher level convenient methods for DatabaseLoader\" (#4182)"},{"Id":"490155239","IsPullRequest":false,"CreatedAt":"2019-09-06T06:52:10","Actor":"crperez5","Number":"4181","RawContent":null,"Title":"Provided label column 'Status' was of type Single, but only type Boolean is allowed.","State":"closed","Body":"Hi,\r\n\r\nI'm using AutoML to auto-generate a model.\r\n\r\nInput file looks like the following:\r\n\"V1\",\"V2\",\"V3\",\"V4\",\"Status\"\r\n-86,-66,-66,4,0\r\n-84,-78,-61,65,0\r\n...\r\n\r\nOutput:\r\nFor further learning check: https://aka.ms/mlnet-cli\r\n|     Trainer                              Accuracy      AUC    AUPRC  F1-score  Duration #Iteration             |\r\n[Source=AutoML, Kind=Trace] Channel started\r\nException occured while exploring pipelines:\r\nProvided label column 'Status' was of type Single, but only type Boolean is allowed.\r\nSystem.ArgumentException: Provided label column 'Status' was of type Single, but only type Boolean is allowed.\r\n   at Microsoft.ML.CLI.CodeGenerator.CodeGenerationHelper.GenerateCode()\r\n   at Microsoft.ML.CLI.Program.<>c__DisplayClass1_0.<Main>b__0(NewCommandSettings options)\r\nPlease see the log file for more info.\r\nExiting ...\r\n\r\n\r\nIs this a bug?","Url":"https://github.com/dotnet/machinelearning/issues/4181","RelatedDescription":"Closed issue \"Provided label column 'Status' was of type Single, but only type Boolean is allowed.\" (#4181)"},{"Id":"490129313","IsPullRequest":false,"CreatedAt":"2019-09-06T04:55:46","Actor":"CESARDELATORRE","Number":"4180","RawContent":null,"Title":"[Clustering] Create/Add an additional trainer for Clustering: Affinity Propagation","State":"open","Body":"In ML.NET we currently only have the [KMeansTrainer](https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks#clustering).\r\n\r\nThe main challenge with that clustering trainer is that you need to provide the number of clusters to use (numberOfClusters param also known as k), and that's a very difficult number to figure out. THere are methods that can help, like the Elbow method, but still it is a challenge.\r\n\r\nThere are other clustering algorithms that doesn‚Äôt require in input the number of expected clusters like the **Affinity Propagation** algorithm. \r\nIt is relatively new (Presented in 2007) and it works by measuring the affinity between data items.\r\n\r\nFurther info about it:\r\nhttps://towardsdatascience.com/unsupervised-machine-learning-affinity-propagation-algorithm-explained-d1fef85f22c8 \r\n\r\nThe function that measures affinity between data items is one of the hyperparameters of the algorithm. \r\n\r\n**Affinity Propagation is an unsupervised machine learning algorithm that is particularly well suited for problems where we don‚Äôt know the optimal number of clusters.**\r\n\r\nAs an additional note, consider that K-means was first proposed for application in the field of statistics back in 1955.\r\n\r\nI suggest that, when possible, we implement and offer this additional clustering algorithm, especially when we currently just have one algorithm for Clustering (KMeansTrainer).","Url":"https://github.com/dotnet/machinelearning/issues/4180","RelatedDescription":"Open issue \"[Clustering] Create/Add an additional trainer for Clustering: Affinity Propagation\" (#4180)"},{"Id":"490039346","IsPullRequest":true,"CreatedAt":"2019-09-05T22:29:29","Actor":"LittleLittleCloud","Number":"4179","RawContent":null,"Title":"pack CodeGen into mlnet","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4179","RelatedDescription":"Open PR \"pack CodeGen into mlnet\" (#4179)"},{"Id":"488745561","IsPullRequest":false,"CreatedAt":"2019-09-05T13:24:50","Actor":"dradoaica","Number":"4172","RawContent":null,"Title":"MulticlassClassification: different predict results depending on the environment the train took place","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10/Azure\r\n- **.NET Version (eg., dotnet --info)**: .NET Core v2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI extracted the code from the MulticlassClassification-GitHubLabeler into a Azure WebJob\r\n- **What happened?**\r\nFirst I run it on my local machine (Windows 10) and after I run it in an app service in Azure\r\n- **What did you expect?**\r\nEven though the \"seed\" param of the \"MLContext\" class is set, the predict results are not the same. The model trained on Windows 10 should be the same with the model trained in Azure. ML.NET takes decisions based on the environment (ProcessorCount , Is64BitProcess, etc.)? \r\n### Source code / logs\r\n\r\n[dotnet/machinelearning-samples MulticlassClassification-GitHubLabeler\r\n](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/end-to-end-apps/MulticlassClassification-GitHubLabeler/GitHubLabeler/GitHubLabelerConsoleApp/Program.cs)","Url":"https://github.com/dotnet/machinelearning/issues/4172","RelatedDescription":"Closed issue \"MulticlassClassification: different predict results depending on the environment the train took place\" (#4172)"},{"Id":"489653381","IsPullRequest":false,"CreatedAt":"2019-09-05T10:00:51","Actor":"larsbeck","Number":"4178","RawContent":null,"Title":"TfIdf setting in ProduceNGrams throws Exception","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro\r\n- **.NET Version (eg., dotnet --info)**: 3.0.0-preview8-28405-07\r\n\r\n### Issue\r\nProduceNGrams throws an InvalidOperationException \"The specified documents are all empty in column 'Tokens'\"\r\n\r\n- **What did you do?**\r\nChanged the parameter setting 'weighting' of type 'WeightingCriteria' from the standard 'WeightingCriteria.Tf' to 'WeightingCriteria.TfIdf' and then ran the code again.\r\n\r\n- **What happened?**\r\nThe exception gets thrown as described above\r\n\r\n- **What did you expect?**\r\nThe code, specifically the line 'var transformer = pipeline.Fit(dataview);' to run just as it did with setting WeightingCriteria.Tf.\r\n\r\n### Source code / logs\r\n\r\n```\r\nvar pipeline = _mlContext.Transforms.Text.NormalizeText(nameof(TransformedTextData.NormalizedText),\r\n                nameof(Profile.Text))\r\n                .Append(_mlContext.Transforms.Text.TokenizeIntoWords(nameof(TransformedTextData.Words),\r\n                    nameof(TransformedTextData.NormalizedText)))\r\n                .Append(_mlContext.Transforms.Text.RemoveDefaultStopWords(nameof(TransformedTextData.Words), nameof(TransformedTextData.Words), StopWordsRemovingEstimator.Language.German))\r\n                .Append(_mlContext.Transforms.Text.RemoveStopWords(nameof(TransformedTextData.Words), null, \"kontext\", \"&\"))\r\n                .Append(_mlContext.Transforms.Conversion.MapValueToKey(nameof(TransformedTextData.Tokens), nameof(TransformedTextData.Words)))\r\n                .Append(_mlContext.Transforms.Text.ProduceNgrams(nameof(TransformedTextData.Tokens), weighting: NgramExtractingEstimator.WeightingCriteria.TfIdf))\r\n                .Append(_mlContext.Transforms.Text.LatentDirichletAllocation(\r\n                    nameof(TransformedTextData.Features), nameof(TransformedTextData.Tokens), numberOfTopics: 10, numberOfSummaryTermsPerTopic:10));\r\n\r\n            // Fit to data.\r\n            var transformer = pipeline.Fit(dataview);\r\n```\r\n\r\nDoes ProduceNGrams not support the setting TfIdf as weighting? If it doesn't, which Transformer would one use to generate NGrams for LatentDirichletAllocation ?","Url":"https://github.com/dotnet/machinelearning/issues/4178","RelatedDescription":"Open issue \"TfIdf setting in ProduceNGrams throws Exception\" (#4178)"},{"Id":"489648560","IsPullRequest":false,"CreatedAt":"2019-09-05T09:51:37","Actor":"yaeldekel","Number":"4177","RawContent":null,"Title":"Change the DnnImageFeaturizers packages to use models from the ONNX model zoo","State":"open","Body":"We should use the models from the [model zoo](https://github.com/onnx/models) to ensure compatibility with future versions of ONNX runtime.\r\n\r\nWe should also add tests for these packages, to ensure they work correctly.\r\n\r\n‚Ä¢\tAlexNet\r\n‚Ä¢\tResNet101\r\n‚Ä¢\tResNet50\r\n‚Ä¢\tResNet18\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4177","RelatedDescription":"Open issue \"Change the DnnImageFeaturizers packages to use models from the ONNX model zoo\" (#4177)"},{"Id":"489282428","IsPullRequest":false,"CreatedAt":"2019-09-04T17:03:46","Actor":"vera-dania","Number":"4176","RawContent":null,"Title":"System.AccessViolationException -- Loading tensorflow model","State":"open","Body":"### System information\r\n\r\n- **Windows 10 Pro for Workstations - 1809**:\r\n- **3.0.100-preview3-010431**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am loading a tensorflow model using ML.NET Model.LoadTensorFlowModel method.\r\nReceived this exception:\r\n\r\n- **What happened?**\r\nSystem.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt. I am unable to locate the source of this exception. I only receive this error when running the application in debug mode.\r\n\r\n- **What did you expect?**\r\nMy model to successfully load and be able to make predictions.\r\n\r\n\r\n### Source code / logs\r\n\r\n      var pipline = context.Transforms.Conversion.MapValueToKey(\"LabelKey\", \"Label\")\r\n        .Append(context.Transforms.LoadImages(\"input\", \"images\", nameof(ImageData.ImagePath)))\r\n        .Append(context.Transforms.ResizeImages(\"input\", GenderSettings.ImageHeight, GenderSettings.ImageWidth, \"input\"))\r\n        .Append(context.Model.LoadTensorFlowModel(\"./modelGender/tensorflow_gender__graph.pb\")\r\n          .ScoreTensorFlowModel(new[] {\"cross_entropy\"}, new[] {\"input\"}, addBatchDimensionInput: true))\r\n        .Append(context.Transforms.Conversion.MapKeyToValue(\"PredictedLabelValue\", \"PredictedLabel\"))\r\n        .AppendCacheCheckpoint(context);\r\n\r\n\r\nIt is not showing any stacktrace or log.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4176","RelatedDescription":"Open issue \"System.AccessViolationException -- Loading tensorflow model\" (#4176)"},{"Id":"488769998","IsPullRequest":false,"CreatedAt":"2019-09-04T06:18:51","Actor":"LittleLittleCloud","Number":"4173","RawContent":null,"Title":"Should use dll location instead of app domain in ResNet18/50/128 packages","State":"closed","Body":"We find out that in  `Resnet18Extension.cs`, It uses `AppDomain.CurrentDomain` to get the DLL location, which could causes some unexpected behavior in Vsix packaging. (in Vsix AppDomain.CurrentDomain returns VS executables, which is `C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Preview\\Common7\\IDE`, so it won't be able to find the right onnx file). It's better to use `GetAssembly.Loaction` to get the DLL location. You can see the following PR to see the suggest fix\r\n\r\n#4174 ","Url":"https://github.com/dotnet/machinelearning/issues/4173","RelatedDescription":"Closed issue \"Should use dll location instead of app domain in ResNet18/50/128 packages\" (#4173)"},{"Id":"488770734","IsPullRequest":true,"CreatedAt":"2019-09-04T06:18:40","Actor":"LittleLittleCloud","Number":"4174","RawContent":null,"Title":"Using `GetAssembly` to get DLL loaction in ResNet18","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4174","RelatedDescription":"Closed or merged PR \"Using `GetAssembly` to get DLL loaction in ResNet18\" (#4174)"},{"Id":"488860362","IsPullRequest":false,"CreatedAt":"2019-09-03T22:54:37","Actor":"MattGal","Number":"4175","RawContent":null,"Title":"Don't create local SQL Database files inside the build workspace","State":"open","Body":"Code like this: https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/DatabaseLoaderTests.cs#L170\r\n\r\n(where you're running tests as part of the build) has been leading to, when the build machine is reused, errors like:\r\n```\r\nMsg 5120, Level 16, State 101, Server <machine name>\\LOCALDB#<somehex>, Line 1\r\nUnable to open the physical file \"F:\\workspace.7\\_work\\1\\s\\bin\\AnyCPU.Release-netcoreapp3_0\\Microsoft.ML.Tests\\netcoreapp3.0\\TestDatabases\\iris.mdf\". Operating system error 3: \"3(The system cannot find the path specified.)\".\r\n```\r\n... this is because workspaces are automatically cleaned up (by deletion) but this leaves SQL server in a bad state.  Ideally this shouldn't happen at all, but if it must it'd be good to use the current user's profile directory;  I don't care where other than the workspace folder is not a good place for it.  This happens even to other teams' builds who also test using local SQL DBs \r\n\r\n### System information\r\n\r\n- **OS version/distro**:  Windows Client and Server\r\n- **.NET Version (eg., dotnet --info)**:  All (test bug)\r\n\r\n### Issue\r\n\r\n- **What did you do?** : Talk to other teams who need local SQL DBs to work\r\n- **What happened?** : I found the code creating MDF files in a guaranteed-to-be-deleted place\r\n- **What did you expect?** : Testing should occur outside builds.  Failing that, invariant cleanup should happen.  Failing that, put the files outside the workspace directory.\r\n\r\n### Source code / logs\r\n\r\nSee https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/DatabaseLoaderTests.cs#L170.  When run as part of the build, the path this resolves is `bin\\Arch.Config-TargetFramework\\Microsoft.ML.Tests\\netcoreapp3.0\\TestDatabases\\iris.mdf` inside the workspace. ","Url":"https://github.com/dotnet/machinelearning/issues/4175","RelatedDescription":"Open issue \"Don't create local SQL Database files inside the build workspace\" (#4175)"},{"Id":"488435937","IsPullRequest":false,"CreatedAt":"2019-09-03T07:24:19","Actor":"jankozeleny","Number":"4171","RawContent":null,"Title":"Error in Microsoft.ML.Extensions (Attempted to divide by zero.) when running in Azure","State":"open","Body":"### System information\r\n\r\n- Azure AppService\r\n- .NET Core 2.2, 64-bit\r\n\r\n### Issue\r\n\r\nDeploy the unmodified E2E sample https://github.com/dotnet/machinelearning-samples/tree/v1.2/samples/csharp/end-to-end-apps/DeepLearning_ObjectDetection_Onnx\r\ninto Azure AppService.\r\nNote that you must switch to 64-bit because the AppService will not even start (I suppose that this is a problem with Core 2.2 in-process hosting but I am not sure).\r\nAlso you must modifiy the relative path in the Get action in the ObjectDetectionController\r\n`string imageFileRelativePath = @\"assets\" + url;`\r\n\r\n**The code stops at the unhandled division by zero exception** (\"Attempted to divide by zero.\") at line:\r\n`            var probs = model.Predict(imageInputData).PredictedLabels;`\r\nin the ObjectDetectionService in the DetectObjectsUsingModel method.\r\n\r\n**The application runs without problem when running locally.**\r\n\r\nStack trace:\r\n\r\n```\r\n   at Microsoft.ML.OnnxRuntime.NativeMethods.OrtRun(IntPtr session, IntPtr runOptions, String[] inputNames, IntPtr[] inputValues, UInt64 inputCount, String[] outputNames, UInt64 outputCount, IntPtr[] outputValues)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs, IReadOnlyCollection`1 outputNames, RunOptions options)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs, IReadOnlyCollection`1 outputNames)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, INamedOnnxValueGetter[] srcNamedOnnxValueGetters, String[] activeOutputColNames, OnnxRuntimeOutputCacher outputCache)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.<>c__DisplayClass11_0`1.<MakeTensorGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolExtensions.Predict[TData,TPrediction](PredictionEnginePool`2 predictionEnginePool, String modelName, TData example)\r\n   at OnnxObjectDetectionE2EAPP.Services.ObjectDetectionService.DetectObjectsUsingModel(ImageInputData imageInputData) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Services\\ObjectDetectionService.cs:line 29\r\n   at OnnxObjectDetectionE2EAPP.Controllers.ObjectDetectionController.DetectAndPaintImage(ImageInputData imageInputData, String imageFilePath) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Controllers\\ObjectDetectionController.cs:line 125\r\n   at OnnxObjectDetectionE2EAPP.Controllers.ObjectDetectionController.Get(String url) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Controllers\\ObjectDetectionController.cs:line 59\r\n```\r\n\r\nI am now clueless and I even don't know how .NET DivideByZeroException can be raised in the C interop call. Where does it come from?\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4171","RelatedDescription":"Open issue \"Error in Microsoft.ML.Extensions (Attempted to divide by zero.) when running in Azure\" (#4171)"},{"Id":"488337706","IsPullRequest":true,"CreatedAt":"2019-09-02T23:36:10","Actor":"codemzs","Number":"4170","RawContent":null,"Title":"Release notes for 1.4.0-preview and 0.16.0-preview.","State":"open","Body":"\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4170","RelatedDescription":"Open PR \"Release notes for 1.4.0-preview and 0.16.0-preview.\" (#4170)"},{"Id":"488308696","IsPullRequest":false,"CreatedAt":"2019-09-02T20:15:49","Actor":"CESARDELATORRE","Number":"4169","RawContent":null,"Title":"[Image Classification DNN Transfer Learning] - Use PredictedLabel as String/Value instead of an UInt32 (Index))","State":"open","Body":"I think it'd be simpler for users and also consistent with other ML.NET APIs if the returned PredictedLabel is a string/value (categorial value) instead UInt32 (Index).\r\n\r\nThat way, simply by having a .MapKeyToValue() at the end of the pipeline, the user will have it as the value being looked for instead of an index which is what we currently get:\r\n\r\n```\r\n//pipeline code\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: \"Label\" , inputColumnName: \"LabelAsKey\"));\r\n```\r\n\r\nAs currently implemented, when the user is simply predicting in an end-user app, you need to find out the real label value by using code based on the schema API, like this:\r\n\r\n```\r\nvar prediction = predictionEngine.Predict(imageToPredict);\r\n\r\nvar index = prediction.PredictedLabel;\r\n\r\n// Obtain the original label names to map through the predicted label-index\r\nVBuffer<ReadOnlyMemory<char>> keys = default;\r\npredictionEngine.OutputSchema[\"LabelAsKey\"].GetKeyValues(ref keys);\r\nvar originalLabels = keys.DenseValues().ToArray();\r\n\r\nConsole.WriteLine($\"ImageFile : [{Path.GetFileName(imageToPredict.ImagePath)}], \" +\r\n                    $\"Scores : [{string.Join(\",\", prediction.Score)}], \" +\r\n                    $\"Predicted Label : {originalLabels[index]}\");\r\n```\r\n\r\nIf the PredictedLabel was already the string/value, the user won't usually need to use the additional `VBuffer `and `OutputSchema `APIs above.\r\n\r\nAlso, this way would be consistent with other multi-class classification algorithms in ML.NET.","Url":"https://github.com/dotnet/machinelearning/issues/4169","RelatedDescription":"Open issue \"[Image Classification DNN Transfer Learning] - Use PredictedLabel as String/Value instead of an UInt32 (Index))\" (#4169)"},{"Id":"488259360","IsPullRequest":false,"CreatedAt":"2019-09-02T16:20:02","Actor":"CBrauer","Number":"4168","RawContent":null,"Title":"I don't understand these predictions","State":"open","Body":"Hey, \r\n\r\nI'm trying to compute the probabilities of the predictions on my dataset.\r\nI am using the 1.3.1 code at: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog.calibratorscatalog.platt?view=ml-dotnet\r\nMy modified code is as follows:\r\n\r\n```\r\n    public static void Run() {\r\n      var mlContext = new MLContext(0);\r\n      var dataPoints = GetDataPoints(@\"/HedgeTools/Datasets/rocket-train-classify.csv\");\r\n      var trainingData = mlContext.Data.LoadFromEnumerable(dataPoints);\r\n\r\n      var testDataPoints = GetDataPoints(@\"/HedgeTools/Datasets/rocket-test-classify.csv\");\r\n      var testData = mlContext.Data.LoadFromEnumerable(testDataPoints);\r\n\r\n      var options = new FastTreeBinaryTrainer.Options {\r\n        EarlyStoppingMetric = EarlyStoppingMetric.L2Norm, // Use L2Norm for early stopping.\r\n        FeatureFirstUsePenalty = 0.1,  // Create a simpler model by penalizing usage of new features.\r\n        NumberOfTrees = 50\r\n      };\r\n\r\n      var pipeline = mlContext.BinaryClassification.Trainers.FastTree(options);\r\n\r\n      var model = pipeline.Fit(trainingData);\r\n      var transformedTestData = model.Transform(testData);\r\n      var outScores = mlContext.Data.CreateEnumerable<ScoreValue>(transformedTestData,\r\n                                                                  reuseRowObject: false);\r\n      var calibratorEstimator = mlContext.BinaryClassification.Calibrators.Platt();\r\n\r\n      // Convert IDataView object to a list.\r\n      var predictions = mlContext.Data.CreateEnumerable<Prediction>(transformedTestData, false).ToList();\r\n      var calibratorTransformer = calibratorEstimator.Fit(transformedTestData);\r\n      var finalData = calibratorTransformer.Transform(transformedTestData);\r\n      var outScoresAndProbabilities = mlContext.Data.CreateEnumerable<ScoreAndProbabilityValue>(finalData, false);\r\n\r\n      Console.WriteLine(\"\\nFirst 10 acutals that are true\");\r\n      Console.WriteLine(\"Actual Predicted     score   probability\");\r\n      Console.WriteLine(\"------ --------- ----------  -----------\");\r\n      var loop = 1;\r\n      for (var index = 0; index < predictions.Count(); index++) {\r\n        var p1 = predictions.ElementAt(index);\r\n        if (!p1.Label) continue;\r\n        var p2 = outScoresAndProbabilities.ElementAt(index);\r\n        Console.WriteLine(\"{0, 6} {1, 9} {2, 10}  {3, 11}\", p1.Label, p1.PredictedLabel, p2.Score, p2.Probability);\r\n        if (++loop > 10) break;\r\n      }\r\n\r\n      var metrics = mlContext.BinaryClassification.Evaluate(transformedTestData);\r\n      PrintMetrics(metrics);\r\n    }\r\n```\r\n\r\nThe results I get are as follows:\r\n\r\n\r\n```\r\nFirst 10 actuals that are true\r\nActual Predicted     score   probability\r\n------ --------- ----------  -----------\r\n  True     False  -6.288363   0.06514609\r\n  True     False  -7.417452   0.03533126\r\n  True     False  -6.883083    0.0473095\r\n  True      True   2.404708    0.9079463\r\n  True     False  -5.611444   0.09295245\r\n  True      True  0.2836371    0.7465712\r\n  True     False   -1.93054    0.4548629\r\n  True     False  -3.087828    0.3014578\r\n  True      True  0.2553135    0.7435061\r\n  True     False  -5.725763   0.08760489\r\n\r\nAccuracy.............0.912087912087912\r\nAUC..................0.748737797056458\r\nF1 Score.............0.147208121827411\r\nNegative Precision...0.913221503103949\r\nNegative Recall......0.997835185452446\r\nPositive Precision...0.794520547945205\r\nPositive Recall......0.0811188811188811\r\n\r\nTEST POSITIVE RATIO:    0.0935 (715.0/(715.0+6929.0))\r\nConfusion table\r\n          ||======================\r\nPREDICTED || positive | negative | Recall\r\nTRUTH     ||======================\r\n positive ||       58 |      657 | 0.0811\r\n negative ||       15 |    6 914 | 0.9978\r\n          ||======================\r\nPrecision ||   0.7945 |   0.9132 |\r\n\r\n```\r\nThe \"Actual\" column is a \"ground truth label\". \r\nWhy am I getting a False prediction when the probability is less than 0.5?\r\nI'm obviously confused.  Please help.\r\n\r\nCharles\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4168","RelatedDescription":"Open issue \"I don't understand these predictions\" (#4168)"},{"Id":"487955473","IsPullRequest":false,"CreatedAt":"2019-09-02T01:23:17","Actor":"ashgadala","Number":"4167","RawContent":null,"Title":"Price PredictionML add projects adding namespaces with space","State":"open","Body":"when I try to add projects after training the price prediction Model. \r\n\r\nCheck the namespace here with auto generated code.\r\n\r\n\r\n`using Microsoft.ML.Data;\r\n\r\nnamespace **Price PredictionML.**Model.DataModels\r\n{\r\n    public class ModelInput\r\n{\r\n    [ColumnName(\"vendor_id\"), LoadColumn(0)]\r\n    public string Vendor_id { get; set; }\r\n\r\n\r\n    [ColumnName(\"rate_code\"), LoadColumn(1)]\r\n    public float Rate_code { get; set; }\r\n\r\n\r\n    [ColumnName(\"passenger_count\"), LoadColumn(2)]\r\n    public float Passenger_count { get; set; }\r\n\r\n\r\n    [ColumnName(\"trip_time_in_secs\"), LoadColumn(3)]\r\n    public float Trip_time_in_secs { get; set; }\r\n\r\n\r\n    [ColumnName(\"trip_distance\"), LoadColumn(4)]\r\n    public float Trip_distance { get; set; }\r\n\r\n\r\n    [ColumnName(\"payment_type\"), LoadColumn(5)]\r\n    public string Payment_type { get; set; }\r\n\r\n\r\n    [ColumnName(\"fare_amount\"), LoadColumn(6)]\r\n    public float Fare_amount { get; set; }\r\n\r\n\r\n}\r\n}`\r\n\r\n\r\n### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4167","RelatedDescription":"Open issue \"Price PredictionML add projects adding namespaces with space\" (#4167)"},{"Id":"487937641","IsPullRequest":true,"CreatedAt":"2019-09-01T22:26:17","Actor":"LittleLittleCloud","Number":"4166","RawContent":null,"Title":"WIP - Refactor on Code Gen","State":"open","Body":"- [x] refactor on `TransformGenerator` derived Class","Url":"https://github.com/dotnet/machinelearning/pull/4166","RelatedDescription":"Open PR \"WIP - Refactor on Code Gen\" (#4166)"},{"Id":"487923285","IsPullRequest":false,"CreatedAt":"2019-09-01T19:39:51","Actor":"CBrauer","Number":"4165","RawContent":null,"Title":"Please do an example","State":"open","Body":"Please do an example of how the probability is computed and used.\n\n---\n#### Document Details\n\n‚ö† *Do not edit this section. It is required for docs.microsoft.com ‚ûü GitHub issue linking.*\n\n* ID: 79a06280-21c8-0ae1-c5d0-17ef5d8d6774\n* Version Independent ID: 4047f033-7557-9533-7626-2c8aeafce38b\n* Content: [DatasetUtils.CalibratedBinaryClassifierOutput.Probability Field (Microsoft.ML.SamplesUtils)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.samplesutils.datasetutils.calibratedbinaryclassifieroutput.probability?view=ml-dotnet-preview)\n* Content Source: [dotnet/xml/Microsoft.ML.SamplesUtils/DatasetUtils+CalibratedBinaryClassifierOutput.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.SamplesUtils/DatasetUtils+CalibratedBinaryClassifierOutput.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/4165","RelatedDescription":"Open issue \"Please do an example\" (#4165)"},{"Id":"487642015","IsPullRequest":false,"CreatedAt":"2019-08-30T19:39:44","Actor":"luisquintanilla","Number":"4164","RawContent":null,"Title":"[Object Detection] Internalize Model Pre/Post-Processing","State":"open","Body":"When doing object detection (especially on pre-trained models), there are some pre-processing and post-processing steps that are required to get the input in the format expected by the model as well as to make sense of the output. Ultimately, while these steps are required to prepare the data and interpret the outputs, they are not directly related to the training / prediction task. With state-of-the-art models, this process is mainly boiler-plate and writing the code is often left up to the user to implement every time. A good example of this can be seen when making predictions using the Tiny YOLOv2 pre-trained model. \r\n\r\n[Create Parser](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-onnx#create-a-parser-to-post-process-model-outputs)\r\n\r\nIn this tutorial, a significant portion is boilerplate code to create a parser that extracts the values output by the model (1-D Tensor into bounding box dimensions, confidence score and class probabilities). Internalizing some of these steps as part of a high-level API, especially for pre-trained state-of-the-art models where the inputs / outputs are well-defined would make it easier for users to use these types of models.  \r\n\r\n__Problem:__\r\n\r\n- Pre-Processing/Post-Processing boilerplate code is required when performing object detection to prepare input/output for the model. Although the process is model-specific, the expected inputs and outputs have already been pre-defined for state-of-the-art pre-trained models. Therefore, it doesn't make sense to keep re-writing the same code every time when it is already a solved problem.\r\n- No consistent way to interpret model outputs\r\n\r\n__Proposal:__\r\n\r\n- Internalize pre-processing/post-processing boiler plate code as part of high-level API\r\n\t- Provide option for user to select the model architecture (i.e. SSD, YOLO, Fast R-CNN) they're interested in using to train / score with. Based on the selection, the appropriate pre-processing/post-processing transformations will take place to produce a simple and consistent output for the user. \r\n- Provide a consistent way to interpret outputs\r\n\t- Currently, models like binary classification have output column names (i.e. PredictedLabel, Probability, Score) that the user can access to get the result of training/scoring. Something similar should exist for object detection models. Typical output features include the dimensions of the bounding boxes detected, the probabilities or labels of objects detected in the bounding boxes and the confidence that there is an object inside the bounding box. These could be made available as part of the output schema for the user to access once the scored output produced by the model is post-processed.\r\n\r\n__Resources:__\r\n\r\nTF provides an object detection API which allows the user to extract the class probabilities, bounding box dimensions and objectness scores from the model outputs. \r\n\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\r\nhttps://github.com/tensorflow/models/tree/master/research/object_detection\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\r\n\r\nWindows ML uses LearningModelEvaluationResult which the user can extract the respective outputs from the model. In the case of ML.NET, this could expose the output schema for an object detection prediction.\r\n\r\nhttps://docs.microsoft.com/en-us/windows/ai/windows-ml/evaluate-model-inputs - \r\nhttps://docs.microsoft.com/en-us/uwp/api/windows.ai.machinelearning.learningmodelevaluationresult","Url":"https://github.com/dotnet/machinelearning/issues/4164","RelatedDescription":"Open issue \"[Object Detection] Internalize Model Pre/Post-Processing\" (#4164)"},{"Id":"487616633","IsPullRequest":true,"CreatedAt":"2019-08-30T18:29:14","Actor":"LittleLittleCloud","Number":"4163","RawContent":null,"Title":"Image featurization","State":"closed","Body":"\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4163","RelatedDescription":"Closed or merged PR \"Image featurization\" (#4163)"},{"Id":"487363555","IsPullRequest":true,"CreatedAt":"2019-08-30T14:05:07","Actor":"Adishone","Number":"4162","RawContent":null,"Title":"Fixed typo in ML.NET Cookbook","State":"closed","Body":"Fixing one small typo\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4162","RelatedDescription":"Closed or merged PR \"Fixed typo in ML.NET Cookbook\" (#4162)"},{"Id":"487285402","IsPullRequest":true,"CreatedAt":"2019-08-30T04:55:54","Actor":"harishsk","Number":"4160","RawContent":null,"Title":"Added export functionality for LpNormNormalizingTransformer","State":"closed","Body":"Fixes #4159 ","Url":"https://github.com/dotnet/machinelearning/pull/4160","RelatedDescription":"Closed or merged PR \"Added export functionality for LpNormNormalizingTransformer\" (#4160)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-09-07T05:30:41.8591835Z","RunDurationInMilliseconds":1061}