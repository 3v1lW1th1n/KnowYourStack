{"Data":{"GitHub":{"Issues":[{"Id":"468421139","IsPullRequest":false,"CreatedAt":"2019-07-16T02:55:06","Actor":"Dmitry-A","Number":"4008","RawContent":null,"Title":"[AutoML] bring AutoML API code into master from feature branch","State":"open","Body":"We have been working out of a features/automl branch.  CLI is going to stay there for now but we want to bring API nuget into master.","Url":"https://github.com/dotnet/machinelearning/issues/4008","RelatedDescription":"Open issue \"[AutoML] bring AutoML API code into master from feature branch\" (#4008)"},{"Id":"468218125","IsPullRequest":true,"CreatedAt":"2019-07-16T00:01:31","Actor":"wangyems","Number":"4002","RawContent":null,"Title":"fixes #3992,  when inputColumnNames is not provided, it is set to new[] { outputColumnName }. and part of #3994(making SlotDroppingTransfomer exposed as public)","State":"closed","Body":"fixes #3992 and part of #3994(making SlotDroppingTransfomer exposed as public)\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4002","RelatedDescription":"Closed or merged PR \"fixes #3992,  when inputColumnNames is not provided, it is set to new[] { outputColumnName }. and part of #3994(making SlotDroppingTransfomer exposed as public)\" (#4002)"},{"Id":"468346816","IsPullRequest":true,"CreatedAt":"2019-07-15T21:36:19","Actor":"RadicalRayan","Number":"4007","RawContent":null,"Title":"Stop LightGbm Warning for Default Metric Input [Issue #3965 Fix]","State":"open","Body":"Issue #3965 reported that a warning, \"LightGBM] [Warning] Unknown parameter metric=\" is produced when the default metric is used. This warning came after this [commit](https://github.com/dotnet/machinelearning/pull/3859) which aimed to provide a consistent user experience from an ML.NET implementation of LightGbm with standalone LightGbm. If a user were to set `EvaluationMetric = EvaluateMetricType.Default`, they might expect that this would set the EvaluationMetric to \"\" and assigned the metric based on the objective as shown in the LightGbm docs. When the correction was made, this warning began to appear when the metric parameter was set to \"\". which was also being produced in LightGbm alone. The only way to prevent this error would be to not assign a parameter to the metric at all.\r\n\r\nThis warning has not appeared in previous versions of ML.NET and can be prevent by assigning the correct metric based on the objective as was previously done.\r\n\r\nTo prevent this warning, the changes from this [commit](https://github.com/dotnet/machinelearning/pull/3859) were reverted.","Url":"https://github.com/dotnet/machinelearning/pull/4007","RelatedDescription":"Open PR \"Stop LightGbm Warning for Default Metric Input [Issue #3965 Fix]\" (#4007)"},{"Id":"468340302","IsPullRequest":true,"CreatedAt":"2019-07-15T21:18:44","Actor":"PranovD","Number":"4006","RawContent":null,"Title":"Cleanuptodate","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4006","RelatedDescription":"Closed or merged PR \"Cleanuptodate\" (#4006)"},{"Id":"468318774","IsPullRequest":false,"CreatedAt":"2019-07-15T20:25:11","Actor":"nicolehaugen","Number":"4005","RawContent":null,"Title":"Provide a way to append\\concatentate multiple IDataViews","State":"open","Body":"### System information\r\n\r\n- ML.NET - 1.2.0: \r\n\r\n### Issue\r\n\r\nThere should be a way to append or concatenate multiple IDataViews together.\r\n\r\nHere's the scenario:\r\nThe [new ranking sample](https://github.com/dotnet/machinelearning-samples/pull/549) needs the ability to train the model using two datasets that are each loaded from a separate text file and have the same schema - specifically, there is a (1) Training dataset and (2) Validation dataset, that need to be combined.  For example, refer to step #3 in the steps outlined below which the sample is based on.\r\n\r\nHere's the steps shown in the sample - generally, the pattern to train, validate, and test a model includes the following steps:\r\n1. The model is trained on the **training** dataset.  The model's metrics are then evaluated using the **validation** dataset.\r\n2. Step #1 is repeated by retraining and reevaluating the model until the desired metrics are achieved.  The outcome of this step is a pipeline that applies the necessary data transformations and trainer.\r\n3. The pipeline is used to train on the combined **training** + **validation** datasets.  The model's metrics are then evaluated on the **testing** dataset (exactly once) -- this is the final set of metrics used to measure the model's quality.\r\n4. The final step is to retrain the pipeline on **all** of the combined **training** + **validation** +  **testing** datasets.  This model is then ready to be deployed into production.\r\n\r\nToday to achieve this, the sample has to first load the data from a text file, then create an enumerable so that the datasets can be concatenated - this process would be greatly simplified if you could append/concatenate two IDataViews together:\r\n\r\n```\r\n\r\n//Load training data (has a header)\r\nIDataView trainData = mlContext.Data.LoadFromTextFile<SearchResultData>(TrainDatasetPath, separatorChar: '\\t', hasHeader: true);\r\n\r\n//Load validation data (has a header)\r\nIDataView validationData = mlContext.Data.LoadFromTextFile<SearchResultData>(ValidationDatasetPath, separatorChar: '\\t', hasHeader: false);\r\n\r\n// Combine the training and validation datasets.\r\nvar validationDataEnum = mlContext.Data.CreateEnumerable<SearchResultData>(validationData, false);\r\nvar trainDataEnum = mlContext.Data.CreateEnumerable<SearchResultData>(trainData, false);\r\nvar trainValidationDataEnum = validationDataEnum.Concat<SearchResultData>(trainDataEnum);\r\nIDataView trainValidationData = mlContext.Data.LoadFromEnumerable<SearchResultData>(trainValidationDataEnum);\r\n```\r\n\r\nNOTE: I also considered creating a text loader to load multiple text files (as described [here])(https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.textloader.load?view=ml-dotnet#Microsoft_ML_Data_TextLoader_Load_Microsoft_ML_Data_IMultiStreamSource_); however, one of the data files included a header while the other didn't.  It looks like to create a TextLoader for multiple files, that the file headers must be consistent across files.\r\n\r\n### Source code / logs\r\n\r\nNote that there is a method today that provides the ability to append rows - we should consider exposing this publicly:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/70ef7ecd43b031b481a4047ea361da5e2f360336/src/Microsoft.ML.Data/DataView/AppendRowsDataView.cs#L23-L31\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4005","RelatedDescription":"Open issue \"Provide a way to append\\concatentate multiple IDataViews\" (#4005)"},{"Id":"468266314","IsPullRequest":false,"CreatedAt":"2019-07-15T18:15:28","Actor":"pieths","Number":"4004","RawContent":null,"Title":"TypeConvertingTransformer requires \"Experimental\" onnx version.","State":"open","Body":"When exporting a NimbusML pipeline which contains a predictor to ONNX, a `TypeConvertingTransformer` is sometimes inserted in the pipeline. The `TypeConvertingTransformer` currently requires the `Experimental` ONNX flag to be set in order for it to be converted to ONNX (see line 390 in `src\\Microsoft.ML.Data\\Transforms\\TypeConverting.cs`). Can this be updated to no longer require the `Experimental` flag?","Url":"https://github.com/dotnet/machinelearning/issues/4004","RelatedDescription":"Open issue \"TypeConvertingTransformer requires \"Experimental\" onnx version.\" (#4004)"},{"Id":"468254487","IsPullRequest":false,"CreatedAt":"2019-07-15T17:47:24","Actor":"baruchiro","Number":"4003","RawContent":null,"Title":"Create from enumerable after registering new type","State":"open","Body":"I think I'm missing something.\r\n\r\nWe have the Type System in `DataViewTypeManager`, and we can register a new type to map it to one of the system types. But even I register a new type to the system, when I try to load from enumerable I getting exception because the next `if`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/02a857a7646188fec2d1cba5e187a6c9d0838e23/src/Microsoft.ML.Data/DataView/InternalSchemaDefinition.cs#L194-L195\r\n\r\nEven if I add a new type, the first condition `!itemType.TryGetDataKind(out _)` will return `!false` = `true` because my type will never be in the next code:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c3bdaaa2a29f88a85dd91cde3fbb805001011903/src/Microsoft.ML.Core/Data/DataKind.cs#L293-L337","Url":"https://github.com/dotnet/machinelearning/issues/4003","RelatedDescription":"Open issue \"Create from enumerable after registering new type\" (#4003)"},{"Id":"468131540","IsPullRequest":true,"CreatedAt":"2019-07-15T13:35:28","Actor":"SnakyBeaky","Number":"4001","RawContent":null,"Title":"Fixing #4000 documentation and code issues","State":"open","Body":"Fixes the documentation/code snippet issues in #4000 \r\n\r\n- Changed `dv` to `dataView` for a more readable variable and aligned style with other variables in snippet.\r\n- Fixed code not using `IrisVectorData` output class\r\n- Fixed code not calling `CreateEnumerable<T>()` from `.Data`\r\n- Fixed some texts referencing variable `arr` (which existed in some previous version of this documentation file, but not anymore\r\n- Fixed minor indentation style in array initialization\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4001","RelatedDescription":"Open PR \"Fixing #4000 documentation and code issues\" (#4001)"},{"Id":"468131415","IsPullRequest":false,"CreatedAt":"2019-07-15T13:35:15","Actor":"SnakyBeaky","Number":"4000","RawContent":null,"Title":"Invalid code and missing variables in SchemaComprehension docs","State":"open","Body":"The documentation for https://github.com/dotnet/machinelearning/blob/master/docs/code/SchemaComprehension.md has invalid code (I'm assuming it worked in previous versions of the framework) and the texts reference variables that don't exist anymore in the code snippets (removed in previous commits).\r\n\r\nWas partially fixed in #2054 and #2039, but still missing some minor things.","Url":"https://github.com/dotnet/machinelearning/issues/4000","RelatedDescription":"Open issue \"Invalid code and missing variables in SchemaComprehension docs\" (#4000)"},{"Id":"467696100","IsPullRequest":false,"CreatedAt":"2019-07-13T09:18:27","Actor":"Suriman","Number":"3999","RawContent":null,"Title":"Possibility to specify the algorithm in AutoML","State":"open","Body":"There are scenarios where you know in advance the algorithms that will work better under certain data. In these cases, it would be very useful to specify through parameters what algorithms we want to test AutoML with different configuration parameters, so the time spent would be used to find better configurations of the specified algorithms, instead of trying algorithms that are known in advance to be to give worse results.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3999","RelatedDescription":"Open issue \"Possibility to specify the algorithm in AutoML\" (#3999)"},{"Id":"467636492","IsPullRequest":false,"CreatedAt":"2019-07-12T23:34:09","Actor":"pieths","Number":"3998","RawContent":null,"Title":"Support saving to ONNX for the OptionalColumnCreator transform","State":"open","Body":"When NimbusML creates pipelines for regressors, classifiers and rankers, it prepends an OptionalColumnCreator transform to the pipeline. These pipelines can not be exported in their entirety in the ONNX format because the OptionalColumnCreator is not exportable to ONNX.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3998","RelatedDescription":"Open issue \"Support saving to ONNX for the OptionalColumnCreator transform\" (#3998)"},{"Id":"467541066","IsPullRequest":false,"CreatedAt":"2019-07-12T18:18:16","Actor":"pieths","Number":"3997","RawContent":null,"Title":"Misleading error message when using Global Contrast Normalizer","State":"open","Body":"When attempting to fit a global contrast normalizer using NimbusML and providing a column of type float32 produces this error message:\r\n\r\n> Expected Single or known-size vector of Single, got Single\r\n\r\nThis error message seems to imply that using a column of type Single (float32) is valid. There are two places in `src\\Microsoft.ML.Transforms\\GcnTransform.cs` where this message is used. In either case a column of type vector is expected.\r\n\r\nShould this message be updated to be more clear about requiring a vector column?","Url":"https://github.com/dotnet/machinelearning/issues/3997","RelatedDescription":"Open issue \"Misleading error message when using Global Contrast Normalizer\" (#3997)"},{"Id":"467385182","IsPullRequest":false,"CreatedAt":"2019-07-12T16:56:33","Actor":"nighotatul","Number":"3996","RawContent":null,"Title":"How we load data in ml.net from sql server table?","State":"closed","Body":"right now, we are loading data in ml.net from csv file. but we want to load data in ml.net through sql server table or how we load data from datatable in ml.net. ","Url":"https://github.com/dotnet/machinelearning/issues/3996","RelatedDescription":"Closed issue \"How we load data in ml.net from sql server table?\" (#3996)"},{"Id":"467200962","IsPullRequest":false,"CreatedAt":"2019-07-12T03:19:02","Actor":"nicolehaugen","Number":"3995","RawContent":null,"Title":"Exception messages need to be richer\\clearer","State":"open","Body":"Many exception messages thrown are unclear - as a result, when an exception occurs, it's challenging to identify whether the issue in with the ML.NET code, with the underlying data, with how the algorithm is being applied, etc.  Often it takes stepping through the ML.NET fwk in attempt to get further context.\r\n\r\nI logged this as a single issue because I think there would be benefit in looking at all places where exceptions are being thrown\\rethrown to ensure that default exception messages aren't provided and that the messages are as clear\\rich as possible.  Let me know if you would like these broken into separate issues rather than having them combined in one.  \r\n\r\nHere are some specific examples:\r\n\r\n\r\n  | Trainer | Scenario | Actual Message | Suggested   Message\r\n-- | -- | -- | -- | --\r\n|1. | N/A | Occurs when invalid field index is provided to the LoadColumn   attribute.         For example:<br>``` [LoadColumn(100)]   public uint Label { get; set; }```<br>In the above code, the value of 100 is an invalid index value since   the underlying data has less than 100 columns. | System.ArgumentNullException: 'Value cannot be null.   Parameter   name: items' | Message should indicate which column has the issue; the reference to   parameter ‘items’ is unclear.|\r\n|2. | N/A | Occurs when Feature column is of some other type than float\\single.        For example: <br>``` [ColumnName(\"Test\"), LoadColumn(135)]   public uint Test { get; set; }``` | System.InvalidOperationException:   'Column ‘Test’ has values of UInt32, which is not the same as earlier   observed type of Single.' | It’s unclear what “same as earlier observed type” means.  Consider rewording to state that the   Feature columns must all be of a certain type (e.g. Single).\r\n|3. | LightGbm | Occurs when custom gains are specified without providing a group id   column.       For example:<br>```var customGains = new LightGbmRankingTrainer.Options();             customGains.CustomGains = new int[] { 0,   1, 2, 3 };IEstimator<ITransformer> trainer = mlContext.Ranking.Trainers.LightGbm(customGains);IEstimator<ITransformer> trainerPipeline =   dataPipeline.Append(trainer);```<br>Notice that in the above code, the Group Id isn’t being explicitly   set as follows:<br> ```customGains.RowGroupColumnName = \"GroupId\";``` | System.ArgumentOutOfRangeException: 'Need a group column.   Parameter   name: data' | ArgumentOutOfRangeException is confusing; instead, throw ArgumentNullException   or InvalidOperationException.       Message should also indicate the ‘Group Id’ column is missing\\null;   the reference to parameter ‘data’ is unclear.\r\n|4. | LightGbm | Occurs when custom gains cardinality doesn’t match the cardinality of  the relevance label values.         For example:<br>```var customGains = new LightGbmRankingTrainer.Options(); customGains.CustomGains  = new int[] { 0, 1, 2 };                customGains.RowGroupColumnName = \"GroupId\";```<br>In the underlying data, the relevance label values are: {0, 1, 2, 3,   4 } – in other words, the cardinality of the relevance label values is   greater than the specified custom gains. | System.InvalidOperationException:   'LightGBM Error, code is -1, error message is 'label (0) excel the max range   3'.' | There appears to be a typo – “excel” should say “exceeds”.  Also, the message should state that the   cardinality of the relevance label values must less than or equal to the   cardinality of the custom gains.       Note: Refer to similar issue logged directly against LightGBM: https://github.com/Microsoft/LightGBM/issues/1090\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3995","RelatedDescription":"Open issue \"Exception messages need to be richer\\clearer\" (#3995)"},{"Id":"467191139","IsPullRequest":false,"CreatedAt":"2019-07-12T02:34:56","Actor":"nicolehaugen","Number":"3994","RawContent":null,"Title":"Docs show using VectorType instead of concatenating features","State":"open","Body":"Numerous places in the docs, we show to store features as a VectorType.  However, this isn't ideal because it doesn't allow you to easily do feature engineering where you pick\\choose the most influential features to include when training a model.  Instead, to easily support feature engineering, it's recommended to concatenate your features as part of the pipeline. \r\n\r\nFor example, here are a few places where we show using a VectorType:\r\n1.) https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/load-data-ml-net#create-the-data-model\r\n2.) https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#how-do-i-load-data-from-a-text-file\r\n\r\nInstead, we should show feature concatenation and explain why this is a preferred approach - for example:\r\n```\r\n   IEstimator<ITransformer> dataPipeline = mlContext.Transforms.Concatenate(FeaturesVectorName, featureCols)\r\n                .Append(mlContext.Transforms.Conversion.MapValueToKey(nameof(SearchResultData.Label)))\r\n                .Append(mlContext.Transforms.Conversion.Hash(nameof(SearchResultData.GroupId), nameof(SearchResultData.GroupId), numberOfBits: 20));\r\n```\r\nAlso, why is there a VectorType attribute?  Are there ever benefits to using this?  If not, we should consider removing.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3994","RelatedDescription":"Open issue \"Docs show using VectorType instead of concatenating features\" (#3994)"},{"Id":"467170942","IsPullRequest":false,"CreatedAt":"2019-07-12T01:02:33","Actor":"nicolehaugen","Number":"3993","RawContent":null,"Title":"Exception is thrown if NDCG > 10 is used with LightGbm for evaluating ranking","State":"open","Body":"- Version: ML.NET 1.2.0\r\n\r\nThe current code in the RankingEvaluator.cs file has the MaxTruncationLevel for NDCG (Normalized Cumulative Gain Metric) set to 10.  Also, the code currently throws an exception if the NDCG is set to a value > 10.  This is a blocking issue for ranking because it prevents the ability to measure the quality of ranking with result sets > 10.  For example, if you were attempting to rank a group of 100 results, with the MaxTruncationLevel of 10, you could only measure whether the first 10 results were ranked correctly.\r\n\r\nHere's the code:\r\n\r\n```\r\n         public RankingEvaluator(IHostEnvironment env, Arguments args)\r\n            : base(env, LoadName)\r\n        {\r\n            // REVIEW: What kind of checking should be applied to labelGains?\r\n            if (args.DcgTruncationLevel <= 0 || args.DcgTruncationLevel > Aggregator.Counters.MaxTruncationLevel)\r\n                throw Host.ExceptUserArg(nameof(args.DcgTruncationLevel), \"DCG Truncation Level must be between 1 and {0}\", Aggregator.Counters.MaxTruncationLevel);\r\n            Host.CheckUserArg(args.LabelGains != null, nameof(args.LabelGains), \"Label gains cannot be null\");\r\n...\r\n}\r\n```\r\nIt appears from the //Review comment in the above code that this functionality hasn't been fully completed.  \r\n\r\nWhile I'm unsure what the MaxTruncationLevel value should be, I have seen on a ranking contest\\example on Kaggle.com where one contest was measuring NDCG with a truncation level of up to 38.  \r\n\r\nI also noticed that in other parts of this file, the code indicates that a value between 0-100 should be allowed:\r\n\r\n```\r\n public Transform(IHostEnvironment env, IDataView input, string labelCol, string scoreCol, string groupCol,\r\n                int truncationLevel, Double[] labelGains)\r\n                : base(env, input, labelCol, scoreCol, groupCol, RegistrationName)\r\n            {\r\n                Host.CheckParam(0 < truncationLevel && truncationLevel < 100, nameof(truncationLevel),\r\n                    \"Truncation level must be between 1 and 99\");\r\n...\r\n}\r\n```\r\n\r\nAlso, refer to the linked bug since it is related to this scenario: [Ranker Evaluate doesn't allow you specify metric parameters.] (https://github.com/dotnet/machinelearning/issues/2728)","Url":"https://github.com/dotnet/machinelearning/issues/3993","RelatedDescription":"Open issue \"Exception is thrown if NDCG > 10 is used with LightGbm for evaluating ranking\" (#3993)"},{"Id":"467103110","IsPullRequest":false,"CreatedAt":"2019-07-11T20:57:22","Actor":"artidoro","Number":"3992","RawContent":null,"Title":"FeaturizeText should allow only outputColumnName to be defined","State":"open","Body":"One of the extension methods for `FeaturizeText` needs both the `outputColumnName` and the `inputColumnNames` to be provided.\r\n\r\nThere is no compile error if `inputColumnNames` is not provided, only a runtime error.\r\n\r\nWe should fix the error so that when `inputColumnNames` is not provided, it is set to `new[] { outputColumnName }` as we do everywhere else in the code base.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c3bdaaa2a29f88a85dd91cde3fbb805001011903/src/Microsoft.ML.Transforms/Text/TextCatalog.cs#L60-L65","Url":"https://github.com/dotnet/machinelearning/issues/3992","RelatedDescription":"Open issue \"FeaturizeText should allow only outputColumnName to be defined\" (#3992)"},{"Id":"467100591","IsPullRequest":false,"CreatedAt":"2019-07-11T20:51:18","Actor":"nicolehaugen","Number":"3991","RawContent":null,"Title":"Need advanced filtering for downsampling","State":"open","Body":"- Version: ML.NET 1.2.1\r\n\r\nTo filter rows in a performance-friendly way and load the data into an IDataView, I attempted to use:\r\n```\r\n mlContext.Data.FilterRowsByColumn(...)\r\n```\r\nHowever, this method only supports the ability to filter on the values of a single column.  There are cases where you need to do more advanced filtering scenarios - for example, filter based on multiple column values, nest queries, etc.  It would be helpful in general to have the ability to provide a linq expression to support a variety of filtering scenarios.\r\n\r\nHere's more information on my specific scenario - as I said, it would be helpful to have advanced filtering capabilities provided since this is a useful way to do down-sampling before training on the data.\r\n\r\n-----------------------------------------------------------------------\r\n**Scenario:**\r\n\r\nMy scenario uses a large hotel result dataset for ranking (1,000,000+ records).  \r\nHere is simple example of the data:\r\n\r\nGroupId | HotelId | Srch_Result_Clicked | Srch_Result_Booked\r\n----------|----------|----------------------|-------------------------|\r\n1 | 12 | 0 | 0 |\r\n1           |       24     |              1                 |             0 |\r\n1           |       45     |              1                 |             1 |\r\n1           |       55     |              0                 |             0 |\r\n\r\nNotice that in the above data, the GroupId corresponds to the query or search id.  There are multiple hotel results then tied to the GroupId since these are the results corresponding to a given query.  Each hotel result may have the following values:\r\n* Srch_Result_Clicked == 1 if the user clicked the hotel search result\r\n* Srch_Result_Booked == 1 if the user both clicked and booked the hotel search result\r\n* Or, the above values are 0 if the user neither clicked nor booked the result\r\n\r\nIn this scenario, I needed to perform down-sampling so that I only trained on hotel search queries where that had been either clicked or booked.  Here's an example of the type of query that I was trying to achieve:\r\n\r\n```\r\n//Get those group\\query ids that have at least one hotel result that was either clicked or booked\r\nvar groupIds = hotelData.Where(h => h.Srch_Result_Clicked == 1 || h.Srch_Result_Booked == 1).Select(h => h.GroupId).Distinct();\r\n\r\n//Down sample retrieve all hotel results for a group\\query matching the above criteria\r\nIDataView downSampleData = hotelData.Where(h => groupIds.Contains(h.GroupId));\r\n\r\n//Train the model\r\n var model = trainingPipeline.Fit(downSampleData);\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3991","RelatedDescription":"Open issue \"Need advanced filtering for downsampling\" (#3991)"},{"Id":"467076166","IsPullRequest":false,"CreatedAt":"2019-07-11T19:51:08","Actor":"colbylwilliams","Number":"3990","RawContent":null,"Title":"PredictedLabel is always true for Anomaly Detection","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: macOS & Windows\r\n- **.NET Version (eg., dotnet --info)**:  .Net Core\r\n\r\n### Issue: PredictedLabel is always true for Anomaly Detection\r\n\r\nIn my experience, and as demonstrated by [this sample](https://github.com/dotnet/machinelearning-samples/tree/AnomalyDetection_FraudDetection/samples/csharp/getting-started/AnomalyDetection_CreditCardFraudDetection), predictions from models trained with the `RandomizedPcaTrainer` always set the value for `PredictedLabel` to `true`.\r\n\r\n_Note: I’m very new to machine learning, I am not a data scientist, nor am I very familiar with this code base, but I’ve taken a crack at figuring out why..._\r\n\r\nThe `BinaryClassifierScorer` is [used for scoring anomaly detection models](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L295-L297), specifically those trained using the `RandomizedPcaTrainer`. Which I _think_ makes sense, as with binary classification the `PredictedLabel` in anomaly detection will be one of two values, `true` or `false`.  \r\n\r\nHowever, when using binary classification, `PredictiveLabel` is set to `true` if the prediction's `Score` is a positive value and set to `false` if the `Score` is negative. This is one place it seems to break down with anomaly detection, as the `Score` is going to be a value between one and zero.  So, the current implementation of `BinaryClassifierScorer` is going to return a value of true for any prediction that does not have a `Score` of zero or NAN.\r\n\r\nAdditionally, it’s my understanding that in anomaly detection it is up to the user to set the threshold of the model that indicates whether a `Score` is considered an anomaly or a normal value.  (Or at least this is the case for supervised training).  From what I can tell, the implementation of `BinaryClassifierScorer` used by anomaly detection, does have a `Threshold` property which [it compares the `Score` value to, to get the value for `PredictedLabel`](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/BinaryClassifierScorer.cs#L259-L263).  It would seem the `BinaryClassifierScorer` could be used for anomaly detection if the user was able to manually set a value for `Threshold`, or if the scorer could intelligently set the value based on the distribution of `Score`s.  However, the [`Threshold` property is by default set to zero](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L270), with no public way of changing its value.\r\n\r\nThus, based on my understanding, the Scorer compares the prediction’s `Score` to zero, and the value for `PredictedLabel` will always be set to `true`, with the exception of the edge case where score is zero or NAN.\r\n\r\nDuring my research, I did find that `BinaryClassificationCatalog` has a method [`ChangeModelThreshold`](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/TrainCatalog.cs#L261-L267) to manually override the value of the scorer’s `Threshold` property.  Unfortunately, this functionality is is not exposed on the `AnomalyDetectionCatalog`, so can’t be used with anomaly detection.\r\n\r\n---\r\n\r\nFinally, and this may need to be moved to a separate issue, but I've found contradictory information on how to interpret the `Score` value of an anomaly detection prediction.  For example [this sample](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/AnomalyDetection/RandomizedPcaSample.cs#L92) indicates that outliers (or anomalies) will have a **smaller** value for `Score` than will normal values.  However, [this documentation](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.randomizedpcatrainer?view=ml-dotnet#training-algorithm-details) states _\"If the error is close to 0, the instance is considered normal (non-anomaly).\"_  This matches the results I'm getting from [my sample](https://github.com/dotnet/machinelearning-samples/tree/AnomalyDetection_FraudDetection/samples/csharp/getting-started/AnomalyDetection_CreditCardFraudDetection), where anomalies have a **higher** value for `Score` than normal values.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3990","RelatedDescription":"Open issue \"PredictedLabel is always true for Anomaly Detection\" (#3990)"},{"Id":"466937119","IsPullRequest":false,"CreatedAt":"2019-07-11T14:44:09","Actor":"ganzikk02","Number":"3989","RawContent":null,"Title":"Multiple trainers in one pipeline","State":"open","Body":"First of all, I would like to thank you for ML.NET as I have waited for **the** C# machine learning library for such a long time (been using Accord.NET and CNTK) and right now I am having a great time with ML.NET.\r\n\r\nAs for my question, I am trying to create a strong classifier for multiclass classification consisting of more weaker classifiers, to do this I need to train different models. Is it possible to train multiple models in one pipeline? Or do I need to create separate pipelines and then even predictor engines for each model?\r\n\r\n```\r\nvar estimatorChain = mlContext.Transforms.Conversion.MapValueToKey(\"Label\")\r\n                .Append(mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy())\r\n                .Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\"));\r\n\r\nvar transformerChain = estimatorChain.Fit(trainDataMemory);\r\n\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<DataItem, DataItemPrediction>(transformerChain, inputSchemaDefinition: inputSchemaDefinition);\r\n```\r\n\r\nI would like to append more trainers into the pipeline which is actually possible to do, but I have no idea what it does because the result of training and of prediction is not very transparent in this regard... Also did not find anything about this in the documentation.\r\n\r\nSo is it possible or do I have to create multiple pipelines which need to be used separately?","Url":"https://github.com/dotnet/machinelearning/issues/3989","RelatedDescription":"Open issue \"Multiple trainers in one pipeline\" (#3989)"},{"Id":"466926699","IsPullRequest":false,"CreatedAt":"2019-07-11T14:26:22","Actor":"SkinnyMan32","Number":"3988","RawContent":null,"Title":"Troubles with CustomMappingEstimator after save/load","State":"open","Body":"### System information\r\n\r\n- **ML.Net v1.2.0**\r\n\r\n### Issue\r\nI try to use CustomMapping with specified column names. It works fine, but after save/load model I get exception:\r\n**System.ArgumentOutOfRangeException: \"Could not find  column 'Words'\".** \r\n'Words' - the original name of property, not specified by me.\r\n\r\nWhat am i doing wrong?\r\n\r\nI can fix it by using only original names, it is not comfortable in some cases.\r\n\r\n### Source code\r\n```C#\r\n// --- Test method ---\r\nvar ml = new MLContext();\r\nvar descriptions = new[]\r\n{\r\n\tnew { Description = \"Painted, Painting, Painter\" }\r\n};\r\nvar dataView = ml.Data.LoadFromEnumerable(descriptions);\r\n\r\nvar pipeline = ml.Transforms.Text.NormalizeText(\"Normalized\", \"Description\")\r\n\t.Append(ml.Transforms.Text.TokenizeIntoWords(\"Tokens\", \"Normalized\"))\r\n     // (Extension method) CustomMapping with specified column names\r\n\t.Append(ml.Transforms.StemText(\"Stemmed\", \"Tokens\"));\r\n\r\nvar model = pipeline.Fit(dataView);\r\nvar preview = model.Transform(dataView).Preview();  // everything is ok\r\n\r\n// Save model\r\nMemoryStream stream = new MemoryStream();\r\nml.Model.Save(model, dataView.Schema, stream);\r\nstream.Position = 0;\r\n\r\n// Load model in the new context\r\nvar ml2 = new MLContext();\r\n// Register custom action\r\nml2.ComponentCatalog.RegisterAssembly(typeof(StemmerCustomAction).Assembly);\r\nvar loadedModel = ml2.Model.Load(stream, out var schema);\r\n\r\n// Exception:\r\n// System.ArgumentOutOfRangeException: \"Could not find  column 'Words'\r\nvar preview2 = loadedModel.Transform(dataView).Preview();\r\n\r\n\r\n//--- Classes ---\r\n\r\npublic class StemmerInput\r\n{\r\n\tpublic string[] Words { get; set; }\r\n}\r\n\r\npublic class StemmerOutput\r\n{\r\n\tpublic string[] Stemmed { get; set; }\r\n}\r\n\r\n[CustomMappingFactoryAttribute(\"StemText\")]\r\npublic class StemmerCustomAction : CustomMappingFactory<StemmerInput, StemmerOutput>\r\n{\r\n\tpublic static void StemAction(StemmerInput input, StemmerOutput output)\r\n\t{\r\n\t\tvar stemmer = new EnglishStemmer();\r\n\t\toutput.Stemmed = new string[input.Words.Length];\r\n\t\tfor (int i = 0; i < input.Words.Length; i++)\r\n\t\t{\r\n\t\t\toutput.Stemmed[i] = stemmer.Stem(input.Words[i]);\r\n\t\t}\r\n\t}\r\n\r\n\tpublic override Action<StemmerInput, StemmerOutput> GetMapping() => StemAction;\r\n}\r\n\r\nstatic class StemmerTransformHelper\r\n{\r\n\tpublic static CustomMappingEstimator<StemmerInput, StemmerOutput> StemText(this TransformsCatalog catalog,\r\n\t\tstring outputColumnName, string inputColumnName = null)\r\n\t{\r\n\t\tvar inputSchema = SchemaDefinition.Create(typeof(StemmerInput), SchemaDefinition.Direction.Read);\t\t\r\n\t\tvar outSchema = SchemaDefinition.Create(typeof(StemmerOutput), SchemaDefinition.Direction.Write);\t\t\r\n\t\t// specify column names\r\n\t\tinputSchema[0].ColumnName = inputColumnName ?? outputColumnName;\r\n\t\toutSchema[0].ColumnName = outputColumnName;\r\n\t\treturn catalog.CustomMapping(new StemmerCustomAction().GetMapping(), \"StemText\", inputSchema, outSchema);\r\n\t}\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3988","RelatedDescription":"Open issue \"Troubles with CustomMappingEstimator after save/load\" (#3988)"},{"Id":"466727956","IsPullRequest":false,"CreatedAt":"2019-07-11T07:59:59","Actor":"mani009","Number":"3987","RawContent":null,"Title":"After packing and install ML.NET Project with Setup installer throws exceptions","State":"open","Body":"### System information\r\n\r\n-Windows 10(18362)\r\n- NET Framework 4.6.1: \r\n\r\n### Issue\r\n\r\n- Try Pack ML.NET Project with Windows Setup Installer\r\n- Installed and run Program throw an exception\r\n\r\n\r\nSimple Example:\r\n```\r\n    public partial class Form1 : Form\r\n    {\r\n        public Form1()\r\n        {\r\n            InitializeComponent();\r\n        }\r\n\r\n        private void button1_Click(object sender, EventArgs e)\r\n        {\r\n                try\r\n                {\r\n                    HousingData[] inMemoryCollection = new HousingData[]\r\n                    {\r\n                new HousingData\r\n                {\r\n                    Size =700f,\r\n                    HistoricalPrices = new float[]\r\n                    {\r\n                        100000f, 3000000f, 250000f\r\n                    },\r\n                    CurrentPrice = 500000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size =1000f,\r\n                    HistoricalPrices = new float[]\r\n                    {\r\n                        600000f, 400000f, 650000f\r\n                    },\r\n                    CurrentPrice=700000f\r\n                }\r\n                    };\r\n\r\n                    MLContext mlContext = new MLContext();\r\n\r\n                    IDataView data = mlContext.Data.LoadFromEnumerable<HousingData>(inMemoryCollection);\r\n                }\r\n                catch (Exception ex)\r\n                {\r\n                    MessageBox.Show(ex.Message);\r\n                }\r\n            }\r\n\r\n        }\r\n```\r\nIf i Run the program and push the button it throws that exception:\r\n\r\n![Exception](https://user-images.githubusercontent.com/13287806/61032695-3635f700-a3c2-11e9-9107-7f150e33cd8c.png)\r\n\r\nAnd if i attach the process with VS 2017 it throws that exception\r\n\r\nException thrown: 'System.BadImageFormatException' in Microsoft.ML.Data.dll","Url":"https://github.com/dotnet/machinelearning/issues/3987","RelatedDescription":"Open issue \"After packing and install ML.NET Project with Setup installer throws exceptions\" (#3987)"},{"Id":"466568495","IsPullRequest":true,"CreatedAt":"2019-07-10T23:12:06","Actor":"wschin","Number":"3986","RawContent":null,"Title":"Allow user to save PredictorTransform in file and then convert it to …","State":"open","Body":"…ONNX via entry point APIs\r\n\r\nFix #3974. The model type in `Microsoft.ML.Model.OnnxConverter.SaveOnnxCommand.Arguments` is `TransformModel` as shown below.\r\n```c#\r\n...\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.CmdLineOnly, HelpText = \"Comma delimited list of output column names to drop\", ShortName = \"odrop\", SortOrder = 7)]\r\n            public string OutputsToDrop;\r\n\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.EntryPointsOnly, HelpText = \"Array of output column names to drop\", Name = nameof(OutputsToDrop), SortOrder = 8)]\r\n            public string[] OutputsToDropArray;\r\n\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.CmdLineOnly, HelpText = \"Whether we should attempt to load the predictor and attach the scorer to the pipeline if one is present.\", ShortName = \"pred\", SortOrder = 9)]\r\n            public bool? LoadPredictor;\r\n\r\n            /// <summary>\r\n            /// Entry point API can save either <see cref=\"TransformModel\"/> or <see cref=\"PredictorModel\"/>.\r\n            /// <see cref=\"Model\"/> is used when the saved model is typed to <see cref=\"TransformModel\"/>.\r\n            /// </summary>\r\n            [Argument(ArgumentType.Required, Visibility = ArgumentAttribute.VisibilityType.EntryPointsOnly, HelpText = \"Model that needs to be converted to ONNX format.\", SortOrder = 10)]\r\n            public TransformModel Model;\r\n...\r\n```\r\nThus, model typed to `PredictorModel` (created by entry point APIs) won't be loaded. To support both of `TransformModel` and `PredictorModel`, we add one extra field (called `PredictiveModel`) in parallel to `Model` and some if-else blocks.","Url":"https://github.com/dotnet/machinelearning/pull/3986","RelatedDescription":"Open PR \"Allow user to save PredictorTransform in file and then convert it to …\" (#3986)"},{"Id":"466093013","IsPullRequest":true,"CreatedAt":"2019-07-10T22:30:23","Actor":"harishsk","Number":"3983","RawContent":null,"Title":"TF package size fix","State":"closed","Body":"The Tensorflow tar files contain libtensorflow.so, libtensorflow.so.$(MajorVersion) and libtensorflow.so.$(Version). Of these, the first two are symlinked to the third. When these files get copied over to the nuget package, they are copied as files and not as symlinks which causes the package size to almost triple. \r\nThis fix reduces the copied files to only libtensorflow.so and libtensorflow_framework.so.$(MajorVersion).\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3983","RelatedDescription":"Closed or merged PR \"TF package size fix\" (#3983)"},{"Id":"466474428","IsPullRequest":false,"CreatedAt":"2019-07-10T19:17:26","Actor":"justinormont","Number":"3985","RawContent":null,"Title":"Add FieldAwareFactorizationMachine to AutoML","State":"open","Body":"FieldAwareFactorizationMachine is good for large dataset like the Criteo 1TB dataset. \r\n\r\nCurrently FieldAwareFactorizationMachine is not swept over in AutoML. \r\n\r\nTask:\r\n* Add trainer to default list of binary learners to try\r\n* Add sweep range\r\n* Add to CLI's C# CodeGen\r\n\r\nShould be easy to just replicate an existing trainer like SDCA:\r\nhttps://github.com/dotnet/machinelearning/blob/d518b587b06ac3896a48646622b0f2169a230855/src/Microsoft.ML.AutoML/TrainerExtensions/BinaryTrainerExtensions.cs#L150-L169","Url":"https://github.com/dotnet/machinelearning/issues/3985","RelatedDescription":"Open issue \"Add FieldAwareFactorizationMachine to AutoML\" (#3985)"},{"Id":"466435561","IsPullRequest":false,"CreatedAt":"2019-07-10T17:40:58","Actor":"baruchiro","Number":"3984","RawContent":null,"Title":"Renaming column","State":"open","Body":"### Issue\r\n\r\nI try to convert column type to another type by using [ConversionsExtensionsCatalog.ConvertType](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.converttype). After the transform, I have duplicated columns with the same name but another type. I want to keep with the same name.\r\n\r\nSo, I convert to a new name, drop the old name, copy the new name to the old name and drop the new name.\r\n\r\nWAT???\r\n\r\nWhy it is so complicated?\r\n\r\nI think we need to add an option to transform \"inplace\", or combine `Drop` & `Copy` to `Rename`.\r\n\r\n### Source code / logs\r\n\r\n```csharp\r\nvar intTypes = new[]\r\n{\r\n        DataKind.Int16,\r\n        DataKind.Int32,\r\n        DataKind.Int64\r\n};\r\nvar intColumnsNames = columns\r\n    .Where(c => intTypes.Contains(c.DataKind))\r\n    .Select(c => c.Name).ToList();\r\nconst string addedName = \"single_\";\r\n\r\nAddPipelineStage(_mlContext.Transforms.Conversion.ConvertType(\r\n    intColumnsNames.Select(c =>\r\n        new InputOutputColumnPair(addedName + c, c)).ToArray(),\r\n    DataKind.Single));\r\nAddPipelineStage(_mlContext.Transforms.DropColumns(intColumnsNames.ToArray()));\r\nintColumnsNames.ForEach(c => AddPipelineStage(_mlContext.Transforms.CopyColumns(c, addedName + c)));\r\nAddPipelineStage(_mlContext.Transforms.DropColumns(intColumnsNames.Select(c => addedName + c).ToArray()));\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3984","RelatedDescription":"Open issue \"Renaming column\" (#3984)"},{"Id":"465922355","IsPullRequest":false,"CreatedAt":"2019-07-09T23:24:31","Actor":"artidoro","Number":"3980","RawContent":null,"Title":"Update API Compat after 1.2 release","State":"closed","Body":"We should update the API Compat tool after the 1.2 release. There are two updates that need to be made.\r\n\r\n1. Update the current projects to point to point to the 1.2 nugets\r\nhttps://github.com/dotnet/machinelearning/blob/78bfecb4c5999e1d675255544e2032f29c5fd621/tools-local/Microsoft.ML.StableApi/Microsoft.ML.StableApi.csproj#L10-L16\r\n\r\n2. Activate API Compat on the new stable projects (Onnx, TensorFlow and TimeSeries) and make the stable version point to the 1.2 nugets.","Url":"https://github.com/dotnet/machinelearning/issues/3980","RelatedDescription":"Closed issue \"Update API Compat after 1.2 release\" (#3980)"},{"Id":"465943872","IsPullRequest":false,"CreatedAt":"2019-07-09T19:18:05","Actor":"nighotatul","Number":"3982","RawContent":null,"Title":"Need More Detail regarding feature","State":"open","Body":"\r\nis feature columns consider as complex variable that means all are consider as object when processes in ml.net?\r\n\r\nex.\r\nif consider label is Purchased Bike\r\nand feature are Commute Distance,Gender,Age,Cars.\r\n\r\nso all feature columns consider as object in ml.net?\r\n\r\nmeans like all column data convert into vector array.\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3982","RelatedDescription":"Open issue \"Need More Detail regarding feature\" (#3982)"},{"Id":"465931398","IsPullRequest":true,"CreatedAt":"2019-07-09T18:51:20","Actor":"artidoro","Number":"3981","RawContent":null,"Title":"Update Api Compat after 1.2 release","State":"closed","Body":"Fixes #3980 \r\n\r\nI update the package version number for the stable projects and I activate the API Compat tool for Onnx, TimeSeries and TensorFlow packages which became stable in the last release.  \r\n","Url":"https://github.com/dotnet/machinelearning/pull/3981","RelatedDescription":"Closed or merged PR \"Update Api Compat after 1.2 release\" (#3981)"},{"Id":"465905104","IsPullRequest":true,"CreatedAt":"2019-07-09T17:39:45","Actor":"artidoro","Number":"3979","RawContent":null,"Title":"Internalizing Static API code","State":"open","Body":"Related to #3952.\r\n\r\nIn this PR I internalize the static API code and do some clean up:\r\n1. Everything in the StaticPipe assembly is made internal\r\n2. The Static API samples have been removed\r\n3. The packaging step does not produce StaticPipe nuget\r\n\r\nNotice that this is the first of a three step process which will end up removing the static API code from the repository.","Url":"https://github.com/dotnet/machinelearning/pull/3979","RelatedDescription":"Open PR \"Internalizing Static API code\" (#3979)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-07-16T05:30:38.8587547Z","RunDurationInMilliseconds":930}