{"Data":{"GitHub":{"Issues":[{"Id":"378038636","IsPullRequest":true,"CreatedAt":"2018-11-07T01:12:12","Actor":"Zruty0","Number":"1551","RawContent":null,"Title":"Making RowMapperTransform a template","State":"closed","Body":"Making RowMapperTransform a template, avoiding load/save for wrapped transformers containing non-wrapped transformers\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1551","RelatedDescription":"Closed or merged PR \"Making RowMapperTransform a template\" (#1551)"},{"Id":"377726645","IsPullRequest":true,"CreatedAt":"2018-11-07T01:11:42","Actor":"TomFinley","Number":"1543","RawContent":null,"Title":"Reduce public surface area of ColumnType and family.","State":"closed","Body":"Fixes #1533 .\r\n\r\n* Introduce internals-visible-to on core, and [BestFriend] attributes on key members of ColumnType (see issue #1519) so internally the implementation can use the old conveniences.\r\n\r\n* Make type-specific data available only on the relevant type, for example, Size on VectorType, which replaces all of VectorSize, ValueCount, IsKnownSizeVectorType.\r\n\r\n* All `IsX` and `AsX` should be replaced with `is XType` or `as XType`.\r\n\r\n* Also in the spirit of the above, hide other redundant conveniences.\r\n\r\n* De-emphasize rather entirely DataKind as having anything to do with ColumnType, at least publicly.\r\n\r\n* Validate new public surface by having the tests use it instead of the old way.\r\n\r\n* No more odd `DimCount`/`GetDim` accessors on vector types, instead an `ImmutableArray<int> Dimensions`.\r\n\r\nNote that I was deliberately trying to err on the side of hiding as much as possible, but I believe the set of actual information you can get out of a type is identical. (Up to the presence of `DataKind`, which I am trying to de-emphasize possibly to the point of killing it outright, though not in this PR.)","Url":"https://github.com/dotnet/machinelearning/pull/1543","RelatedDescription":"Closed or merged PR \"Reduce public surface area of ColumnType and family.\" (#1543)"},{"Id":"377592001","IsPullRequest":false,"CreatedAt":"2018-11-07T01:11:41","Actor":"TomFinley","Number":"1533","RawContent":null,"Title":"IDataView Cleanup: ColumnType cleanup","State":"closed","Body":"The `IDataView` type system is extensible (as we see with [`ImageType`](https://github.com/dotnet/machinelearning/blob/f9202628fbfac9e599e8c63dc5ed26eae77afbee/src/Microsoft.ML.ImageAnalytics/ImageType.cs#L12)).\r\n\r\nThis is fine, but there is something confusing about `ColumnType` as well, since there are lots of methods and properties on the base class `ColumnType` that are specific for derived types. For example, `.IsVector`, `.KeyCount`, and other such things, that are only really relevant if the type *is* either vector, key, or whatever.\r\n\r\n## Why clean up?\r\n\r\nThere are lots of things on `ColumnType` that are unappealing. There are things like `AsVector` and `IsVector` which, as the documentation states, are equivalent to `as VectorType` and `is VectorType`. I mean, *why*? You save a few characters here and there, but at the cost of complicating one of the most central classes in the API.\r\n\r\nSome things are just plain old silly. Why `IsTimeSpan`? How useful is that, really? Some things are like this.\r\n\r\nThere's also `DataKind`. This is so strange. This has already caused a fair amount of confusion among some people: they see this, and they think, \"oh the types are just from this `enum`.\" No, they're not.\r\n\r\nThe reality is, these things are *conveniences*, but they're conveniences I think that confuse people (multiple smart people have thought their presence meant the type system was *not* extensible), so maybe we ought not to expose them, at least, not in their current form.\r\n\r\n## Why not clean up?\r\n\r\nIn a sense, forming an analogue between the IDV and .NET type systems, there is some precedent for this sort of thing: if we consider `System.Type`. This has the property `IsArray`, with the methods `GetArrayRank`, which is only sensible to use. However in *our* case, `ColumnType` is an abstract class, and while `System.Type` is abstract, its inheritance structure does not capture specific types of values in this sense. If, hypothetically, `.GetType` of an `int[]` returned some type `System.ArrayType` that descended from `System.Type`, then we might equally hypothetically imagine that the method to get the array rank would be on that derived `ArrayType`, rather than on `Type` directly.\r\n\r\nThere is also a practical consideration. The reality though is that some types are definitely more important and more heavily used than others.\r\n\r\nLet's imagine that we kept the `ColumnType` inheritance structure as it is now, but removed any properties relevant only to any derived type, specifically. What would hypothetically happen? I picked this usage more or less randomly from our codebase.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f9202628fbfac9e599e8c63dc5ed26eae77afbee/src/Microsoft.ML.Data/Evaluators/ClusteringEvaluator.cs#L799-L801\r\n\r\nNow then, let's imagine that we have *none* of the \"specialty\" properties on `ColumnType` used above, but instead have a `IsKnownSize` and `ItemType` on `VectorType` *specifically*, that is, not on the root class, and you must rephrase this thing as a `VectorType` if you wished to access these. The most clear way I can imagine to deliver equivalent logic to the linked condition is this:\r\n\r\n```csharp\r\nif (!(type is VectorType vecType && vecType.IsKnownSize && vecType.ItemType == NumberType.Float))\r\n```\r\nThat's not *so* bad really... the condition went from 60 to 92 characters, which while not great, is hardly ridiculous.\r\n\r\nIt's even conceivable that had we had pattern matching at the time this code is written, we would have done this. Prior to C# 7.0 (and this code is *way* prior to C# 7.0), there was no such things as this pattern matching, as we see used here in the `type is VectorType vecType` expression. So the equivalent in the pre-pattern match days would have been considerably more obnoxious and verbose.\r\n\r\nLet's talk about `DataKind`. Unquestionably it is confusing, but if you take a look at it, it is also really, really helpful to have, for the common builtin types, an `enum`.\r\n\r\n## Proposed balance\r\n\r\nI think it's possible to sort of have our cake and eat it too. Now that we have #1520, we can sort of make our public surface as sparse as possible, while allowing the conveniences we currently enjoy for the internal implementation to remain more or less unmolested.\r\n\r\n* Let us mark these questionable things as `internal`, but with `BestFriend` attributes on them. The internal code can retain is sparsity, \r\n* Let us add to the public surface the same information that we get from the types on the specific relevant types themselves. (E.g., the vector size would just be *publicly* part of `VectorSize` itself.)\r\n* In any event, some of the properties have no reason to exist in *any* world. For example, a property like `IsTimeSpan` exists just because someone misunderstood what was going on, and thought, \"gee I'm adding a new class, I see we have tests for things like vector and text, let me just add this.\" Nope, we just have those special things as conveniences.\r\n\r\nWe could then, if we *like* either (1) make the conveniences public or (2) remove them altogether, at our own pace, without jeopardizing the public surface of the API at all.\r\n\r\n/cc @Zruty0 @shauheen @terrajobst \r\n","Url":"https://github.com/dotnet/machinelearning/issues/1533","RelatedDescription":"Closed issue \"IDataView Cleanup: ColumnType cleanup\" (#1533)"},{"Id":"378096347","IsPullRequest":true,"CreatedAt":"2018-11-07T00:51:28","Actor":"artidoro","Number":"1561","RawContent":null,"Title":"WIP: Publish test artifacts on timeout and not just failure","State":"open","Body":"Fixes #1556.\r\n\r\nIn this PR I add a condition so that we post test artifacts not just in case of failures, but also in case of timeouts, by using `not(succeeded())` condition.\r\n\r\nI also set the timeout limit for the running the tests to 30 min (this does not include the build time).\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1561","RelatedDescription":"Open PR \"WIP: Publish test artifacts on timeout and not just failure\" (#1561)"},{"Id":"378093070","IsPullRequest":false,"CreatedAt":"2018-11-07T00:34:51","Actor":"sfilipi","Number":"1560","RawContent":null,"Title":"Categorical Hash transform Create method ignores the number of HashBits ","State":"open","Body":"Looking at the [Create method](https://github.com/dotnet/machinelearning/blob/850f91c2e67679a825b49d3eefd96dea2cc2c153/src/Microsoft.ML.Transforms/CategoricalHashTransform.cs#L148) it doesn't pass the number of HashBits to the OneHotHashEncodingEstimator. ","Url":"https://github.com/dotnet/machinelearning/issues/1560","RelatedDescription":"Open issue \"Categorical Hash transform Create method ignores the number of HashBits \" (#1560)"},{"Id":"378083716","IsPullRequest":true,"CreatedAt":"2018-11-06T23:51:56","Actor":"danmosemsft","Number":"1559","RawContent":null,"Title":"Update README to add 32 bit support in 0.7","State":"open","Body":"Also change .NET Core 2.0 - >2.1 as 2.0 is now out of support.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1559","RelatedDescription":"Open PR \"Update README to add 32 bit support in 0.7\" (#1559)"},{"Id":"378078134","IsPullRequest":true,"CreatedAt":"2018-11-06T23:28:13","Actor":"sfilipi","Number":"1558","RawContent":null,"Title":"sample link and xml format  fixes","State":"open","Body":"Fixes #1557 by correcting the link and XML format. \r\n","Url":"https://github.com/dotnet/machinelearning/pull/1558","RelatedDescription":"Open PR \"sample link and xml format  fixes\" (#1558)"},{"Id":"378077981","IsPullRequest":false,"CreatedAt":"2018-11-06T23:27:36","Actor":"sfilipi","Number":"1557","RawContent":null,"Title":"The format of the example XML is not correct in a few cases. ","State":"open","Body":"The sample link for the NormalizerCatalog.cs has an extra bracket out of place. \r\nThe samples in MatrixFactorization and TimeSeries are missing the surrounding <example> XML  node. \r\n\r\nThose are causing problems with the samples displaying in the APIs documentation site. ","Url":"https://github.com/dotnet/machinelearning/issues/1557","RelatedDescription":"Open issue \"The format of the example XML is not correct in a few cases. \" (#1557)"},{"Id":"378074610","IsPullRequest":false,"CreatedAt":"2018-11-06T23:14:19","Actor":"artidoro","Number":"1556","RawContent":null,"Title":"No artifacts produced when CI builds time out","State":"open","Body":"This is related to #1473.\r\n\r\nOur current CI builds hang quite often. #1473 suggests to retain the output files produced during tests and inspect them to help identify the problem. Thanks to #1527 we now produce artifacts. However, we only produce them when the builds fail, and not when they time out. It would be useful to produce the artifacts also when the builds time out as that is a significant part of the current build issues encountered. \r\n\r\nTake https://dnceng.visualstudio.com/public/_build/results?buildId=40590&view=logs for example. You cannot access the artifacts because the build simply timed out. \r\n\r\nHere instead, there was one build failure and one time out. You can only access artifacts for the build that failed. https://dnceng.visualstudio.com/public/_build/results?buildId=40591&view=logs\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1556","RelatedDescription":"Open issue \"No artifacts produced when CI builds time out\" (#1556)"},{"Id":"378064821","IsPullRequest":true,"CreatedAt":"2018-11-06T22:40:34","Actor":"sfilipi","Number":"1555","RawContent":null,"Title":"adding more logging to failures.","State":"open","Body":"Fixes #1477 by adding more logging around the failure on the baselines number comparison. \r\n\r\nLogging on failures looks like this now:\r\n\r\n```\r\nValues to compare are 0.49224 and 0.49223705031518167\r\n\t AllowedVariance: 1E-07\r\n\t delta: 2.9E-06\r\n\t delta2: 2.9E-06\r\n\r\n*** Failure: Output and baseline mismatch at line 3: 'FieldAwareFactorizationMachine\\FieldAwareFactorizationMachine-CV-breast-cancer.txt\r\n```'\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1555","RelatedDescription":"Open PR \"adding more logging to failures.\" (#1555)"},{"Id":"378054234","IsPullRequest":false,"CreatedAt":"2018-11-06T22:08:01","Actor":"helloguo","Number":"1554","RawContent":null,"Title":"Build failed on Ubuntu 18.04","State":"open","Body":"Build failed on Ubuntu 18.04. The ML.NET was forked today 11/6/18. The error msg says tensorflow.redist is not able to be downloaded as shown below. Any guidance to solve it? Thank you.\r\n\r\n![build-fail](https://user-images.githubusercontent.com/18431130/48096873-45c6c580-e1cd-11e8-9736-4ee6e355af0d.PNG)\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1554","RelatedDescription":"Open issue \"Build failed on Ubuntu 18.04\" (#1554)"},{"Id":"378045075","IsPullRequest":false,"CreatedAt":"2018-11-06T21:41:24","Actor":"CESARDELATORRE","Number":"1553","RawContent":null,"Title":"Saving a DataView to a file should be simpler and not through to the LocalEnvironment class","State":"open","Body":"I'm using v0.7.\r\nIssue: Saving a DataView to a file should be simpler and not having to directly use the LocalEnvironment class.\r\nIf there's any new way to do this in v0.7 or v08, please tell me, but I haven't found it. :)\r\n\r\nAs far as I know, this is the code needed, currently:\r\n\r\n```\r\n                // save test split dataset\r\n                IHostEnvironment env = (IHostEnvironment)mlContext;\r\n                using (var ch = env.Start(\"SaveData\"))\r\n                using (var file = env.CreateOutputFile(Path.Combine(_outputPath, \"testData.idv\")))\r\n                {\r\n                    var saver = new BinarySaver(mlContext, new BinarySaver.Arguments());\r\n                    DataSaverUtils.SaveDataView(ch, saver, testDataView, file);\r\n                }\r\n```\r\n\r\nFirst, it needs to use the `IChannel` object that has to be obtained from the `IHostEnvironment` object that you can get by casting the `MLContext `object to `IHostEnvironment`. The developer shouldn't need to use `IHostEnvironment` in any case, I think.\r\n\r\nThen, still a few more lines for saving the file.\r\n\r\nWe should aim to achieve a simpler API for doing this, just something like:\r\n\r\n`testDataView.SaveToFile(testDataSetFilePath);`\r\n\r\nOr if we need to do it through any utility class:\r\n\r\n`DataSaverUtils.SaveDataViewToFile(testDataView, testDataSetFilePath);`\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1553","RelatedDescription":"Open issue \"Saving a DataView to a file should be simpler and not through to the LocalEnvironment class\" (#1553)"},{"Id":"378038696","IsPullRequest":true,"CreatedAt":"2018-11-06T21:22:53","Actor":"rantri","Number":"1552","RawContent":null,"Title":"Fixes #1550 - Type mismatch in TransformSamples.SampleInfertDataWithFeatures","State":"open","Body":"Fixes #1550\r\n\r\nType mismatch in TransformSamples.SampleInfertDataWithFeatures\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1552","RelatedDescription":"Open PR \"Fixes #1550 - Type mismatch in TransformSamples.SampleInfertDataWithFeatures\" (#1552)"},{"Id":"378035743","IsPullRequest":false,"CreatedAt":"2018-11-06T21:14:10","Actor":"rantri","Number":"1550","RawContent":null,"Title":"Type mismatch in TransformSamples.SampleInfertDataWithFeatures","State":"open","Body":"Type should be changed from int to float.\r\n\r\nFrom:\r\n```\r\nclass SampleInfertDataWithFeatures\r\n{\r\n    public VBuffer<int> Features { get; set; }\r\n}\r\n```\r\n\r\nTo:\r\n\r\n```\r\nclass SampleInfertDataWithFeatures\r\n{\r\n    public VBuffer<float> Features { get; set; }\r\n}\r\n```\r\n\r\nIt caused exception:\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Can't bind the IDataView column 'Features' of type 'Vec<R4, 3>' to field or property 'Features' of type 'Microsoft.ML.Runtime.Data.VBuffer`1[[System.Int32, System.Private.CoreLib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]]'.\r\n  Source=Microsoft.ML.Api\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.Api.TypedCursorable`1..ctor(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, InternalSchemaDefinition schemaDefn) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 129\r\n   at Microsoft.ML.Runtime.Api.TypedCursorable`1.Create(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 249\r\n   at Microsoft.ML.Runtime.Api.CursoringUtils.AsCursorable[TRow](IDataView data, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 550\r\n   at Microsoft.ML.Runtime.Api.PipeEngine`1..ctor(IHostEnvironment env, IDataView pipe, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\PredictionEngine.cs:line 98\r\n   at Microsoft.ML.Runtime.Api.CursoringUtils.AsEnumerable[TRow](IDataView data, IHostEnvironment env, Boolean reuseRowObject, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 589\r\n   at Microsoft.ML.Samples.Dynamic.TransformSamples.ConcatTransform() in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Dynamic\\ConcatTransform.cs:line 49\r\n   at Microsoft.ML.Samples.Program.Main(String[] args) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Program.cs:line 13\r\n \r\n","Url":"https://github.com/dotnet/machinelearning/issues/1550","RelatedDescription":"Open issue \"Type mismatch in TransformSamples.SampleInfertDataWithFeatures\" (#1550)"},{"Id":"378021332","IsPullRequest":false,"CreatedAt":"2018-11-06T20:32:12","Actor":"cosmincatalin","Number":"1549","RawContent":null,"Title":"Scoring with ONNX does not work as expected","State":"open","Body":"I have an _onnx_ model generated from an MXNet model. I try to use it for scoring a regression problem. It does not work. Here are the steps I followed:\r\n\r\n## Build the MXNet model\r\n\r\n```python\r\nimport pandas as pd\r\n```\r\n\r\n```python\r\ndf_train = pd.read_csv(\"train.csv\")\r\ndf_test = pd.read_csv(\"test.csv\")\r\n```\r\n\r\n\r\n```python\r\nimport mxnet as mx\r\n```\r\n\r\n\r\n```python\r\ntrain_X = mx.nd.array(df_train.drop(\"Target\", axis=1).values)\r\ntrain_y = mx.nd.array(df_train.Target.values)\r\ntest_X = mx.nd.array(df_test.drop(\"Target\", axis=1).values)\r\ntest_y = mx.nd.array(df_test.Target.values)\r\ntrain_nd = list(zip(train_X, train_y))\r\ntest_nd = list(zip(test_X, test_y))\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet.gluon.data import DataLoader\r\n```\r\n\r\n\r\n```python\r\nbatch_size = 64\r\n```\r\n\r\n\r\n```python\r\ntrain_data = DataLoader(train_nd, batch_size, shuffle=True)\r\ntest_data = DataLoader(test_nd, batch_size, shuffle=True)\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet.gluon.nn import HybridSequential, Dense, Dropout\r\nfrom mxnet.initializer import Xavier\r\nfrom mxnet.gluon.loss import L2Loss\r\nfrom mxnet.gluon.trainer import Trainer\r\n```\r\n\r\n\r\n```python\r\nnet = HybridSequential()\r\nwith net.name_scope():\r\n    net.add(Dense(9))\r\n    net.add(Dropout(.25))\r\n    net.add(Dense(16))\r\n    net.add(Dropout(.25))\r\n    net.add(Dense(1))\r\n```\r\n\r\n\r\n```python\r\nnet.hybridize()\r\n```\r\n\r\n\r\n```python\r\nctx = mx.cpu()\r\n```\r\n\r\n\r\n```python\r\nnet.collect_params().initialize(Xavier(magnitude=2.24), ctx=ctx)\r\n```\r\n\r\n\r\n```python\r\nloss = L2Loss()\r\n```\r\n\r\n\r\n```python\r\ntrainer = Trainer(net.collect_params(), optimizer=\"adam\")\r\n```\r\n\r\n\r\n```python\r\nsmoothing_constant = .01\r\nepochs = 5\r\n```\r\n\r\n\r\n```python\r\ndef measure_performance(model, ctx, data_iter):\r\n    mae = mx.metric.MAE()\r\n    for _, (data, labels) in enumerate(data_iter):\r\n        data = data.as_in_context(ctx)\r\n        labels = labels.as_in_context(ctx)\r\n        output = model(data)\r\n        predictions = output\r\n        mae.update(preds=predictions, labels=labels)\r\n    return mae.get()[1]\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet import autograd\r\n```\r\n\r\n\r\n```python\r\nfor e in range(epochs):\r\n    moving_loss = 0\r\n    for i, (data, label) in enumerate(train_data):\r\n        data = data.as_in_context(ctx)\r\n        label = label.as_in_context(ctx)\r\n        with autograd.record():\r\n            output = net(data)\r\n            loss_result = loss(output, label)\r\n        loss_result.backward()\r\n        trainer.step(batch_size)\r\n\r\n        curr_loss = mx.nd.mean(loss_result).asscalar()\r\n        moving_loss = (curr_loss if ((i == 0) and (e == 0))\r\n                       else (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss)\r\n\r\n    test_mae = measure_performance(net, ctx, test_data)\r\n    train_mae = measure_performance(net, ctx, train_data)\r\n    print(\"Epoch %s. Loss: %s, Train_mae %s, Test_mae %s\" % (e, moving_loss, train_mae, test_mae))\r\n```\r\nOutput:\r\n\r\n    Epoch 0. Loss: 5.848355519538663, Train_mae 1.1675882118595375, Test_mae 1.2460664133482342\r\n    Epoch 1. Loss: 2.8617846590961733, Train_mae 0.8983533112182495, Test_mae 0.9300098409758338\r\n    Epoch 2. Loss: 1.6959465687435336, Train_mae 0.6692642353930274, Test_mae 0.6831557900656627\r\n    Epoch 3. Loss: 0.91648433711298, Train_mae 0.5097093659054811, Test_mae 0.5119943500885481\r\n    Epoch 4. Loss: 0.5725724269757653, Train_mae 0.4398727014996231, Test_mae 0.4710224339667755\r\n    \r\n\r\n\r\n```python\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\nnet(mx.nd.array(np.expand_dims(np.ones(9), axis=0))).asnumpy().ravel().tolist()[0]\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    7.281115531921387\r\n\r\n\r\n\r\n\r\n```python\r\nnet.export(\"model\", epoch=epochs - 1)\r\n```\r\n\r\n**7.281115531921387 is what I expect to get when I provide _ones_ as feature.**\r\n\r\n## Export the MXNet model as ONNX\r\n\r\n\r\n\r\n```python\r\nfrom mxnet.contrib import onnx as onnx_mxnet\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\nonnx_mxnet.export_model(sym=\"model-symbol.json\",\r\n                  params=\"model-0004.params\",\r\n                  input_shape=[(1, 9)],\r\n                  input_type=np.float32,\r\n                  onnx_file_path=\"model.onnx\",\r\n                  verbose=True)\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    'model.onnx'\r\n\r\nThe model as visualized with Netron is as follows (the model is trivial):\r\n\r\n![model](https://user-images.githubusercontent.com/525590/48091230-61e85800-e209-11e8-83fe-4cd66e067e2f.png)\r\n\r\n## Testing with Tensorflow\r\n\r\nBefore loading the onnx model into ML.NET I tested it with Tensorflow\r\n\r\n\r\n\r\n```python\r\nimport onnx\r\n```\r\n\r\n\r\n```python\r\nmodel = onnx.load(\"model.onnx\")\r\n```\r\n\r\n\r\n```python\r\nfrom onnx_tf.backend import prepare\r\n```\r\n\r\n\r\n```python\r\ntf_rep = prepare(model)\r\n```\r\n\r\nOutput:\r\n\r\n    c:\\users\\cosmin\\dev\\generate-mxnet-model\\env\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:74: UserWarning: Unknown op ConstantLike in domain `ai.onnx`.\r\n      handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\r\n    \r\n\r\n\r\n```python\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\ntf_rep.run(np.expand_dims(np.ones(9), axis=0)).hybridsequential0_dense2_fwd.ravel().tolist()[0]\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    7.281115531921387\r\n\r\n\r\n\r\n\r\n```python\r\ntf_rep.export_graph(\"model.pb\")\r\n```\r\n\r\n**As you can see running the regression on ones returns the expected result: 7.281115531921387**\r\n\r\n## ML.NET 0.6\r\n\r\nMy programs is as follows:\r\n\r\n`Program.cs`\r\n```csharp\r\nusing System;\r\nusing Microsoft.ML.Runtime.Data;\r\nusing Microsoft.ML.Transforms;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n    internal static class Program\r\n    {\r\n        private static void Main(string[] args)\r\n        {\r\n            var env = new LocalEnvironment();\r\n            var reader = TextLoader.CreateReader(env,\r\n                ctx => (\r\n                    Feature1: ctx.LoadFloat(0),\r\n                    Feature2: ctx.LoadFloat(1),\r\n                    Feature3: ctx.LoadFloat(2),\r\n                    Feature4: ctx.LoadFloat(3),\r\n                    Feature5: ctx.LoadFloat(4),\r\n                    Feature6: ctx.LoadFloat(5),\r\n                    Feature7: ctx.LoadFloat(6),\r\n                    Feature8: ctx.LoadFloat(7),\r\n                    Feature9: ctx.LoadFloat(8),\r\n                    Target: ctx.LoadFloat(9)),\r\n                separator: ',',\r\n                hasHeader: true);\r\n            var data = reader.Read(new MultiFileSource(\"test.csv\"));\r\n            \r\n            var learningPipeline = reader.MakeNewEstimator()\r\n                .Append(row => (Target: row.Target, Features: row.Feature1.ConcatWith(\r\n                    row.Feature2, row.Feature3, row.Feature4, row.Feature5, row.Feature6,\r\n                    row.Feature7, row.Feature8, row.Feature9)))\r\n                .Append(row => (Truth: row.Target, Estimate: row.Features.ApplyOnnxModel(\"model.onnx\")));\r\n\r\n            var model = learningPipeline.Fit(data);\r\n            \r\n            var predictionFunction = model.AsDynamic.MakePredictionFunction<SearchData, SearchPrediction>(env);\r\n\r\n            var prediction = predictionFunction.Predict(new SearchData()\r\n            {\r\n                Feature1 = 1.0f,\r\n                Feature2 = 1.0f,\r\n                Feature3 = 1.0f,\r\n                Feature4 = 1.0f,\r\n                Feature5 = 1.0f,\r\n                Feature6 = 1.0f,\r\n                Feature7 = 1.0f,\r\n                Feature8 = 1.0f,\r\n                Feature9 = 1.0f\r\n            });            \r\n            Console.WriteLine(prediction.Estimate);\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n`SearchData.cs`\r\n```csharp\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n\r\n    public class SearchData\r\n    {\r\n        [ColumnName(\"Target\")]\r\n        public float DummyUnused{ get; set; }\r\n        \r\n        public float Feature1{ get; set; }\r\n\r\n        public float Feature2{ get; set; }\r\n\r\n        public float Feature3{ get; set; }\r\n\r\n        public float Feature4{ get; set; }\r\n\r\n        public float Feature5{ get; set; }\r\n\r\n        public float Feature6{ get; set; }\r\n\r\n        public float Feature7{ get; set; }\r\n\r\n        public float Feature8{ get; set; }\r\n\r\n        public float Feature9{ get; set; }\r\n\r\n    }\r\n\r\n}\r\n\r\n```\r\n\r\n`SearchPrediction.cs`\r\n```csharp\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n    public class SearchPrediction\r\n    {\r\n        [ColumnName(\"Target\")]\r\n        public float Estimate{ get; set; }\r\n    }\r\n}\r\n\r\n```\r\n\r\nWhen running the program, I get 0, which is not great. The training and test sets are just full of 10 columns of floats.\r\n\r\nI also attach the `pip` requirements.txt file, so that you can see the onnx version I've used\r\n\r\n```\r\nabsl-py==0.6.1\r\nastor==0.7.1\r\nbackcall==0.1.0\r\nbleach==3.0.2\r\ncertifi==2018.10.15\r\nchardet==3.0.4\r\ncolorama==0.4.0\r\ndecorator==4.3.0\r\ndefusedxml==0.5.0\r\nentrypoints==0.2.3\r\ngast==0.2.0\r\ngraphviz==0.8.4\r\ngrpcio==1.16.0\r\nh5py==2.8.0\r\nidna==2.6\r\nipykernel==5.1.0\r\nipython==7.1.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.4.2\r\njedi==0.13.1\r\nJinja2==2.10\r\njsonschema==2.6.0\r\njupyter==1.0.0\r\njupyter-client==5.2.3\r\njupyter-console==6.0.0\r\njupyter-core==4.4.0\r\nKeras-Applications==1.0.6\r\nKeras-Preprocessing==1.0.5\r\nMarkdown==3.0.1\r\nMarkupSafe==1.0\r\nmistune==0.8.4\r\nmxnet==1.3.0\r\nnbconvert==5.4.0\r\nnbformat==4.4.0\r\nnotebook==5.7.0\r\nnumpy==1.14.6\r\nonnx==1.3.0\r\nonnx-tf==1.2.0\r\npandas==0.23.4\r\npandocfilters==1.4.2\r\nparso==0.3.1\r\npickleshare==0.7.5\r\nprometheus-client==0.4.2\r\nprompt-toolkit==2.0.7\r\nprotobuf==3.6.1\r\nPygments==2.2.0\r\npython-dateutil==2.7.5\r\npytz==2018.7\r\npywinpty==0.5.4\r\nPyYAML==3.13\r\npyzmq==17.1.2\r\nqtconsole==4.4.2\r\nrequests==2.18.4\r\nSend2Trash==1.5.0\r\nsix==1.11.0\r\ntensorboard==1.11.0\r\ntensorflow==1.11.0\r\ntermcolor==1.1.0\r\nterminado==0.8.1\r\ntestpath==0.4.2\r\ntornado==5.1.1\r\ntraitlets==4.3.2\r\ntyping==3.6.6\r\ntyping-extensions==3.6.6\r\nurllib3==1.22\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nWerkzeug==0.14.1\r\nwidgetsnbextension==3.4.2\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/1549","RelatedDescription":"Open issue \"Scoring with ONNX does not work as expected\" (#1549)"},{"Id":"377994073","IsPullRequest":true,"CreatedAt":"2018-11-06T20:18:47","Actor":"shauheen","Number":"1547","RawContent":null,"Title":"Cherrypick for release 0.7","State":"closed","Body":"Cherry-pick into release for 0.7","Url":"https://github.com/dotnet/machinelearning/pull/1547","RelatedDescription":"Closed or merged PR \"Cherrypick for release 0.7\" (#1547)"},{"Id":"378006080","IsPullRequest":false,"CreatedAt":"2018-11-06T19:48:14","Actor":"shmoradims","Number":"1548","RawContent":null,"Title":"Typo in name ExtractWordEmbeedings (extra e)","State":"open","Body":"typo: ExtractWordEmb**ee**dings -> ExtractWordEmb**e**ddings (double **d** instead of double **e**)\r\n\r\nLocation:\r\n        public static WordEmbeddingsExtractorEstimator ExtractWordEmbeedings(this TransformsCatalog.TextTransforms catalog,\r\n            string inputColumn,\r\n            string outputColumn = null,\r\n            WordEmbeddingsTransform.PretrainedModelKind modelKind = WordEmbeddingsTransform.PretrainedModelKind.Sswe)\r\n            => new WordEmbeddingsExtractorEstimator(Contracts.CheckRef(catalog, nameof(catalog)).GetEnvironment(), inputColumn, outputColumn, modelKind);\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1548","RelatedDescription":"Open issue \"Typo in name ExtractWordEmbeedings (extra e)\" (#1548)"},{"Id":"377989098","IsPullRequest":true,"CreatedAt":"2018-11-06T19:03:01","Actor":"sfilipi","Number":"1546","RawContent":null,"Title":"removing space that is causing the docs CI to fail","State":"closed","Body":"removing space in the XML that is causing the docs CI to fail\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1546","RelatedDescription":"Closed or merged PR \"removing space that is causing the docs CI to fail\" (#1546)"},{"Id":"377973621","IsPullRequest":true,"CreatedAt":"2018-11-06T18:18:36","Actor":"yaeldekel","Number":"1545","RawContent":null,"Title":"Fix ConvertingTransform bug","State":"open","Body":"Fixes #1544 .","Url":"https://github.com/dotnet/machinelearning/pull/1545","RelatedDescription":"Open PR \"Fix ConvertingTransform bug\" (#1545)"},{"Id":"377647196","IsPullRequest":false,"CreatedAt":"2018-11-06T18:07:05","Actor":"abgoswam","Number":"1537","RawContent":null,"Title":"Invalid arguments provided when using Iris dataset with TextLoader ","State":"closed","Body":"There are two versions of the Iris data set in the ML.NET repo.\r\n- [iris.data](https://github.com/dotnet/machinelearning/blob/master/test/data/iris.data)\r\n- [iris.txt](https://github.com/dotnet/machinelearning/blob/master/test/data/iris.txt)\r\n\r\nBoth of these datasets do not have a header.  As such, when using these datasets with Textloader, the `HasHeader` field in the `TextLoader.Arguments` class should be `false` . \r\n\r\nInstead, we see several places (e.g. [here](https://github.com/dotnet/machinelearning/blob/453eb57f0cd94d6412b1f8dee76c00c686e2e06e/test/Microsoft.ML.Tests/TrainerEstimators/TrainerEstimators.cs#L178) ) where we have set `HasHeader=true`  while working with the above two datasets. \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1537","RelatedDescription":"Closed issue \"Invalid arguments provided when using Iris dataset with TextLoader \" (#1537)"},{"Id":"377615479","IsPullRequest":true,"CreatedAt":"2018-11-06T18:07:05","Actor":"abgoswam","Number":"1535","RawContent":null,"Title":"Fix TextLoader.Argument (HasHeader=true) for Iris dataset","State":"closed","Body":"Fixes #1537 \r\n\r\nDropped `HasHeader=true` from  `GetMultiClassPipeline` and `MakeIrisTextLoaderArgs`\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1535","RelatedDescription":"Closed or merged PR \"Fix TextLoader.Argument (HasHeader=true) for Iris dataset\" (#1535)"},{"Id":"377964954","IsPullRequest":false,"CreatedAt":"2018-11-06T17:55:48","Actor":"yaeldekel","Number":"1544","RawContent":null,"Title":"ConvertTransform bug.","State":"open","Body":"If a column specifies return type of U*, but the arguments specify a key range, the column is converted to key instead to plain old unsigned integer type.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1544","RelatedDescription":"Open issue \"ConvertTransform bug.\" (#1544)"},{"Id":"377689131","IsPullRequest":false,"CreatedAt":"2018-11-06T04:33:22","Actor":"TomFinley","Number":"1542","RawContent":null,"Title":"TensorFlow transform would throw on non-vector input","State":"open","Body":"In the process of working on #1533, I found the following code in the tensorflow transform.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/73762a8d8f23d27f3c15b4382c0bc374934ccad5/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L834-L844\r\n\r\nConsider the above code. We have at line 834 this assignment to a boolean value depending on whether the input is of type vector, or not. This strongly suggests that the transform can accomodate non-vector types. However at lines 841 and 844, we have this `type.AsVector.DimCount`. Now, `AsVector` will be `null` in the case where the type is not a vector of course, so this would throw a null reference exception if we were to ever feed this transform a non-vector value.\r\n\r\nSo, there's something wrong here. Unfortunately the intent of what the author *meant* to write is somewhat hidden from me, so perhaps whoever wrote this code could check this out. Maybe even write a test to test this condition.","Url":"https://github.com/dotnet/machinelearning/issues/1542","RelatedDescription":"Open issue \"TensorFlow transform would throw on non-vector input\" (#1542)"},{"Id":"377674673","IsPullRequest":false,"CreatedAt":"2018-11-06T03:11:08","Actor":"AceHack","Number":"1541","RawContent":null,"Title":"Please support autodifferentiation","State":"open","Body":"This would be a great feature to have.","Url":"https://github.com/dotnet/machinelearning/issues/1541","RelatedDescription":"Open issue \"Please support autodifferentiation\" (#1541)"},{"Id":"377674070","IsPullRequest":false,"CreatedAt":"2018-11-06T03:07:51","Actor":"TomFinley","Number":"1540","RawContent":null,"Title":"IDataView Cleanup: KeyType Simplification","State":"open","Body":"We have by now multiple years of experience with `KeyType`. In the documentation of the `IDatView` type system, [key types](https://github.com/dotnet/machinelearning/blob/master/docs/code/IDataViewTypeSystem.md#key-types) are described as having the following properties:\r\n\r\nAll of our current transformers produce key-types that are (1) known size and (2) have a minimum value of `0`, and are (3) contiguous, with absolutely no exceptions. Also if we consider how key-types are actually used (always, even in the hash transformer, considered enumerations into a set), then there is no particular rason for this. I therefore suggest that we simplify the key types by removing the properties describing this, and just make it a rule.\r\n\r\nThis does represent a loss of capability, but it is a capability that AFAIK has never been exercised beyond unit tests and small toy demonstrations to clarify to new developers, \"by the way, our key-types have this really, really weird capability...\"\r\n\r\nOn the flip side, I feel like having a *count* have the maximum of `int.MaxValue` is arguably too limiting. The reason for this is that it was anticipated that the only real usage of key values would be to project into a vector, but this is not true. I would like to replace it with a `ulong` maximum value instead.","Url":"https://github.com/dotnet/machinelearning/issues/1540","RelatedDescription":"Open issue \"IDataView Cleanup: KeyType Simplification\" (#1540)"},{"Id":"377662091","IsPullRequest":false,"CreatedAt":"2018-11-06T02:04:52","Actor":"AceHack","Number":"1539","RawContent":null,"Title":"Please support XGBoost i.e. gradient boosting machines","State":"open","Body":"This is the 2nd most popular model on Kaggle.\r\n\r\nThanks.","Url":"https://github.com/dotnet/machinelearning/issues/1539","RelatedDescription":"Open issue \"Please support XGBoost i.e. gradient boosting machines\" (#1539)"},{"Id":"377649240","IsPullRequest":true,"CreatedAt":"2018-11-06T01:00:57","Actor":"shmoradims","Number":"1538","RawContent":null,"Title":"Added dynamic API snippets to cookbook","State":"open","Body":"Added the dynamic API equivalent for all the snippets that were using static API, except for the snippet that uses onFit, which is not supported by dynamic API yet.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1538","RelatedDescription":"Open PR \"Added dynamic API snippets to cookbook\" (#1538)"},{"Id":"377642246","IsPullRequest":true,"CreatedAt":"2018-11-06T00:30:45","Actor":"eerhardt","Number":"1536","RawContent":null,"Title":"Introduce VBuffer GetValues and GetIndices","State":"open","Body":"Use the new methods in place of Count and Values/Indices in as many readonly situations as possible.\r\n\r\nWorking towards #608 \r\n\r\nSee proposed change (4) in https://github.com/dotnet/machinelearning/issues/608#issuecomment-433185895\r\n\r\nEventually, `Count`, `Values` and `Indices` will be hidden/private on VBuffer and `GetValues()` and `GetIndices()` will be the only way to read these values.","Url":"https://github.com/dotnet/machinelearning/pull/1536","RelatedDescription":"Open PR \"Introduce VBuffer GetValues and GetIndices\" (#1536)"},{"Id":"377606569","IsPullRequest":false,"CreatedAt":"2018-11-05T22:17:19","Actor":"TomFinley","Number":"1534","RawContent":null,"Title":"IDataView Cleanup: Rename `UInt128`","State":"open","Body":"The row cursor IDs serve a purpose as described here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/Data/ICursor.md#getidgetter\r\n\r\nThese IDs are represented as 128-bit numbers. Correspondingly, I named them `UInt128` back in the long vanished past. However, this is a troubling name: this first of all conflicts with any name .NET would use in the future to represent 128-bit unsigned integers (assuming they ever did so), which is reason enough not to use it. But even without this reason, this type just doesn't *quite* act like a number.\r\n\r\nOn the other hand, I am not certain what a good name would be. Something like `RowId`, `RecordId`, or something like that?\r\n\r\n/cc @Zruty0 @shauheen @terrajobst ","Url":"https://github.com/dotnet/machinelearning/issues/1534","RelatedDescription":"Open issue \"IDataView Cleanup: Rename `UInt128`\" (#1534)"},{"Id":"377565010","IsPullRequest":false,"CreatedAt":"2018-11-05T20:16:47","Actor":"TomFinley","Number":"1532","RawContent":null,"Title":"IDataView Cleanup: Clear cutting the `IRowCursor` interface jungle","State":"open","Body":"Right now we have a fairly elaborate set of interfaces surrounding `IRowCursor`. These include `ISchematized`, `ICounted`, `IRow`.\r\n\r\nWhile `IRowCursor` and `IRow` are quite useful, it is not clear if separating out `ICursor` and `ICounted` as separate interfaces is actually helpful, and we think we ought to get rid of `ISchematized` anyway (see #1502). The goal would be to refactor this jungle so that there are, relating to row cursors, two types, both abstract ***classes***, corresponding to `IRow` and `IRowCursor`, but of course not named that since they won't be interfaces. (What would be a good name is up for debate. `RowCursor` seems probably fine, but just `Row` does not seem like a good name.)\r\n\r\nIt may be that we have the name `Row` for now until we imagine a better name, and treat that renaming as a separate issue from this issue which mostly treats on the proper refactoring of the code.\r\n\r\n`ICursor` does have some implementations that are not also `IRowCursor`, but it is unclear whether this *has* to be this way, or if it is just that way just because it was there.\r\n\r\nThe collapse of `ICounted` into these hypothetical `Row` and `RowCursor` classes would be mostly into `Row`.\r\n\r\n## While we are at it...\r\n\r\nWhile refactoring this code it would be advantageous to at the same time deal with the refactorings of other things methods in cursors, as we will be restructuring them anyway.\r\n\r\n* The utility of `State` on cursors has proven to not be terribly useful. People create and use cursors more or less like they do enumerators -- they create them, move-next over them, then when they stop the thing is disposed. It is valuable for the sake of assert checking, but otherwise I am not aware of any use. Certainly `IEnumerator` gets along just fine without this...\r\n\r\n* The `MoveMany` method *seems* attractive. In many cases, you can in fact move faster than just an exhaustive `MoveNext` to get to where you want to go. The trouble is the utility for such a mechanism has proven to be limited -- sure, a `Skip` filter could be more performant, but beyond that usages are few. We may as well remove it.\r\n\r\n* `GetRootCursor`'s performs an essential job (bypass nested move-next so that nested cursors, which is to say *most* cursors, have a fast `MoveNext`). By moving this to an abstract class, we can see if this \"bypass\" mechanism can be achieved in a less obnoxious (possibly internal) way to cursors.\r\n\r\n* Possibly not to be done here, it would be nice if instead of `IRowCursor` (or rather, its abstract class descendant) being disposable, that the `IRow` is disposable. This is desirable but may require additional considerations, and might be best achieved in a separate issue.\r\n\r\n* The utility of the `IsActiveColumn` is not immediately clear. Can we get away with simply not providing it? It may be though that we decide to keep it.\r\n\r\n/cc @Zruty0 @shauheen @terrajobst ","Url":"https://github.com/dotnet/machinelearning/issues/1532","RelatedDescription":"Open issue \"IDataView Cleanup: Clear cutting the `IRowCursor` interface jungle\" (#1532)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-11-07T05:30:33.3274216Z","RunDurationInMilliseconds":1194}