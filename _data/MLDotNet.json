{"Data":{"GitHub":{"Issues":[{"Id":"419793212","IsPullRequest":true,"CreatedAt":"2019-03-12T04:09:53","Actor":"rogancarr","Number":"2923","RawContent":null,"Title":"Logistic Regression NumberOfIterations to MaximumNumberOfIterations","State":"open","Body":"This PR updates `Logistic Regression` (multiclass, regression aka poisson, and multiclass) to specify the `MaximumNumberOfIterations` instead of `NumberOfIterations` as it's a stopping criterion and not necessarily a tuning parameter.\r\n\r\nI also took a look around the codebase, and this is the last change of this sort that will be needed.\r\n\r\nFixes #2922 ","Url":"https://github.com/dotnet/machinelearning/pull/2923","RelatedDescription":"Open PR \"Logistic Regression NumberOfIterations to MaximumNumberOfIterations\" (#2923)"},{"Id":"419792652","IsPullRequest":false,"CreatedAt":"2019-03-12T04:06:44","Actor":"rogancarr","Number":"2922","RawContent":null,"Title":"Logistic Regression: NumberOfIterations should be MaximumNumberOfIterations","State":"open","Body":"Similar to `SDCA` and `K-Means`, `Logistic Regression` has a `NumberOfIterations` option that stands for the maximum number of iterations.\r\n\r\nI propose changing it to `MaximumNumberOfIterations`.\r\n\r\n** I searched through all the learners, and this is the last learner that needs this change.","Url":"https://github.com/dotnet/machinelearning/issues/2922","RelatedDescription":"Open issue \"Logistic Regression: NumberOfIterations should be MaximumNumberOfIterations\" (#2922)"},{"Id":"419766655","IsPullRequest":true,"CreatedAt":"2019-03-12T02:07:56","Actor":"rogancarr","Number":"2921","RawContent":null,"Title":"Adding functional tests for all training scenarios","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Training functionality we want fully supported in V1.\r\n\r\nScenarios\r\n\r\n- I can provide multiple learners and easily compare evaluation metrics between them.\r\n- I can use an initial predictor to update/train the model for some trainers (e.g. linear learners like averaged perceptron). Specifically, start the weights for the model from the existing weights.  \r\n- Metacomponents smartly restrict their use to compatible components.   Example: \"When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.\"\r\n- I can use OVA and easily add any binary classifier to it\r\n\r\nFixes #2906 ","Url":"https://github.com/dotnet/machinelearning/pull/2921","RelatedDescription":"Open PR \"Adding functional tests for all training scenarios\" (#2921)"},{"Id":"419766088","IsPullRequest":false,"CreatedAt":"2019-03-12T02:05:16","Actor":"rogancarr","Number":"2920","RawContent":null,"Title":"OVA Multiclass Classification works with a variety of sub-trainer training tasks","State":"open","Body":"In writing a test for #2859, I have found that it is possible to create an `OVA` (aka \"One-Versus-All\") multiclass classification trainer learners other than a binary classifier as an input.\r\n\r\nOne of our V1 Goals is:\r\n- Metacomponents smartly restrict their use to compatible components.   Example: \"When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.\"\r\n\r\nFor all types\r\n- **Anomaly Detection** throws on `Fit()` due to data mismatch. Suggests that this could work under ideal conditions.\r\n- **Binary classification** works, as expected.\r\n- **Clustering** is a runtime error upon pipeline construction (OVA checks the model type produced).\r\n- **Multiclass classification** is a runtime error upon pipeline construction (OVA checks the model type produced).\r\n- **Ranking** produces a model, transforms the data, and evaluates the scored data.\r\n- **Regression** produces a model, transforms the data, and evaluates the scored data.\r\n\r\n(Note that I didn't run a recommender check because this needs to be coded x64-only at this point.)","Url":"https://github.com/dotnet/machinelearning/issues/2920","RelatedDescription":"Open issue \"OVA Multiclass Classification works with a variety of sub-trainer training tasks\" (#2920)"},{"Id":"419764027","IsPullRequest":true,"CreatedAt":"2019-03-12T01:56:00","Actor":"artidoro","Number":"2919","RawContent":null,"Title":"One name for MulticlassClassification","State":"open","Body":"Solves part of #2623.\r\n\r\nIn this PR I rename:\r\n- `MulticlassClassifier[...]` to `MulticlassClassification[...]`\r\n- `MulticlassPredictionTransformer` to `MulticlassClassificationPredictionTransformer`\r\n\r\nNot in public surface but renamed for consistency:\r\n- `MultiClassMamlEvaluator` to `MultiClassClassificationMamlEvaluator`\r\n\r\nNotice that this does not completely solve the issue. Part of the issue is related to the trainers. PR #2903 establishes a common pattern for trainers, and once that is checked in, the issue can be closed. The pattern proposed in #2903 for trainers is: if the name is not too long `MulticlassClassification` is included in the name, otherwise it is not mentioned. ","Url":"https://github.com/dotnet/machinelearning/pull/2919","RelatedDescription":"Open PR \"One name for MulticlassClassification\" (#2919)"},{"Id":"419748347","IsPullRequest":true,"CreatedAt":"2019-03-12T00:41:00","Actor":"wschin","Number":"2918","RawContent":null,"Title":"Scrub text normalizer","State":"open","Body":"Another step toward #2832. This PR is all about renaming with an internalization of `IReadOnlyCollection`,\r\n```\r\n-        public IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n+        internal IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2918","RelatedDescription":"Open PR \"Scrub text normalizer\" (#2918)"},{"Id":"419583931","IsPullRequest":true,"CreatedAt":"2019-03-12T00:28:28","Actor":"Ivanidzo4ka","Number":"2904","RawContent":null,"Title":"Hide some duplicate methods","State":"closed","Body":"fixes #2897","Url":"https://github.com/dotnet/machinelearning/pull/2904","RelatedDescription":"Closed or merged PR \"Hide some duplicate methods\" (#2904)"},{"Id":"419009750","IsPullRequest":false,"CreatedAt":"2019-03-12T00:28:28","Actor":"rogancarr","Number":"2897","RawContent":null,"Title":"Two Ways to Save a Model","State":"closed","Body":"The current API has two ways to save a model:\r\n\r\n```cs\r\nmodel.SaveTo(MlContext, stream);\r\nmlContext.Model.Save(ITransformer, stream);\r\n```\r\n\r\nDo we just want one of these?\r\n\r\nMaybe related to #2735 ","Url":"https://github.com/dotnet/machinelearning/issues/2897","RelatedDescription":"Closed issue \"Two Ways to Save a Model\" (#2897)"},{"Id":"419738674","IsPullRequest":false,"CreatedAt":"2019-03-11T23:58:22","Actor":"Ivanidzo4ka","Number":"2917","RawContent":null,"Title":"Unify way of setting random seed","State":"open","Body":"I can understand why we use nullable seed in one place and defaults in another, but why it's uint in one places and int in others is beyond my understanding.\r\n\r\n**UInt:**\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/Transforms/Hashing.cs#L1164\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L892\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L377\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/Text/WrappedTextTransformers.cs#L184\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/OneHotHashEncoding.cs#L241\r\n\r\n**Int:**\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L135\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L293\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/RandomFourierFeaturizing.cs#L659\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.PCA/PCACatalog.cs#L31\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/MLContext.cs#L79\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2917","RelatedDescription":"Open issue \"Unify way of setting random seed\" (#2917)"},{"Id":"419727543","IsPullRequest":true,"CreatedAt":"2019-03-11T23:13:50","Actor":"wschin","Number":"2916","RawContent":null,"Title":"Polish char- and word-level tokenizers & stopword removers","State":"open","Body":"Another sub-task of #2832.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2916","RelatedDescription":"Open PR \"Polish char- and word-level tokenizers & stopword removers\" (#2916)"},{"Id":"419699070","IsPullRequest":true,"CreatedAt":"2019-03-11T22:43:50","Actor":"ganik","Number":"2915","RawContent":null,"Title":"Fixing inconsistency in usage of LossFunction","State":"closed","Body":"fixes #2174\r\nfixes #2594 \r\nI had to re-do the PR due to messed up forked branch. This is a duplicate of #2856","Url":"https://github.com/dotnet/machinelearning/pull/2915","RelatedDescription":"Closed or merged PR \"Fixing inconsistency in usage of LossFunction\" (#2915)"},{"Id":"419685093","IsPullRequest":true,"CreatedAt":"2019-03-11T21:45:37","Actor":"ganik","Number":"2913","RawContent":null,"Title":"Fixing inconsistency in usage of LossFunction","State":"closed","Body":"fixes #2174\r\nfixes #2594 \r\n\r\nI had to re-do the PR due to messed up forked branch. This is a duplicate of #2856 ","Url":"https://github.com/dotnet/machinelearning/pull/2913","RelatedDescription":"Closed or merged PR \"Fixing inconsistency in usage of LossFunction\" (#2913)"},{"Id":"419692418","IsPullRequest":true,"CreatedAt":"2019-03-11T21:29:18","Actor":"sfilipi","Number":"2914","RawContent":null,"Title":"updating namespaces ","State":"open","Body":"Towards #2751\r\n\r\nMicrosoft.ML.LightGBM -> changes to Microsoft.ML.Trainers.LightGBM\r\nMicrosoft.ML.Transforms.FeatureSelection -> moves to Microsoft.ML.Transforms","Url":"https://github.com/dotnet/machinelearning/pull/2914","RelatedDescription":"Open PR \"updating namespaces \" (#2914)"},{"Id":"419649999","IsPullRequest":true,"CreatedAt":"2019-03-11T21:02:19","Actor":"codemzs","Number":"2908","RawContent":null,"Title":"Fix links in Entrypoints.md after StandardLearners rename.","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/2908","RelatedDescription":"Closed or merged PR \"Fix links in Entrypoints.md after StandardLearners rename.\" (#2908)"},{"Id":"419653161","IsPullRequest":true,"CreatedAt":"2019-03-11T20:43:56","Actor":"ganik","Number":"2909","RawContent":null,"Title":"Make IServerFactory internal","State":"closed","Body":"fixes #1973\r\nThis concludes the issue 1973. The only remaining issue of same kind is making ISupportBoosterParameterFactory internal and its addressed by #2559","Url":"https://github.com/dotnet/machinelearning/pull/2909","RelatedDescription":"Closed or merged PR \"Make IServerFactory internal\" (#2909)"},{"Id":"419668176","IsPullRequest":false,"CreatedAt":"2019-03-11T20:28:01","Actor":"eerhardt","Number":"2912","RawContent":null,"Title":"Consider making DataView and IEstimator Preview methods return DataTable","State":"open","Body":"Visual Studio has the ability to visualize a data set if the object is a `System.Data.DataTable`.\r\n\r\nWe currently have some debugger extension methods:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/DebuggerExtensions.cs#L15-L62\r\n\r\nWe should consider making these return `DataTable`, so VS can visualize them. Or potentially we could add ancillary methods that return `DataTable`, and keep the current methods returning `DataDebuggerPreview`, if we think the current experience has value over the visualization in VS.","Url":"https://github.com/dotnet/machinelearning/issues/2912","RelatedDescription":"Open issue \"Consider making DataView and IEstimator Preview methods return DataTable\" (#2912)"},{"Id":"419659231","IsPullRequest":true,"CreatedAt":"2019-03-11T20:06:50","Actor":"zeahmed","Number":"2911","RawContent":null,"Title":"Exposed ngram extraction options in TextFeaturizer","State":"open","Body":"This PR fixes #2802, fixes #2838 and partially fixes #838,.\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2911","RelatedDescription":"Open PR \"Exposed ngram extraction options in TextFeaturizer\" (#2911)"},{"Id":"419655669","IsPullRequest":false,"CreatedAt":"2019-03-11T19:58:19","Actor":"gilnahmias","Number":"2910","RawContent":null,"Title":"Support encrypted models","State":"open","Body":"We want the ability to publish trained models that people can use to predict on their own devices, but not to reverse engineer the algorithms used to train them. That, in order to protect IP while allowing sensitive data to be predicted on customer machines.\r\nCan you support that?","Url":"https://github.com/dotnet/machinelearning/issues/2910","RelatedDescription":"Open issue \"Support encrypted models\" (#2910)"},{"Id":"419626884","IsPullRequest":true,"CreatedAt":"2019-03-11T19:43:30","Actor":"ganik","Number":"2907","RawContent":null,"Title":"TrainTestSplit should be inside MLContext.Data","State":"closed","Body":"fixes #2337","Url":"https://github.com/dotnet/machinelearning/pull/2907","RelatedDescription":"Closed or merged PR \"TrainTestSplit should be inside MLContext.Data\" (#2907)"},{"Id":"419602797","IsPullRequest":true,"CreatedAt":"2019-03-11T18:43:39","Actor":"ganik","Number":"2905","RawContent":null,"Title":"TrainTestSplit should be inside MLContext.Data","State":"closed","Body":"fixes #2337","Url":"https://github.com/dotnet/machinelearning/pull/2905","RelatedDescription":"Closed or merged PR \"TrainTestSplit should be inside MLContext.Data\" (#2905)"},{"Id":"419602870","IsPullRequest":false,"CreatedAt":"2019-03-11T17:49:40","Actor":"rogancarr","Number":"2906","RawContent":null,"Title":"Create functional tests for all Training scenarios","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Training functionality we want fully supported in V1.\r\n\r\nScenarios\r\n- I can provide multiple learners and easily compare evaluation metrics between them. \r\n- I can use an initial predictor to update/train the model for some trainers (e.g. linear learners like averaged perceptron). Specifically, start the weights for the model from the existing weights.  \r\n- Metacomponents smartly restrict their use to compatible components.   Example: \"When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.\"\r\n- I can use OVA and easily add any binary classifier to it\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2906","RelatedDescription":"Open issue \"Create functional tests for all Training scenarios\" (#2906)"},{"Id":"419298006","IsPullRequest":true,"CreatedAt":"2019-03-11T05:16:36","Actor":"abgoswam","Number":"2903","RawContent":null,"Title":"Fixing names of trainer estimators","State":"open","Body":"Fixes #2762 and #2172\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2903","RelatedDescription":"Open PR \"Fixing names of trainer estimators\" (#2903)"},{"Id":"419191841","IsPullRequest":true,"CreatedAt":"2019-03-10T14:27:29","Actor":"jwood803","Number":"2902","RawContent":null,"Title":"Add sample to get data from a SQL database","State":"open","Body":"Sample to help with #2498.\r\n\r\nThis sample using the Entity Framework in-memory data provider to load and read data that can be used to create an ML.NET model.\r\n\r\nHopefully, this is close to what was in mind for the sample. 😄","Url":"https://github.com/dotnet/machinelearning/pull/2902","RelatedDescription":"Open PR \"Add sample to get data from a SQL database\" (#2902)"},{"Id":"419136723","IsPullRequest":true,"CreatedAt":"2019-03-10T02:03:26","Actor":"jwood803","Number":"2901","RawContent":null,"Title":"Explainability doc","State":"open","Body":"Initial draft to add explainability documentation.\r\n\r\nFix for #2438.","Url":"https://github.com/dotnet/machinelearning/pull/2901","RelatedDescription":"Open PR \"Explainability doc\" (#2901)"},{"Id":"419042077","IsPullRequest":true,"CreatedAt":"2019-03-09T07:00:31","Actor":"sfilipi","Number":"2900","RawContent":null,"Title":"Time series samples and documentation alignment","State":"open","Body":"- [x] All overloads have method and parameter documentation according to XML template table below. \r\n- [x] The returned estimator  and its class hierarchy have documentation according to template table below. \r\n- [x] The corresponding options class and its class hierarchy have documentation \r\n- [x]  All overloaded versions have samples \r\n- [x]  Sample names are <API_method>.cs or <API_method>WithOptions.cs. \r\n- [x]  Sample path mirrors the MLContext path. (e.g. MLContext.Transforms.Categorical.OneHotEncoding goes to Dynamic/Transforms/Categorical/OneHotEncoding.cs \r\n- [x]  Sample is included in the API xml documentation.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2900","RelatedDescription":"Open PR \"Time series samples and documentation alignment\" (#2900)"},{"Id":"419017008","IsPullRequest":true,"CreatedAt":"2019-03-09T01:23:55","Actor":"rogancarr","Number":"2899","RawContent":null,"Title":"Create model file V1 scenario tests","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Model Files functionality we want fully supported in V1.\r\n\r\nThis PR adds tests for the following scenarios:\r\n\r\n* I can train a model and save it as a file. This model includes the learner as well as the transforms\r\n* I can use a model file in a completely different process to make predictions\r\n* I can easily figure out which NuGets (and versions) I need to score an ML.NET model\r\n* I can export ML.NET models to ONNX (limited to the existing internal functionality)\r\n\r\nFixes #2896 ","Url":"https://github.com/dotnet/machinelearning/pull/2899","RelatedDescription":"Open PR \"Create model file V1 scenario tests\" (#2899)"},{"Id":"419014212","IsPullRequest":true,"CreatedAt":"2019-03-09T01:02:21","Actor":"wschin","Number":"2898","RawContent":null,"Title":"Scrub n-gram hashing and n-gram","State":"open","Body":"One step closer to #2832. This PR only polishes NgramHashingTransform.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2898","RelatedDescription":"Open PR \"Scrub n-gram hashing and n-gram\" (#2898)"},{"Id":"418963554","IsPullRequest":true,"CreatedAt":"2019-03-09T00:59:50","Actor":"rogancarr","Number":"2894","RawContent":null,"Title":"Renaming IterationsToRemember to HistorySize for L-BFGS learners.","State":"closed","Body":"This PR renames the L-BFGS parameter `IterationsToRemember` to `HistorySize` to be more in line with the common nomenclature. (Previously it was `MemorySize`.)\r\n\r\nFixes #2882 ","Url":"https://github.com/dotnet/machinelearning/pull/2894","RelatedDescription":"Closed or merged PR \"Renaming IterationsToRemember to HistorySize for L-BFGS learners.\" (#2894)"},{"Id":"419007474","IsPullRequest":false,"CreatedAt":"2019-03-09T00:21:45","Actor":"rogancarr","Number":"2896","RawContent":null,"Title":"Create functional tests for all Model Files scenarios","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Model Files functionality we want fully supported in V1.\r\n\r\nDefinitely need for V1\r\n- I can train a model and save it as a file. This model includes the learner as well as the transforms\r\n- I can use a model file in a completely different process to make predictions \r\n- I can easily figure out which NuGets (and versions) I need to score an ML.NET model \r\n- I can export ML.NET models to ONNX (limited to the existing internal functionality)\r\n\r\nMay not need for now:\r\n- I can save a model to text \r\n- I can use newer versions of ML.NET with ML.NET model files of previous versions (for v1.x)\r\n- I can use model files interchangeably between compatible versions of ML.NET and NimbusML\r\n- I can move data between NimbusML and ML.NET (using IDV). Prepare with NimbusML and load with ML.NET","Url":"https://github.com/dotnet/machinelearning/issues/2896","RelatedDescription":"Open issue \"Create functional tests for all Model Files scenarios\" (#2896)"},{"Id":"419005311","IsPullRequest":false,"CreatedAt":"2019-03-09T00:09:37","Actor":"zeahmed","Number":"2895","RawContent":null,"Title":"Discrepancy in NgramExtractorTrasform, NgramExtractingTransformer and NgramExtractingEstimator.","State":"open","Body":"If you search for `NgramExtract` in the solution, the following three main classes pop up.\r\n\r\n1. NgramExtractorTransform (in WordBagTransform.cs)\r\n2. NgramExtractingTransformer (in NgramTransform.cs)\r\n3. NgramExtractingEstimator (in NgramTrasnform.cs)\r\n\r\n`2` and `3` seem to be the actual classes where ngram extraction logic is written. However, `1` uses `2` and `3` with a pre-processing step where if input is text it is first converted to terms using ValueToKeyMappingTransformer.\r\n\r\nFirst, `NgramExtractorTransform` does not seem to be in correct file i.e filename and class name do not match.\r\nSecond, the `NgramExtractorTransform` is not doing ngram extraction instead composing two different estimators (NgramExtractingEstimator and ValueToKeyMappingEstimator).\r\n\r\nI think `NgramExtractorTransform` be renamed to `WordBagTransform` or something appropirate.\r\n\r\nCC: @Ivanidzo4ka, @TomFinley, @sfilipi, @rogancarr.","Url":"https://github.com/dotnet/machinelearning/issues/2895","RelatedDescription":"Open issue \"Discrepancy in NgramExtractorTrasform, NgramExtractingTransformer and NgramExtractingEstimator.\" (#2895)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-03-12T05:30:34.6354997Z","RunDurationInMilliseconds":638}