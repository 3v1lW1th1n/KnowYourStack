{"Data":{"GitHub":{"Issues":[{"Id":"360593094","IsPullRequest":false,"CreatedAt":"2018-09-16T02:02:27","Actor":"zeahmed","Number":"927","RawContent":null,"Title":"Convert WordEmbeddingsTransform into Estimator.","State":"open","Body":"This is the workitem related to #754.","Url":"https://github.com/dotnet/machinelearning/issues/927","RelatedDescription":"Open issue \"Convert WordEmbeddingsTransform into Estimator.\" (#927)"},{"Id":"360579353","IsPullRequest":true,"CreatedAt":"2018-09-15T21:57:44","Actor":"jwood803","Number":"926","RawContent":null,"Title":"Fix duplicate transform friendly name","State":"open","Body":"Fix for issue #214 \r\n\r\n@TomFinley I'm not sure if this is the right way to go about it, but I took a shot at it. üòÑ \r\n","Url":"https://github.com/dotnet/machinelearning/pull/926","RelatedDescription":"Open PR \"Fix duplicate transform friendly name\" (#926)"},{"Id":"360407021","IsPullRequest":false,"CreatedAt":"2018-09-15T06:37:37","Actor":"michasacuer","Number":"916","RawContent":null,"Title":"‚ÄúScore Column‚Äù is missing, System.Reflection.TargetInvocationException","State":"closed","Body":"### System information\r\n\r\n- **OS Windows 10**:\r\n- **.NET Version: 2.0.7**: \r\n\r\n### Issue\r\n\r\nI try to build ML.NET app that working on [Wisconsin Prognostic Breast Cancer Dataset](https://www.kaggle.com/sarahvch/breast-cancer-wisconsin-prognostic-data-set). Whatever i do i get \r\n\r\n> ArgumentOutOfRangeException: Score column is missing\r\n\r\nEven if i add `Score` Column. The error showing on `ClassificationMetrics metrics = evaluator.Evaluate(model, testData);` line. \r\n\r\nMy data looks like this:\r\n\r\n```\r\ndiagnosis;radius_mean;texture_mean;perimeter_mean;area_mean;smoothness_mean;compactness_mean;concavity_mean;concave points_mean;symmetry_mean;fractal_dimension_mean;radius_se;texture_se;perimeter_se;area_se;smoothness_se;compactness_se;concavity_se;concave points_se;symmetry_se;fractal_dimension_se;radius_worst;texture_worst;perimeter_worst;area_worst;smoothness_worst;compactness_worst;concavity_worst;concave points_worst;symmetry_worst;fractal_dimension_worst\r\nB;11.62;18.18;76.38;408.8;0.1175;0.1483;0.102;0.05564;0.1957;0.07255;0.4101;1.74;3.027;27.85;0.01459;0.03206;0.04961;0.01841;0.01807;0.005217;13.36;25.4;88.14;528.1;0.178;0.2878;0.3186;0.1416;0.266;0.0927\r\nB;9.667;18.49;61.49;289.1;0.08946;0.06258;0.02948;0.01514;0.2238;0.06413;0.3776;1.35;2.569;22.73;0.007501;0.01989;0.02714;0.009883;0.0196;0.003913;11.14;25.62;70.88;385.2;0.1234;0.1542;0.1277;0.0656;0.3174;0.08524\r\n```\r\n\r\nCode can be pretty long, i posted my question into StackOverflow too: [ML.NET, ‚ÄúScore Column‚Äù is missing](https://stackoverflow.com/questions/52335066/ml-net-score-column-is-missing?noredirect=1#comment91619986_52335066)\r\n\r\n### Source code / logs\r\n\r\n**My CancerData.cs looks like this:**\r\n\r\n\r\n```\r\nclass CancerData\r\n{\r\n\r\n    [Column(ordinal: \"0\")]\r\n    public string Diagnosis;\r\n\r\n    [Column(ordinal: \"1\")]\r\n    public float RadiusMean;\r\n\r\n    [Column(ordinal: \"2\")]\r\n    public float TextureMean;\r\n\r\n    [Column(ordinal: \"3\")]\r\n    public float PerimeterMean;\r\n\r\n   //.........\r\n\r\n   [Column(ordinal: \"28\")] \r\n    public float ConcavPointsWorst;\r\n\r\n    [Column(ordinal: \"29\")]\r\n    public float SymmetryWorst;\r\n\r\n    [Column(ordinal: \"30\")]\r\n    public float FractalDimensionWorst;\r\n\r\n    [Column(ordinal: \"31\", name: \"Label\")]\r\n    public string Label;\r\n}\r\n```\r\n\r\n**CancerPrediction.cs**\r\n\r\n```\r\nclass CancerPrediction\r\n{\r\n    [ColumnName(\"PredictedLabel\")]\r\n    public string Diagnosis;\r\n\r\n    [ColumnName(\"Score\")]\r\n    public float Score;\r\n}\r\n```\r\n**Main.cs**\r\n```\r\nclass Program\r\n{\r\n\r\n    static void Main(string[] args)\r\n    {\r\n        PredictionModel<CancerData, CancerPrediction> model = Train();\r\n        Evaluate(model);\r\n    }\r\n\r\n    public static PredictionModel<CancerData, CancerPrediction> Train()\r\n    {\r\n        var pipeline = new LearningPipeline();\r\n        pipeline.Add(new TextLoader(\"Cancer-train.csv\").CreateFrom<CancerData>(useHeader: true, separator: ';'));\r\n        pipeline.Add(new Dictionarizer((\"Diagnosis\", \"Label\")));\r\n        pipeline.Add(new ColumnConcatenator(outputColumn: \"Features\",\r\n            \"RadiusMean\",\r\n            \"TextureMean\",\r\n            \"PerimeterMean\",\r\n            //... all of the features\r\n            \"FractalDimensionWorst\"));\r\n        pipeline.Add(new StochasticDualCoordinateAscentBinaryClassifier());\r\n        pipeline.Add(new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn = \"PredictedLabel\" });\r\n        PredictionModel<CancerData, CancerPrediction> model = pipeline.Train<CancerData, CancerPrediction>();\r\n        model.WriteAsync(modelPath);\r\n        return model;\r\n\r\n    }\r\n\r\n    public static void Evaluate(PredictionModel<CancerData, CancerPrediction> model)\r\n    {\r\n        var testData = new TextLoader(\"Cancer-test.csv\").CreateFrom<CancerData>(useHeader: true, separator: ';');\r\n        var evaluator = new ClassificationEvaluator();\r\n        ClassificationMetrics metrics = evaluator.Evaluate(model, testData);\r\n        var accuracy = Math.Round(metrics.AccuracyMicro, 2);\r\n        Console.WriteLine(\"The accuracy is: \" + accuracy);\r\n        Console.ReadLine();\r\n    }\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/916","RelatedDescription":"Closed issue \"‚ÄúScore Column‚Äù is missing, System.Reflection.TargetInvocationException\" (#916)"},{"Id":"360477570","IsPullRequest":true,"CreatedAt":"2018-09-15T00:42:11","Actor":"Ivanidzo4ka","Number":"922","RawContent":null,"Title":"Make Create constructors private and handle that in ComponentCatalog.","State":"closed","Body":"Fixes #921","Url":"https://github.com/dotnet/machinelearning/pull/922","RelatedDescription":"Closed or merged PR \"Make Create constructors private and handle that in ComponentCatalog.\" (#922)"},{"Id":"360467932","IsPullRequest":false,"CreatedAt":"2018-09-15T00:42:11","Actor":"Ivanidzo4ka","Number":"921","RawContent":null,"Title":"ComponentCatalog and public constructors","State":"closed","Body":"In current moment our component catalog looking for constructor methods only if they public which force us to have lot of public constructors and static Create methods, which is bad from API point of view.\r\nWe should change ComponentCatalog to look for private methods as well and change visibility of public constructors.\r\n\r\n```\r\n // Factory method for SignatureDataTransform.\r\n        public static IDataTransform Create(IHostEnvironment env, Arguments args, IDataView input)\r\n```\r\nor \r\n```\r\n // Factory method for SignatureLoadDataTransform.\r\n        public static IDataTransform Create(IHostEnvironment env, ModelLoadContext ctx, IDataView input)\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/921","RelatedDescription":"Closed issue \"ComponentCatalog and public constructors\" (#921)"},{"Id":"360491448","IsPullRequest":false,"CreatedAt":"2018-09-15T00:39:41","Actor":"Ivanidzo4ka","Number":"925","RawContent":null,"Title":"Tests need their own environment implementation","State":"open","Body":"Right now we use TlcEnvironment (or ConsoleEnvironment) which outputs everything to console.\r\nAnd XUnit don't care about console, and if you want to look on output during test execution you need to do something like this:\r\nhttps://github.com/dotnet/machinelearning/blob/4cb7dd9047b4c456e81ba014c664c27efe217351/test/Microsoft.ML.StaticPipelineTesting/StaticPipeTests.cs#L31\r\n\r\nWe should have XUnitEnvironment or TestEnvironment and redirect all output to ITestOutputHelper.","Url":"https://github.com/dotnet/machinelearning/issues/925","RelatedDescription":"Open issue \"Tests need their own environment implementation\" (#925)"},{"Id":"360486115","IsPullRequest":false,"CreatedAt":"2018-09-14T23:52:41","Actor":"Ivanidzo4ka","Number":"924","RawContent":null,"Title":"Significant time difference between linux, macos and windows test executions on build machines","State":"open","Body":"Let's look on this [build](https://dnceng.visualstudio.com/public/_build/results?buildId=21056&view=logs)\r\n\r\nMacOS Release  - tests: 19:08\r\nMacOS Debug  - tests: 22:59\r\nLinux Release - test 17:02\r\nLinux Debug - test 21:02\r\nWindows Release - test 5:00\r\nWindows Debug - test 7:53\r\n\r\nWindows machine:\r\n2018-09-14T22:47:22.5353796Z Results File: D:\\a\\1\\s\\bin/AnyCPU.Debug\\Microsoft.ML.Predictor.Tests\\VssAdministrator_factoryvm-az366_2018-09-14_22_43_12.trx\r\n2018-09-14T22:47:22.5354312Z \r\n2018-09-14T22:47:22.5355746Z Total tests: 105. Passed: 49. Failed: 0. Skipped: 56.\r\n2018-09-14T22:47:22.5356035Z Test Run Successful.\r\n2018-09-14T22:47:22.5357667Z Test execution time: 4.2240 Minutes\r\n\r\nLinux machine:\r\n\r\n2018-09-14T22:59:26.1088812Z Results File: /__w/1/s/bin/AnyCPU.Debug/Microsoft.ML.Predictor.Tests/_5438db60ae8a_2018-09-14_22_41_24.trx\r\n2018-09-14T22:59:26.1096444Z \r\n2018-09-14T22:59:26.1109704Z Total tests: 105. Passed: 49. Failed: 0. Skipped: 56.\r\n2018-09-14T22:59:26.1124041Z Test Run Successful.\r\n2018-09-14T22:59:26.1137781Z Test execution time: 18.0608 Minutes\r\n\r\nIt looks like we run same set of tests but for some reason where is huge difference in execution.\r\nAny one willing to investigate?","Url":"https://github.com/dotnet/machinelearning/issues/924","RelatedDescription":"Open issue \"Significant time difference between linux, macos and windows test executions on build machines\" (#924)"},{"Id":"360480977","IsPullRequest":true,"CreatedAt":"2018-09-14T23:14:48","Actor":"Zruty0","Number":"923","RawContent":null,"Title":"Renamed TlcEnvironment to Console. Also introduced LocalEnvironment","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/923","RelatedDescription":"Open PR \"Renamed TlcEnvironment to Console. Also introduced LocalEnvironment\" (#923)"},{"Id":"360466607","IsPullRequest":true,"CreatedAt":"2018-09-14T21:54:59","Actor":"Zruty0","Number":"920","RawContent":null,"Title":"Rename Microsoft.ML to Microsoft.ML.Legacy","State":"open","Body":"This is a purely mechanical rename.\r\n- `Microsoft.ML` -> `Microsoft.ML.Legacy`\r\n- Moved to `src/Microsoft.ML.Legacy`\r\n- Updated project references and solution","Url":"https://github.com/dotnet/machinelearning/pull/920","RelatedDescription":"Open PR \"Rename Microsoft.ML to Microsoft.ML.Legacy\" (#920)"},{"Id":"360232597","IsPullRequest":true,"CreatedAt":"2018-09-14T21:37:29","Actor":"justinormont","Number":"914","RawContent":null,"Title":"TLS Links for Improved Security","State":"closed","Body":"Changes various HTTP links to HTTPS. Links are checked to ensure the HTTPS serves the same content. Not all HTTP links could be converted.\r\n\r\nCloses #911 \r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/914","RelatedDescription":"Closed or merged PR \"TLS Links for Improved Security\" (#914)"},{"Id":"360150496","IsPullRequest":false,"CreatedAt":"2018-09-14T21:37:29","Actor":"justinormont","Number":"911","RawContent":null,"Title":"TLS Links for Improved Security","State":"closed","Body":"For general web security, we should use HTTP**S** links instead of HTTP. \r\n\r\nWithin the ML.NET repo, I see ~60 locations where we use HTTP:\r\n  https://github.com/dotnet/machinelearning/search?p=3&q=http%3A%2F%2F&unscoped_q=http%3A%2F%2F\r\n\r\nTask:\r\n* Verify that HTTPS links are equivalent\r\n* Where possible, change links to utilize HTTPS\r\n\r\nQ: Assuming we can alter all HTTP links to HTTPS, should we block new HTTP links as part of a git check-in test? A check-in test would help reduce unintentional HTTP links; for example, I missed [this http://aka.ms link](https://github.com/dotnet/machinelearning/blob/f0f04ef8854bd1ae05987072e2f0fd660d4be662/build.proj#L84)  as a reviewer.","Url":"https://github.com/dotnet/machinelearning/issues/911","RelatedDescription":"Closed issue \"TLS Links for Improved Security\" (#911)"},{"Id":"360455082","IsPullRequest":false,"CreatedAt":"2018-09-14T21:06:26","Actor":"wschin","Number":"919","RawContent":null,"Title":"Categorical Feature and FastTree","State":"open","Body":"FastTree has a very powerful mechanism to process categorical features. However, which feature is considered as categorical is not described anywhere in doc. Some questions a data scientist may want to ask:\r\n1. How to make feature categorical if they are stored as floats such as 1.00 and 128.00?\r\n2. How does categorical metadata propagate through the learning pipeline? For example, some transforms may drop those metadata so that categorical features are no longer categorical after them.\r\n3. How to make categorical not considered as categorical in FastTree?\r\n\r\nNote that [LightGBM](https://lightgbm.readthedocs.io/en/latest/Python-API.html) has a nice description for how they handle categorical features. Let me just copy it here.\r\n_categorical_feature (list of strings or int, or 'auto', optional (default=\"auto\")) ‚Äì Categorical features. If list of int, interpreted as indices. If list of strings, interpreted as feature names (need to specify feature_name as well). If ‚Äòauto‚Äô and data is pandas DataFrame, pandas categorical columns are used._ \r\n\r\nThanks,","Url":"https://github.com/dotnet/machinelearning/issues/919","RelatedDescription":"Open issue \"Categorical Feature and FastTree\" (#919)"},{"Id":"360109902","IsPullRequest":true,"CreatedAt":"2018-09-14T20:59:46","Actor":"Zruty0","Number":"909","RawContent":null,"Title":"Fix for trainer estimator metadata propagation","State":"closed","Body":"Added tests for metadata propagation on existing trainers, also fixed SDCA to pass metadata correctly.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/909","RelatedDescription":"Closed or merged PR \"Fix for trainer estimator metadata propagation\" (#909)"},{"Id":"360436709","IsPullRequest":false,"CreatedAt":"2018-09-14T20:03:14","Actor":"Zruty0","Number":"918","RawContent":null,"Title":"Flaky assert failure in SDCA test ","State":"open","Body":"```\r\n2018-09-13T23:25:02.4332634Z Failed   Microsoft.ML.Scenarios.ScenariosTests.TrainAndPredictIrisModelWithStringLabelTest\r\n2018-09-13T23:25:02.4332936Z Error Message:\r\n2018-09-13T23:25:02.4333077Z  Assert failed: longIdx=37, invariants.Length=37\r\n2018-09-13T23:25:02.4333210Z Expected: True\r\n2018-09-13T23:25:02.4333341Z Actual:   False\r\n2018-09-13T23:25:02.4333453Z Stack Trace:\r\n2018-09-13T23:25:02.4333653Z    at Microsoft.ML.Runtime.Internal.Internallearn.Test.GlobalBase.AssertHandler(String msg, IExceptionContext ectx) in D:\\a\\1\\s\\test\\Microsoft.ML.TestFramework\\GlobalBase.cs:line 47\r\n2018-09-13T23:25:02.4333951Z    at Microsoft.ML.Runtime.Contracts.DbgFailCore(String msg, IExceptionContext ctx) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 770\r\n2018-09-13T23:25:02.4334183Z    at Microsoft.ML.Runtime.Contracts.DbgFail(String msg) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 783\r\n2018-09-13T23:25:02.4334404Z    at Microsoft.ML.Runtime.Contracts.Assert(Boolean f, String msg) in D:\\a\\1\\s\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 841\r\n2018-09-13T23:25:02.4334962Z    at Microsoft.ML.Runtime.Learners.SdcaTrainerBase`2.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor, Int32 weightSetCount) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardLearners\\Standard\\LinearClassificationTrainer.cs:line 514\r\n2018-09-13T23:25:02.4335278Z    at Microsoft.ML.Runtime.Learners.StochasticTrainerBase`2.TrainModelCore(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardLearners\\Standard\\StochasticTrainerBase.cs:line 42\r\n2018-09-13T23:25:02.4335567Z    at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Train(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 88\r\n2018-09-13T23:25:02.4336480Z    at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 154\r\n2018-09-13T23:25:02.4336826Z    at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 260\r\n2018-09-13T23:25:02.4337494Z    at Microsoft.ML.Runtime.Data.TrainUtils.Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 228\r\n2018-09-13T23:25:02.4337856Z    at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in D:\\a\\1\\s\\src\\Microsoft.ML.Data\\EntryPoints\\InputBase.cs:line 189\r\n2018-09-13T23:25:02.4338176Z    at Microsoft.ML.Runtime.Learners.Sdca.TrainMultiClass(IHostEnvironment env, Arguments input) in D:\\a\\1\\s\\src\\Microsoft.ML.StandardLearners\\Standard\\SdcaMultiClass.cs:line 437\r\n```\r\n\r\nThe data  pipeline has a `TextLoader`, a `Dictionarizer` and `ColumnConcatenator`, then it trains SDCA classifier.\r\n\r\n@TomFinley suggests that it could be related to the difference in ID generation between iterations. \r\nThe fact that the test is not failing every time suggests that either there is a race condition somewhere (in the `TextLoader`?), or somehow the data is sometimes modified mid-run.","Url":"https://github.com/dotnet/machinelearning/issues/918","RelatedDescription":"Open issue \"Flaky assert failure in SDCA test \" (#918)"},{"Id":"360411152","IsPullRequest":true,"CreatedAt":"2018-09-14T18:35:57","Actor":"Ivanidzo4ka","Number":"917","RawContent":null,"Title":"WIP NAReplace estimator","State":"open","Body":"Converts NAReplace to estimator\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/917","RelatedDescription":"Open PR \"WIP NAReplace estimator\" (#917)"},{"Id":"360386989","IsPullRequest":false,"CreatedAt":"2018-09-14T17:15:37","Actor":"ftdube","Number":"915","RawContent":null,"Title":"Trying to left-outer join two datasets using a PK/FK","State":"open","Body":"Is there any way to manipulate the input data in order to join two distinct datasets using a primary key/foreign key?  Is the expectation that the input from the TextLoader is always partially pre-processed?","Url":"https://github.com/dotnet/machinelearning/issues/915","RelatedDescription":"Open issue \"Trying to left-outer join two datasets using a PK/FK\" (#915)"},{"Id":"359693812","IsPullRequest":true,"CreatedAt":"2018-09-14T17:02:58","Actor":"Zruty0","Number":"901","RawContent":null,"Title":"Legacy API namespace rename","State":"closed","Body":"Fixes #756 .","Url":"https://github.com/dotnet/machinelearning/pull/901","RelatedDescription":"Closed or merged PR \"Legacy API namespace rename\" (#901)"},{"Id":"360195071","IsPullRequest":false,"CreatedAt":"2018-09-14T07:52:38","Actor":"WladdGorshenin","Number":"913","RawContent":null,"Title":"Feature request: get reasons behind predictions made by Decision Trees","State":"open","Body":"My team had long conversation with ML.NET's team (based on issue #599) and we came up with this feature request as the result.\r\n\r\nFor a model based on decision trees we'd like to have public API method similar to Scikit Learn's \"decision_path\" which does the following: for each input sample in outputs route traveled from root to leaf in each tree (i.e. list of nodes and edges).\r\n\r\nWe need that to understand reasons behind each prediction our model made.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/913","RelatedDescription":"Open issue \"Feature request: get reasons behind predictions made by Decision Trees\" (#913)"},{"Id":"360175318","IsPullRequest":true,"CreatedAt":"2018-09-14T06:39:25","Actor":"sfilipi","Number":"912","RawContent":null,"Title":"[WIP] FAFM to extend TrainerEstimatorBase","State":"open","Body":"FAFM now extends TrainerEstimatorBase\r\n\r\nMarked as still in progress because it will need to incorporate changes of PR #909 and add a test. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/912","RelatedDescription":"Open PR \"[WIP] FAFM to extend TrainerEstimatorBase\" (#912)"},{"Id":"360110315","IsPullRequest":false,"CreatedAt":"2018-09-14T00:09:36","Actor":"Zruty0","Number":"910","RawContent":null,"Title":"Fix AP and OGD metadata propagation and behavior","State":"open","Body":"In the process of writing #909 I discovered that AP is now seemingly uncalibrated, and cannot accept float labels, and OGD throws at training. \r\n\r\nEnable the `OnlineLinearWorkout` test in #909 and fix the resulting bugs.","Url":"https://github.com/dotnet/machinelearning/issues/910","RelatedDescription":"Open issue \"Fix AP and OGD metadata propagation and behavior\" (#910)"},{"Id":"360104699","IsPullRequest":false,"CreatedAt":"2018-09-13T23:38:45","Actor":"wschin","Number":"908","RawContent":null,"Title":"Command Line Usages","State":"open","Body":"Are command line tool exposed to users with some docs? It looks it's not straightforward for external users to use command line to train a model. Thanks.","Url":"https://github.com/dotnet/machinelearning/issues/908","RelatedDescription":"Open issue \"Command Line Usages\" (#908)"},{"Id":"360096062","IsPullRequest":false,"CreatedAt":"2018-09-13T22:56:25","Actor":"dckorben","Number":"907","RawContent":null,"Title":"Evaluator.Evaluate throws \"Expected exactly one column with role 'Score', but found 0.'\"","State":"open","Body":"Windows 10 Enterprise 1803\r\n.net 4.7.2\r\n\r\n### Issue\r\n- **What did you do?**\r\nLoaded Data, Created FastForestRegression Predictor, Trained Model Successfully\r\nCreated Regression Evaluator under new Direct API\r\nCalled Evaluated on Training or Validation Data Set\r\n- **What happened?**\r\nthrew  \"Expected exactly one column with role 'Score', but found 0.'\"\r\n- **What did you expect?**\r\nRegression Metrics Dictionary returned\r\n\r\n### Source code / logs\r\nSentimentPredictionTests contains comments to what seems to be similar effect for another evaluator. \r\n\r\n`          // Evaluate.\r\n            // It does not work. It throws error \"Failed to find 'Score' column\" when Evaluate is called`\r\n\r\nMy cursory review of the source makes it seem it is not possible to specify a \"Score\" role column at the moment. Attempted to decorate the model class a number of different ways to no effect. This could be a redundant issue covered somewhere else I wasn't able to identify.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/907","RelatedDescription":"Open issue \"Evaluator.Evaluate throws \"Expected exactly one column with role 'Score', but found 0.'\"\" (#907)"},{"Id":"360079284","IsPullRequest":false,"CreatedAt":"2018-09-13T21:50:04","Actor":"abgoswam","Number":"906","RawContent":null,"Title":"TensorFlowTransform does not dispose TFSession","State":"open","Body":"Currently the TensorFlowTransform does not dispose the TFSession object. \r\n\r\nThis prevents us from using the Dispose pattern on the TensorFlowTransform to clean up un-managed resources\r\n","Url":"https://github.com/dotnet/machinelearning/issues/906","RelatedDescription":"Open issue \"TensorFlowTransform does not dispose TFSession\" (#906)"},{"Id":"360023244","IsPullRequest":false,"CreatedAt":"2018-09-13T18:57:13","Actor":"ericstj","Number":"905","RawContent":null,"Title":"Model Saving / Loading memory usage","State":"open","Body":"In reviewing the TensorFlow saving/loading code [PR](https://github.com/dotnet/machinelearning/pull/853) I noticed that we were creating very large byte arrays in the [frozen model case](https://github.com/dotnet/machinelearning/blob/52aff025df29cc02c00999c5ca4a0833a658d142/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L123).  I believe these can be *very* large models (100MB - many GB) so we might approach the upper limit of the size of managed arrays, not to mention the memory usage of shuttling these bytes into a managed array, just so that they can then be interpreted/read into TensorFlow's object model.\r\n\r\nMy understanding of the ModelSaveContext / ModelLoadContext get backed with a ZipArchive.  This will be backed by a stream (file or memory) and thus not load the entire ML.NET model into memory at one time.  As entries are accessed these get loaded as streams which load from disk on demand / decompress on demand.  As such the backing stack for model loading/saving permits a minimal memory footprint for loading and saving models.  The problem comes in with usage.  Many cases where folks are using ReadByteArray they should instead be using a Stream that is constrained to the length of the entry.\r\n\r\nI discussed this a bit with @abgoswam and prototyped a sample stream that would wrap the context's BinaryReader/Writer stream and only expose a region.  I'm sure we have a better impl floating around somewhere.\r\n\r\nI looked a a few of the usage cases of `ReadByteArray` and the following all look suspect of containing large payloads:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Api/SerializableLambdaTransform.cs#L66-L74\r\n\r\nI imagine they payload passed to the `LoadDelegate` could be arbitrarily large and should be streamed.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/307b38f4c86cc31a6a0dbff8c1a302d66f4fe7e7/src/Microsoft.ML.Data/DataLoadSave/PartitionedFileLoader.cs#L226-L234\r\n\r\nIt looks like the byte array gets stored off in a memory stream until it later gets read as files.  I don't see much value in the additional byte-array.  Why not instead keep a stream open to the entry in the ModelLoadContext for the lifetime of the loader?\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Transforms/OptionalColumnTransform.cs#L99-L103\r\n\r\nSimilar to above.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5e08fa1ea7bfb54f28ed0815cb6413e0068e6dd1/src/Microsoft.ML.Parquet/ParquetLoader.cs#L193-L195\r\n\r\nSimilar to above.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/52aff025df29cc02c00999c5ca4a0833a658d142/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L123-L141\r\nIn the TensorFlowTransform case I don't see a great alternative since the [TF API](https://github.com/tensorflow/tensorflow/blob/3be04971716fcaf0c11ad9262e60efa428553e14/tensorflow/c/c_api.h#L1018-L1020) we call expects a byte buffer and doesn't have a stream-like API for importing the graph (as far as I can tell).  It's possible I'm missing something though.  A slightly hacky alternative would be to make a memory mapped file, write to that, and pass the [pointer](https://docs.microsoft.com/en-us/dotnet/api/microsoft.win32.safehandles.safememorymappedviewhandle?view=netframework-4.7.2#methods) of the memory mapped file to tensorflow.  That way we're never dealing in large byte arrays.  We could have some size threshold at which we switch from using a byte array to a memory mapped file. Since there would likely be some tradeoff to creating the MMF.\r\n\r\n/cc @Zruty0 ","Url":"https://github.com/dotnet/machinelearning/issues/905","RelatedDescription":"Open issue \"Model Saving / Loading memory usage\" (#905)"},{"Id":"359947109","IsPullRequest":false,"CreatedAt":"2018-09-13T15:26:17","Actor":"yaeldekel","Number":"904","RawContent":null,"Title":"Enable unit tests using Inception and ssd_mobilenet TensorFlow models","State":"open","Body":"Upload the models to MyGet with the appropriate license, and enable the unit tests which are currently skipped.","Url":"https://github.com/dotnet/machinelearning/issues/904","RelatedDescription":"Open issue \"Enable unit tests using Inception and ssd_mobilenet TensorFlow models\" (#904)"},{"Id":"359944478","IsPullRequest":false,"CreatedAt":"2018-09-13T15:20:16","Actor":"yaeldekel","Number":"903","RawContent":null,"Title":"Pixel extractor transform needs to have a per-channel offset argument","State":"open","Body":"Some TensorFlow models require preprocessing of the image where a different offset is subtracted from every channel. For example: https://github.com/pudae/tensorflow-densenet/blob/master/preprocessing/densenet_preprocessing.py#L39. \r\nThe ML.NET pixel extractor transform only has a global offset parameter, which means that preprocessing would need to be done outside of ML.NET.","Url":"https://github.com/dotnet/machinelearning/issues/903","RelatedDescription":"Open issue \"Pixel extractor transform needs to have a per-channel offset argument\" (#903)"},{"Id":"359855211","IsPullRequest":false,"CreatedAt":"2018-09-13T11:29:43","Actor":"lefig","Number":"902","RawContent":null,"Title":"Feature Importance with ML.NET","State":"open","Body":"Hi all,\r\n\r\nI have been revisiting some models recently to deduce feature importance. To remove highly correlated items, features of no importance etc.\r\n\r\nAnd judging from the issues raised so far, this theme has come up already. Such as Feature Importance with ML.NET #599.\r\n\r\nIdeally, it should be possible to run a pipeline task not to generate a full model, but to profile the model data using a method such as nearest neighbour or PCA before rather than after the event.\r\n\r\nWould it be possible to add such a feature (no pun intended:)) to the release road map?\r\n\r\nThanks\r\nFig","Url":"https://github.com/dotnet/machinelearning/issues/902","RelatedDescription":"Open issue \"Feature Importance with ML.NET\" (#902)"},{"Id":"359679972","IsPullRequest":true,"CreatedAt":"2018-09-12T23:27:05","Actor":"yaeldekel","Number":"900","RawContent":null,"Title":"Fix bug in pixel extractor transform, and add more unit tests.","State":"closed","Body":"Fixes #897 .\r\nThe pixel extractor mixes up the green and blue values in one place, and does the wrong thing with the alpha value in another place.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/900","RelatedDescription":"Closed or merged PR \"Fix bug in pixel extractor transform, and add more unit tests.\" (#900)"},{"Id":"359668990","IsPullRequest":true,"CreatedAt":"2018-09-12T22:02:13","Actor":"Ivanidzo4ka","Number":"899","RawContent":null,"Title":"Categorical estimator","State":"open","Body":"Converts Categorical transform to Estimator chain","Url":"https://github.com/dotnet/machinelearning/pull/899","RelatedDescription":"Open PR \"Categorical estimator\" (#899)"},{"Id":"359666507","IsPullRequest":false,"CreatedAt":"2018-09-12T21:53:06","Actor":"zeahmed","Number":"898","RawContent":null,"Title":"Need to have vector trimming and padding functionality to deal with fixed size text inputs for DNNs.","State":"open","Body":"Convolution based text classification models and fixed length seq2seq models in Tensorflow ( or in any other DNN platform in general) requires fixed length vector of integers as input. However, in ML.Net sentences/documents transform into variable length vectors when split into words/characters.\r\n\r\nTo enable these scenarios, we need to find out a way to trim/pad vector to make them fixed length. May be make a trimming and padding transform.\r\n\r\nThis task item was derived from the investigation of issue #747 ","Url":"https://github.com/dotnet/machinelearning/issues/898","RelatedDescription":"Open issue \"Need to have vector trimming and padding functionality to deal with fixed size text inputs for DNNs.\" (#898)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-09-16T05:30:33.6433943Z","RunDurationInMilliseconds":1199}