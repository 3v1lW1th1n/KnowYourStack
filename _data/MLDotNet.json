{"Data":{"GitHub":{"Issues":[{"Id":"342913050","IsPullRequest":false,"CreatedAt":"2018-07-19T22:37:32","Actor":"eerhardt","Number":"561","RawContent":null,"Title":"API to create a TextLoader from class metadata","State":"open","Body":"In the `LearningPipeline` API, we have the ability to create a TextLoader object using metadata applied to a regular C# class:\r\n\r\n```C#\r\npipeline.Add(new TextLoader(dataPath).CreateFrom<HousePriceData>(useHeader: true, separator: ','));\r\n\r\npublic class HousePriceData\r\n{\r\n    [Column(ordinal: \"0\")]\r\n    public string Id;\r\n    [Column(ordinal: \"1\")]\r\n    public string Date;\r\n    [Column(ordinal: \"2\", name: \"Label\")]\r\n    public float Price;\r\n    [Column(ordinal: \"3\")]\r\n    public float Bedrooms;\r\n    [Column(ordinal: \"4\")]\r\n    public float Bathrooms;\r\n    [Column(ordinal: \"5\")]\r\n    public float SqftLiving;\r\n    [Column(ordinal: \"6\")]\r\n    public float SqftLot;\r\n    ...\r\n```\r\n\r\nI find it more intuitive to have a class decorated with metadata to use to load data instead of imperatively building up a schema in code, like the following:\r\n\r\n```C#\r\nprivate static TextLoader.Column ScalarCol(string name, int ordinal, DataKind kind = DataKind.Num)\r\n    => new TextLoader.Column() { Name = name, Type = kind, Source = new[] { new TextLoader.Range() { Min = ordinal, Max = ordinal } } };\r\n\r\nvar loader = new TextLoader(env, new TextLoader.Arguments()\r\n{\r\n    HasHeader = true,\r\n    SeparatorChars = new char[] { ',' },\r\n    // These column declarations are meant to mirror those that appear in HousePriceData.\r\n    Column = new[] {\r\n        ScalarCol(\"Id\", 0, DataKind.Text),\r\n        ScalarCol(\"Date\", 1, DataKind.Text),\r\n        ScalarCol(\"Label\", 2),\r\n        ScalarCol(\"Bedrooms\", 3),\r\n        ScalarCol(\"Bathrooms\", 4),\r\n        ScalarCol(\"SqftLiving\", 5),\r\n        ScalarCol(\"SqftLot\", 6),\r\n}, new MultiFileSource(dataPath));\r\n```\r\n\r\nThis issue is being opened to ensure we preserve this behavior with the new direct access API design proposed in #371 (possibly using a different API design, but preserving the functionality).\r\n\r\n/cc @ericstj @TomFinley @Zruty0 @terrajobst ","Url":"https://github.com/dotnet/machinelearning/issues/561","RelatedDescription":"Open issue \"API to create a TextLoader from class metadata\" (#561)"},{"Id":"342909287","IsPullRequest":false,"CreatedAt":"2018-07-19T22:20:27","Actor":"eerhardt","Number":"560","RawContent":null,"Title":"Simple API to go from a trainer to something that can make predictions","State":"open","Body":"With the API proposal change in https://github.com/dotnet/machinelearning/issues/371, the current proposed API looks something like:\r\n\r\n```C#\r\n... // load data and make transforms\r\n\r\n// Train.\r\nvar trainer = new SdcaRegressionTrainer(env, new SdcaRegressionTrainer.Arguments());\r\nvar cached = new CacheDataView(env, trans, prefetch: null);\r\nvar trainRoles = TrainUtils.CreateExamples(cached, label: \"Label\", feature: \"Features\");\r\nvar pred = trainer.Train(trainRoles);\r\n\r\n// Score.\r\nIDataView scoredData = ScoreUtils.GetScorer(pred, trainRoles, env, trainRoles.Schema);\r\n\r\n// Do a simple prediction.\r\nvar engine = env.CreatePredictionEngine<HousePriceData, HousePricePrediction>(scoredData);\r\n\r\nHousePricePrediction prediction = engine.Predict(new HousePriceData()\r\n....\r\n```\r\n\r\nCompare and contrast the similar code what what we have in the LearningPipeline API:\r\n\r\n```C#\r\n... // load data and make transforms\r\n\r\npipeline.Add(new StochasticDualCoordinateAscentRegressor());\r\n\r\nPredictionModel<HousePriceData, HousePricePrediction> model = pipeline.Train<HousePriceData, HousePricePrediction>();\r\n\r\nHousePricePrediction prediction = model.Predict(new HousePriceData()\r\n....\r\n```\r\n\r\nYou can see the proposed API has what feels like boilerplate code (create a cache data view, create examples, call train, get a scorer, create an engine).  Where the LearningPipeline API simplifies this into roughly one call: call train, get something that can make predictions.\r\n\r\nI don't think our simplest API example should have so many concepts in it.  In my mind, the main concepts a new user needs to know about are:\r\n\r\n* Load data\r\n* Do transforms\r\n* Pick a learning algorithm\r\n* Train\r\n* Predict\r\n\r\nHowever, in the current proposed API, they also need to think/learn about:\r\n\r\n* Whether or not they need a cached data view\r\n* Creating roles/examples\r\n    - I'm not sure which is it. The type is `RoleMappedData`, but the method is named `CreateExamples`.\r\n* An IPredictor object\r\n    - which doesn't make predictions\r\n* Calling `GetScorer`, which returns an `IDataView` that we call `scoredData`.\r\n    - Is this object really data, or is it something that does `scoring` as implied by the method name: `GetScorer`?\r\n\r\nIn my opinion, this API is too complex and non-intuitive for first time users. We should investigate ways to make it simpler and see if we can come up with a design with less concepts to learn when first interacting with ML.NET.\r\n\r\n/cc @ericstj @TomFinley @Zruty0 @terrajobst ","Url":"https://github.com/dotnet/machinelearning/issues/560","RelatedDescription":"Open issue \"Simple API to go from a trainer to something that can make predictions\" (#560)"},{"Id":"342846651","IsPullRequest":false,"CreatedAt":"2018-07-19T18:48:09","Actor":"Anipik","Number":"559","RawContent":null,"Title":"LoadTransform and LinearClassificationTrainer doesnot work in AzureFunctions","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: \r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.400-preview-009063\r\n Commit:    dd0179a67c\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.400-preview-009063\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.1\r\n  Commit:  6985b9f684\r\n```\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am trying to use the ML.net package in azure functions. I am running this https://github.com/dotnet/machinelearning-samples/tree/master/samples/end-to-end-apps/github-labeler inside an azure function.\r\n\r\n- **What happened?**\r\nThe entry point map for these  ```Microsoft.ML.Runtime.Data.LoadTransform``` and ```Microsoft.ML.Runtime.Learners.LinearClassificationTrainer```  types are not getting loaded properly. As a result I am not able to train or test using ML.net inside the Azure Function.\r\n\r\nErrors\r\n```\r\nSystem.Private.CoreLib: Exception while executing function: GithubIssueLabeler. Microsoft.ML.Data: Couldn't load model: 'DataLoaderModel\\Transform_001\r\nSystem.Private.CoreLib: Exception while executing function: GithubIssueLabeler. System.Private.CoreLib: Exception has been thrown by the target of an invocation. Microsoft.ML.Data: Couldn't load model: 'DataLoaderModel\\Transform_020\\SchemaBindableMapper\\InnerMapper\\Predictor'.\r\n```\r\n- **What did you expect?**\r\nExpect to work properly.\r\n\r\n### Source code / logs\r\n``` C#\r\n        [FunctionName(\"GithubIssueLabeler\")]\r\n        public static async Task<IActionResult> Run([HttpTrigger(AuthorizationLevel.Function, \"get\", \"post\", Route = null)]HttpRequest req, TraceWriter log)\r\n        {\r\n            //var type = typeof(Microsoft.ML.Runtime.Data.LoadTransform);\r\n            //var type1 = typeof(Microsoft.ML.Runtime.Learners.LinearClassificationTrainer);\r\n            log.Info(\"Http Issue Webhook Request is Being Processed\");\r\n\r\n            string requestBody = new StreamReader(req.Body).ReadToEnd();\r\n            dynamic data = JsonConvert.DeserializeObject(requestBody);\r\n\r\n            string Action = data?.action;\r\n            dynamic issue = data?.issue;\r\n            dynamic labels = issue?.labels;\r\n\r\n            if (Action == \"opened\" && labels.Count == 0)\r\n            {\r\n                string title = issue?.title;\r\n                int number = issue?.number;\r\n                string body = issue?.body;\r\n                log.Info($\"A {number.ToString()} issue with {title} has been opened.\");\r\n\r\n                Configuration = new ConfigurationBuilder()\r\n                    .SetBasePath(Directory.GetCurrentDirectory())\r\n                    .AddJsonFile(\"appsettings.json\").Build();\r\n\r\n                var labeler = new Labeler(Configuration[\"GitHubRepoOwner\"], Configuration[\"GitHubRepoName\"], Configuration[\"GitHubToken\"]);\r\n                await labeler.PredictAndApplyLabelAsync(number, title, body, log); // can do training or prediting using already load model\r\n                log.Info(\"Labeling completed\");\r\n            }\r\n            else\r\n            {\r\n                log.Info(\"The issue is already opened or it already has a label\");\r\n            }\r\n\r\n            Console.ReadLine();\r\n            log.Info($\"Issue Label request handled\");\r\n            return Action != null\r\n                ? (ActionResult)new OkObjectResult($\"Issue Label request handled\")\r\n                : new BadRequestObjectResult(\"Please pass a name on the query string or in the request body\");\r\n        }\r\n```\r\n# WorkArounds\r\n\r\nAdding these lines to the function helps the app to run perfectly fine.\r\n```\r\nvar type = typeof(Microsoft.ML.Runtime.Data.LoadTransform);\r\nvar type1 = typeof(Microsoft.ML.Runtime.Learners.LinearClassificationTrainer);\r\n```\r\n\r\ncc @eerhardt \r\n","Url":"https://github.com/dotnet/machinelearning/issues/559","RelatedDescription":"Open issue \"LoadTransform and LinearClassificationTrainer doesnot work in AzureFunctions\" (#559)"},{"Id":"341571989","IsPullRequest":true,"CreatedAt":"2018-07-19T17:23:41","Actor":"abgoswam","Number":"539","RawContent":null,"Title":"PipelineSweeperMacro for Multi-Class Classification","State":"closed","Body":"Fixes #538\r\n\r\n- The PipelineSweeper currently only supports AUC as the optimization metric.  Trying to optimize on any other metric throws an exception.\r\n- Need to fix the way metrics are handled by the PipelineSweeper Macro.\r\n- Added a test case for MultiClass classification using the PipelineSweeper.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/539","RelatedDescription":"Closed or merged PR \"PipelineSweeperMacro for Multi-Class Classification\" (#539)"},{"Id":"341569557","IsPullRequest":false,"CreatedAt":"2018-07-19T17:23:41","Actor":"abgoswam","Number":"538","RawContent":null,"Title":"PipelineSweeping fails for MultiClass classification","State":"closed","Body":"### Issue\r\n\r\n- **PipelineSweeper fails for 'TrainerKind': 'SignatureMultiClassClassifierTrainer'**\r\n- **System.InvalidOperationException : Requested value 'Accuracy(micro-avg)' is not a member of the Enum type 'Metrics'**\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/538","RelatedDescription":"Closed issue \"PipelineSweeping fails for MultiClass classification\" (#538)"},{"Id":"341951176","IsPullRequest":true,"CreatedAt":"2018-07-19T16:48:25","Actor":"eerhardt","Number":"542","RawContent":null,"Title":" Allow CpuMath to reference C# Hardware Intrinsics APIs.","State":"closed","Body":"Need to multi-target CpuMath for netstandard and netcoreapp3.0.  Also, since we are going to move CpuMath into its own NuGet package, remove the dependency from CpuMath to the ML.Core project.\r\n\r\nAdd a build parameter to enable building against .NET Core 3.0's Runtime Intrinsics APIs.\r\n\r\nFix #534 ","Url":"https://github.com/dotnet/machinelearning/pull/542","RelatedDescription":"Closed or merged PR \" Allow CpuMath to reference C# Hardware Intrinsics APIs.\" (#542)"},{"Id":"341175974","IsPullRequest":false,"CreatedAt":"2018-07-19T16:48:25","Actor":"eerhardt","Number":"534","RawContent":null,"Title":"Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core","State":"closed","Body":".NET Core 2.1 [introduced hardware intrinsics APIs](https://github.com/dotnet/designs/blob/master/accepted/platform-intrinsics.md) that allow C# code to take full advantage of the CPU. For example, you can now write algorithms using SSE or AVX instructions purely from C# code.\r\n\r\nThe CpuMathNative assembly exists solely so ML.NET can take advantage of SSE and AVX instructions in its algorithms. When running on .NET Core 2.1+, we can remove our dependency on this native assembly, and instead port the C++ SIMD code to using the new C# intrinsics APIs.\r\n\r\nHowever, to do this (and still support the full .NET Framework), we need to do some refactoring to our assemblies and NuGet packages.\r\n\r\nThe first thing we need to do is allow `Microsoft.ML.CpuMath` to be multi-targeted for `netstandard2.0;netcoreapp2.1`. This will allow us to compile against the netcoreapp2.1 specific SSE APIs.\r\n\r\nHowever, doing that affects our `Microsoft.ML` nuget package. This is because when you make a nuget package, you put your assemblies into TFM specific folders `lib\\netstandard2.0`, `lib\\netcoreapp2.1`, etc. And the way asset picking works is that once it finds assets for a specific TFM, it stops looking.  (The reasoning is typically there is a single assembly per nuget package.) So if we have a single assembly, CpuMath, that needs to go into both `lib\\netstandard2.0` and `lib\\netcoreapp2.1`, we have a problem. It means ALL our assemblies need to go into BOTH folders, which is unnecessary duplication.\r\n\r\nTo solve this duplication, I propose to split CpuMath into its own nuget package.  So we will have this structure:\r\n\r\n* `Microsoft.ML.CpuMath`\r\n    - Contains the CpuMath managed assemblies (one for each TFM) and the CpuMathNative assemblies.\r\n* `Microsoft.ML`\r\n    - Has a dependency on `Microsoft.ML.CpuMath`.\r\n\r\nIn order to do this correctly, we need to remove the assembly reference from `Microsoft.ML.CpuMath.dll` on `Microsoft.ML.Core.dll`. This is because the nuget dependency goes the other way.  The only reason `Microsoft.ML.CpuMath.dll` depends on `Microsoft.ML.Core.dll` is so it can use the `Contracts` class.  We can break this dependency by using the `PRIVATE_CONTRACTS` define constant, and source linking the `Contracts.cs` file into CpuMath.\r\n\r\n/cc @TomFinley @ericstj @briancylui @tannergooding ","Url":"https://github.com/dotnet/machinelearning/issues/534","RelatedDescription":"Closed issue \"Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core\" (#534)"},{"Id":"342719538","IsPullRequest":false,"CreatedAt":"2018-07-19T13:04:46","Actor":"bzn7","Number":"558","RawContent":null,"Title":"Invalid type ('Vec<R4>') error on Training.","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 17134.165\r\n- **.NET Version (eg., dotnet --info)**: 4.7.03056\r\n\r\n### Issue\r\nI'm getting this exception while Train. Couldn't find any tip, please help.\r\n\r\n`ArgumentOutOfRangeException: Source column 'Features' has invalid type ('Vec<R4>'): Expected known size vector.`\r\n\r\n- **What did you do?**\r\nCopied some code from iris sample to my project.\r\n- **What happened?**\r\nCouldn't train my model.\r\n\r\n\r\n### Source code / logs\r\n\r\n\r\n        public class IrisData\r\n        {\r\n            [Column(\"0\")] public float[] param1 = new float[1];\r\n            [Column(\"1\")] public float[] param2 = new float[1000];\r\n            [Column(\"2\")] public float[] param3 = new float[1000];\r\n            [Column(\"3\")] public float[] param4 = new float[1000];\r\n            [Column(\"4\")] public float[] param5 = new float[1000];\r\n            [Column(\"5\", name: \"Label\")] public string Label;\r\n        }\r\n\r\n        public class IrisPrediction\r\n        {\r\n            [ColumnName(\"PredictedLabel\")]\r\n            public string PredictedLabels;\r\n        }\r\n\r\n        //Program adds some irisData to this list while working\r\n        public static List<IrisData> History = new List<IrisData>()  { };\r\n        \r\n        private static PredictionModel<IrisData,IrisPrediction> readyModel;\r\n\r\n\r\nWorking code\r\n\r\n        public static async void Learn()\r\n        {\r\n            readyModel = await TrainAsync();\r\n        }\r\n\r\n        internal static async Task<PredictionModel<IrisData, IrisPrediction>> TrainAsync()\r\n        {\r\n            var pipeline = new LearningPipeline();\r\n            var data = History;\r\n            var collection = CollectionDataSource.Create(data);\r\n\r\n            pipeline.Add(collection);\r\n            pipeline.Add(new ColumnConcatenator(\"Features\", \"param1\", \"param2\", \"param3\", \"param4\", \"param5\"));\r\n            pipeline.Add(new StochasticDualCoordinateAscentClassifier());\r\n\r\n            var model = pipeline.Train<IrisData, IrisPrediction>();\r\n            return model;\r\n        }\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/558","RelatedDescription":"Open issue \"Invalid type ('Vec<R4>') error on Training.\" (#558)"},{"Id":"342605196","IsPullRequest":true,"CreatedAt":"2018-07-19T07:11:14","Actor":"TomFinley","Number":"557","RawContent":null,"Title":"Initial code analyzer for Microsoft.ML","State":"open","Body":"Fixes #553.\r\n\r\nSome WIP items:\r\n- [x] Fix issue with `new` declarations on members not being properly handled by accessibility modifier check.\r\n- [x] Enable checking in all source projects, not just `Microsoft.ML.Core`. (Done only there for now just to validate approach.)\r\n\r\nAdds code analysis initially for correct usage of common Contracts.Except/Check patterns, naming conventions, variable usage and initializations, access modifiers, and other idioms used throughout the Microsoft.ML codebase. Enables analysis on Microsoft.ML projects.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/557","RelatedDescription":"Open PR \"Initial code analyzer for Microsoft.ML\" (#557)"},{"Id":"342556761","IsPullRequest":true,"CreatedAt":"2018-07-19T02:30:07","Actor":"codemzs","Number":"556","RawContent":null,"Title":"WIP Port SymSGD","State":"open","Body":"This PR depends on the MKL nuget for native code and hence it won't compile at the moment. I will be updating it with tests and documentation as MKL PR comes up. I have also upgraded SymSGD trainer to use ITrainer interface that returns a predictor.","Url":"https://github.com/dotnet/machinelearning/pull/556","RelatedDescription":"Open PR \"WIP Port SymSGD\" (#556)"},{"Id":"342549622","IsPullRequest":true,"CreatedAt":"2018-07-19T01:46:31","Actor":"Ivanidzo4ka","Number":"555","RawContent":null,"Title":"Don't fail in case of const field in Collection source and extended support for type conversion","State":"open","Body":"Fixes  #537.\r\nAdds support for multiple basic C# types to convert Dataview <-> collection.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/555","RelatedDescription":"Open PR \"Don't fail in case of const field in Collection source and extended support for type conversion\" (#555)"},{"Id":"342531912","IsPullRequest":false,"CreatedAt":"2018-07-18T23:59:17","Actor":"Zruty0","Number":"554","RawContent":null,"Title":"Need a doc on Type-to-DataView schema mapping","State":"open","Body":"We should have a doc that describes exactly how we go from \r\n```(csharp)\r\n        public class IrisData\r\n        {\r\n            [Column(\"0\")]\r\n            public float Label;\r\n\r\n            [Column(\"1\")]\r\n            public float SepalLength;\r\n\r\n            [Column(\"2\")]\r\n            public float SepalWidth;\r\n\r\n            [Column(\"3\")]\r\n            public float PetalLength;\r\n\r\n            [Column(\"4\")]\r\n            public float PetalWidth;\r\n        }\r\n```\r\nto the schema of the data view. It should cover:\r\n* Why field types are important, and how they are used\r\n* What exactly is `ColumnAttribute`, `ColumnNameAttribute`\r\n* Handling of vectors and `VectorTypeAttribute`\r\n* Handling of key types and `KeyTypeAttribute`\r\n* `SchemaDefinition` as a means of runtime schema hints.\r\n* Limitations / what can not be done.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/554","RelatedDescription":"Open issue \"Need a doc on Type-to-DataView schema mapping\" (#554)"},{"Id":"342469916","IsPullRequest":false,"CreatedAt":"2018-07-18T19:57:21","Actor":"TomFinley","Number":"553","RawContent":null,"Title":"Introduce code analyzer","State":"open","Body":"Like most sufficiently large codebases the ML.NET project is guilty of having acquired a set of idioms. Internally we had a code analyzer, to help catch some of the most common issues that tended to come up in PRs, but sometimes we don't do this, and need to fix issues later (e.g., #271, #442, #478). I want to migrate that analyzer to the open source repository, to hopefully automate some of this.\r\n\r\nThere are of course other things we could do with an analyzer, once we have one.\r\n\r\n/cc @ericstj ","Url":"https://github.com/dotnet/machinelearning/issues/553","RelatedDescription":"Open issue \"Introduce code analyzer\" (#553)"},{"Id":"342443150","IsPullRequest":false,"CreatedAt":"2018-07-18T18:33:04","Actor":"briancylui","Number":"552","RawContent":null,"Title":"Port native SIMD algorithms for SSE to managed code","State":"open","Body":"### Summary (July 18)\r\n1. Prepare to check in code to ML.NET repo, with:\r\n* [C# implementations](https://github.com/briancylui/machinelearning/blob/SseKey/src/Microsoft.ML.CpuMath/CpuMathUtils.DotNetCoreApp.cs) of [SSE intrinsics](https://github.com/briancylui/machinelearning/blob/SseKey/src/Microsoft.ML.CpuMath/SseIntrinsics.cs) living in [src/Microsoft.ML.CpuMath](https://github.com/briancylui/machinelearning/tree/SseKey/src/Microsoft.ML.CpuMath)\r\n* [Unit tests](https://github.com/briancylui/machinelearning/blob/SseKey/test/Microsoft.ML.CpuMath.UnitTests/UnitTests.cs) and [performance tests](https://github.com/briancylui/machinelearning/blob/SseKey/test/Microsoft.ML.CpuMath.PerformanceTests/SsePerformanceTests.cs) living in [test/Microsoft.ML.CpuMath.[Unit/Performance]Tests](https://github.com/briancylui/machinelearning/tree/SseKey/test)\r\n2. Resolve multi-targeting issue of targeting two different frameworks: .NET Core App 3.0 and .NET Standard 2.0\r\n3. Additional rigorous unit tests and performance tests to ensure correctness and efficiency\r\n4. Link to working repo (forked): https://github.com/briancylui/machinelearning\r\n5. Link to original issue page for 12-week timeline: https://github.com/briancylui/machinelearning/issues/1\r\n\r\n### Goals\r\n1.\tPort ML.NET C++ SIMD algorithms for SSE to C#\r\n2.\tEnsure C# Hardware Intrinsics feature for SSE meets the needs of ML.NET\r\n3.\tUnit test all functions and get performance benchmark numbers for before and after changes\r\n4.\t(Stretch) Provide software fallback implementations to support more architectures\r\n\r\n[Keeping only the relevant, high-level details below from original [progress](https://github.com/briancylui/machinelearning/issues/1) page to give a general sense of progress]\r\n### Progress\r\n\r\n**Week 2 (Jun 25-29): Port SIMD operations in .NET to managed code outside of ML.NET**\r\n- [x] Implement SSE support and software fallbacks in managed code for all key intrinsics\r\n- [x] Comply with coding style standard\r\n- [x] Implement working unit tests for all key intrinsics\r\n- [x] Implement working performance tests for all key intrinsics using [BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet) ([slides](https://microsoft.sharepoint.com/:p:/r/teams/netfx/corefx/_layouts/15/Doc.aspx?sourcedoc=%7Bf4cdc660-09d2-40ae-a099-4c6bf213bec1%7D&action=default) and [recording](https://microsoft.sharepoint.com/teams/netfx/corefx/Documents/Forms/AllItems.aspx?id=%2Fteams%2Fnetfx%2Fcorefx%2FDocuments%2FModern%20BCL%2Fmodern%20BCL%20talk%20series%20%2D%20Benchmark%2ENET%204%2027%202018%2Emp4&parent=%2Fteams%2Fnetfx%2Fcorefx%2FDocuments%2FModern%20BCL&p=true&slrid=1efa769e-e056-0000-7f34-41a0941dbef8))\r\n- [x] Present performance results in a table ([SsePerf-report-github.pdf](https://github.com/briancylui/machinelearning/files/2157186/SsePerf-report-github.pdf))\r\n\r\n``` ini\r\n\r\nBenchmarkDotNet=v0.10.14, OS=Windows 10.0.15063.1155 (1703/CreatorsUpdate/Redstone2)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\nFrequency=3515623 Hz, Resolution=284.4446 ns, Timer=TSC\r\n.NET Core SDK=2.1.300\r\n  [Host]     : .NET Core 2.1.0 (CoreCLR 4.6.26515.07, CoreFX 4.6.26515.06), 64bit RyuJIT\r\n  DefaultJob : .NET Core 2.1.0 (CoreCLR 4.6.26515.07, CoreFX 4.6.26515.06), 64bit RyuJIT\r\n\r\n\r\n```\r\n|                    Method |       Mean |      Error |     StdDev |\r\n|-------------------------- |-----------:|-----------:|-----------:|\r\n|            NativeDotUPerf |   363.2 us |  7.7293 us | 18.8143 us |\r\n|                MyDotUPerf |   340.2 us |  6.7218 us |  8.0018 us |\r\n|           NativeDotSUPerf | 2,178.3 us | 43.4641 us | 40.6563 us |\r\n|               MyDotSUPerf | 2,144.7 us | 19.1638 us | 16.0027 us |\r\n|          NativeSumSqUPerf |   540.6 us |  3.0299 us |  2.8342 us |\r\n|              MySumSqUPerf |   538.8 us |  2.5507 us |  2.3859 us |\r\n|            NativeAddUPerf |   313.9 us |  2.5163 us |  2.3537 us |\r\n|                MyAddUPerf |   303.3 us |  4.5125 us |  4.2210 us |\r\n|           NativeAddSUPerf | 2,691.8 us | 29.4588 us | 27.5558 us |\r\n|               MyAddSUPerf | 2,658.1 us | 51.3336 us | 64.9206 us |\r\n|       NativeAddScaleUPerf |   300.0 us |  5.5529 us |  5.1941 us |\r\n|           MyAddScaleUPerf |   309.8 us |  5.3974 us |  4.7846 us |\r\n|      NativeAddScaleSUPerf | 2,550.9 us | 21.8322 us | 20.4218 us |\r\n|          MyAddScaleSUPerf | 2,805.3 us | 20.5171 us | 19.1917 us |\r\n|          NativeScaleUPerf |   131.4 us |  0.6347 us |  0.5626 us |\r\n|              MyScaleUPerf |   130.7 us |  1.2159 us |  1.1373 us |\r\n|           NativeDist2Perf |   336.4 us |  2.0555 us |  1.9227 us |\r\n|               MyDist2Perf |   335.2 us |  8.3427 us | 11.4196 us |\r\n|         NativeSumAbsUPerf |   258.0 us |  1.6470 us |  1.5406 us |\r\n|            MySumAbsqUPerf |   258.9 us |  0.9447 us |  0.7889 us |\r\n| NativeMulElementWiseUPerf |   466.4 us |  1.9625 us |  1.6388 us |\r\n|     MyMulElementWiseUPerf |   467.2 us |  4.3560 us |  4.0747 us |\r\n\r\n\r\n**Week 3-5 (Jul 2-20): Port algo to C#, write unit tests and performance tests, check in code**\r\n- [x] Apply real data to test implemented managed code using BenchmarkDotNet\r\n- [x] Integrate local code into ML.NET repo to prepare for checking in code, including:\r\n* C# implementations of intrinsics\r\n* Unit tests\r\n* Performance tests\r\n- [ ] Implement additional unit tests to test the complete code paths for two different target frameworks\r\n- [ ] Scale up implementation, unit tests, and performance tests to cover all SSE intrinsics\r\n\r\n**Week 6 (Jul 23-27)**\r\n- [ ] Write blog post on how ML.NET is taking advantage of .NET Core hardware intrinsics\r\n\r\n**Week 7-9 (Jul 30-Aug 17)**\r\n- [ ] Write AVX implementations \r\n- [ ] Performance test before and after. We should see some perf gains here.\r\n- [ ] Write blog post on AVX vs SSE comparisons (both implementation and runtime perf)\r\n- [ ] Check in code to ML.NET\r\n\r\n**Week 10-11 (Aug 20-31) (Stretch)**\r\n- [ ] Provide software fallback implementations\r\n\r\n**Week 12 (Sept 3-7)**\r\n- [ ] Clean up, presentation, close out remaining issues","Url":"https://github.com/dotnet/machinelearning/issues/552","RelatedDescription":"Open issue \"Port native SIMD algorithms for SSE to managed code\" (#552)"},{"Id":"342210925","IsPullRequest":false,"CreatedAt":"2018-07-18T07:36:13","Actor":"StanislavChankov","Number":"551","RawContent":null,"Title":"Score column is missing. Parameter name ScoreColumn.","State":"open","Body":"### Issue\r\nThrows an exception \r\n- **What did you do?**\r\n![image](https://user-images.githubusercontent.com/35253870/42866807-475cd2a8-8a76-11e8-9509-d8d147534fa7.png)\r\n\r\n- **What happened?**\r\n![image](https://user-images.githubusercontent.com/35253870/42866529-6e75a5d2-8a75-11e8-8aaf-b4a609affc96.png)\r\n\r\n- **What did you expect?**\r\nTo train without errors or warnings like I have.\r\n### Source code / logs\r\n**ML.NET Version: 0.3.0**\r\n![image](https://user-images.githubusercontent.com/35253870/42866497-59a16876-8a75-11e8-80c8-dfe0ca695d56.png)\r\n![image](https://user-images.githubusercontent.com/35253870/42866716-0f85de24-8a76-11e8-8da4-8cd233d3f7d3.png)\r\n\r\n![image](https://user-images.githubusercontent.com/35253870/42866191-96d304a8-8a74-11e8-99da-4eb762792eb0.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/551","RelatedDescription":"Open issue \"Score column is missing. Parameter name ScoreColumn.\" (#551)"},{"Id":"342139971","IsPullRequest":true,"CreatedAt":"2018-07-18T01:05:47","Actor":"codemzs","Number":"550","RawContent":null,"Title":"Ensure ONNX export is compatible with Windows RS5","State":"open","Body":"fixes #549 by testing ONNX models on Windows RS5 machine.","Url":"https://github.com/dotnet/machinelearning/pull/550","RelatedDescription":"Open PR \"Ensure ONNX export is compatible with Windows RS5\" (#550)"},{"Id":"342139834","IsPullRequest":false,"CreatedAt":"2018-07-18T01:04:56","Actor":"codemzs","Number":"549","RawContent":null,"Title":"Ensure ONNX export is Windows RS5 compatible.","State":"open","Body":"Added more tests for ONNX export and ran the model on RS5 machine to ensure model loads and evaluates.","Url":"https://github.com/dotnet/machinelearning/issues/549","RelatedDescription":"Open issue \"Ensure ONNX export is Windows RS5 compatible.\" (#549)"},{"Id":"342119690","IsPullRequest":true,"CreatedAt":"2018-07-17T23:04:51","Actor":"zeahmed","Number":"548","RawContent":null,"Title":"Fixed the TextTransform bug where chargrams where being computed differently when using with/without word tokenizer.","State":"open","Body":"This PR fixes #530. The cause of the problem was `word tokenizer` being applied before `char tokenizer` causing scalar valued text (e.g. `This is a cat`) to become vector (e.g. <This, is, a, cat>). \r\n\r\nPreviously, char tokenizer treated every vector item as separate text item (e.g. computing chargrams on each item by placing start and end markers `<STX>token<ETX>` instead of taking `This is a cat` as single text item).\r\n\r\nThe fix is in CharTokenizeTransform. The CharTokenizeTransform can take either a scalar or vector column as input. The processing of chargrams are done as follows.\r\n\r\n- If the input column is a scalar with text type then chargrams are computed by prepending `<STX>` and appending `<ETX>` characters at the start and at the end of the text respectively.  For example, if the input is `This is a cat` then chargrams will be computed on `<STX>This is a cat<ETX>`.\r\n\r\n- If the input column is a vector with text type (it could be a result of concatenation of several text columns together or application of word tokenizer before char tokenizer) then chargrams will be computed by prepending `<STX>` and appending `<ETX>` characters at start and at the end of the vector respectively. Also, <US> characters are inserted after every item in the vector. For example, if the input is `<This, is, a, cat>` then chargrams will be computed on `<STX>This<US>is<US>a<US>cat<ETX>`.\r\n\r\n- To be backward compatible, CharTokenizerTransform version was bumped up and the support for loading models saved with previous version is added.\r\n\r\nMoving forward, the chargrams will be computed as follows\r\n\r\n- if `stop word removal` is request, chargrams will be computed after `StopwordRemovalTransform` is applied e.g. `<STX>This<US>is<US>a<US>cat<ETX>`.\r\n- otherwise, raw text after text normalization will be used for chargram computing e.g. `This is a cat`.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/548","RelatedDescription":"Open PR \"Fixed the TextTransform bug where chargrams where being computed differently when using with/without word tokenizer.\" (#548)"},{"Id":"342110400","IsPullRequest":false,"CreatedAt":"2018-07-17T22:22:50","Actor":"Ivanidzo4ka","Number":"547","RawContent":null,"Title":"ColumnType not properly implements IEquatable","State":"open","Body":"https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/Data/ColumnType.cs\r\nAccording to https://msdn.microsoft.com/en-us/library/ms131190(v=vs.110).aspx (see Notes to Implementers:) we suppose to also override GetHashCode which we don't do.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/547","RelatedDescription":"Open issue \"ColumnType not properly implements IEquatable\" (#547)"},{"Id":"342077809","IsPullRequest":false,"CreatedAt":"2018-07-17T20:45:02","Actor":"Ivanidzo4ka","Number":"546","RawContent":null,"Title":"Rename tlcresources in Resource manager","State":"open","Body":"```\r\n        private const string DefaultUrl = \"https://aka.ms/tlc-resources/\";\r\n      \r\n        private static string TlcResourcesUrl\r\n```\r\nwe have this TLC mentions in https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/Utilities/ResourceManagerUtils.cs\r\nand it would be nice to rename them to something ml.net specific.\r\n\r\nIn same time we need to make sure default url should point to valid location (we can't just rename it in code, we also need to update aka.ms)","Url":"https://github.com/dotnet/machinelearning/issues/546","RelatedDescription":"Open issue \"Rename tlcresources in Resource manager\" (#546)"},{"Id":"342076074","IsPullRequest":true,"CreatedAt":"2018-07-17T20:39:52","Actor":"Ivanidzo4ka","Number":"545","RawContent":null,"Title":"WIP word embedding transform","State":"open","Body":"I heard word embedding can be nice thing for Text classification\r\n- [ ] Create issue\r\n- [ ] Put legal attributes for Wikipedia files\r\n- [ ] Put legal attributes for Glove files\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/545","RelatedDescription":"Open PR \"WIP word embedding transform\" (#545)"},{"Id":"342056815","IsPullRequest":false,"CreatedAt":"2018-07-17T19:40:10","Actor":"EduardoGarcias","Number":"544","RawContent":null,"Title":"CrossValidation fails with a valid pipeline","State":"open","Body":"### System information\r\n\r\n- **Windows 10 Home (1803) - 64bit**:\r\n- **.NET Version 2.1.202**: \r\n- **WPF application with includes class libraries in .net 4.7 framework version**:\r\n\r\n### Issue\r\n\r\nIt is not possible for me to perform a CrossValidation on a Pipline, which I use for training my model. The training is performed without any issues. Normal evaluation works correctly (using classes like BinaryClassificationEvaluator or RegressionEvaluator) but the CrossValidation ends with an error. The error is as follows:\r\n> InvalidOperationException: No valid training instances found, all instances have missing features.\r\n\r\n\r\n### Source code / logs\r\n\r\n- Pipeline body is like:\r\n`          \r\n     \r\n                new TextLoader(filePath).CreateFrom<ReopenedIssueData>(),\r\n                new TextFeaturizer(Columns.Environment, Columns.Environment),\r\n                new TextFeaturizer(Columns.Type, Columns.Type),\r\n                new TextFeaturizer(Columns.ProjectName, Columns.ProjectName),\r\n                new TextFeaturizer(Columns.AsigneeEmail, Columns.AsigneeEmail),\r\n                new TextFeaturizer(Columns.ReporterEmail, Columns.ReporterEmail),\r\n                new ColumnConcatenator(\r\n                    Columns.Features,\r\n                    Columns.Environment,\r\n                    Columns.Type,\r\n                    Columns.CommentsCount,\r\n                    Columns.CommentsLenght,\r\n                    Columns.ReporterCommentsCount,\r\n                    Columns.ProjectName,\r\n                    Columns.AsigneeEmail,\r\n                    Columns.ReporterEmail),\r\n                new FastTreeBinaryClassifier(),\r\n                new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn=Columns.PredictedLabel   }\r\n                    \r\n`\r\n\r\n- And the StackTrace is as follows:\r\n\r\n>  at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node)\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros()\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll()\r\n   at Microsoft.ML.Models.CrossValidator.CrossValidate[TInput,TOutput](LearningPipeline pipeline)\r\n   at RepositoryAnalyser.MachineLearning.Services.TrainingModelEvaluator.CrossValidate[TData,TPrediction](LearningPipeline pipeline, MachineLearningMechanism mechanism, Int32 numOfFolds)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/544","RelatedDescription":"Open issue \"CrossValidation fails with a valid pipeline\" (#544)"},{"Id":"341998856","IsPullRequest":false,"CreatedAt":"2018-07-17T16:43:38","Actor":"TomFinley","Number":"543","RawContent":null,"Title":"Rename properties of `ITrainerEx` (`TrainerInfo`)","State":"open","Body":"`ITrainerEx` (or its functional successor `TrainerInfo` from #522) contains the following properties.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ef169b2c67ef394b65d5bedbebd378913789fd9c/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L35-L58\r\n\r\nAs the comment suggests, we ought to be consistent in naming. There are several things we might consider doing here.\r\n\r\nThe first thing we might consider is getting rid of `NeedCalibration` specifically. It is I believe always true when the predictor returned from this is a binary predictor, but does not itself return probabilities. This is a trait that I believe can be directly derived from the predictor object itself, so we might be able to simplify the code here. (Certainly the code to detect whether a predictor produces probabilities might potentially be somewhat involved, and the situation here may be less simple than I suspect.)\r\n\r\nThe other thing is reconciling `Need` and `Want`. The prefix `Need` is a bit odd, since certainly you don't *need* to do any of those things for things to work, it's just a suggestion that it might work better *if* you do those things.\r\n\r\nHowever rather than just reconciling the prefix, we might consider renaming them altogether. They're very oddly named in the sense that they don't describe a property of the trainer they are attached to, they describe an action we suggest a user of the trainer should do to use them (or in the case of `NeedCalibration`, an action to take on the result of training). That is, they are *prescriptive* as opposed to *descriptive*, which seems undesirable.\r\n\r\nSo take `NeedNormalization`... trainers don't just need normalization randomly for no reason, they need normalization because they have parametric assumptions about feature data -- maybe a property could be devised to explain that, with the understanding that if it's true a user may benefit from normalizing features. Similarly, caching tends to be useful if an algorithm could perform many passes over the data (therefore making it better to keep in memory).\r\n\r\nHowever maybe this is a bit too goofy... `NeedNormalization` is easy for more people to reach the desired action vs. some complicated multi-step process of reasoning (\"it has parametric assumptions about features, I think my data is not, the way people tend to fix this is apply normalizers, so I will apply a normalizer\" vs. just \"ah, needs normalization, I will normalize.\"). Despite the fact that the name is prescriptive and not descriptive, maybe that does not in itself make it inferior to the alternative?\r\n\r\nNot sure about this.\r\n\r\n/cc @eerhardt , @ericstj , @Zruty0 ","Url":"https://github.com/dotnet/machinelearning/issues/543","RelatedDescription":"Open issue \"Rename properties of `ITrainerEx` (`TrainerInfo`)\" (#543)"},{"Id":"341657323","IsPullRequest":false,"CreatedAt":"2018-07-16T19:59:51","Actor":"eerhardt","Number":"541","RawContent":null,"Title":"Need to rename TlcEnvironment","State":"open","Body":"Our only public, concrete environment class is named \"TlcEnvironment\", which uses the internal \"TLC\" acronym/name and has no meaning anymore.\r\n\r\nWe should come up with a better name for our default environment class.\r\n\r\n/cc @ericstj @TomFinley ","Url":"https://github.com/dotnet/machinelearning/issues/541","RelatedDescription":"Open issue \"Need to rename TlcEnvironment\" (#541)"},{"Id":"341599530","IsPullRequest":false,"CreatedAt":"2018-07-16T17:01:01","Actor":"dsyme","Number":"540","RawContent":null,"Title":"Plan for F# bug and testing","State":"open","Body":"I've been asked to fix some issues related to F# in this repo, especially #180. This is a planning note regarding this work.\r\n\r\nTODO:\r\n\r\n* [ ] Add one F# scripting \"smoke test\" under `tests\\FSharpScripting\\SmokeTest` based around those done by @isaacabraham, see https://github.com/isaacabraham/ml-test-experiment.  \r\n\r\n   * This test will run under CI on Windows. It will currently require .NET Framework or Mono.  \r\n\r\n* [ ] Add one F# compiled-project \"smoke test\" under `tests\\FSharpProjects\\SmokeTest` based around those done by @isaacabraham, see https://github.com/isaacabraham/ml-test-experiment.  \r\n\r\n   * This test will run under CI on both Windows and Linux and only require .NET Core\r\n\r\nWhen futher API updates and re-designs are made it is up to the person doing the re-design to adjust these tests :) Ask for help if you need it, but the F# code will be simple and I'm sure all contributors are capable of adjusting trivial F# code, F# is dead simple to learn.\r\n\r\nThen, when [this bug](https://github.com/dotnet/machinelearning/issues/180) is fixed, a test will be added to both tests\\FSharpScripting\\SmokeTest and tests\\FSharpProjects\\SmokeTest.\r\n\r\nSeparately I will propose updates for documentation for F#, and we can later look at more comprehensive documentation, samples and testing.","Url":"https://github.com/dotnet/machinelearning/issues/540","RelatedDescription":"Open issue \"Plan for F# bug and testing\" (#540)"},{"Id":"341403566","IsPullRequest":false,"CreatedAt":"2018-07-16T06:32:52","Actor":"rauhs","Number":"537","RawContent":null,"Title":"`const` on the instance class will throw","State":"open","Body":"Adding a:\r\n\r\n```\r\n    public const string MagicNone = \" NONE \";\r\n```\r\n\r\nto an \"instance\" class (ie the class used to feed ML.NET the instances) will throw an ugly exception which is hard to figure out.\r\n\r\nI think there is another issue where more careful reflecting of the class is suggested. Can't find it right now though","Url":"https://github.com/dotnet/machinelearning/issues/537","RelatedDescription":"Open issue \"`const` on the instance class will throw\" (#537)"},{"Id":"341354477","IsPullRequest":false,"CreatedAt":"2018-07-15T21:38:28","Actor":"galvesribeiro","Number":"536","RawContent":null,"Title":"WASM support","State":"open","Body":"Hello folks!\r\n\r\nTrying to make ML.Net to work on mono-wasm but I just figured out the hard way that it only works on x64:\r\n\r\n![image](https://user-images.githubusercontent.com/4714040/42738687-1104bf6e-885e-11e8-813b-e55a91976ccc.png)\r\n\r\nIs there any chance to get the native part built to wasm?\r\n\r\nThanks!","Url":"https://github.com/dotnet/machinelearning/issues/536","RelatedDescription":"Open issue \"WASM support\" (#536)"},{"Id":"341193133","IsPullRequest":false,"CreatedAt":"2018-07-14T00:27:17","Actor":"dan-drews","Number":"535","RawContent":null,"Title":"How would I concatenate columns of different types?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**:  .NET Framework 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Combined numeric columns with FeaturizedText Columns\r\n- **What happened?** I received an exception about mismatched column Types\r\n- **What did you expect?** I'm not 100% sure. I am hoping to find a way to combine a text featurizer with numeric values into the \"Features\" column to take multiple data types into account. I saw that we have the categorical vectorizers and Hash Transform Columns available, but I from what i understand, that is for a distinct number of categories.\r\n\r\nWhat I am trying to accomplish is utilizing numeric and text values in the prediction. Maybe this is just a lack of understanding on my part for this and it is not possible, but I'm kind of hoping to post the pieces of my business object that that I think could impact the result, and I cannot figure out how to do that effectively.\r\n\r\nNote: I am using a FastTreeRegressor predicting a float value.","Url":"https://github.com/dotnet/machinelearning/issues/535","RelatedDescription":"Open issue \"How would I concatenate columns of different types?\" (#535)"},{"Id":"341148843","IsPullRequest":false,"CreatedAt":"2018-07-13T20:24:29","Actor":"bsexton","Number":"533","RawContent":null,"Title":"Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.","State":"open","Body":"### System information\r\nIssue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**:  4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I started with the TaxiFare Example and that works. But then I changed the model and added my own values and my data. I got the error about the \"Features\" above. I played with it for a while and tried limiting my data. Even tried predicting the Fare Amount again.\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/533","RelatedDescription":"Open issue \"Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.\" (#533)"},{"Id":"341147669","IsPullRequest":false,"CreatedAt":"2018-07-13T20:19:49","Actor":"vivekpradhan","Number":"532","RawContent":null,"Title":"LightGBM on ML.NET trains slower than LightGBM command line","State":"open","Body":"### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.301\r\n Commit:    59524873d6\r\n\r\nRuntime Environment:\r\n OS Name:     ubuntu\r\n OS Version:  16.04\r\n\r\nHardware:\r\nGoogle Cloud default 64 core machine.\r\n\r\n### Issue\r\n\r\nRan training on same dataset with same params.\r\nDataset: 25k features x 140k rows (balanced binary classes)\r\nParams: \r\nCommand Line: \r\n```\r\n./lightgbm metric=binary_logloss min_data_in_leaf=500 bagging_fraction=0.8 boosting_type=gbdt bagging_freq=5 max_bin=255 objective=binary valid_data=../../../pedata/test.csv max_depth=10 feature_fraction=0.8 num_leaves=70 output_result=prediction.txt num_machines=1 learning_rate=0.1 output_model=LightGBM_model.txt data=../../../pedata/train.csv num_threads=64 task=train is_training_metric=true num_iterations=500 metric_freq=1 tree_learner=serial\r\n```\r\nML.NET\r\n```\r\nvar lclassifier = new LightGbmBinaryClassifier() { UseCat=false, MaxBin= 255, EvalMetric= LightGbmArgumentsEvalMetricType.Logloss , NumLeaves= 70, NThread= 64,LearningRate= 0.1, NumBoostRound= 500, MinDataPerLeaf= 500};\r\n            lclassifier.Booster = new GbdtBoosterParameterFunction() { \r\n                MaxDepth = 10,\r\n                FeatureFraction=0.8,\r\n                SubsampleFreq=5 };\r\n            pipeline.Add(lclassifier);\r\n```\r\n- **What happened?**\r\n\r\nBoth use all the 64 cores (As seen on htop).\r\nData Loading + Training Time: Command Line: 10mins, ML.NET: 17mins\r\n\r\n- **What did you expect?**\r\nSince both were build on my machine from source, I expected that the training time would be comparable.  \r\n\r\nWhy is the ML.NET implementation slower? Is there something I can do to speed it up?\r\n\r\n```\r\nStopwatch stopwatch = new Stopwatch();\r\nstopwatch.Start();\r\n// STEP 5: Train your model based on the data set\r\nvar model = pipeline.Train<IrisData, IrisPrediction>();\r\nstopwatch.Stop();\r\n```\r\nThe above stopwatch gives me time taken for Loading+Training. Is there a way to check the time taken only for the training step. Right now I am not sure if the data loading is slow or the training is slow.\r\n\r\n-----------------\r\nEdit: I got approximate training time by assuming that when CPU usage spikes, thats when training starts.\r\nTraining Time: Command Line: 335s, ML.NET:680s (approx)\r\nData Loading: Command Line: 265s, ML.NET: 340s (approx)","Url":"https://github.com/dotnet/machinelearning/issues/532","RelatedDescription":"Open issue \"LightGBM on ML.NET trains slower than LightGBM command line\" (#532)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-07-20T05:30:37.9887717Z","RunDurationInMilliseconds":1124}