{"Data":{"GitHub":{"Issues":[{"Id":"449533150","IsPullRequest":true,"CreatedAt":"2019-05-29T00:26:46","Actor":"pkumar07","Number":"3785","RawContent":null,"Title":"Add AVX and FMA intrinsics in Factorization Machine","State":"open","Body":"Added AVX and FMA C++ intrinsics in factorizationmachinenative.dll which currently implements C++ SSE code as suggested in #3000.","Url":"https://github.com/dotnet/machinelearning/pull/3785","RelatedDescription":"Open PR \"Add AVX and FMA intrinsics in Factorization Machine\" (#3785)"},{"Id":"449300715","IsPullRequest":false,"CreatedAt":"2019-05-28T23:14:00","Actor":"nfnpmc","Number":"3784","RawContent":null,"Title":"Bitmap data","State":"closed","Body":"What is (I assume a variable) Enumerable and how do you get it from a Bitmap or Image, neither of which is Enumerable? Two loops to examine the pixels and put it into a linear array?\n\n---\n#### Document Details\n\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\n\n* ID: 8b9c0132-7901-8114-b8bc-faa09ad74797\n* Version Independent ID: 8274abb2-6952-674b-e8bc-1e314aeee4cc\n* Content: [TensorFlowModel.ScoreTensorFlowModel Method (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowmodel.scoretensorflowmodel?view=ml-dotnet-preview#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/TensorFlowModel.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/TensorFlowModel.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/3784","RelatedDescription":"Closed issue \"Bitmap data\" (#3784)"},{"Id":"447896097","IsPullRequest":true,"CreatedAt":"2019-05-28T05:30:54","Actor":"yaeldekel","Number":"3772","RawContent":null,"Title":"Fix the user name in LoadableClassAttribute of VectorToImageTransformer","State":"closed","Body":"Update user name in loadable class attribute to the right name.","Url":"https://github.com/dotnet/machinelearning/pull/3772","RelatedDescription":"Closed or merged PR \"Fix the user name in LoadableClassAttribute of VectorToImageTransformer\" (#3772)"},{"Id":"448327873","IsPullRequest":true,"CreatedAt":"2019-05-28T04:29:12","Actor":"yaeldekel","Number":"3774","RawContent":null,"Title":"Add load names to Platt calibrator","State":"closed","Body":"The load names of the `PlattCalibratorTrainerFactory` need to match those of the `LoadableClassAttribute`.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3774","RelatedDescription":"Closed or merged PR \"Add load names to Platt calibrator\" (#3774)"},{"Id":"448787407","IsPullRequest":false,"CreatedAt":"2019-05-27T10:41:01","Actor":"PeterPann23","Number":"3783","RawContent":null,"Title":"[AutoML]  feature request Include PFI statistics","State":"open","Body":"Users of AutoML would probably appreciate having templating injected PFI for the \"best\" model as described in the online [documentation](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/explain-machine-learning-model-permutation-feature-importance-ml-net)\r\n\r\nI guess one could add it after the training dialogue as well. Nice for those that like to spin the data. perhaps start training again after the user excludes some of the \"noisy features\"","Url":"https://github.com/dotnet/machinelearning/issues/3783","RelatedDescription":"Open issue \"[AutoML]  feature request Include PFI statistics\" (#3783)"},{"Id":"448720019","IsPullRequest":false,"CreatedAt":"2019-05-27T09:32:09","Actor":"constructor-igor","Number":"3781","RawContent":null,"Title":"Error message 'Could not find feature column' in Fit() method","State":"closed","Body":"### System information\r\n\r\n- **Windows7x64**:\r\n- **.NET Version 2.1.502**: \r\n\r\n### Issue\r\n\r\n- I try to create my first sample of Microsoft.ML and my program fails with message 'Could not find feature column 'X'', but type contains the field.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/1849690/58404863-d03e1c00-806e-11e9-9845-2e43e2fcbf1e.png)\r\n\r\n\r\n### Source code / logs\r\n\r\n```c#\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing System.Numerics;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Trainers;\r\n\r\nnamespace ML.NET\r\n{\r\n    public class FormulaData{\r\n        [ColumnName(\"Label\")]\r\n        public float Y;\r\n        [ColumnName(\"Features\")]\r\n        public float X;\r\n        public FormulaData(double x, double y){\r\n            X = Convert.ToSingle(x);\r\n            Y = Convert.ToSingle(y);\r\n        }\r\n    }\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            Console.WriteLine(\"Hello World!\");\r\n\r\n            List<FormulaData> pointsValues = Enumerable\r\n                .Range(-1, 8)\r\n                .Select(value => {return new FormulaData(value, value*2-1);})\r\n                .ToList();\r\n\r\n            // Create MLContext\r\n            var mlContext = new MLContext(1);\r\n\r\n            // Load Data\r\n            IDataView data = mlContext.Data.LoadFromEnumerable<FormulaData>(pointsValues);\r\n\r\n            DataOperationsCatalog.TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data, testFraction: 0.2);\r\n            IDataView trainData = dataSplit.TrainSet;\r\n            IDataView testData = dataSplit.TestSet;\r\n\r\n            // Define trainer options.\r\n            var options = new SdcaRegressionTrainer.Options\r\n            {\r\n                LabelColumnName = nameof(FormulaData.Y),\r\n                FeatureColumnName = nameof(FormulaData.X),\r\n                // Make the convergence tolerance tighter. It effectively leads to more training iterations.\r\n                ConvergenceTolerance = 0.02f,\r\n                // Increase the maximum number of passes over training data. Similar to ConvergenceTolerance,\r\n                // this value specifics the hard iteration limit on the training algorithm.\r\n                MaximumNumberOfIterations = 30,\r\n                // Increase learning rate for bias.\r\n                BiasLearningRate = 0.1f            \r\n            };\r\n\r\n            // Define StochasticDualCoodrinateAscent regression algorithm estimator\r\n            var sdcaEstimator = mlContext.Regression.Trainers.Sdca(options);\r\n\r\n            // Build machine learning model\r\n            var trainedModel = sdcaEstimator.Fit(trainData);\r\n\r\n            // Use trained model to make inferences on test data\r\n            IDataView testDataPredictions = trainedModel.Transform(testData);\r\n\r\n            // Extract model metrics and get RSquared\r\n            RegressionMetrics trainedModelMetrics = mlContext.Regression.Evaluate(testDataPredictions);\r\n            double rSquared = trainedModelMetrics.RSquared;\r\n\r\n            Console.WriteLine($\"rSquared: {rSquared}\");\r\n        }\r\n    }\r\n}\r\n\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3781","RelatedDescription":"Closed issue \"Error message 'Could not find feature column' in Fit() method\" (#3781)"},{"Id":"448743119","IsPullRequest":false,"CreatedAt":"2019-05-27T08:58:43","Actor":"PeterPann23","Number":"3782","RawContent":null,"Title":"Cookbook could use a sample of tweeking schema for training","State":"open","Body":"At the moment the [cook book](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md) is the best kick starter for using the model and explains the getting started concepts of the API. \r\n\r\nMissing though I feel is how to manipulate the pipeline when it comes to adding bias and or techniques for dealing with under and overfitting. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3782","RelatedDescription":"Open issue \"Cookbook could use a sample of tweeking schema for training\" (#3782)"},{"Id":"448621429","IsPullRequest":false,"CreatedAt":"2019-05-27T00:09:35","Actor":"Ashish225","Number":"3780","RawContent":null,"Title":"Bias value gets changed every run at 100th place","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I run sample code on given document (Using full data as Traning data)\r\n\r\n- **What happened?** Bias value gets changed every run at 100th place\r\n1st try result -\r\n2nd try result -\r\n3rd try result -\r\n\r\n- **What did you expect?**\r\nSame value, because of using same sample data at every run.\r\n\r\n### Source code / logs\r\nSample code I tried - https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/train-machine-learning-model-ml-net\r\n\r\n`HousingData[] housingData = new HousingData[]\r\n            {\r\n                new HousingData\r\n                {\r\n                    Size = 600f,\r\n                    HistoricalPrices = new float[] { 100000f ,125000f ,122000f },\r\n                    CurrentPrice = 170000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 1000f,\r\n                    HistoricalPrices = new float[] { 200000f, 250000f, 230000f },\r\n                    CurrentPrice = 225000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 1000f,\r\n                    HistoricalPrices = new float[] { 126000f, 130000f, 200000f },\r\n                    CurrentPrice = 195000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 850f,\r\n                    HistoricalPrices = new float[] { 150000f,175000f,210000f },\r\n                    CurrentPrice = 205000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 900f,\r\n                    HistoricalPrices = new float[] { 155000f, 190000f, 220000f },\r\n                    CurrentPrice = 210000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size = 550f,\r\n                    HistoricalPrices = new float[] { 99000f, 98000f, 130000f },\r\n                    CurrentPrice = 180000f\r\n                }\r\n            };\r\n\r\n            MLContext mlContext = new MLContext();\r\n            IDataView trainingData = mlContext.Data.LoadFromEnumerable(housingData);\r\n\r\n            // Define Data Prep Estimator\r\n            // 1. Concatenate Size and Historical into a single feature vector output to a new column called Features\r\n            // 2. Normalize Features vector\r\n            IEstimator<ITransformer> dataPrepEstimator =\r\n                mlContext.Transforms.Concatenate(\"Features\", \"Size\", \"HistoricalPrices\")\r\n                    .Append(mlContext.Transforms.NormalizeMinMax(\"Features\"));\r\n\r\n            // Create data prep transformer\r\n            ITransformer dataPrepTransformer = dataPrepEstimator.Fit(trainingData);\r\n\r\n            // Apply tranforms to training data\r\n            IDataView transformedTrainingData = dataPrepTransformer.Transform(trainingData);\r\n\r\n            var UserDefinedColumnSdcaEstimator = mlContext.Regression.Trainers.Sdca(labelColumnName: \"CurrentPrice\", featureColumnName: \"Features\");\r\n            // Define StochasticDualCoodrinateAscent regression algorithm estimator\r\n            var sdcaEstimator = mlContext.Regression.Trainers.Sdca();\r\n\r\n            // Build machine learning model\r\n            var trainedModel = sdcaEstimator.Fit(transformedTrainingData);\r\n\r\n            var trainedModelParameters = trainedModel.Model as LinearRegressionModelParameters;\r\n            var bias = trainedModelParameters.Bias;`\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3780","RelatedDescription":"Open issue \"Bias value gets changed every run at 100th place\" (#3780)"},{"Id":"448599254","IsPullRequest":false,"CreatedAt":"2019-05-26T19:40:56","Actor":"daholste","Number":"3779","RawContent":null,"Title":"[AutoML] Add dataset statistics that indicate whether or not a shuffle transform could be helpful","State":"open","Body":"Thanks @justinormont for pointing this out\r\n\r\nThanks also for brainstorming that a snazzy way to do this could be to append row #s from the original dataset to the reservoir sample from https://github.com/dotnet/machinelearning/issues/3778, and then calculate correlation between row # and label","Url":"https://github.com/dotnet/machinelearning/issues/3779","RelatedDescription":"Open issue \"[AutoML] Add dataset statistics that indicate whether or not a shuffle transform could be helpful\" (#3779)"},{"Id":"448598514","IsPullRequest":false,"CreatedAt":"2019-05-26T19:31:47","Actor":"daholste","Number":"3778","RawContent":null,"Title":"[AutoML] Reservoir sample dataset statistics","State":"open","Body":"Currently dataset statistics within AutoML are calculated from the first 1,000 rows of a dataset. Instead, we should be calculating statistics from a random sample of 1,000 rows. (First 1,000 rows could be biased if they are sorted by label, any other column, time of collection, etc.) We can use reservoir sampling to obtain a random sample of a fixed size in a single pass over the dataset","Url":"https://github.com/dotnet/machinelearning/issues/3778","RelatedDescription":"Open issue \"[AutoML] Reservoir sample dataset statistics\" (#3778)"},{"Id":"448596499","IsPullRequest":true,"CreatedAt":"2019-05-26T19:06:42","Actor":"daholste","Number":"3777","RawContent":null,"Title":"[AutoML] Enhance calculated dataset statistics; expose dataset statistics to CLI","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3777","RelatedDescription":"Open PR \"[AutoML] Enhance calculated dataset statistics; expose dataset statistics to CLI\" (#3777)"},{"Id":"448501311","IsPullRequest":true,"CreatedAt":"2019-05-25T20:47:57","Actor":"daholste","Number":"3776","RawContent":null,"Title":"[AutoML] Reservoir sample dataset statistics","State":"open","Body":"Closes #3778","Url":"https://github.com/dotnet/machinelearning/pull/3776","RelatedDescription":"Open PR \"[AutoML] Reservoir sample dataset statistics\" (#3776)"},{"Id":"448402582","IsPullRequest":false,"CreatedAt":"2019-05-25T02:18:07","Actor":"seabluescn","Number":"3775","RawContent":null,"Title":"An Exception about using CustomMappingFactory","State":"open","Body":"Hello there,\r\nI am learning about CustomMappingFactory, I found the following code: \r\nmachinelearning/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/CustomMappingSaveAndLoad.cs\r\nThis code runs normally, but if I create a new MLContext before loading the model (line 36), as follows: \r\n\r\nmlContext = new MLContext();\r\nvar loadedTransform = mlContext.Model.Load(\"customTransform.zip\", out var inputSchema);\r\n\r\nThen the system will report an error: \r\nInvalidOperationException: Unable to locate an extension for the contract 'IsUnderThirty'. Ensure you have called ComponentCatalog.RegisterAssembly with the Assembly that contains a class decorated with a 'Microsoft.ML.Transforms.CustomMappingFactoryAttributeAttribute'.\r\n\r\nI think creating a new MLContext before loading the model should be a necessary operation. Is this a bug?","Url":"https://github.com/dotnet/machinelearning/issues/3775","RelatedDescription":"Open issue \"An Exception about using CustomMappingFactory\" (#3775)"},{"Id":"447390298","IsPullRequest":true,"CreatedAt":"2019-05-24T20:26:00","Actor":"najeeb-kazmi","Number":"3768","RawContent":null,"Title":"Improve error message for non-vector input to TensorFlowTransform","State":"closed","Body":"Closes #1542 \r\n\r\nThe behavior is expected. TensorFlow treats all inputs as tensors. A scalar input should simply be loaded as a uni-dimensional tensor.\r\n\r\nThis PR improves the error message for the existing check for non-vector inputs to make this clear and closes the issue.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3768","RelatedDescription":"Closed or merged PR \"Improve error message for non-vector input to TensorFlowTransform\" (#3768)"},{"Id":"448145353","IsPullRequest":false,"CreatedAt":"2019-05-24T12:30:37","Actor":"drake7707","Number":"3773","RawContent":null,"Title":"Incorrect metrics when the order of labels do not correspond to the indices in multiclassification","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2, ML.1.0.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** Train a trainingset with LightGbm and then evaluate a test set\r\n- **What happened?** The printed metrics are incorrect if the labels are not ordered from 0 -> n\r\n- **What did you expect?** A correct confusion matrix and LogLoss, ... metrics\r\n\r\nConfusion matrix when I add the labels ascending (0 -> n)  of the samples (e.g 0,1,2,3,4,0,1,2,3,4,...). This is the correct evaluation.\r\n```\r\n          ||========================================================================================\r\nPREDICTED ||     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 | Recall\r\nTRUTH     ||========================================================================================\r\n        0 ||    58 |     0 |     1 |    19 |     0 |     0 |     1 |     1 |     2 |     0 |     2 | 0,6905\r\n        1 ||     0 |    79 |     0 |     0 |     0 |     5 |     0 |     0 |     0 |     0 |     0 | 0,9405\r\n        2 ||     0 |     0 |    79 |     3 |     0 |     0 |     0 |     0 |     2 |     0 |     0 | 0,9405\r\n        3 ||     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 1,0000\r\n        4 ||     0 |     0 |     0 |     0 |    81 |     0 |     0 |     0 |     3 |     0 |     0 | 0,9643\r\n        5 ||     0 |     8 |     0 |     0 |     0 |    71 |     5 |     0 |     0 |     0 |     0 | 0,8452\r\n        6 ||     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 | 1,0000\r\n        7 ||     0 |     0 |     0 |     0 |     0 |     2 |     0 |    82 |     0 |     0 |     0 | 0,9762\r\n        8 ||     0 |     0 |     0 |     8 |     0 |     0 |     0 |     1 |    72 |     0 |     3 | 0,8571\r\n        9 ||     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 | 1,0000\r\n       10 ||     0 |     0 |     0 |     0 |     0 |     2 |     1 |     0 |     0 |     0 |    81 | 0,9643\r\n          ||========================================================================================\r\nPrecision ||1,0000 |0,9080 |0,9875 |0,7368 |1,0000 |0,8875 |0,9231 |0,9762 |0,9114 |1,0000 |0,9419 |\r\n\r\n************************************************************\r\n```\r\nNow when I do OrderByDescending to reverse the labels and run it again, I get:\r\n\r\nConfusion matrix when I reverse the labels (n -> 0)  of the samples (e.g 4,3,2,1,0,4,3,2,1,0,...)\r\n\r\n```\r\n          ||========================================================================================\r\nPREDICTED ||     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 | Recall\r\nTRUTH     ||========================================================================================\r\n        0 ||     3 |     0 |     3 |     1 |     0 |     6 |     0 |    14 |     0 |     0 |    57 | 0,0357\r\n        1 ||     0 |     0 |     0 |     0 |     0 |     2 |     0 |     0 |     0 |    82 |     0 | 0,0000\r\n        2 ||     0 |     0 |     3 |     0 |     0 |     0 |     0 |     8 |    73 |     0 |     0 | 0,0357\r\n        3 ||     0 |     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 |     0 |     0 | 0,0000\r\n        4 ||     0 |     0 |     2 |     0 |     0 |     0 |    82 |     0 |     0 |     0 |     0 | 0,0000\r\n        5 ||     0 |     0 |     0 |     0 |     3 |    74 |     0 |     0 |     0 |     7 |     0 | 0,8810\r\n        6 ||     0 |     0 |     0 |     0 |    83 |     0 |     0 |     0 |     0 |     0 |     1 | 0,0000\r\n        7 ||     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n        8 ||     2 |     0 |    76 |     0 |     0 |     0 |     0 |     6 |     0 |     0 |     0 | 0,0000\r\n        9 ||     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n       10 ||    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n          ||========================================================================================\r\nPrecision ||0,0337 |0,0000 |0,0357 |0,0000 |0,0000 |0,9024 |0,0000 |0,0000 |0,0000 |0,0000 |0,0000 |\r\n```\r\n\r\nI think there is an expectation somewhere that the label == the label index.\r\n\r\n### Source code / logs\r\n```\r\n            var trainingDataView = mlContext.Data.LoadFromEnumerable(trainingDataArray, schemaDef);\r\n            var testDataView = mlContext.Data.LoadFromEnumerable(testDataArray, schemaDef);\r\n\r\n            var featureNames = typeof(RecordFeatures).GetProperties().Where(p => p.Name != nameof(RecordFeatures.Label)).Select(p => p.Name).ToArray();\r\n\r\n            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"KeyColumn\", inputColumnName: nameof(RecordFeatures.Label))\r\n                                                                       .Append(mlContext.Transforms.Concatenate(\"Features\", featureNames))\r\n                                                                       .AppendCacheCheckpoint(mlContext);\r\n\r\n            var trainer = mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName: \"KeyColumn\", featureColumnName: \"Features\");\r\n          \r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n            Console.WriteLine(\"=============== Training the model ===============\");\r\n            var trainedModel = trainingPipeline.Fit(trainingDataView);\r\n\r\n            Console.WriteLine(\"===== Evaluating Model's accuracy with Test data =====\");\r\n            var predictions = trainedModel.Transform(testDataView);\r\n            var metrics = mlContext.MulticlassClassification.Evaluate(predictions, \"Label\", \"Score\");\r\n\r\n            PrintMultiClassClassificationMetrics(trainer.ToString(), metrics);\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3773","RelatedDescription":"Open issue \"Incorrect metrics when the order of labels do not correspond to the indices in multiclassification\" (#3773)"},{"Id":"447665443","IsPullRequest":false,"CreatedAt":"2019-05-23T13:32:42","Actor":"sharpwood","Number":"3771","RawContent":null,"Title":"Are there any algorithms that are independent of native libraries and can run in xamarin forms?","State":"open","Body":"Are there any algorithms that are independent of native libraries and can run in xamarin forms?","Url":"https://github.com/dotnet/machinelearning/issues/3771","RelatedDescription":"Open issue \"Are there any algorithms that are independent of native libraries and can run in xamarin forms?\" (#3771)"},{"Id":"447593748","IsPullRequest":false,"CreatedAt":"2019-05-23T11:12:23","Actor":"PeterPann23","Number":"3770","RawContent":null,"Title":"AutoML feature request for TensorFlow","State":"open","Body":"Would be nice to see some TensorFlow integration in AutoML.\r\nOne find nice Multiclass Iris prediction with TensorFlow in Python in the web. \r\nWould be nice to see it implemented in AutoMl as I guess it's a good _bootstrap'er_  for those that would like to implement it. ","Url":"https://github.com/dotnet/machinelearning/issues/3770","RelatedDescription":"Open issue \"AutoML feature request for TensorFlow\" (#3770)"},{"Id":"447498029","IsPullRequest":false,"CreatedAt":"2019-05-23T07:42:42","Actor":"PeterPann23","Number":"3769","RawContent":null,"Title":"ConfusionMatrix.GetFormattedConfusionTable() sorts on arbitrary in order found on disk ","State":"open","Body":"\r\n[Enter feedback here]\r\nWhen training a MultiClass you will/can discover the classes in a random order.\r\nThe \"random\" order is then indexed and repeated in the labels. \r\nOne can influence the order using keyOrdinality in MlContext.Transforms.Conversion.MapValueToKey \r\n\r\n```\r\n//     How items should be ordered when vectorized. If Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByOccurrence\r\n//     chosen they will be in the order encountered. If Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByValue,\r\n```\r\n\r\nThe Y axis does map the index to a label, this helps but it would be better to allow users to sort on the label to get a consistent layout as well as allow the user to use cast the labels back to enumerable classes (if this is what is used for the labels) and sort in order of the enumerable.   \r\n\r\nTo \"fix\" report formatting one should not have to alter the learning pipeline, these are 2 separate concerns. \r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: a65b98b6-bd97-8615-8f5f-827305a203c1\r\n* Version Independent ID: 6975eed6-3d30-cb7d-295d-edce198c2e43\r\n* Content: [ConfusionMatrix.GetFormattedConfusionTable Method (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.confusionmatrix.getformattedconfusiontable?f1url=https%3A%2F%2Fmsdn.microsoft.com%2Fquery%2Fdev15.query%3FappId%3DDev15IDEF1%26l%3DEN-US%26k%3Dk(Microsoft.ML.Data.ConfusionMatrix.GetFormattedConfusionTable);k(SolutionItemsProject);k(TargetFrameworkMoniker-.NETFramework,Version%3Dv4.7.2);k(DevLang-csharp)%26rd%3Dtrue&view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Data/ConfusionMatrix.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/ConfusionMatrix.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/3769","RelatedDescription":"Open issue \"ConfusionMatrix.GetFormattedConfusionTable() sorts on arbitrary in order found on disk \" (#3769)"},{"Id":"447032608","IsPullRequest":true,"CreatedAt":"2019-05-22T21:46:50","Actor":"codemzs","Number":"3763","RawContent":null,"Title":"Access indices array for VBuffer in KeyToVector transformer only when resulting vector is sparse.","State":"closed","Body":"fixes #3757\r\nfixes #1751\r\nfixes #2678","Url":"https://github.com/dotnet/machinelearning/pull/3763","RelatedDescription":"Closed or merged PR \"Access indices array for VBuffer in KeyToVector transformer only when resulting vector is sparse.\" (#3763)"},{"Id":"446813574","IsPullRequest":false,"CreatedAt":"2019-05-22T21:46:49","Actor":"lisahua","Number":"3757","RawContent":null,"Title":"KeyToVectorMappingTransformer: Index was outside the bounds of the array.","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: 1.0.0\r\n- **.NET Version (eg., dotnet --info)**: 4.6.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** Apply Normalization superviseBin and OneHot, \r\n- **What happened?** Got \"Index was outside the bounds of the array.\"\r\n- **What did you expect?** No error\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n```\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n            var dataPath = \"test1.csv\";\r\n            var featureName = \"Features\";\r\n            var loader = mlContext.Data.CreateTextLoader(new[] \r\n            {\r\n                new TextLoader.Column(\"int1\", DataKind.Int64, 0),\r\n                new TextLoader.Column(\"int2\", DataKind.Int64, 1),\r\n                new TextLoader.Column(\"Label\", DataKind.Boolean, 2),\r\n            }, hasHeader: true, separatorChar: ',');\r\n\r\n            var data = loader.Load(dataPath);\r\n            var learningPipeline = mlContext.Transforms.Conversion.ConvertType(\"int1\", outputKind: DataKind.Single)\r\n                    .Append(mlContext.Transforms.Conversion.ConvertType(\"int2\", outputKind: DataKind.Single))\r\n                    .Append(mlContext.Transforms.Concatenate(featureName, new string[] { \"int1\", \"int2\" }))\r\n                    .Append(mlContext.Transforms.NormalizeSupervisedBinning(featureName, fixZero: false, maximumBinCount: 5, labelColumnName: \"Label\"))\r\n                    .Append(mlContext.Transforms.Categorical.OneHotEncoding(featureName, outputKind: OneHotEncodingEstimator.OutputKind.Indicator));\r\n            learningPipeline.Fit(data).Transform(data).Preview();\r\n```\r\n\r\n```\r\nint1, int2, label\r\n301, 2000, true\r\n450, 3000, true\r\n-300, 4000, true\r\n300, 2000, false\r\n115, 2000, false\r\n115, 2000, false\r\n```\r\n\r\nI think it is related to [issue 1751](https://github.com/dotnet/machinelearning/issues/1751) And based on the discussion for this issue,  I tried \r\n- adding MapKeyToValue() but no help.\r\n- OneHotEncode cannot be easily removed, we want to treat binning as categorical feature. \r\n\r\n```\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n            var dataPath = \"test1.csv\";\r\n            var featureName = \"Features\";\r\n            var loader = mlContext.Data.CreateTextLoader(new[] \r\n            {\r\n                new TextLoader.Column(\"int1\", DataKind.Int64, 0),\r\n                new TextLoader.Column(\"int2\", DataKind.Int64, 1),\r\n                new TextLoader.Column(\"Label\", DataKind.Boolean, 2),\r\n            }, hasHeader: true, separatorChar: ',');\r\n\r\n            var data = loader.Load(dataPath);\r\n            var learningPipeline = mlContext.Transforms.Conversion.ConvertType(\"int1\", outputKind: DataKind.Single)\r\n                    .Append(mlContext.Transforms.Conversion.ConvertType(\"int2\", outputKind: DataKind.Single))\r\n                    .Append(mlContext.Transforms.Conversion.MapValueToKey(\"Label\"))\r\n                    .Append(mlContext.Transforms.Concatenate(featureName, new string[] { \"int1\", \"int2\" }))\r\n                    .Append(mlContext.Transforms.NormalizeSupervisedBinning(featureName, fixZero: false, maximumBinCount: 5, labelColumnName: \"Label\"))\r\n                    .Append(mlContext.Transforms.Categorical.OneHotEncoding(featureName, outputKind: OneHotEncodingEstimator.OutputKind.Indicator))\r\n                    .Append(mlContext.Transforms.Conversion.MapKeyToValue(\"Label\"));\r\n            learningPipeline.Fit(data).Transform(data).Preview();\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3757","RelatedDescription":"Closed issue \"KeyToVectorMappingTransformer: Index was outside the bounds of the array.\" (#3757)"},{"Id":"447344339","IsPullRequest":false,"CreatedAt":"2019-05-22T21:09:20","Actor":"huy302","Number":"3767","RawContent":null,"Title":"OneHotEncoder on array of strings","State":"open","Body":"I couldn't find an example to run OneHotEncoder on an array of strings. From the sample code at https://github.com/dotnet/machinelearning/issues/2678 is it just as simple as ctx.Transforms.Categorical.OneHotEncoding(\"A\")? Preview function is yet to be fixed in ml.net 1.0.0 so I can't tell if it gives the desired result.\r\n\r\nThanks","Url":"https://github.com/dotnet/machinelearning/issues/3767","RelatedDescription":"Open issue \"OneHotEncoder on array of strings\" (#3767)"},{"Id":"446852458","IsPullRequest":true,"CreatedAt":"2019-05-22T20:49:52","Actor":"zeahmed","Number":"3758","RawContent":null,"Title":"Upgraded the TensorFlow version from 1.12.0 to 1.13.1","State":"closed","Body":"Upgraded the TensorFlow version from 1.12.0 to 1.13.1. Cannot upgrade to version 2.0 as it is currently in alpha.","Url":"https://github.com/dotnet/machinelearning/pull/3758","RelatedDescription":"Closed or merged PR \"Upgraded the TensorFlow version from 1.12.0 to 1.13.1\" (#3758)"},{"Id":"447108222","IsPullRequest":false,"CreatedAt":"2019-05-22T12:30:42","Actor":"rauhs","Number":"3766","RawContent":null,"Title":"Does GetFeatureWeights support categorical splits?","State":"open","Body":"Version: 1.0\r\n\r\nI'm training my multi class LightGBM with mostly categorical features (which works great). But when I want to get the `GetFeatureWeights` from the binary predictors I get huge values for feature of index `-1`. Though, just inspecting the models in the debugger the trees almost exclusively use categorical features for the splits. It seems that the `GainMap` doesn't actually consider any categorical splits and just assigns all those gains to the index `-1` which makes the feature weights vector completely useless in my case.\r\n\r\nIs this something that will be supported? Or am I wrong here?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3766","RelatedDescription":"Open issue \"Does GetFeatureWeights support categorical splits?\" (#3766)"},{"Id":"447097534","IsPullRequest":false,"CreatedAt":"2019-05-22T12:06:46","Actor":"rauhs","Number":"3765","RawContent":null,"Title":"How to get LightGBM multiclass calibrated","State":"open","Body":"Version: 1.0\r\n\r\nAfter training the a multi class LightGBM predictor it seems the Platt calibrator on each model has the fixed parameter of 0, and -0.5:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3798bf8b73a2ce83a526326e05639d54a331fbdd/src/Microsoft.ML.LightGbm/LightGbmMulticlassTrainer.cs#L185-L191\r\n\r\nIs that on purpose? How can I get a calibrated predictor?","Url":"https://github.com/dotnet/machinelearning/issues/3765","RelatedDescription":"Open issue \"How to get LightGBM multiclass calibrated\" (#3765)"},{"Id":"447048620","IsPullRequest":false,"CreatedAt":"2019-05-22T10:11:21","Actor":"korneliuscode","Number":"3764","RawContent":null,"Title":"Unable to load DLL 'CpuMathNative'","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 x64 (1809 17763.503) and x86 (1809 17763.503)\r\n- **.NET Version (eg., dotnet --info)**:\r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.700-preview-009597\r\n Commit:    96b18bcb5c\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.700-preview-009597\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.9\r\n  Commit:  dcedc87d22\r\n\r\n.NET Core SDKs installed:\r\n  2.1.601 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.602 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700-preview-009597 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**: \r\nCreated a new .net standard project, added ML.NET from nuget and added the project  to my existing solution (.net Framework 4.7.2). Both are set to Any CPU, as I [read that ML.NET also supports x86](https://devblogs.microsoft.com/dotnet/announcing-ml-net-0-7-machine-learning-net/#x86-support-in-addition-to-x64). The DLL Microsoft.ML.CpuMath.dll is present in the release folder.\r\n- **What happened?**: When creating the model I get the exception as shown below in \"logs\"\r\n- **What did you expect?**: Creating the model as expected.\r\n\r\n### Source code / logs\r\n\r\n```\r\n05/21/2019 16:15:32: Runtime terminating: True\r\n05/22/2019 11:58:37: System.InvalidOperationException: Shuffle input cursor reader failed with an exception ---> System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data ---> System.DllNotFoundException: Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Internal.CpuMath.Thunk.SumSqU(Single* ps, Int32 c)\r\n   at Microsoft.ML.Transforms.LpNormNormalizingTransformer.Mapper.<>c__DisplayClass6_0.<MakeGetter>b__5(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass5_1.<ConsolidateCore>b__2()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.<LoopProducerWorker>d__31.MoveNext()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.MoveNext()\r\n   at Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.StochasticTrainerBase`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3764","RelatedDescription":"Open issue \"Unable to load DLL 'CpuMathNative'\" (#3764)"},{"Id":"447025185","IsPullRequest":false,"CreatedAt":"2019-05-22T09:22:00","Actor":"PeterPann23","Number":"3762","RawContent":null,"Title":"Perhaps not a popular question but why are you not using the sample Gighub labeler","State":"open","Body":"Hi\r\n\r\nI don't want to poke but why are the items not getting labeled by something like the [github labeler](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/end-to-end-apps/MulticlassClassification-GitHubLabeler) sample found in the samples solution?\r\n\r\nWould help finding similar issues and re-use the answers provided (if still applicable in the current API)","Url":"https://github.com/dotnet/machinelearning/issues/3762","RelatedDescription":"Open issue \"Perhaps not a popular question but why are you not using the sample Gighub labeler\" (#3762)"},{"Id":"446949741","IsPullRequest":false,"CreatedAt":"2019-05-22T06:12:18","Actor":"PeterPann23","Number":"3761","RawContent":null,"Title":"The given key 'metric' was not present in the dictionary","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\nWindows 2012\r\nWindows 2019\r\n- **.NET Version (eg., dotnet --info)**: \r\nCore 3.0                          Version 3.0.100-preview5-011568\r\nMicrosoft.ML.LightGbm  Version 1.0.0.0, Culture=neutral\r\nMicrosoft.ML                   Version 1.0.0.0\r\n\r\n### Issue\r\n- **What did you do?**\r\nLoad csv file as and train model loading by all floats in single vector \r\nsee code bellow\r\n\r\n- **What happened?**\r\nGet error _The given key 'metric' was not present in the dictionary_ during the training \r\n\r\n- **What did you expect?**\r\nNot sure why I get the error, also I do not mention a key metric.\r\n\r\n### Source code / logs\r\nThe error:\r\n```\r\n[Source=LightGBMMulticlass; Training with LightGBM, Kind=Trace] Channel disposed. Elapsed 00:00:04.0970203\r\n.57.erLeaf = 5059.0337420.\r\nError stack    at System.Collections.Generic.Dictionary`2.get_Item(TKey key)r_6_MinTicks_In_15Sec_B_ND.tsv\r\n   at Microsoft.ML.Trainers.LightGbm.WrappedLightGbmTraining.Train(IChannel ch, IProgressChannel pch, Dictionary`2 param\r\neters, Dataset dtrain, Dataset dvalid, Int32 numIteration, Boolean verboseEval, Int32 earlyStoppingRound)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainCore(IChannel ch, IProgressChannel pch, Dataset dtrain,\r\nCategoricalMetaData catMetaData, Dataset dvalid)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredic\r\ntor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Cats.DeepBookTrainer.Infrastructure.Trainer.ExecuteLightGbm(ITransformer& transformer, Nullable`1 maxIterations, N\r\nullable`1 maxThreads) \r\n```\r\n\r\nData Loading:\r\n```\r\npublic static IDataView GetDataViewAsVector(MLContext mlContext, FileInfo trainingFile, int labelIndex=1, char[] separators = null, long? maxRows = null, bool makeBin=false)\r\n{\r\n    if (separators is null)\r\n        separators = new[] { '|' };\r\n\r\n    var loader = mlContext.Data.CreateTextLoader(options: new TextLoader.Options()\r\n    {\r\n        Columns = new[] {\r\n            new TextLoader.Column(name:\"Label\", dataKind: DataKind.String, index: labelIndex),\r\n            new TextLoader.Column(name:\"RawFeatures\",dataKind:DataKind.Single,minIndex:2,maxIndex:40732)\r\n        },\r\n        HasHeader = false,\r\n        Separators = separators,\r\n        UseThreads = false,\r\n        MaxRows=maxRows\r\n    });\r\n    var dv = loader.Load(trainingFile.FullName);\r\n    return dv;\r\n}\r\n```\r\n\r\n\r\nPipeline:\r\n```\r\nhorizonDataset = mlContext.Data.TrainTestSplit(DataViewUtils.GetDataViewAsVector(mlContext, trainingFile, labelIndex: 1, separators: new[] {'|'}));\r\n\r\nvar options = new LightGbmMulticlassTrainer.Options\r\n{\r\n    LabelColumnName = \"KeyColumn\",\r\n    FeatureColumnName = Features,\r\n    Silent = false,\r\n    Verbose = true,\r\n    EvaluationMetric = LightGbmMulticlassTrainer.Options.EvaluateMetricType.Default,\r\n    UseSoftmax       = true,\r\n    NumberOfThreads  = 1,                \r\n};\r\n\r\nvar featureColumns = Mapper.GetFieldNames();\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"KeyColumn\", inputColumnName: \"Label\")\r\n        .Append(mlContext.Transforms.NormalizeMinMax(outputColumnName: \"Features\", inputColumnName: \"RawFeatures\"))\r\n        .AppendCacheCheckpoint(mlContext)\r\n        .Append(mlContext.MulticlassClassification.Trainers.LightGbm(options))\r\n        .Append(mlContext.Transforms.CopyColumns(inputColumnName: \"KeyColumn\", outputColumnName: nameof(PredictedResult.PredictedLabelIndex)))\r\n```\r\nLine throwing the error \r\n`var model = pipeline.Fit(horizonDataset.TrainSet);`","Url":"https://github.com/dotnet/machinelearning/issues/3761","RelatedDescription":"Open issue \"The given key 'metric' was not present in the dictionary\" (#3761)"},{"Id":"446911675","IsPullRequest":false,"CreatedAt":"2019-05-22T03:07:43","Actor":"yaeldekel","Number":"3760","RawContent":null,"Title":"Implement Doc2vec text featurization","State":"open","Body":"This was brought up in issue #3743 .","Url":"https://github.com/dotnet/machinelearning/issues/3760","RelatedDescription":"Open issue \"Implement Doc2vec text featurization\" (#3760)"},{"Id":"446876120","IsPullRequest":false,"CreatedAt":"2019-05-22T00:07:48","Actor":"klausmh","Number":"3759","RawContent":null,"Title":"Support custom mapping without type parameters","State":"open","Body":"ML.NET supports [custom mappings](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.custommappingcatalog.custommapping?view=ml-dotnet) if a source and destination type are specified statically.\r\n\r\nWould it also be possible to support this in a dynamic setting, i.e., doing custom mappings from IDataView to IDataView?","Url":"https://github.com/dotnet/machinelearning/issues/3759","RelatedDescription":"Open issue \"Support custom mapping without type parameters\" (#3759)"},{"Id":"446778780","IsPullRequest":false,"CreatedAt":"2019-05-21T19:09:44","Actor":"daholste","Number":"3756","RawContent":null,"Title":"Potential memory leak when training?","State":"open","Body":"I modified a project in the samples repo to repro:\r\n\r\nhttps://github.com/daholste/machinelearning-samples/commit/577946224747959759ca1b4da9fd86f77eea81a9\r\n\r\nIf breakpoint at https://github.com/daholste/machinelearning-samples/blob/577946224747959759ca1b4da9fd86f77eea81a9/samples/csharp/getting-started/BinaryClassification_SentimentAnalysis/SentimentAnalysis/SentimentAnalysisConsoleApp/Program.cs#L52 , each model that is trained, the memory usage of the process consistently increases by about 80 MB (especially after the first few iterations of the loop).\r\n\r\nWhen the model is compressed & saved to disk, the size of the model file is only about 4.5 MB.\r\n\r\nWhen loading the saved model back into memory, memory of the process appears to jump by around 50 MB. (When loading the model several times back from disk to memory in the same process, average size of the model appears to be around 40 MB in memory. Not sure why. Perhaps string pooling? Not sure.)\r\n\r\nIs this a memory leak? \r\n80 MB of memory taken up by training model - 50 MB megabytes of same model serialized / deserialized = 30 MB of leakage?\r\nOr, does serializing / deserializing the model potentially restructure the data structures to use memory more efficiently?","Url":"https://github.com/dotnet/machinelearning/issues/3756","RelatedDescription":"Open issue \"Potential memory leak when training?\" (#3756)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-05-29T05:30:35.798186Z","RunDurationInMilliseconds":629}