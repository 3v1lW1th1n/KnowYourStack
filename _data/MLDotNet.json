{"Data":{"GitHub":{"Issues":[{"Id":"369852212","IsPullRequest":true,"CreatedAt":"2018-10-13T23:43:41","Actor":"ganik","Number":"1254","RawContent":null,"Title":"Estimators for Timeseries SSA / IID ChangepointDetection and SpikeDetection transforms","State":"open","Body":"* Created Estimators for SSAChangePointDetector, SSASpikeDetector,  IidChangePointDetector, IidSpikeDetector\r\n* Added unit tests ","Url":"https://github.com/dotnet/machinelearning/pull/1254","RelatedDescription":"Open PR \"Estimators for Timeseries SSA / IID ChangepointDetection and SpikeDetection transforms\" (#1254)"},{"Id":"369790713","IsPullRequest":true,"CreatedAt":"2018-10-13T10:48:36","Actor":"stunner2k18","Number":"1253","RawContent":null,"Title":"ml_hin.md","State":"open","Body":"Some basic point on machine learning translated in hindi..!!\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1253","RelatedDescription":"Open PR \"ml_hin.md\" (#1253)"},{"Id":"369755906","IsPullRequest":true,"CreatedAt":"2018-10-13T01:52:31","Actor":"Zruty0","Number":"1252","RawContent":null,"Title":"ML Context to create them all","State":"open","Body":"Fixes #1098 . \r\nAdds a couple extensions for transforms, and almost all trainers.\r\nAdds text loading and saving, model loading.","Url":"https://github.com/dotnet/machinelearning/pull/1252","RelatedDescription":"Open PR \"ML Context to create them all\" (#1252)"},{"Id":"369698942","IsPullRequest":true,"CreatedAt":"2018-10-13T01:25:44","Actor":"f1x3d","Number":"1243","RawContent":null,"Title":"Fix string normalization in tests","State":"closed","Body":"Since the `%Source%` path can be a substring of the `%Output%` path, we should replace the larger one first.\r\n\r\nFixes #810\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1243","RelatedDescription":"Closed or merged PR \"Fix string normalization in tests\" (#1243)"},{"Id":"369751433","IsPullRequest":false,"CreatedAt":"2018-10-13T00:56:11","Actor":"Zruty0","Number":"1251","RawContent":null,"Title":"Make Binary classification evaluator configurable","State":"open","Body":"The following method:\r\n```csharp\r\n        public BinaryClassifierEvaluator.CalibratedResult Evaluate(IDataView data, string label = DefaultColumnNames.Label, string score = DefaultColumnNames.Score,\r\n            string probability = DefaultColumnNames.Probability, string predictedLabel = DefaultColumnNames.PredictedLabel)\r\n```\r\nneeds to expose additional parameters from `BinaryClassifierEvaluator.Arguments`, or a delegate to set them.","Url":"https://github.com/dotnet/machinelearning/issues/1251","RelatedDescription":"Open issue \"Make Binary classification evaluator configurable\" (#1251)"},{"Id":"369748577","IsPullRequest":false,"CreatedAt":"2018-10-13T00:25:36","Actor":"vaeksare","Number":"1250","RawContent":null,"Title":"Improve testing on ONNX exporting","State":"open","Body":"Currently, tests for saving models as ONNX just check to make sure the ONNX models themselves are as expected by comparing them to a pre-saved version of that ONNX model. These tests do not actually check that these models are runnable or that they produce the same results as the original transform. With the new ONNXTransform, this testing framework could be improved to ensure correct exportability.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1250","RelatedDescription":"Open issue \"Improve testing on ONNX exporting\" (#1250)"},{"Id":"369744891","IsPullRequest":true,"CreatedAt":"2018-10-12T23:54:46","Actor":"vaeksare","Number":"1249","RawContent":null,"Title":"Export WordEmbeddingsTransform to ONNX","State":"open","Body":"Implements the ability to export the WordEmbeddingsTransform by converting it to an ONNX model, as well as expanding the functionality of some existing structures to allow for more efficient conversion implementation. The detailed conversion strategy can be found in comments inline. Fixes #1248 \r\n\r\nTesting was done through running the model on the same input using ML.NET and Lotus runtime directly using python bindings, producing the same results. Due to this testing strategy, no formal tests are currently checked in to ML.NET repo, but WIP is being done on improving the testing functionality for ONNX exporting using the ONNXTransform.\r\n\r\nThe resulting ONNX model looks as follows:\r\n![image](https://user-images.githubusercontent.com/42353187/46898532-2f805080-ce3f-11e8-96a5-ade1d8b768e9.png)\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1249","RelatedDescription":"Open PR \"Export WordEmbeddingsTransform to ONNX\" (#1249)"},{"Id":"369742927","IsPullRequest":false,"CreatedAt":"2018-10-12T23:40:13","Actor":"vaeksare","Number":"1248","RawContent":null,"Title":"Export WordEmbeddingsTransform to ONNX","State":"open","Body":"WordEmbeddingsTransform applies a series of simple matrix/tensor operations based on a pretrained model, as is therefore exportable to ONNX using a combination of existing ONNX ops.","Url":"https://github.com/dotnet/machinelearning/issues/1248","RelatedDescription":"Open issue \"Export WordEmbeddingsTransform to ONNX\" (#1248)"},{"Id":"369739043","IsPullRequest":false,"CreatedAt":"2018-10-12T23:13:53","Actor":"danmosemsft","Number":"1247","RawContent":null,"Title":"Remove unnecessary JIT SBCG workaround","State":"open","Body":"```c#\r\n        public static uint GetLo(ulong uu)\r\n        {\r\n            // REVIEW: Work around Dev10 Bug 884217: JIT64  -Silent bad codegen for accessing 4-byte parts of 8-byte locals\r\n            // http://vstfdevdiv:8080/WorkItemTracking/WorkItem.aspx?artifactMoniker=884217\r\n            // return (uint)uu;\r\n            return (uint)(uu & 0xFFFFFFFF);\r\n        }\r\n```\r\n\r\nI dug up this bug, it was fixed in a dev branch in 4/2010 and it looks like it reached 4.0 - certainly would be fixed in 4.5.0 which shipped in 8/2012. Although we don't explicitly state what .NET Framework versions we support, is probably reasonable for us to expect 4.5 or later and safe for us to remove this workaround.","Url":"https://github.com/dotnet/machinelearning/issues/1247","RelatedDescription":"Open issue \"Remove unnecessary JIT SBCG workaround\" (#1247)"},{"Id":"369735798","IsPullRequest":false,"CreatedAt":"2018-10-12T22:57:48","Actor":"Zruty0","Number":"1246","RawContent":null,"Title":"FastTreeRanking doesn't have non-advanced args","State":"open","Body":"Consider the following constructors:\r\n```csharp\r\n        public FastTreeBinaryClassificationTrainer(IHostEnvironment env,\r\n            string labelColumn,\r\n            string featureColumn,\r\n            string weightColumn = null,\r\n            int numLeaves = Defaults.NumLeaves,\r\n            int numTrees = Defaults.NumTrees,\r\n            int minDocumentsInLeafs = Defaults.MinDocumentsInLeafs,\r\n            double learningRate = Defaults.LearningRates,\r\n            Action<Arguments> advancedSettings = null)\r\n\r\n        public FastTreeRegressionTrainer(IHostEnvironment env,\r\n            string labelColumn,\r\n            string featureColumn,\r\n            string weightColumn = null,\r\n            int numLeaves = Defaults.NumLeaves,\r\n            int numTrees = Defaults.NumTrees,\r\n            int minDocumentsInLeafs = Defaults.MinDocumentsInLeafs,\r\n            double learningRate = Defaults.LearningRates,\r\n            Action<Arguments> advancedSettings = null)\r\n\r\n        public FastTreeRankingTrainer(IHostEnvironment env, string labelColumn, string featureColumn, string groupIdColumn,\r\n            string weightColumn = null, Action<Arguments> advancedSettings = null)\r\n```\r\n\r\nThere is no reason to have disparity here: ranker should expose the same `numLeaves`, `numTrees` etc.\r\n\r\nThe only difference should be the presence of required `groupId` in the ranker constructor.","Url":"https://github.com/dotnet/machinelearning/issues/1246","RelatedDescription":"Open issue \"FastTreeRanking doesn't have non-advanced args\" (#1246)"},{"Id":"369720097","IsPullRequest":false,"CreatedAt":"2018-10-12T21:42:02","Actor":"Anipik","Number":"1245","RawContent":null,"Title":"Dead Add Flag in Matrix Multiplication","State":"open","Body":"we are not using the ```Add``` Flag in Matrix multiplication.\r\n\r\nShould we go ahead and remove it ?\r\n\r\n```public static void MatTimesSrc(bool tran, bool add, AlignedArray mat, AlignedArray src, AlignedArray dst, int crun)```\r\n\r\ncc @danmosemsft @eerhardt @tannergooding @TomFinley ","Url":"https://github.com/dotnet/machinelearning/issues/1245","RelatedDescription":"Open issue \"Dead Add Flag in Matrix Multiplication\" (#1245)"},{"Id":"369613840","IsPullRequest":false,"CreatedAt":"2018-10-12T21:39:46","Actor":"wschin","Number":"1239","RawContent":null,"Title":"An ONNX variable name not correct","State":"closed","Body":"To declare intermediate ONNX variables in ONNX graph, we should do\r\n`var nameZ = ctx.AddIntermediateVariable(null, \"Z\", true); `\r\ninstead of\r\n`var nameZ = \"Z\";`\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1239","RelatedDescription":"Closed issue \"An ONNX variable name not correct\" (#1239)"},{"Id":"369702794","IsPullRequest":false,"CreatedAt":"2018-10-12T20:40:36","Actor":"Ivanidzo4ka","Number":"1244","RawContent":null,"Title":"Add property to Environment class which would indicate can we use disk operations or not","State":"open","Body":"In some environments we can be limited by access to disk, so we need to perform all operations in memory. We already has code which specify should we use file system or not for loading/unloading model\r\nhttps://github.com/dotnet/machinelearning/blob/f8f3873958a0a8114df49bb6d8dc292dc071820b/src/Microsoft.ML.Data/Model/Repository.cs#L438\r\n\r\nor HybridMemoryStream should respect that parameter as well.\r\n\r\nAny temporary file creations need to respect this property and create memory streams instead.","Url":"https://github.com/dotnet/machinelearning/issues/1244","RelatedDescription":"Open issue \"Add property to Environment class which would indicate can we use disk operations or not\" (#1244)"},{"Id":"369684645","IsPullRequest":false,"CreatedAt":"2018-10-12T19:37:40","Actor":"Zruty0","Number":"1242","RawContent":null,"Title":"Debugger visualizer for DataView's","State":"open","Body":"1. Implement a custom data view debug visualizer.\r\n - It should have a column view and a row view\r\n - Column view will present values as `IEnumerable<object>`\r\n - Row view will present values as `Dictionary<string, object>\r\n\r\n2. Implement custom `ToString` for schema columns and for metadata.\r\n- For `Schema.Column` it should be something like `{ColumnName: ColumnType}`\r\n- For `Schema.Metadata` we would probably want to visualize that as `Dictionary<string, object>`\r\n\r\n3. Custom visualizers for `VBuffer`\r\n- Similar to the code in TLC GUI\r\n\r\n4. Custom visualizer for key values in a column view\r\n- For example, display as `KeyValue (Key)`\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1242","RelatedDescription":"Open issue \"Debugger visualizer for DataView's\" (#1242)"},{"Id":"369612590","IsPullRequest":true,"CreatedAt":"2018-10-12T19:27:10","Actor":"wschin","Number":"1238","RawContent":null,"Title":"Uncomment the correct code","State":"closed","Body":"Two very minor changes for fixing #1239:\r\n- Make one comment more clear\r\n- Uncomment the correct line of declaring variable name in ONNX graph\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1238","RelatedDescription":"Closed or merged PR \"Uncomment the correct code\" (#1238)"},{"Id":"369672201","IsPullRequest":false,"CreatedAt":"2018-10-12T18:58:44","Actor":"danmosemsft","Number":"1241","RawContent":null,"Title":"Remove IndentingTextWriter in favor of the existing IndentedTextWriter ","State":"open","Body":"Remove ML.NET's IndentingTextWriter in favor of System.CodeDom.Compiler.IndentedTextWriter (a mainstream type in S.Runtime.Extensions.dll just in an oddly chosen namespace)\r\n\r\nThe main thing IndentedTextWriter doesn't have is the little IDisposable Scope helper that ML.NET uses in a decent number of places, that lets you write code like `using (writer.Nest()) { /* indented */ }` rather than explicitly indenting and outdenting before and after.  For now it could be left as an 8-line helper in ML.NET, but based on IndentedTextWriter instead of their IndentingTextWriter, and optionally open an API proposal in the CoreFX repo to add such a small feature.\r\n\r\nPer discussions w/ @stephentoub @Zruty0 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1241","RelatedDescription":"Open issue \"Remove IndentingTextWriter in favor of the existing IndentedTextWriter \" (#1241)"},{"Id":"369622038","IsPullRequest":true,"CreatedAt":"2018-10-12T16:26:22","Actor":"montebhoover","Number":"1240","RawContent":null,"Title":"Move build to Hosted macOS and remove unnecessary LightGBM reference.","State":"open","Body":"After updating LightGBM, we can now move build to Hosted macOS.  Also removed unnecessary LightGBM reference in response to comment on #1234.","Url":"https://github.com/dotnet/machinelearning/pull/1240","RelatedDescription":"Open PR \"Move build to Hosted macOS and remove unnecessary LightGBM reference.\" (#1240)"},{"Id":"369608471","IsPullRequest":false,"CreatedAt":"2018-10-12T15:48:44","Actor":"yaeldekel","Number":"1237","RawContent":null,"Title":"Sweep command doesn't work","State":"open","Body":"The method \"GetFullExePath\" on line 91 in ConfigRunner.cs sets the default executable to be \"maml.exe\", which doesn't exist.","Url":"https://github.com/dotnet/machinelearning/issues/1237","RelatedDescription":"Open issue \"Sweep command doesn't work\" (#1237)"},{"Id":"369603296","IsPullRequest":true,"CreatedAt":"2018-10-12T15:35:15","Actor":"yaeldekel","Number":"1236","RawContent":null,"Title":"Fix ResultProcessor bug, LogisticRegression bug and missing value conversion bug","State":"open","Body":"- LogisticRegression doesn't pass the training stats to the predictor: fixes #1205 .\r\n- ResultProcessor has code that doesn't build: fixes #1186 .\r\n- Missing value conversion: fixes #1187 .\r\n- Sweeper needs to load all components into ComponentCatalog: fixes #1188 .","Url":"https://github.com/dotnet/machinelearning/pull/1236","RelatedDescription":"Open PR \"Fix ResultProcessor bug, LogisticRegression bug and missing value conversion bug\" (#1236)"},{"Id":"369549063","IsPullRequest":false,"CreatedAt":"2018-10-12T13:21:31","Actor":"derekendres","Number":"1235","RawContent":null,"Title":"Training regression model from DataView","State":"open","Body":"How do I train a regression models if I bring in the data via a DataView from a custom end point via the IEnumerable<>?  I tried following the cookbook example but I couldn't find the right trainer to do this.","Url":"https://github.com/dotnet/machinelearning/issues/1235","RelatedDescription":"Open issue \"Training regression model from DataView\" (#1235)"},{"Id":"369334498","IsPullRequest":true,"CreatedAt":"2018-10-12T01:16:08","Actor":"montebhoover","Number":"1234","RawContent":null,"Title":"Update to version of Lightgbm with no runtime dependency on GCC.","State":"closed","Body":"Update to version of Lightgbm with no runtime dependency on GCC.\r\n\r\nRequires adding installation of libomp to Mac build phase. (It now has a runtime dependency on the standard OpenMP (libomp) instead of the GCC implementation (libgomp)).\r\n\r\nFixes #1067 and #494.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1234","RelatedDescription":"Closed or merged PR \"Update to version of Lightgbm with no runtime dependency on GCC.\" (#1234)"},{"Id":"369319822","IsPullRequest":false,"CreatedAt":"2018-10-11T22:49:37","Actor":"Anipik","Number":"1233","RawContent":null,"Title":"Dead Matrix Multiplication Code","State":"closed","Body":"We are not currently using  Some of the matrix multiplication code anywhere\r\nparticularly \r\n```C#\r\npublic static void MatTimesSrc(bool tran, bool add, AlignedArray mat, int[] rgposSrc, AlignedArray srcValues, int posMin, int iposMin, int iposLim, AlignedArray dst, int crun)\r\n```\r\nwhich is the sparse matrix multiplication. Is it okay to remove it ?\r\n Another thing we are not using the ```add = true``` flag in any of the existing implementations.\r\n\r\nCan I go ahead and remove that too ?\r\n\r\ncc @eerhardt @danmosemsft @shauheen @codemzs \r\n","Url":"https://github.com/dotnet/machinelearning/issues/1233","RelatedDescription":"Closed issue \"Dead Matrix Multiplication Code\" (#1233)"},{"Id":"369313040","IsPullRequest":false,"CreatedAt":"2018-10-11T21:30:42","Actor":"vaeksare","Number":"1232","RawContent":null,"Title":"Pretrained DNN Image Featurization","State":"open","Body":"Support for a DNN Image Featurizer Transform is to be added to ML.NET. This will allow users to use 1 of 4 pretrained DNN models (ResNet18, ResNet50, ResNet101, and AlexNet) trained on ImageNet in order to featurize an input image. \r\n\r\nThis transform will use the ONNX Transform as the backbone of doing input preprocessing and applying the pretrained DNN model.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1232","RelatedDescription":"Open issue \"Pretrained DNN Image Featurization\" (#1232)"},{"Id":"369299546","IsPullRequest":false,"CreatedAt":"2018-10-11T20:49:47","Actor":"wschin","Number":"1231","RawContent":null,"Title":"Factorization Machine Better to Support Regression","State":"open","Body":"ML.NET's (field-aware) factorization machine doesn't support regression problems while SageMaker [does](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html). Rating prediction is an important application about this.","Url":"https://github.com/dotnet/machinelearning/issues/1231","RelatedDescription":"Open issue \"Factorization Machine Better to Support Regression\" (#1231)"},{"Id":"369260354","IsPullRequest":true,"CreatedAt":"2018-10-11T20:40:35","Actor":"seemantsagar","Number":"1230","RawContent":null,"Title":"Release/preview","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1230","RelatedDescription":"Closed or merged PR \"Release/preview\" (#1230)"},{"Id":"369230433","IsPullRequest":true,"CreatedAt":"2018-10-11T17:38:55","Actor":"eerhardt","Number":"1229","RawContent":null,"Title":"Refactor CpuMathUtils","State":"open","Body":"- Allow it to take Spans instead of arrays.\r\n- Remove redundant overloads\r\n- When multiple spans are accepted, always use an explicit count parameter instead of one being chosen as having the right length.\r\n\r\nWorking towards #608","Url":"https://github.com/dotnet/machinelearning/pull/1229","RelatedDescription":"Open PR \"Refactor CpuMathUtils\" (#1229)"},{"Id":"369229133","IsPullRequest":false,"CreatedAt":"2018-10-11T17:35:44","Actor":"vaeksare","Number":"1228","RawContent":null,"Title":"ONNX Transform Crashing or Freezing","State":"open","Body":"ONNX Transform occasionally crashes or freezes when running certain onnx models (currently found with the Split operator). \r\n\r\n- The error is non deterministic and varies based on different machines\r\n- On some machines, the ML.NET process will freeze, while on others it will simply silently crash without producing any output\r\n- The larger the input, the more likely the issue seems to occur - almost never happens with <100 inputs, sometimes happens with 100-300 inputs, and almost always happens with >300 inputs\r\n- When ML.NET is built in debug mode, the error will never occur. It only happens if it is built in release mode\r\n- The issue is not tied to any specific input. Smaller inputs will never produce an error, while larger ones almost always will (in release mode)","Url":"https://github.com/dotnet/machinelearning/issues/1228","RelatedDescription":"Open issue \"ONNX Transform Crashing or Freezing\" (#1228)"},{"Id":"369030470","IsPullRequest":true,"CreatedAt":"2018-10-11T17:18:57","Actor":"harshsaver","Number":"1227","RawContent":null,"Title":"Grammar corrected in README.md","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1227","RelatedDescription":"Closed or merged PR \"Grammar corrected in README.md\" (#1227)"},{"Id":"369013823","IsPullRequest":false,"CreatedAt":"2018-10-11T08:44:55","Actor":"rauhs","Number":"1226","RawContent":null,"Title":"SelectFeaturesBasedOnCount is extremely slow","State":"open","Body":"I'm using the new static pipeline and adding a `SelectFeaturesBasedOnCount(2)` slows down the pipeline by orders of magnitude.\r\n\r\nJust using ~8000 samples and doing some simple One hot encoding will prepare my data ready for learning in about 200ms. If I just add `SelectFeaturesBasedOnCount(2)` on a single one hot encoded feature it will run in 4 seconds. Adding another one to a second feature will run it in 12 seconds. I'd like to add it to about 7 features but this will run for hours and never finish.\r\n\r\nAlso, just pressing \"Brake all\" while it runs it will often stop in the `RepositoryWriter`/`Reader` and thousands of temporary folders/files are create in my temp directory. In case that helps.","Url":"https://github.com/dotnet/machinelearning/issues/1226","RelatedDescription":"Open issue \"SelectFeaturesBasedOnCount is extremely slow\" (#1226)"},{"Id":"369000530","IsPullRequest":false,"CreatedAt":"2018-10-11T08:08:36","Actor":"rauhs","Number":"1225","RawContent":null,"Title":"Pigsty for VarVector doesn't have hash one hot","State":"open","Body":"I'm trying to convert my `LearningPipeline` to 0.6 static pipeline. I have some *variable* length features in my input instances.\r\n\r\nWith the pipeline I did:\r\n\r\n```C#\r\nnew CategoricalHashOneHotVectorizer(nameof(TransportOrderInstance.PosAmount)) { OutputKind = CategoricalTransformOutputKind.Bag, Ordered = false, HashBits = 5},\r\n```\r\n\r\nWhat is the equivalent in the new static pipeline? The `VarVector` doesn't have a whole lot of extension functions. Shouldn't it also have `OneHotEncoding`? Though, it's not \"One\" necessarily.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1225","RelatedDescription":"Open issue \"Pigsty for VarVector doesn't have hash one hot\" (#1225)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-10-14T05:30:33.101811Z","RunDurationInMilliseconds":1017}