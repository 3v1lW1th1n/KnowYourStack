{"Data":{"GitHub":{"Issues":[{"Id":"341657323","IsPullRequest":false,"CreatedAt":"2018-07-16T19:59:51","Actor":"eerhardt","Number":"541","RawContent":null,"Title":"Need to rename TlcEnvironment","State":"open","Body":"Our only public, concrete environment class is named \"TlcEnvironment\", which uses the internal \"TLC\" acronym/name and has no meaning anymore.\r\n\r\nWe should come up with a better name for our default environment class.\r\n\r\n/cc @ericstj @TomFinley ","Url":"https://github.com/dotnet/machinelearning/issues/541","RelatedDescription":"Open issue \"Need to rename TlcEnvironment\" (#541)"},{"Id":"339993621","IsPullRequest":true,"CreatedAt":"2018-07-16T18:51:26","Actor":"zeahmed","Number":"520","RawContent":null,"Title":"[Part 3] Added convenience constructors for set of transforms.","State":"closed","Body":"This PR fixes #518. The convenience constructors were added for following transforms.\r\n\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs","Url":"https://github.com/dotnet/machinelearning/pull/520","RelatedDescription":"Closed or merged PR \"[Part 3] Added convenience constructors for set of transforms.\" (#520)"},{"Id":"339961735","IsPullRequest":false,"CreatedAt":"2018-07-16T18:51:26","Actor":"zeahmed","Number":"518","RawContent":null,"Title":"[Part 3] Create convenience constructor for the listed Transforms.","State":"closed","Body":"This work item is related to #371 and is the 3rd work item in series of creating convenience constructor (cf. #380 and #487). In this work item, convenience constructors will be created following set of transforms. \r\n\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs\r\n","Url":"https://github.com/dotnet/machinelearning/issues/518","RelatedDescription":"Closed issue \"[Part 3] Create convenience constructor for the listed Transforms.\" (#518)"},{"Id":"341599530","IsPullRequest":false,"CreatedAt":"2018-07-16T17:01:01","Actor":"dsyme","Number":"540","RawContent":null,"Title":"Plan for F# bug and testing","State":"open","Body":"I've been asked to fix some issues related to F# in this repo, especially #180. This is a planning note regarding this work.\r\n\r\nTODO:\r\n\r\n* [ ] Add one F# scripting \"smoke test\" under `tests\\FSharpScripting\\SmokeTest` based around those done by @isaacabraham, see https://github.com/isaacabraham/ml-test-experiment.  \r\n\r\n   * This test will run under CI on Windows. It will currently require .NET Framework or Mono.  \r\n\r\n* [ ] Add one F# compiled-project \"smoke test\" under `tests\\FSharpProjects\\SmokeTest` based around those done by @isaacabraham, see https://github.com/isaacabraham/ml-test-experiment.  \r\n\r\n   * This test will run under CI on both Windows and Linux and only require .NET Core\r\n\r\nWhen futher API updates and re-designs are made it is up to the person doing the re-design to adjust these tests :) Ask for help if you need it, but the F# code will be simple and I'm sure all contributors are capable of adjusting trivial F# code, F# is dead simple to learn.\r\n\r\nThen, when [this bug](https://github.com/dotnet/machinelearning/issues/180) is fixed, a test will be added to both tests\\FSharpScripting\\SmokeTest and tests\\FSharpProjects\\SmokeTest.\r\n\r\nSeparately I will propose updates for documentation for F#, and we can later look at more comprehensive documentation, samples and testing.","Url":"https://github.com/dotnet/machinelearning/issues/540","RelatedDescription":"Open issue \"Plan for F# bug and testing\" (#540)"},{"Id":"341571989","IsPullRequest":true,"CreatedAt":"2018-07-16T15:40:33","Actor":"abgoswam","Number":"539","RawContent":null,"Title":"WIP . Fixes PipelineSweeperMacro for Multi-Class Classification","State":"open","Body":"`Fixes #538`\r\n\r\n- The PipelineSweeper currently only supports AUC as the optimization metric.  Trying to optimize on any other metric throws an exception.\r\n- Need to fix the way metrics are handled by the PipelineSweeper Macro.\r\n- Added a test case for MultiClass classification using the PipelineSweeper.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/539","RelatedDescription":"Open PR \"WIP . Fixes PipelineSweeperMacro for Multi-Class Classification\" (#539)"},{"Id":"341569557","IsPullRequest":false,"CreatedAt":"2018-07-16T15:34:25","Actor":"abgoswam","Number":"538","RawContent":null,"Title":"PipelineSweeping fails for MultiClass classification","State":"open","Body":"### Issue\r\n\r\n- **PipelineSweeper fails for 'TrainerKind': 'SignatureMultiClassClassifierTrainer'**\r\n- **System.InvalidOperationException : Requested value 'Accuracy(micro-avg)' is not a member of the Enum type 'Metrics'**\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/538","RelatedDescription":"Open issue \"PipelineSweeping fails for MultiClass classification\" (#538)"},{"Id":"341144408","IsPullRequest":false,"CreatedAt":"2018-07-16T14:12:15","Actor":"mgolois","Number":"531","RawContent":null,"Title":"How to get the accuracy when using a FastTreeRegressor?","State":"closed","Body":"When predicting a flight delay, I would like to let the user know how accurate is the prediction. I was not able to find a way to ouput that information with a regression algorithm:\r\n\r\n```\r\n         static void Main(string[] args)\r\n        {\r\n\r\n            string trainDataPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Flight Delay Prediction-TrainData.csv\");\r\n            string testDataPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Flight Delay Prediction-TestData.csv\");\r\n            string modelPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Model.zip\");\r\n            Console.WriteLine(Environment.CurrentDirectory);\r\n\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                new TextLoader(trainDataPath).CreateFrom<FlightInfo>(useHeader: true, separator: ','),\r\n                new ColumnCopier((\"ArrivalDelay\", \"Label\")),\r\n                new CategoricalOneHotVectorizer(\"Airline\", \"OriginAirport\"),\r\n                new ColumnConcatenator(\"Features\", \"Airline\", \"OriginAirport\"),\r\n                new FastTreeRegressor()\r\n            };\r\n\r\n            var model = pipeline.Train<FlightInfo, FlightDelayPrediction>();\r\n\r\n            model.WriteAsync(modelPath).Wait();\r\n\r\n\r\n            var testData = new TextLoader(testDataPath).CreateFrom<FlightInfo>(useHeader: true, separator: ',');\r\n\r\n            var evaluator = new RegressionEvaluator();\r\n\r\n            var metrics = evaluator.Evaluate(model, testData);\r\n\r\n            Console.WriteLine($\"Rms = {metrics.Rms}\");\r\n            Console.WriteLine($\"RSquared = {metrics.RSquared}\");\r\n\r\n            var predictDelay = new FlightInfo();\r\n\r\n            Console.WriteLine(\"Let's try to predict an airline and departing city delay:\");\r\n            Console.Write(\"Airline: \");\r\n            predictDelay.Airline = Console.ReadLine();\r\n            Console.Write(\"Departing City: \");\r\n            predictDelay.OriginAirport = Console.ReadLine();\r\n\r\n            var prediction = model.Predict(predictDelay);\r\n            Console.WriteLine($\"Predicted Arrival Delay: {prediction.ArrivalDelay}\");\r\n            Console.ReadKey();\r\n        }\r\n    }\r\n    public class FlightInfo\r\n    {\r\n        [Column(\"0\")]\r\n        public string Airline;\r\n        [Column(\"1\")]\r\n        public float ArrivalDelay;\r\n        [Column(\"2\")]\r\n        public string OriginAirport;\r\n\r\n    }\r\n\r\n    public class FlightDelayPrediction\r\n    {\r\n        [ColumnName(\"Score\")]\r\n        public float ArrivalDelay;\r\n    }\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/531","RelatedDescription":"Closed issue \"How to get the accuracy when using a FastTreeRegressor?\" (#531)"},{"Id":"341403566","IsPullRequest":false,"CreatedAt":"2018-07-16T06:32:52","Actor":"rauhs","Number":"537","RawContent":null,"Title":"`const` on the instance class will throw","State":"open","Body":"Adding a:\r\n\r\n```\r\n    public const string MagicNone = \" NONE \";\r\n```\r\n\r\nto an \"instance\" class (ie the class used to feed ML.NET the instances) will throw an ugly exception which is hard to figure out.\r\n\r\nI think there is another issue where more careful reflecting of the class is suggested. Can't find it right now though","Url":"https://github.com/dotnet/machinelearning/issues/537","RelatedDescription":"Open issue \"`const` on the instance class will throw\" (#537)"},{"Id":"341354477","IsPullRequest":false,"CreatedAt":"2018-07-15T21:38:28","Actor":"galvesribeiro","Number":"536","RawContent":null,"Title":"WASM support","State":"open","Body":"Hello folks!\r\n\r\nTrying to make ML.Net to work on mono-wasm but I just figured out the hard way that it only works on x64:\r\n\r\n![image](https://user-images.githubusercontent.com/4714040/42738687-1104bf6e-885e-11e8-813b-e55a91976ccc.png)\r\n\r\nIs there any chance to get the native part built to wasm?\r\n\r\nThanks!","Url":"https://github.com/dotnet/machinelearning/issues/536","RelatedDescription":"Open issue \"WASM support\" (#536)"},{"Id":"341193133","IsPullRequest":false,"CreatedAt":"2018-07-14T00:27:17","Actor":"dan-drews","Number":"535","RawContent":null,"Title":"How would I concatenate columns of different types?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**:  .NET Framework 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Combined numeric columns with FeaturizedText Columns\r\n- **What happened?** I received an exception about mismatched column Types\r\n- **What did you expect?** I'm not 100% sure. I am hoping to find a way to combine a text featurizer with numeric values into the \"Features\" column to take multiple data types into account. I saw that we have the categorical vectorizers and Hash Transform Columns available, but I from what i understand, that is for a distinct number of categories.\r\n\r\nWhat I am trying to accomplish is utilizing numeric and text values in the prediction. Maybe this is just a lack of understanding on my part for this and it is not possible, but I'm kind of hoping to post the pieces of my business object that that I think could impact the result, and I cannot figure out how to do that effectively.\r\n\r\nNote: I am using a FastTreeRegressor predicting a float value.","Url":"https://github.com/dotnet/machinelearning/issues/535","RelatedDescription":"Open issue \"How would I concatenate columns of different types?\" (#535)"},{"Id":"341175974","IsPullRequest":false,"CreatedAt":"2018-07-13T22:22:13","Actor":"eerhardt","Number":"534","RawContent":null,"Title":"Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core","State":"open","Body":".NET Core 2.1 [introduced hardware intrinsics APIs](https://github.com/dotnet/designs/blob/master/accepted/platform-intrinsics.md) that allow C# code to take full advantage of the CPU. For example, you can now write algorithms using SSE or AVX instructions purely from C# code.\r\n\r\nThe CpuMathNative assembly exists solely so ML.NET can take advantage of SSE and AVX instructions in its algorithms. When running on .NET Core 2.1+, we can remove our dependency on this native assembly, and instead port the C++ SIMD code to using the new C# intrinsics APIs.\r\n\r\nHowever, to do this (and still support the full .NET Framework), we need to do some refactoring to our assemblies and NuGet packages.\r\n\r\nThe first thing we need to do is allow `Microsoft.ML.CpuMath` to be multi-targeted for `netstandard2.0;netcoreapp2.1`. This will allow us to compile against the netcoreapp2.1 specific SSE APIs.\r\n\r\nHowever, doing that affects our `Microsoft.ML` nuget package. This is because when you make a nuget package, you put your assemblies into TFM specific folders `lib\\netstandard2.0`, `lib\\netcoreapp2.1`, etc. And the way asset picking works is that once it finds assets for a specific TFM, it stops looking.  (The reasoning is typically there is a single assembly per nuget package.) So if we have a single assembly, CpuMath, that needs to go into both `lib\\netstandard2.0` and `lib\\netcoreapp2.1`, we have a problem. It means ALL our assemblies need to go into BOTH folders, which is unnecessary duplication.\r\n\r\nTo solve this duplication, I propose to split CpuMath into its own nuget package.  So we will have this structure:\r\n\r\n* `Microsoft.ML.CpuMath`\r\n    - Contains the CpuMath managed assemblies (one for each TFM) and the CpuMathNative assemblies.\r\n* `Microsoft.ML`\r\n    - Has a dependency on `Microsoft.ML.CpuMath`.\r\n\r\nIn order to do this correctly, we need to remove the assembly reference from `Microsoft.ML.CpuMath.dll` on `Microsoft.ML.Core.dll`. This is because the nuget dependency goes the other way.  The only reason `Microsoft.ML.CpuMath.dll` depends on `Microsoft.ML.Core.dll` is so it can use the `Contracts` class.  We can break this dependency by using the `PRIVATE_CONTRACTS` define constant, and source linking the `Contracts.cs` file into CpuMath.\r\n\r\n/cc @TomFinley @ericstj @briancylui @tannergooding ","Url":"https://github.com/dotnet/machinelearning/issues/534","RelatedDescription":"Open issue \"Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core\" (#534)"},{"Id":"341148843","IsPullRequest":false,"CreatedAt":"2018-07-13T20:24:29","Actor":"bsexton","Number":"533","RawContent":null,"Title":"Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.","State":"open","Body":"### System information\r\nIssue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**:  4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I started with the TaxiFare Example and that works. But then I changed the model and added my own values and my data. I got the error about the \"Features\" above. I played with it for a while and tried limiting my data. Even tried predicting the Fare Amount again.\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/533","RelatedDescription":"Open issue \"Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.\" (#533)"},{"Id":"341147669","IsPullRequest":false,"CreatedAt":"2018-07-13T20:19:49","Actor":"vivekpradhan","Number":"532","RawContent":null,"Title":"LightGBM on ML.NET trains slower than LightGBM command line","State":"open","Body":"### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.301\r\n Commit:    59524873d6\r\n\r\nRuntime Environment:\r\n OS Name:     ubuntu\r\n OS Version:  16.04\r\n\r\nHardware:\r\nGoogle Cloud default 64 core machine.\r\n\r\n### Issue\r\n\r\nRan training on same dataset with same params.\r\nDataset: 25k features x 140k rows (balanced binary classes)\r\nParams: \r\nCommand Line: \r\n```\r\n./lightgbm metric=binary_logloss min_data_in_leaf=500 bagging_fraction=0.8 boosting_type=gbdt bagging_freq=5 max_bin=255 objective=binary valid_data=../../../pedata/test.csv max_depth=10 feature_fraction=0.8 num_leaves=70 output_result=prediction.txt num_machines=1 learning_rate=0.1 output_model=LightGBM_model.txt data=../../../pedata/train.csv num_threads=64 task=train is_training_metric=true num_iterations=500 metric_freq=1 tree_learner=serial\r\n```\r\nML.NET\r\n```\r\nvar lclassifier = new LightGbmBinaryClassifier() { UseCat=false, MaxBin= 255, EvalMetric= LightGbmArgumentsEvalMetricType.Logloss , NumLeaves= 70, NThread= 64,LearningRate= 0.1, NumBoostRound= 500, MinDataPerLeaf= 500};\r\n            lclassifier.Booster = new GbdtBoosterParameterFunction() { \r\n                MaxDepth = 10,\r\n                FeatureFraction=0.8,\r\n                SubsampleFreq=5 };\r\n            pipeline.Add(lclassifier);\r\n```\r\n- **What happened?**\r\n\r\nBoth use all the 64 cores (As seen on htop).\r\nData Loading + Training Time: Command Line: 10mins, ML.NET: 17mins\r\n\r\n- **What did you expect?**\r\nSince both were build on my machine from source, I expected that the training time would be comparable.  \r\n\r\nWhy is the ML.NET implementation slower? Is there something I can do to speed it up?\r\n\r\n```\r\nStopwatch stopwatch = new Stopwatch();\r\nstopwatch.Start();\r\n// STEP 5: Train your model based on the data set\r\nvar model = pipeline.Train<IrisData, IrisPrediction>();\r\nstopwatch.Stop();\r\n```\r\nThe above stopwatch gives me time taken for Loading+Training. Is there a way to check the time taken only for the training step. Right now I am not sure if the data loading is slow or the training is slow.\r\n\r\n-----------------\r\nEdit: I got approximate training time by assuming that when CPU usage spikes, thats when training starts.\r\nTraining Time: Command Line: 335s, ML.NET:680s (approx)\r\nData Loading: Command Line: 265s, ML.NET: 340s (approx)","Url":"https://github.com/dotnet/machinelearning/issues/532","RelatedDescription":"Open issue \"LightGBM on ML.NET trains slower than LightGBM command line\" (#532)"},{"Id":"341133131","IsPullRequest":false,"CreatedAt":"2018-07-13T19:24:58","Actor":"zeahmed","Number":"530","RawContent":null,"Title":"[TextTransform] Char n-grams are different when using with/without word n-grams.","State":"open","Body":"### System information\r\n\r\n`Not relevant`\r\n\r\n### Issue\r\nWhen using TextTransform to compute n-grams, it has been observed that character n-grams produced are not consistent when computing it with/without word n-grams option. For example, for the following sentence \r\n```\r\nThis is a cat\r\n```\r\nThe character n-grams produced are as follows. where `<STX>`, `<ETX>` and `<SP>` are start of sentence, end of sentence and space control characters respectively.\r\n\r\n| Char 3-gram | Char 3-gram + Word 3-gram|\r\n|-|-|\r\n|\\<STX\\>\\|t\\|h | \\<STX\\>\\|t\\|h\r\n| t\\|h\\|i | t\\|h\\|i\r\n| h\\|i\\|s | h\\|i\\|s\r\n| i\\|s\\|\\<SP\\> | i\\|s\\|\\<ETX\\>\r\n| s\\|\\<SP\\>\\|i | s\\|\\<ETX\\>\\|\\<STX\\>\r\n| \\<SP\\>\\|i\\|s | \\<ETX\\>\\|\\<STX\\>\\|i\r\n| s\\|\\<SP\\>\\|a | \\<STX\\>\\|i\\|s\r\n| \\<SP\\>\\|a\\|\\<SP\\> | \\<ETX\\>\\|\\<STX\\>\\|a\r\n| a\\|\\<SP\\>\\|c | \\<STX\\>\\|a\\|\\<ETX\\>\r\n| \\<SP\\>\\|c\\|a | a\\|\\<ETX\\>\\|\\<STX\\>\r\n| c\\|a\\|t | \\<ETX\\>\\|\\<STX\\>\\|c\r\n| a\\|t\\|\\<ETX\\> | \\<STX\\>\\|c\\|a\r\n|-| c\\|a\\|t\r\n|-| a\\|t\\|\\<ETX\\>\r\n\r\n### Source code / logs\r\nThe cause of the problem is word tokenizer which is applied at the following location in the code.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/669f4fad33184c9c558314f8bc758f7928ad62bf/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L266\r\n\r\nThe `NeedsWordTokenizationTransform` property is set according to following criteria\r\nhttps://github.com/dotnet/machinelearning/blob/669f4fad33184c9c558314f8bc758f7928ad62bf/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L169\r\n\r\nThis means whenever word n-grams are being computed the tokenization is performed first and character n-gram extractor computes n-grams on words instead of sentences i.e. \r\n\r\ninstead of computing char n-grams on \r\n```\r\n<STX>This<SP>is<SP>a<SP>cat<ETX>\r\n```\r\nit computes char n-grams on\r\n```\r\n<STX>This<ETX>\r\n<STX>is<ETX>\r\n<STX>a<ETX>\r\n<STX>cat<ETX>\r\n```\r\nFirst of all, is the expected behavior?\r\nI my point of view `NOT` because in this way character n-gram is adding noise and losing important information regarding the sentence which in some cases may give superior performance.\r\n\r\n### Solution\r\nApply char n-gram extractor on `IDataView` that was not used for word processing in the code.","Url":"https://github.com/dotnet/machinelearning/issues/530","RelatedDescription":"Open issue \"[TextTransform] Char n-grams are different when using with/without word n-grams.\" (#530)"},{"Id":"339677302","IsPullRequest":true,"CreatedAt":"2018-07-13T18:38:33","Actor":"dan-drews","Number":"514","RawContent":null,"Title":"Remove Extra Code Comments and unused InternalStreams project","State":"closed","Body":"Fixes #513\r\n\r\nThis is the first go-around at finding extra commented code sitting around. I'll circle back on more when I have a chance.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/514","RelatedDescription":"Closed or merged PR \"Remove Extra Code Comments and unused InternalStreams project\" (#514)"},{"Id":"339673667","IsPullRequest":false,"CreatedAt":"2018-07-13T18:38:33","Actor":"dan-drews","Number":"513","RawContent":null,"Title":"Remove commented code","State":"closed","Body":"While digging into the source code, I discovered a large amount of commented out code throughout the solution.\r\n\r\nUnless there is a reason behind this that I am not aware of, I think it is best to remove this. In a worst-case scenario, we have the git history to take care of this.\r\n\r\nOne example is in UnbufferedStream.cs, the following code is all commented out:\r\n\r\n    //}\r\n    //if (checkStream == null)\r\n    //{\r\n    //    checkStream = new FileStream(fileName, FileMode.Open, FileAccess.Read, FileShare.Read);\r\n    //}\r\n    //byte[] cbuf = new byte[count];\r\n    //int checkRead = checkStream.Read(cbuf, 0, cbuf.Length);\r\n    //if (checkRead != read)\r\n    //{\r\n    //    Console.WriteLine(\"!!! bytes read mismatch at \" + fileName + \": \"  + checkStream.Position + \" / \" + Position + \": \" +\r\n    //        \"read = \" + read + \"; checkRead = \" + checkRead);\r\n    //}\r\n    //else\r\n    //{\r\n    //    Console.WriteLine(\">>> bytes read match at \" + fileName + \": \" + checkStream.Position + \" / \" + Position + \": \" +\r\n    //        \"read = \" + read + \"; checkRead = \" + checkRead);\r\n    //}\r\n\r\nI haven't yet discovered the extent of this, but I think some work should be done on this.","Url":"https://github.com/dotnet/machinelearning/issues/513","RelatedDescription":"Closed issue \"Remove commented code\" (#513)"},{"Id":"341087165","IsPullRequest":true,"CreatedAt":"2018-07-13T16:44:39","Actor":"sfilipi","Number":"529","RawContent":null,"Title":"Adding documentation about the rest of the classes involved on generating the CSharpAPI","State":"open","Body":"Resolves #389 \r\nAdded more documentation and examples about mostly transforms components. (A few learners as well.)\r\n\r\nThe documentation for the classes involved in generating the entry points lives in the doc.xml documents, since it needs to be referenced from two locations, for the most part, and since the CSharpApi is auto-generated. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/529","RelatedDescription":"Open PR \"Adding documentation about the rest of the classes involved on generating the CSharpAPI\" (#529)"},{"Id":"341032515","IsPullRequest":true,"CreatedAt":"2018-07-13T16:32:56","Actor":"TomFinley","Number":"527","RawContent":null,"Title":"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest","State":"closed","Body":"Fixes #526 .\r\n\r\nThe test `TrainAndPredictIrisModelUsingDirectInstantiationTest` now has analogous changes to the `TrainAndPredictIrisModelTest` test.","Url":"https://github.com/dotnet/machinelearning/pull/527","RelatedDescription":"Closed or merged PR \"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest\" (#527)"},{"Id":"341030146","IsPullRequest":false,"CreatedAt":"2018-07-13T16:32:56","Actor":"TomFinley","Number":"526","RawContent":null,"Title":"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest test from commit #428","State":"closed","Body":"PR #428 was merged July 12, many days after PR #468 which added a new test on the Iris dataset July 2. The changes in #428 were not applied to that new test, and with the merge that test is failing.","Url":"https://github.com/dotnet/machinelearning/issues/526","RelatedDescription":"Closed issue \"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest test from commit #428\" (#526)"},{"Id":"341041086","IsPullRequest":true,"CreatedAt":"2018-07-13T14:30:02","Actor":"Ivanidzo4ka","Number":"528","RawContent":null,"Title":"WIP Image support","State":"open","Body":"address #489 \r\nneed create issue about IDataView datatype extensibility.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/528","RelatedDescription":"Open PR \"WIP Image support\" (#528)"},{"Id":"340825260","IsPullRequest":false,"CreatedAt":"2018-07-12T22:52:36","Actor":"sfilipi","Number":"525","RawContent":null,"Title":"Rename the NGramNgramExtractor class to a better name. ","State":"open","Body":"I think the NGramNgramExtractor class in the CSharpApi.cs should have a better name. \r\n\r\nCirca line 17990: \r\n`public sealed class NGramNgramExtractor : NgramExtractor` ","Url":"https://github.com/dotnet/machinelearning/issues/525","RelatedDescription":"Open issue \"Rename the NGramNgramExtractor class to a better name. \" (#525)"},{"Id":"340727915","IsPullRequest":false,"CreatedAt":"2018-07-12T18:10:32","Actor":"CESARDELATORRE","Number":"523","RawContent":null,"Title":"ML.NET exports to ONNX v1.2.2 file which is not supported in current released Windows 10 RS4 but only in RS5","State":"closed","Body":"### System information\r\n- **Windows RS4 vs. RS5**\r\n- **ML.NET 0.3**\r\n\r\n### Issue\r\nThe current released Windows (RS4) with WinML, supports only ONNX v1.0 models while Windows RS5 WinML supports only ONNX v1.2.2 models.\r\n\r\nThis is an issue since ML.NET exports ONNX 1.2.2 files which therefore don't work on current released Windows (RS4) with WinML, but only on the next version of Windows (RS5), which is still not publicly available.\r\n\r\nSince this issue might be happening depending on the target platforms, it would be advisable to parametrize the ONNX version of the model to export/generate (ONNX v1.0, v1.2.2, etc.), so it can work on multiple target platforms depending on the version. \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/523","RelatedDescription":"Closed issue \"ML.NET exports to ONNX v1.2.2 file which is not supported in current released Windows 10 RS4 but only in RS5\" (#523)"},{"Id":"340734090","IsPullRequest":false,"CreatedAt":"2018-07-12T17:42:32","Actor":"zeahmed","Number":"524","RawContent":null,"Title":"Add description to convenience constructors.","State":"open","Body":"Recently, convenience constructors were added to different components to help easily create these components in the pipeline (cf. #380 #487 and #520).\r\n\r\nIt is also desirable to add helpful comments/description to these constructor to help user understand the components purpose and possible usage.\r\n\r\nTo be more precise, here is list of transforms that needs description for convenience constructors.\r\n\r\n- BootstrapSampleTransform\r\n- CategoricalHashTransform\r\n- CategoricalTransform\r\n- ConcatTransform\r\n- CopyColumnsTransform\r\n- CountFeatureSelection\r\n- DropColumnsTransform\r\n- LpNormNormalizerTransform\r\n- NAFilter\r\n- NormalizeTransform\r\n- ChooseColumnsTransform.cs\r\n- ConvertTransform.cs\r\n- DropSlotsTransform.cs\r\n- GenerateNumberTransform.cs\r\n- HashTransform.cs\r\n- KeyToValueTransform.cs\r\n- KeyToVectorTransform.cs\r\n- LabelConvertTransform.cs\r\n- LabelIndicatorTransform.cs\r\n- RangeFilter.cs\r\n- ShuffleTransform.cs\r\n- SkipTakeFilter.cs\r\n- TermTransform.cs\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs","Url":"https://github.com/dotnet/machinelearning/issues/524","RelatedDescription":"Open issue \"Add description to convenience constructors.\" (#524)"},{"Id":"340486297","IsPullRequest":true,"CreatedAt":"2018-07-12T04:35:43","Actor":"TomFinley","Number":"522","RawContent":null,"Title":"Conversion of ITrainer.Train returns predictor, accepts +TrainContext","State":"open","Body":"Fixes #509.\r\n\r\n* `ITrainer.Train` returns a predictor. There is no `CreatePredictor` method on the interface.\r\n\r\n* `ITrainer.Train` always accepts a `TrainContext`. Dataset type is no longer a generic parameter. This context object replaces the functionality previously offered by the combination of `ITrainer`, `IValidatingTrainer`, `IIncrementalTrainer`, and `IIncrementalValidatingTrainer`, which is now captured in one `ITrainer.Train` method with differently configured contexts.\r\n\r\n* All trainers updated to these two new idioms. Many trainers correspondingly improved to no longer be stateful objects. (The exceptions are those that are just too far gone to be done with less than herculean effort at refactoring them to no longer use instance fields for their computation, most notably, LBFGS and FastTree based trainers.)\r\n\r\n* Utility code meant to deal with the complexity of the aforementioned `IT/IVT/IIT/IIVT` idiom reduced considerably.\r\n\r\n* Opportunistic improvements to `ITrainer` implementors where observed.","Url":"https://github.com/dotnet/machinelearning/pull/522","RelatedDescription":"Open PR \"Conversion of ITrainer.Train returns predictor, accepts +TrainContext\" (#522)"},{"Id":"340248576","IsPullRequest":false,"CreatedAt":"2018-07-11T13:44:19","Actor":"hrkrx","Number":"521","RawContent":null,"Title":"Structure of a regression tree","State":"open","Body":"I want to visualize a regression tree.\r\nSo i got one form my trained model.\r\n\r\nBut now i am wondering how the object (RegressionTree from Microsoft.ML.Runtime.FastTree.Internal) is structured and how i can obtain a connected tree from that object.\r\n\r\nOnly for display purposes i have a class like this:\r\n\r\n```\r\npublic class TreeNode\r\n{\r\n     public List<TreeNode> Children;\r\n     public TreeNode Parent;\r\n     public string Content;\r\n     [...]\r\n}\r\n```\r\n\r\nand i am struggling to connect the values of the arrays in RegressionTree to a TreeNode based tree.\r\n\r\nThank you for your time!","Url":"https://github.com/dotnet/machinelearning/issues/521","RelatedDescription":"Open issue \"Structure of a regression tree\" (#521)"},{"Id":"339877803","IsPullRequest":true,"CreatedAt":"2018-07-10T22:47:43","Actor":"jwood803","Number":"516","RawContent":null,"Title":"Fix quotes on json","State":"closed","Body":"Fixes issue #507.\r\n\r\nDidn't see any impacted tests for this, but going to see about adding one.","Url":"https://github.com/dotnet/machinelearning/pull/516","RelatedDescription":"Closed or merged PR \"Fix quotes on json\" (#516)"},{"Id":"339990673","IsPullRequest":false,"CreatedAt":"2018-07-10T20:15:43","Actor":"dotChris90","Number":"519","RawContent":null,"Title":"Is a simulation model not also a kind of machine learning model?","State":"open","Body":"Hello ML.NET Team, \r\n\r\nthis week I was talking with some guys from simulation and a question come up into my mind. **It is more a general question about machine learning**. Why simulation models are not part of models for machine learning? A simulation model like from MATLAB/Simulink, Amesim, Modellica, .... are basically a text based description (XML or sth else) in form of mathematical formulas for prediction. \r\n\r\nYou see - yeah maybe they look different but they are not too different from each others. A simulation model also has a signal flow / topology and parameters which need to be \"trained\" just like a neuronal network. This \"training\" is mostly done by measurement signals and by finding the parameter which produce the smallest error (like traditional regression problem). As you can see - like neuronal network. Actual in last years I often saw some articles which suggested neuronal networks for simulation - okay nice idea but .... if you think about car or airplane simulation .... such measurements are extrem expensive and most articles I saw did not connect physical laws with the network (which is a pity).\r\n\r\nI just ask myself - is such a model + parameter finding algorithm not also a kind of \"Learner\"? And if so - why most frameworks like Spark, Scikit etc. ignore them? If it is because there are too many model formats (file formats) - then just let you know : there is \"Functional Mockup Interface (FMI)\" --> a model format to rule all other formats. .NET brings different programming languages together, FMI brings different models. \r\n\r\nDo not see it as task or critical wish. I just want to discuss with others and see their opinion. :D\r\n\r\n  \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/519","RelatedDescription":"Open issue \"Is a simulation model not also a kind of machine learning model?\" (#519)"},{"Id":"339919247","IsPullRequest":false,"CreatedAt":"2018-07-10T16:32:01","Actor":"22140505","Number":"517","RawContent":null,"Title":"How to continue training based on the existing model?","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/issues/517","RelatedDescription":"Open issue \"How to continue training based on the existing model?\" (#517)"},{"Id":"339802189","IsPullRequest":false,"CreatedAt":"2018-07-10T11:29:44","Actor":"satish860","Number":"515","RawContent":null,"Title":"NA Handling ","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows \r\n- **.NET Version (eg., dotnet --info)**:  2.1.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI was trying to work on Titanic kaggle problem and trying to train and I am looking for an example of how to handle Null values. \r\nI have seen handling option but not able to find how to use it in Pipeline.\r\n\r\nBetween one difference I have seen between Python interfaces and .net is the ability to experiment easily and I am finding it bit harder to do here. If you have any practices it will be helpful if we can discuss here. \r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/515","RelatedDescription":"Open issue \"NA Handling \" (#515)"},{"Id":"339640745","IsPullRequest":false,"CreatedAt":"2018-07-09T23:24:12","Actor":"mjmckp","Number":"512","RawContent":null,"Title":"Make grid search of parameter space more efficient","State":"open","Body":"The ML.Net library suffers from a lack of decoupling between data preparation and model training, required to do an efficient grid search over training parameters.\r\n\r\nThat is, ideally the API should be structured in such a way that it is possible to do the following:\r\n\r\n1. Prepare the data set once, so that it can be **re-used multiple times**.  As much as possible, any pre-training calculations should be done up front (or perhaps cached to be re-used).  For large data sets, the overhead of repeating this step each time is significant, taking as long or longer than the training itself.\r\n2. For algorithms with multiple training iterations, it should be straightforward to **retain the intermediate trained models** at each iteration (or at a specified set of iterations).  This way, it is then easy to compute metrics for the intermediate models on training and validation data sets, and ultimately select one of the intermediate models for use in production without having to re-run the training.\r\n\r\nFor example, consider training a LightGBM model.  This is the training method in `LightGbmTrainerBase.cs`:\r\n```\r\n        public void Train(RoleMappedData data)\r\n        {\r\n            Dataset dtrain;\r\n            CategoricalMetaData catMetaData;\r\n            using (var ch = Host.Start(\"Loading data for LightGBM\"))\r\n            {\r\n                using (var pch = Host.StartProgressChannel(\"Loading data for LightGBM\"))\r\n                    dtrain = LoadTrainingData(ch, data, out catMetaData);\r\n                ch.Done();\r\n            }\r\n            using (var ch = Host.Start(\"Training with LightGBM\"))\r\n            {\r\n                using (var pch = Host.StartProgressChannel(\"Training with LightGBM\"))\r\n                    TrainCore(ch, pch, dtrain, catMetaData);\r\n                ch.Done();\r\n            }\r\n            dtrain.Dispose();\r\n            DisposeParallelTraining();\r\n        }\r\n```\r\n\r\nIn order to address point 1) above, the `dtrain` object returned by `LoadTrainingData` should be available to be re-used.  This would require that the configuration parameters for data preparation are specified separately to those for training, instead of all thrown in together into the `LightGbmArguments` type.\r\n\r\nNow, in regards to point 2) above, note that the `TrainCore` method calls `WrappedLightGBMTraining.Train`, which has the following structure:\r\n```\r\n        public static Booster Train(IChannel ch, IProgressChannel pch,\r\n            Dictionary<string, object> parameters, Dataset dtrain, Dataset dvalid = null, int numIteration = 100,\r\n            bool verboseEval = true, int earlyStoppingRound = 0)\r\n        {\r\n            // create Booster.\r\n            Booster bst = new Booster(parameters, dtrain, dvalid);\r\n\r\n            for (int iter = 0; iter < numIteration; ++iter)\r\n            {\r\n                // training logic\r\n            }\r\n            return bst;\r\n        }\r\n```\r\nIn order to get the intermediate models, this method should return `Booster []` instead of just the final `Booster` (or perhaps instead in this case, the `Booster` object should support extraction of a prediction model which only contains the first `N` trees of the ensemble).\r\n\r\nPerhaps there is already the facility to do this in ML.Net, but I'm unable to find anything from my reading of the source or any of the examples.\r\n\r\nI think 99.9% of all machine learning research requires doing a parameter grid search at some stage, and hence this is essential functionality that should be as efficient as possible.","Url":"https://github.com/dotnet/machinelearning/issues/512","RelatedDescription":"Open issue \"Make grid search of parameter space more efficient\" (#512)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-07-17T05:30:38.8365507Z","RunDurationInMilliseconds":1074}