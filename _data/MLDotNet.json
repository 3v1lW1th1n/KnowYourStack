{"Data":{"GitHub":{"Issues":[{"Id":"378579525","IsPullRequest":false,"CreatedAt":"2018-11-08T04:57:31","Actor":"sfilipi","Number":"1576","RawContent":null,"Title":"Remove the copyright from the samples files","State":"open","Body":"There is no need for copyright in the docs/Microsoft.Ml.Samples project source files. \r\n1- Remove the copyright from the docs/Microsoft.Ml.Samples project sources.\r\n2- Change the other source files files that reference the samples in the XML to not contain a range\r\n. like [here](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.FastTree/TreeTrainersStatic.cs#L41): \r\n\r\nthe reference to the other file is:\r\n\r\n`[!code-csharp[FastTree](~/../docs/samples/docs/samples/Microsoft.ML.Samples/Static/FastTreeRegression.cs?range=6-11,19-69 \"FastTree regression example.\")]\r\n`\r\nand it should change to not include a range nor comment anymore:\r\n\r\n`[!code-csharp[FastTree](~/../docs/samples/docs/samples/Microsoft.ML.Samples/Static/FastTreeRegression.cs)]\r\n`\r\n \r\n","Url":"https://github.com/dotnet/machinelearning/issues/1576","RelatedDescription":"Open issue \"Remove the copyright from the samples files\" (#1576)"},{"Id":"378559227","IsPullRequest":false,"CreatedAt":"2018-11-08T03:03:50","Actor":"najeeb-kazmi","Number":"1575","RawContent":null,"Title":"ClusteringContext should have CrossValidate","State":"open","Body":"Currently, `ClusteringContext` lacks a `CrossValidate` method. We should add this for completeness and parity with the internal code which supports CV on clustering tasks.","Url":"https://github.com/dotnet/machinelearning/issues/1575","RelatedDescription":"Open issue \"ClusteringContext should have CrossValidate\" (#1575)"},{"Id":"378559185","IsPullRequest":true,"CreatedAt":"2018-11-08T03:03:38","Actor":"abgoswam","Number":"1574","RawContent":null,"Title":"WIP : More OVA Fixes","State":"open","Body":"Targets issue : #1387 \r\n\r\n- bug in OVA. Under the hood we were using LinearSVM as the binary classifier all the time \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1574","RelatedDescription":"Open PR \"WIP : More OVA Fixes\" (#1574)"},{"Id":"378542051","IsPullRequest":true,"CreatedAt":"2018-11-08T01:37:35","Actor":"najeeb-kazmi","Number":"1573","RawContent":null,"Title":"Fixing typo in ExtractWordEmbeddings","State":"open","Body":"Fix #1548 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/1573","RelatedDescription":"Open PR \"Fixing typo in ExtractWordEmbeddings\" (#1573)"},{"Id":"378530330","IsPullRequest":false,"CreatedAt":"2018-11-08T00:41:11","Actor":"wschin","Number":"1572","RawContent":null,"Title":"Some times we may want to provide test set in addition to training and validation sets","State":"open","Body":"Imagining that one day, a user prepares a training set and a validation, and she wants to train a `FastTree` (gradient boosting decision tree) with early stopping. Then, she probably also would like to know how good our early stopping is by calculating a score based on some predictions. If this is the case, she may need another data set (let's call it test set) because it's not fair to use validation set again because the training iteration number is determined by validation set via early stopping.","Url":"https://github.com/dotnet/machinelearning/issues/1572","RelatedDescription":"Open issue \"Some times we may want to provide test set in addition to training and validation sets\" (#1572)"},{"Id":"378508339","IsPullRequest":true,"CreatedAt":"2018-11-07T23:07:06","Actor":"wschin","Number":"1571","RawContent":null,"Title":"[WIP] Printing out test scores in training phase for FastTree","State":"open","Body":"The current `FastTree` (defined in `FastTree.cs`) has a nice framework for handling the presence of training, validation, and test sets. This PR exposes this functionality to users by\r\n\r\n1. Extend `MLContext` defined in `TrainContext.cs`\r\n2. Create `Test` (defined in `Test.cs` under `FastTree` project) following what we having been doing for validation set.\r\n3. Make sure that the test data set can be accessed in `FastTree.InitializeTests()` when using `Train` or `TrainTest` commands.\r\n\r\nFixes #1572.","Url":"https://github.com/dotnet/machinelearning/pull/1571","RelatedDescription":"Open PR \"[WIP] Printing out test scores in training phase for FastTree\" (#1571)"},{"Id":"378503408","IsPullRequest":true,"CreatedAt":"2018-11-07T22:49:52","Actor":"ganik","Number":"1570","RawContent":null,"Title":"Register assemblies in  legacy predictor model","State":"open","Body":"fixes #1150","Url":"https://github.com/dotnet/machinelearning/pull/1570","RelatedDescription":"Open PR \"Register assemblies in  legacy predictor model\" (#1570)"},{"Id":"378496767","IsPullRequest":true,"CreatedAt":"2018-11-07T22:28:47","Actor":"Zruty0","Number":"1569","RawContent":null,"Title":"Added support for caching and filtering","State":"open","Body":"Fixes #1568 . Adds caching and range filtering as MLContext extensions","Url":"https://github.com/dotnet/machinelearning/pull/1569","RelatedDescription":"Open PR \"Added support for caching and filtering\" (#1569)"},{"Id":"378496469","IsPullRequest":false,"CreatedAt":"2018-11-07T22:27:54","Actor":"Zruty0","Number":"1568","RawContent":null,"Title":"Add support for caching and filtering","State":"open","Body":"We need to add the API to cache the data view in memory (via `CacheDataView`).\r\n\r\nAlso, we want to add some filtering functionality: I think `RangeFilter` is enough. We have agreed in #933 to not make estimators/transformers for filtering, so I suggest to have only `MLContext` extensions for these operations.","Url":"https://github.com/dotnet/machinelearning/issues/1568","RelatedDescription":"Open issue \"Add support for caching and filtering\" (#1568)"},{"Id":"378155580","IsPullRequest":true,"CreatedAt":"2018-11-07T22:26:32","Actor":"TomFinley","Number":"1563","RawContent":null,"Title":"Moving IModelCombiner to Ensemble and related changes","State":"closed","Body":"This is an elaborate series of changes that are, incredibly, actually related and strongly dependent on each other. The end result is positive, but how we got there was kind of a wild ride. Hearken to my tale.\r\n\r\n* Move IModelCombiner out of Core to Ensemble since it clearly belongs there,\r\n  not in Core.\r\n\r\n* Remove dependency of Ensemble on FastTree.\r\n\r\n* Remove learners in Ensemble having defaults of FastTree or indeed any\r\n  learner. (Incidentally: fixes #682.)\r\n\r\n* Rename *FastTree* Ensemble to TreeEnsemble, so as to avoid namespace/type\r\n  collisions with that type and Ensemble namespace.\r\n\r\n* Add dependency of FastTree to Ensemble project so something there can\r\n  implement TreeEnsembleCombiner.\r\n\r\n* Resolve circular dependency of FastTree -> Ensemble -> StandardLearners ->\r\n  Legacy -> FastTree by removing Legacy as dependency of StandardLearners,\r\n  since no project we intend to keep should depend on Legacy.\r\n\r\n* Move Legacy specific infrastructure that somehow was in StandardLearners\r\n  over to Legacy.\r\n\r\n* Fix documentation in StandardLearners that was incorrectly referring to the\r\n  Legacy pipelines and types directly, since in reality they have nothing to\r\n  do with the types in Legacy.","Url":"https://github.com/dotnet/machinelearning/pull/1563","RelatedDescription":"Closed or merged PR \"Moving IModelCombiner to Ensemble and related changes\" (#1563)"},{"Id":"378493367","IsPullRequest":false,"CreatedAt":"2018-11-07T22:18:22","Actor":"artidoro","Number":"1567","RawContent":null,"Title":"Access whitening transform models","State":"open","Body":"There is no way for the user to access the models produced by the whitening transform (the whitening matrices). We would need to expose that, as well as a function that allows to apply the matrix to new suitable input vectors (something similar to FillValues in the current code).\r\n\r\nFurthermore, we need to have an onFit function for pigsty to pass this class out.\r\n\r\nAdding @Ivanidzo4ka  to the conversation. \r\n","Url":"https://github.com/dotnet/machinelearning/issues/1567","RelatedDescription":"Open issue \"Access whitening transform models\" (#1567)"},{"Id":"378064821","IsPullRequest":true,"CreatedAt":"2018-11-07T22:06:00","Actor":"sfilipi","Number":"1555","RawContent":null,"Title":"adding more logging to failures.","State":"closed","Body":"Fixes #1477 by adding more logging around the failure on the baselines number comparison. \r\n\r\nLogging on failures looks like this now:\r\n\r\n```\r\nValues to compare are 0.49224 and 0.49223705031518167\r\n\t AllowedVariance: 1E-07\r\n\t delta: 2.9E-06\r\n\t delta2: 2.9E-06\r\n\r\n*** Failure: Output and baseline mismatch at line 3: 'FieldAwareFactorizationMachine\\FieldAwareFactorizationMachine-CV-breast-cancer.txt\r\n```'\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1555","RelatedDescription":"Closed or merged PR \"adding more logging to failures.\" (#1555)"},{"Id":"378472284","IsPullRequest":true,"CreatedAt":"2018-11-07T21:15:49","Actor":"jwood803","Number":"1566","RawContent":null,"Title":"[WIP] Add debug asserts","State":"open","Body":"Potential fix for #828 \r\n\r\n@briancylui Is this on the right track to what was needed? Do you think we should do the same to the `AvxIntrinsics` class, as well?","Url":"https://github.com/dotnet/machinelearning/pull/1566","RelatedDescription":"Open PR \"[WIP] Add debug asserts\" (#1566)"},{"Id":"378096347","IsPullRequest":true,"CreatedAt":"2018-11-07T19:35:18","Actor":"artidoro","Number":"1561","RawContent":null,"Title":"Publish test artifacts on timeout and not just failure","State":"closed","Body":"Fixes #1556.\r\n\r\nIn this PR I add a condition so that we post test artifacts not just in case of failures, but also in case of timeouts, by using `not(succeeded())` condition.\r\n\r\nI also set the timeout limit for the running the tests to 40 min (this does not include the build time). Still working on the right syntax for the timeout setting.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1561","RelatedDescription":"Closed or merged PR \"Publish test artifacts on timeout and not just failure\" (#1561)"},{"Id":"378074610","IsPullRequest":false,"CreatedAt":"2018-11-07T19:35:18","Actor":"artidoro","Number":"1556","RawContent":null,"Title":"No artifacts produced when CI builds time out","State":"closed","Body":"This is related to #1473.\r\n\r\nOur current CI builds hang quite often. #1473 suggests to retain the output files produced during tests and inspect them to help identify the problem. Thanks to #1527 we now produce artifacts. However, we only produce them when the builds fail, and not when they time out. It would be useful to produce the artifacts also when the builds time out as that is a significant part of the current build issues encountered. \r\n\r\nTake https://dnceng.visualstudio.com/public/_build/results?buildId=40590&view=logs for example. You cannot access the artifacts because the build simply timed out. \r\n\r\nHere instead, there was one build failure and one time out. You can only access artifacts for the build that failed. https://dnceng.visualstudio.com/public/_build/results?buildId=40591&view=logs\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1556","RelatedDescription":"Closed issue \"No artifacts produced when CI builds time out\" (#1556)"},{"Id":"378359193","IsPullRequest":false,"CreatedAt":"2018-11-07T16:14:08","Actor":"TomFinley","Number":"1565","RawContent":null,"Title":"Legacy API: Should we migrate its entry-points?","State":"open","Body":"The plan is to deprecate then delete the legacy API. While most items in it are of questionable worth, the legacy API does contain some components that might be worth saving, and some we may have to save.\r\n\r\nConsider this entry-point definition, in the legacy project.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7b2461cfdad150047dbbcbc163290a32e9f4d829/src/Microsoft.ML.Legacy/Runtime/EntryPoints/ModelOperations.cs#L81\r\n\r\nAs it is an entry-point, it was [duly published in NimbusML as we see here](https://github.com/Microsoft/NimbusML/blob/e1004720ec0c252ba87f02c190c33739d9c00f20/src/python/nimbusml/internal/entrypoints/models_ovamodelcombiner.py), and this internal entry-point definition actually [wound up being used here](https://github.com/Microsoft/NimbusML/blob/e1004720ec0c252ba87f02c190c33739d9c00f20/src/python/nimbusml/model_selection/cv.py#L474).\r\n\r\nThere are a couple questions we might want to ask. The legacy pipeline API was entry-point based, so anything that was part of a pipeline had to be an entry-point (I think). So were these entry-points defined in legacy *specifically* intended to be useful beyond legacy?\r\n\r\nIf we want to keep this entry-point, and others like it, we should have a migration plan somewhere, since legacy is to be deleted.","Url":"https://github.com/dotnet/machinelearning/issues/1565","RelatedDescription":"Open issue \"Legacy API: Should we migrate its entry-points?\" (#1565)"},{"Id":"378292503","IsPullRequest":true,"CreatedAt":"2018-11-07T13:42:16","Actor":"feiyun0112","Number":"1564","RawContent":null,"Title":"Pass hashBits, invertHash to OneHotHashEncodingEstimator","State":"open","Body":"Fix #1560 ","Url":"https://github.com/dotnet/machinelearning/pull/1564","RelatedDescription":"Open PR \"Pass hashBits, invertHash to OneHotHashEncodingEstimator\" (#1564)"},{"Id":"378152965","IsPullRequest":false,"CreatedAt":"2018-11-07T05:57:51","Actor":"AceHack","Number":"1562","RawContent":null,"Title":"Please support Keras","State":"open","Body":"Tensor flow is really nice but Keras support would be great!!  We would then get Theano and CNTK.","Url":"https://github.com/dotnet/machinelearning/issues/1562","RelatedDescription":"Open issue \"Please support Keras\" (#1562)"},{"Id":"378038636","IsPullRequest":true,"CreatedAt":"2018-11-07T01:12:12","Actor":"Zruty0","Number":"1551","RawContent":null,"Title":"Making RowMapperTransform a template","State":"closed","Body":"Making RowMapperTransform a template, avoiding load/save for wrapped transformers containing non-wrapped transformers\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1551","RelatedDescription":"Closed or merged PR \"Making RowMapperTransform a template\" (#1551)"},{"Id":"378093070","IsPullRequest":false,"CreatedAt":"2018-11-07T00:34:51","Actor":"sfilipi","Number":"1560","RawContent":null,"Title":"Categorical Hash transform Create method ignores the number of HashBits ","State":"open","Body":"Looking at the [Create method](https://github.com/dotnet/machinelearning/blob/850f91c2e67679a825b49d3eefd96dea2cc2c153/src/Microsoft.ML.Transforms/CategoricalHashTransform.cs#L148) it doesn't pass the number of HashBits to the OneHotHashEncodingEstimator. ","Url":"https://github.com/dotnet/machinelearning/issues/1560","RelatedDescription":"Open issue \"Categorical Hash transform Create method ignores the number of HashBits \" (#1560)"},{"Id":"378083716","IsPullRequest":true,"CreatedAt":"2018-11-06T23:51:56","Actor":"danmosemsft","Number":"1559","RawContent":null,"Title":"Update README to add 32 bit support in 0.7","State":"open","Body":"Also change .NET Core 2.0 - >2.1 as 2.0 is now out of support.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1559","RelatedDescription":"Open PR \"Update README to add 32 bit support in 0.7\" (#1559)"},{"Id":"378078134","IsPullRequest":true,"CreatedAt":"2018-11-06T23:28:13","Actor":"sfilipi","Number":"1558","RawContent":null,"Title":"sample link and xml format  fixes","State":"open","Body":"Fixes #1557 by correcting the link and XML format. \r\n","Url":"https://github.com/dotnet/machinelearning/pull/1558","RelatedDescription":"Open PR \"sample link and xml format  fixes\" (#1558)"},{"Id":"378077981","IsPullRequest":false,"CreatedAt":"2018-11-06T23:27:36","Actor":"sfilipi","Number":"1557","RawContent":null,"Title":"The format of the example XML is not correct in a few cases. ","State":"open","Body":"The sample link for the NormalizerCatalog.cs has an extra bracket out of place. \r\nThe samples in MatrixFactorization and TimeSeries are missing the surrounding <example> XML  node. \r\n\r\nThose are causing problems with the samples displaying in the APIs documentation site. ","Url":"https://github.com/dotnet/machinelearning/issues/1557","RelatedDescription":"Open issue \"The format of the example XML is not correct in a few cases. \" (#1557)"},{"Id":"378054234","IsPullRequest":false,"CreatedAt":"2018-11-06T22:08:01","Actor":"helloguo","Number":"1554","RawContent":null,"Title":"Build failed on Ubuntu 18.04","State":"open","Body":"Build failed on Ubuntu 18.04. The ML.NET was forked today 11/6/18. The error msg says tensorflow.redist is not able to be downloaded as shown below. Any guidance to solve it? Thank you.\r\n\r\n![build-fail](https://user-images.githubusercontent.com/18431130/48096873-45c6c580-e1cd-11e8-9736-4ee6e355af0d.PNG)\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1554","RelatedDescription":"Open issue \"Build failed on Ubuntu 18.04\" (#1554)"},{"Id":"378045075","IsPullRequest":false,"CreatedAt":"2018-11-06T21:41:24","Actor":"CESARDELATORRE","Number":"1553","RawContent":null,"Title":"Saving a DataView to a file should be simpler and not through to the LocalEnvironment class","State":"open","Body":"I'm using v0.7.\r\nIssue: Saving a DataView to a file should be simpler and not having to directly use the LocalEnvironment class.\r\nIf there's any new way to do this in v0.7 or v08, please tell me, but I haven't found it. :)\r\n\r\nAs far as I know, this is the code needed, currently:\r\n\r\n```\r\n                // save test split dataset\r\n                IHostEnvironment env = (IHostEnvironment)mlContext;\r\n                using (var ch = env.Start(\"SaveData\"))\r\n                using (var file = env.CreateOutputFile(Path.Combine(_outputPath, \"testData.idv\")))\r\n                {\r\n                    var saver = new BinarySaver(mlContext, new BinarySaver.Arguments());\r\n                    DataSaverUtils.SaveDataView(ch, saver, testDataView, file);\r\n                }\r\n```\r\n\r\nFirst, it needs to use the `IChannel` object that has to be obtained from the `IHostEnvironment` object that you can get by casting the `MLContext `object to `IHostEnvironment`. The developer shouldn't need to use `IHostEnvironment` in any case, I think.\r\n\r\nThen, still a few more lines for saving the file.\r\n\r\nWe should aim to achieve a simpler API for doing this, just something like:\r\n\r\n`testDataView.SaveToFile(testDataSetFilePath);`\r\n\r\nOr if we need to do it through any utility class:\r\n\r\n`DataSaverUtils.SaveDataViewToFile(testDataView, testDataSetFilePath);`\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1553","RelatedDescription":"Open issue \"Saving a DataView to a file should be simpler and not through to the LocalEnvironment class\" (#1553)"},{"Id":"378038696","IsPullRequest":true,"CreatedAt":"2018-11-06T21:22:53","Actor":"rantri","Number":"1552","RawContent":null,"Title":"Fixes #1550 - Type mismatch in TransformSamples.SampleInfertDataWithFeatures","State":"open","Body":"Fixes #1550\r\n\r\nType mismatch in TransformSamples.SampleInfertDataWithFeatures\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1552","RelatedDescription":"Open PR \"Fixes #1550 - Type mismatch in TransformSamples.SampleInfertDataWithFeatures\" (#1552)"},{"Id":"378035743","IsPullRequest":false,"CreatedAt":"2018-11-06T21:14:10","Actor":"rantri","Number":"1550","RawContent":null,"Title":"Type mismatch in TransformSamples.SampleInfertDataWithFeatures","State":"open","Body":"Type should be changed from int to float.\r\n\r\nFrom:\r\n```\r\nclass SampleInfertDataWithFeatures\r\n{\r\n    public VBuffer<int> Features { get; set; }\r\n}\r\n```\r\n\r\nTo:\r\n\r\n```\r\nclass SampleInfertDataWithFeatures\r\n{\r\n    public VBuffer<float> Features { get; set; }\r\n}\r\n```\r\n\r\nIt caused exception:\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Can't bind the IDataView column 'Features' of type 'Vec<R4, 3>' to field or property 'Features' of type 'Microsoft.ML.Runtime.Data.VBuffer`1[[System.Int32, System.Private.CoreLib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]]'.\r\n  Source=Microsoft.ML.Api\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.Api.TypedCursorable`1..ctor(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, InternalSchemaDefinition schemaDefn) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 129\r\n   at Microsoft.ML.Runtime.Api.TypedCursorable`1.Create(IHostEnvironment env, IDataView data, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 249\r\n   at Microsoft.ML.Runtime.Api.CursoringUtils.AsCursorable[TRow](IDataView data, IHostEnvironment env, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 550\r\n   at Microsoft.ML.Runtime.Api.PipeEngine`1..ctor(IHostEnvironment env, IDataView pipe, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\PredictionEngine.cs:line 98\r\n   at Microsoft.ML.Runtime.Api.CursoringUtils.AsEnumerable[TRow](IDataView data, IHostEnvironment env, Boolean reuseRowObject, Boolean ignoreMissingColumns, SchemaDefinition schemaDefinition) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\src\\Microsoft.ML.Api\\TypedCursor.cs:line 589\r\n   at Microsoft.ML.Samples.Dynamic.TransformSamples.ConcatTransform() in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Dynamic\\ConcatTransform.cs:line 49\r\n   at Microsoft.ML.Samples.Program.Main(String[] args) in C:\\Users\\rtrifon\\Documents\\GitHub\\machinelearning\\docs\\samples\\Microsoft.ML.Samples\\Program.cs:line 13\r\n \r\n","Url":"https://github.com/dotnet/machinelearning/issues/1550","RelatedDescription":"Open issue \"Type mismatch in TransformSamples.SampleInfertDataWithFeatures\" (#1550)"},{"Id":"378021332","IsPullRequest":false,"CreatedAt":"2018-11-06T20:32:12","Actor":"cosmincatalin","Number":"1549","RawContent":null,"Title":"Scoring with ONNX does not work as expected","State":"open","Body":"I have an _onnx_ model generated from an MXNet model. I try to use it for scoring a regression problem. It does not work. Here are the steps I followed:\r\n\r\n## Build the MXNet model\r\n\r\n```python\r\nimport pandas as pd\r\n```\r\n\r\n```python\r\ndf_train = pd.read_csv(\"train.csv\")\r\ndf_test = pd.read_csv(\"test.csv\")\r\n```\r\n\r\n\r\n```python\r\nimport mxnet as mx\r\n```\r\n\r\n\r\n```python\r\ntrain_X = mx.nd.array(df_train.drop(\"Target\", axis=1).values)\r\ntrain_y = mx.nd.array(df_train.Target.values)\r\ntest_X = mx.nd.array(df_test.drop(\"Target\", axis=1).values)\r\ntest_y = mx.nd.array(df_test.Target.values)\r\ntrain_nd = list(zip(train_X, train_y))\r\ntest_nd = list(zip(test_X, test_y))\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet.gluon.data import DataLoader\r\n```\r\n\r\n\r\n```python\r\nbatch_size = 64\r\n```\r\n\r\n\r\n```python\r\ntrain_data = DataLoader(train_nd, batch_size, shuffle=True)\r\ntest_data = DataLoader(test_nd, batch_size, shuffle=True)\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet.gluon.nn import HybridSequential, Dense, Dropout\r\nfrom mxnet.initializer import Xavier\r\nfrom mxnet.gluon.loss import L2Loss\r\nfrom mxnet.gluon.trainer import Trainer\r\n```\r\n\r\n\r\n```python\r\nnet = HybridSequential()\r\nwith net.name_scope():\r\n    net.add(Dense(9))\r\n    net.add(Dropout(.25))\r\n    net.add(Dense(16))\r\n    net.add(Dropout(.25))\r\n    net.add(Dense(1))\r\n```\r\n\r\n\r\n```python\r\nnet.hybridize()\r\n```\r\n\r\n\r\n```python\r\nctx = mx.cpu()\r\n```\r\n\r\n\r\n```python\r\nnet.collect_params().initialize(Xavier(magnitude=2.24), ctx=ctx)\r\n```\r\n\r\n\r\n```python\r\nloss = L2Loss()\r\n```\r\n\r\n\r\n```python\r\ntrainer = Trainer(net.collect_params(), optimizer=\"adam\")\r\n```\r\n\r\n\r\n```python\r\nsmoothing_constant = .01\r\nepochs = 5\r\n```\r\n\r\n\r\n```python\r\ndef measure_performance(model, ctx, data_iter):\r\n    mae = mx.metric.MAE()\r\n    for _, (data, labels) in enumerate(data_iter):\r\n        data = data.as_in_context(ctx)\r\n        labels = labels.as_in_context(ctx)\r\n        output = model(data)\r\n        predictions = output\r\n        mae.update(preds=predictions, labels=labels)\r\n    return mae.get()[1]\r\n```\r\n\r\n\r\n```python\r\nfrom mxnet import autograd\r\n```\r\n\r\n\r\n```python\r\nfor e in range(epochs):\r\n    moving_loss = 0\r\n    for i, (data, label) in enumerate(train_data):\r\n        data = data.as_in_context(ctx)\r\n        label = label.as_in_context(ctx)\r\n        with autograd.record():\r\n            output = net(data)\r\n            loss_result = loss(output, label)\r\n        loss_result.backward()\r\n        trainer.step(batch_size)\r\n\r\n        curr_loss = mx.nd.mean(loss_result).asscalar()\r\n        moving_loss = (curr_loss if ((i == 0) and (e == 0))\r\n                       else (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss)\r\n\r\n    test_mae = measure_performance(net, ctx, test_data)\r\n    train_mae = measure_performance(net, ctx, train_data)\r\n    print(\"Epoch %s. Loss: %s, Train_mae %s, Test_mae %s\" % (e, moving_loss, train_mae, test_mae))\r\n```\r\nOutput:\r\n\r\n    Epoch 0. Loss: 5.848355519538663, Train_mae 1.1675882118595375, Test_mae 1.2460664133482342\r\n    Epoch 1. Loss: 2.8617846590961733, Train_mae 0.8983533112182495, Test_mae 0.9300098409758338\r\n    Epoch 2. Loss: 1.6959465687435336, Train_mae 0.6692642353930274, Test_mae 0.6831557900656627\r\n    Epoch 3. Loss: 0.91648433711298, Train_mae 0.5097093659054811, Test_mae 0.5119943500885481\r\n    Epoch 4. Loss: 0.5725724269757653, Train_mae 0.4398727014996231, Test_mae 0.4710224339667755\r\n    \r\n\r\n\r\n```python\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\nnet(mx.nd.array(np.expand_dims(np.ones(9), axis=0))).asnumpy().ravel().tolist()[0]\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    7.281115531921387\r\n\r\n\r\n\r\n\r\n```python\r\nnet.export(\"model\", epoch=epochs - 1)\r\n```\r\n\r\n**7.281115531921387 is what I expect to get when I provide _ones_ as feature.**\r\n\r\n## Export the MXNet model as ONNX\r\n\r\n\r\n\r\n```python\r\nfrom mxnet.contrib import onnx as onnx_mxnet\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\nonnx_mxnet.export_model(sym=\"model-symbol.json\",\r\n                  params=\"model-0004.params\",\r\n                  input_shape=[(1, 9)],\r\n                  input_type=np.float32,\r\n                  onnx_file_path=\"model.onnx\",\r\n                  verbose=True)\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    'model.onnx'\r\n\r\nThe model as visualized with Netron is as follows (the model is trivial):\r\n\r\n![model](https://user-images.githubusercontent.com/525590/48091230-61e85800-e209-11e8-83fe-4cd66e067e2f.png)\r\n\r\n## Testing with Tensorflow\r\n\r\nBefore loading the onnx model into ML.NET I tested it with Tensorflow\r\n\r\n\r\n\r\n```python\r\nimport onnx\r\n```\r\n\r\n\r\n```python\r\nmodel = onnx.load(\"model.onnx\")\r\n```\r\n\r\n\r\n```python\r\nfrom onnx_tf.backend import prepare\r\n```\r\n\r\n\r\n```python\r\ntf_rep = prepare(model)\r\n```\r\n\r\nOutput:\r\n\r\n    c:\\users\\cosmin\\dev\\generate-mxnet-model\\env\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:74: UserWarning: Unknown op ConstantLike in domain `ai.onnx`.\r\n      handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\r\n    \r\n\r\n\r\n```python\r\nimport numpy as np\r\n```\r\n\r\n\r\n```python\r\ntf_rep.run(np.expand_dims(np.ones(9), axis=0)).hybridsequential0_dense2_fwd.ravel().tolist()[0]\r\n```\r\n\r\n\r\nOutput:\r\n\r\n    7.281115531921387\r\n\r\n\r\n\r\n\r\n```python\r\ntf_rep.export_graph(\"model.pb\")\r\n```\r\n\r\n**As you can see running the regression on ones returns the expected result: 7.281115531921387**\r\n\r\n## ML.NET 0.7\r\n\r\nMy programs is as follows:\r\n\r\n`Program.cs`\r\n```csharp\r\nusing System;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Runtime.Data;\r\nusing Microsoft.ML.Transforms;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n    internal static class Program\r\n    {\r\n        private static void Main(string[] args)\r\n        {\r\n            var env = new MLContext();\r\n            var reader = TextLoader.CreateReader(env,\r\n                ctx => (\r\n                    Feature1: ctx.LoadFloat(0),\r\n                    Feature2: ctx.LoadFloat(1),\r\n                    Feature3: ctx.LoadFloat(2),\r\n                    Feature4: ctx.LoadFloat(3),\r\n                    Feature5: ctx.LoadFloat(4),\r\n                    Feature6: ctx.LoadFloat(5),\r\n                    Feature7: ctx.LoadFloat(6),\r\n                    Feature8: ctx.LoadFloat(7),\r\n                    Feature9: ctx.LoadFloat(8),\r\n                    Target: ctx.LoadFloat(9)),\r\n                separator: ',',\r\n                hasHeader: true);\r\n            var data = reader.Read(new MultiFileSource(\"test.csv\"));\r\n            \r\n            var learningPipeline = reader.MakeNewEstimator()\r\n                .Append(row => (Target: row.Target, Features: row.Feature1.ConcatWith(\r\n                    row.Feature2, row.Feature3, row.Feature4, row.Feature5, row.Feature6,\r\n                    row.Feature7, row.Feature8, row.Feature9)))\r\n                .Append(row => (Truth: row.Target, Estimate: row.Features.ApplyOnnxModel(\"model.onnx\")));\r\n\r\n            var model = learningPipeline.Fit(data);\r\n            \r\n            var predictionFunction = model.AsDynamic.MakePredictionFunction<SearchData, SearchPrediction>(env);\r\n\r\n            var prediction = predictionFunction.Predict(new SearchData()\r\n            {\r\n                Feature1 = 1.0f,\r\n                Feature2 = 1.0f,\r\n                Feature3 = 1.0f,\r\n                Feature4 = 1.0f,\r\n                Feature5 = 1.0f,\r\n                Feature6 = 1.0f,\r\n                Feature7 = 1.0f,\r\n                Feature8 = 1.0f,\r\n                Feature9 = 1.0f\r\n            });            \r\n            Console.WriteLine(prediction.Estimate);\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n`SearchData.cs`\r\n```csharp\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n\r\n    public class SearchData\r\n    {\r\n        [ColumnName(\"Target\")]\r\n        public float DummyUnused{ get; set; }\r\n        \r\n        public float Feature1{ get; set; }\r\n\r\n        public float Feature2{ get; set; }\r\n\r\n        public float Feature3{ get; set; }\r\n\r\n        public float Feature4{ get; set; }\r\n\r\n        public float Feature5{ get; set; }\r\n\r\n        public float Feature6{ get; set; }\r\n\r\n        public float Feature7{ get; set; }\r\n\r\n        public float Feature8{ get; set; }\r\n\r\n        public float Feature9{ get; set; }\r\n\r\n    }\r\n\r\n}\r\n\r\n```\r\n\r\n`SearchPrediction.cs`\r\n```csharp\r\nusing Microsoft.ML.Runtime.Api;\r\n\r\nnamespace ml.net_with_mxnet\r\n{\r\n    public class SearchPrediction\r\n    {\r\n        [ColumnName(\"Target\")]\r\n        public float Estimate{ get; set; }\r\n    }\r\n}\r\n\r\n```\r\n\r\nWhen running the program, I get 0, which is not great. The training and test sets are just full of 10 columns of floats.\r\n\r\nI also attach the `pip` requirements.txt file, so that you can see the onnx version I've used\r\n\r\n```\r\nabsl-py==0.6.1\r\nastor==0.7.1\r\nbackcall==0.1.0\r\nbleach==3.0.2\r\ncertifi==2018.10.15\r\nchardet==3.0.4\r\ncolorama==0.4.0\r\ndecorator==4.3.0\r\ndefusedxml==0.5.0\r\nentrypoints==0.2.3\r\ngast==0.2.0\r\ngraphviz==0.8.4\r\ngrpcio==1.16.0\r\nh5py==2.8.0\r\nidna==2.6\r\nipykernel==5.1.0\r\nipython==7.1.1\r\nipython-genutils==0.2.0\r\nipywidgets==7.4.2\r\njedi==0.13.1\r\nJinja2==2.10\r\njsonschema==2.6.0\r\njupyter==1.0.0\r\njupyter-client==5.2.3\r\njupyter-console==6.0.0\r\njupyter-core==4.4.0\r\nKeras-Applications==1.0.6\r\nKeras-Preprocessing==1.0.5\r\nMarkdown==3.0.1\r\nMarkupSafe==1.0\r\nmistune==0.8.4\r\nmxnet==1.3.0\r\nnbconvert==5.4.0\r\nnbformat==4.4.0\r\nnotebook==5.7.0\r\nnumpy==1.14.6\r\nonnx==1.3.0\r\nonnx-tf==1.2.0\r\npandas==0.23.4\r\npandocfilters==1.4.2\r\nparso==0.3.1\r\npickleshare==0.7.5\r\nprometheus-client==0.4.2\r\nprompt-toolkit==2.0.7\r\nprotobuf==3.6.1\r\nPygments==2.2.0\r\npython-dateutil==2.7.5\r\npytz==2018.7\r\npywinpty==0.5.4\r\nPyYAML==3.13\r\npyzmq==17.1.2\r\nqtconsole==4.4.2\r\nrequests==2.18.4\r\nSend2Trash==1.5.0\r\nsix==1.11.0\r\ntensorboard==1.11.0\r\ntensorflow==1.11.0\r\ntermcolor==1.1.0\r\nterminado==0.8.1\r\ntestpath==0.4.2\r\ntornado==5.1.1\r\ntraitlets==4.3.2\r\ntyping==3.6.6\r\ntyping-extensions==3.6.6\r\nurllib3==1.22\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nWerkzeug==0.14.1\r\nwidgetsnbextension==3.4.2\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/1549","RelatedDescription":"Open issue \"Scoring with ONNX does not work as expected\" (#1549)"},{"Id":"377994073","IsPullRequest":true,"CreatedAt":"2018-11-06T20:18:47","Actor":"shauheen","Number":"1547","RawContent":null,"Title":"Cherrypick for release 0.7","State":"closed","Body":"Cherry-pick into release for 0.7","Url":"https://github.com/dotnet/machinelearning/pull/1547","RelatedDescription":"Closed or merged PR \"Cherrypick for release 0.7\" (#1547)"},{"Id":"378006080","IsPullRequest":false,"CreatedAt":"2018-11-06T19:48:14","Actor":"shmoradims","Number":"1548","RawContent":null,"Title":"Typo in name ExtractWordEmbeedings (extra e)","State":"open","Body":"typo: ExtractWordEmb**ee**dings -> ExtractWordEmb**e**ddings (double **d** instead of double **e**)\r\n\r\nLocation:\r\n        public static WordEmbeddingsExtractorEstimator ExtractWordEmbeedings(this TransformsCatalog.TextTransforms catalog,\r\n            string inputColumn,\r\n            string outputColumn = null,\r\n            WordEmbeddingsTransform.PretrainedModelKind modelKind = WordEmbeddingsTransform.PretrainedModelKind.Sswe)\r\n            => new WordEmbeddingsExtractorEstimator(Contracts.CheckRef(catalog, nameof(catalog)).GetEnvironment(), inputColumn, outputColumn, modelKind);\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1548","RelatedDescription":"Open issue \"Typo in name ExtractWordEmbeedings (extra e)\" (#1548)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-11-08T05:30:34.6134865Z","RunDurationInMilliseconds":1201}