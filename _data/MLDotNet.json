{"Data":{"GitHub":{"Issues":[{"Id":"503765806","IsPullRequest":true,"CreatedAt":"2019-10-08T02:56:12","Actor":"codemzs","Number":"4310","RawContent":null,"Title":"Modify image classification sample to take in-memory image for prediction.","State":"closed","Body":"fixes #4153\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4310","RelatedDescription":"Closed or merged PR \"Modify image classification sample to take in-memory image for prediction.\" (#4310)"},{"Id":"503674384","IsPullRequest":false,"CreatedAt":"2019-10-07T20:30:55","Actor":"Lynx1820","Number":"4309","RawContent":null,"Title":"LightGBM Build Failure","State":"open","Body":"### Issue\r\nI tried adding a test case to test RankingEvaluator with Maml using the LightGBMRanking trainer. The testcase passed on my machine and other build configurations. However, it failed on those same configurations on the github build. The testcase was added in response to issue #4081. To unblock me, I used the FastRankRanking trainer instead, which does work as expected.   \r\n\r\n### Source code / logs\r\nThe test case I added looks like this\r\n```\r\n        public void EvaluateRankingWithMaml()\r\n        {\r\n            string _mslrWeb10k_Train = GetDataPath(TestDatasets.MSLRWeb.trainFilename);\r\n            string extraArgs = \" tr=LightGBMRanking\" +\r\n                \" eval=RankingEvaluator{t=10}\" +\r\n                \" k=2\";\r\n            string loaderArgs = \" loader=TextLoader{col=Label:R4:0 col=GroupId:TX:1 col=Features:R4:2-138 header=+}\" +\r\n                \" xf = HashTransform{col=GroupId}\" +\r\n                \" xf = NAHandleTransform{col=Features}\";\r\n            int digitsOfPrecision = 2;\r\n            TestCore(\"cv\", _mslrWeb10k_Train, loaderArgs, extraArgs, digitsOfPrecision);\r\n            Done();\r\n\r\n        }\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4309","RelatedDescription":"Open issue \"LightGBM Build Failure\" (#4309)"},{"Id":"503667463","IsPullRequest":true,"CreatedAt":"2019-10-07T20:16:08","Actor":"tannergooding","Number":"4308","RawContent":null,"Title":"Adding a LoadColumnNameAttribute","State":"open","Body":"This resolves https://github.com/dotnet/machinelearning/issues/4195","Url":"https://github.com/dotnet/machinelearning/pull/4308","RelatedDescription":"Open PR \"Adding a LoadColumnNameAttribute\" (#4308)"},{"Id":"503626428","IsPullRequest":false,"CreatedAt":"2019-10-07T18:49:45","Actor":"eerhardt","Number":"4307","RawContent":null,"Title":"DnnCatalog methods should use a public Options class","State":"open","Body":"The two methods in `DnnCatalog`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c9f616fdc5a144250535949fc8c8f9c971cbab88/src/Microsoft.ML.Dnn/DnnCatalog.cs#L49-L63\r\n\r\nand\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c9f616fdc5a144250535949fc8c8f9c971cbab88/src/Microsoft.ML.Dnn/DnnCatalog.cs#L120-L143\r\n\r\nhave a lot of optional parameters, and users may get confused on which ones are important, and which aren't.\r\n\r\nI've seen comments from @terrajobst in the past saying:\r\n\r\n> In UX studies we have seen that many developers struggle with methods that have many optional arguments.\r\n\r\nIn ML.NET, the pattern we have established is that we have 2 overloads:\r\n\r\n1. An overload that takes the required parameters, and optionally the most important/common parameters to a method.\r\n2. An overload that takes an `Options` object, which contains all the options to the method - simple and advanced.\r\n\r\nWe should follow this pattern with these DNN APIs as well. See the discussions and related PRs to https://github.com/dotnet/machinelearning/issues/1798.\r\n\r\n/cc @ebarsoumMS @codemzs ","Url":"https://github.com/dotnet/machinelearning/issues/4307","RelatedDescription":"Open issue \"DnnCatalog methods should use a public Options class\" (#4307)"},{"Id":"503626211","IsPullRequest":true,"CreatedAt":"2019-10-07T18:49:17","Actor":"antoniovs1029","Number":"4306","RawContent":null,"Title":"(WIP) Fixes #4292 about using PFI with BPT and CMPB","State":"open","Body":"Fixes #4292 about using PFI with a `BinaryPredictionTransformer<>` and `CalibratedModelParametersBase<>`.\r\n\r\nThis is a draft, so more tests need to be added, and some comments might need to be removed. I will do that if this approach of solution is approved.\r\n\r\n### Approach of the solution\r\nRegarding the 3 problems listed in #4292 the solutions were the following:\r\n1. **To call the correct 'create' method**: I created a static non-generic class for `ParameterMixingCalibratedModelParameters` whose create method would call the create method of the generic `PMCMP<>` when loading a `PMCMP<>`.\r\n2. **To create a `PMCMP` object with the correct parameter types**: I used a similar approach as the one explained in my previous pull request #4262. Here the calibrator and submodel of the `PMCMP<>` are loaded first, and then they are used to create a generic type at runtime for `PMCMP<>` but now using the correct parameter types.\r\n3. **To create a `BPT<CMPB<>>` object whereas a `PMCMP<>` was loaded**: After trying different approaches that didn't work, the best way I found to fix this was to add a field to `PMCMP<>` called  `LoadType`. I modified the create method of the prediction transformers so that when loading, for example, a `BPT<>`, it would look at the `LoadType` of the internal model and use that as the parameter type for the `BPT<>`. In this case, at runtime, `LoadType` would be `CMPB<>` with the correct type parameters for the calibrator and submodel, and so the BPT can be correctly loaded as a `BPT<CMPB<>>` instead of  `BPT<PMCMP<>>` (which is what happens if only problems 1) and 2) are addressed). If the internal model doesn't have a field called `LoadType` then this is pretty much ignored, and the behavior is the same as before.\r\n\r\nIf there's a better way to solve problem 3) I will be very happy to hear it.\r\n\r\n### Changes implemented\r\n* Changes in `PredictionTransformer.cs` and `Calibrator.cs` to implement the approach previously described\r\n* Added a working sample for using PFI with BPT and CMPB while loading a model from disk. This is based entirely in the original sample.\r\n* Changed a couple of tests in `LbfgsTests.cs` that failed because they used casts that now return 'null'. Notice that those casts involved using classes such as `IPredictorProducing ` and `PMCMP `which are internal classes, so a regular user wouldn't have been able to use those casts. They have now been replaced with casts to `BPT<CMPB<>>` and `CMPB<>` using the correct type parameters of the model.","Url":"https://github.com/dotnet/machinelearning/pull/4306","RelatedDescription":"Open PR \"(WIP) Fixes #4292 about using PFI with BPT and CMPB\" (#4306)"},{"Id":"503613368","IsPullRequest":false,"CreatedAt":"2019-10-07T18:21:48","Actor":"eerhardt","Number":"4305","RawContent":null,"Title":"ML.TensorFlow has a dependency on ML.Dnn","State":"open","Body":"I don't think the dependency from `ML.TensorFlow` to `ML.Dnn` is correct. My understanding of `ML.Dnn` is that it is a higher-level abstraction for deep neural networks, of which TensorFlow is the first one we are using. However, in the future, we may want to add more neural network libraries to `ML.Dnn` - for example, PyTorch. If that ever happens, now the `ML.TensorFlow` library will also be dependent on PyTorch, since it will have a transitive reference from `ML.Dnn` to PyTorch.\r\n\r\nWe should rethink the dependency structure here. If the only reason `ML.TensorFlow` has a dependency on `ML.Dnn` is for sharing internal code, we should come up with a different code sharing mechanism. For example, the way we solve this in dotnet/corefx is we use share the same source code, and compile it directly into multiple assemblies using source links in the .csprojs.","Url":"https://github.com/dotnet/machinelearning/issues/4305","RelatedDescription":"Open issue \"ML.TensorFlow has a dependency on ML.Dnn\" (#4305)"},{"Id":"502274691","IsPullRequest":true,"CreatedAt":"2019-10-07T17:38:00","Actor":"Nucs","Number":"4290","RawContent":null,"Title":"TensorTypeExtensions: Added conversion between Tensor to primitive C# types instead of throwing NotSupportedException","State":"closed","Body":"- Added conversion between Tensor to native C# types instead of throwing NotSupportedException\r\n- Fixed proper reading of TF_STRING\r\n- Added overloads that support TF_STRING (string does not meet T generic constraint `unmanaged`","Url":"https://github.com/dotnet/machinelearning/pull/4290","RelatedDescription":"Closed or merged PR \"TensorTypeExtensions: Added conversion between Tensor to primitive C# types instead of throwing NotSupportedException\" (#4290)"},{"Id":"502657868","IsPullRequest":false,"CreatedAt":"2019-10-07T15:22:11","Actor":"nighotatul","Number":"4295","RawContent":null,"Title":"How to Convert Transform Result into DataTable by dynamically ?","State":"closed","Body":"@eerhardt - \r\n\r\nIDataView multiclassTransformer = model.Transform(trainTestData.TestSet);\r\n\r\nDataViewSchema columns = multiclassTransformer.Schema;\r\n\r\nDataViewSchema.Column? columnOrNull = multiclassTransformer.Schema.GetColumnOrNull(\"Features\");\r\n                            VBuffer<ReadOnlyMemory<char>> slotNames = new VBuffer<ReadOnlyMemory<char>>();\r\n                            if (columnOrNull.HasValue)\r\n                                columnOrNull.GetValueOrDefault().GetSlotNames(ref slotNames);\r\n\r\n                            IList<string> featurenameCollection= (IList<string>)slotNames.Items(false).Select<KeyValuePair<int, ReadOnlyMemory<char>>, string>((Func<KeyValuePair<int, ReadOnlyMemory<char>>, string>)(kv => kv.Value.ToString())).ToList<string>();\r\n\r\n\r\nHow i can convert the output result into DataTable\r\n\r\nAs Many of example uses Hardcoded class like below example\r\n\r\npublic class MultiClassResultPrediction\r\n        {\r\n            // public uint GroupId { get; set; }\r\n\r\n            // public uint Label { get; set; }\r\n\r\n            // Prediction made by the model that is used to indicate the relative ranking of the candidate search results.\r\n            public float Score { get; set; }\r\n\r\n            // Values that are influential in determining the relevance of a data instance. This is a vector that contains concatenated columns from the underlying dataset.\r\n            // public float[] Features { get; set; }\r\n        }\r\n\r\n\r\nList<MultiClassResultPrediction> predictedResult = context.Data.CreateEnumerable<MultiClassResultPrediction>(predictions, reuseRowObject: false).ToList();\r\n\r\nor \r\n\r\nelse dynamic class where we can access featurevalues,label values and output result schema\r\nlike PredictedLabel,Score\r\nlike below example :\r\n\r\nwhere we can return output in web.\r\n\r\n       IDictionary<string, object> flexibleJson = new ExpandoObject();\r\n        for (int i = 0; i < length; i++)\r\n        {\r\n           \r\n            flexibleJson.Add(colName, colValue);\r\n        }\r\n\r\n        var serialized = JsonConvert.SerializeObject(flexibleJson);\r\n\r\nSo my concern is how we can convert result into DataTable\r\n\r\nis there any way we can achieve the desired result by dynamically into DataTabel?","Url":"https://github.com/dotnet/machinelearning/issues/4295","RelatedDescription":"Closed issue \"How to Convert Transform Result into DataTable by dynamically ?\" (#4295)"},{"Id":"503275449","IsPullRequest":false,"CreatedAt":"2019-10-07T07:22:48","Actor":"nighotatul","Number":"4304","RawContent":null,"Title":"how we visualize output for ranking?","State":"open","Body":"@eerhardt - how we visualize output for ranking?\r\ni.e. charts or heatmap and how?","Url":"https://github.com/dotnet/machinelearning/issues/4304","RelatedDescription":"Open issue \"how we visualize output for ranking?\" (#4304)"},{"Id":"503268888","IsPullRequest":false,"CreatedAt":"2019-10-07T07:05:22","Actor":"nighotatul","Number":"4303","RawContent":null,"Title":"why binning is importance in binary classification?","State":"open","Body":"@eerhardt - when i have studied binning is one of the method to represent numeric data into the group of data.as per studied which numeric column have unique value that data taken into binning as consider.\r\nif this true then unique value is more then that numeric column does not consider as binning process.\r\nconsider heart attack prediction(for data:https://towardsdatascience.com/heart-disease-prediction-73468d630cfc)\r\nin that we calculate binning for age but we cannot calculate for Resting Blood Pressure\r\nhow we calculate number bins in numeric column and which numeric column has been consider for binning process?","Url":"https://github.com/dotnet/machinelearning/issues/4303","RelatedDescription":"Open issue \"why binning is importance in binary classification?\" (#4303)"},{"Id":"503263900","IsPullRequest":false,"CreatedAt":"2019-10-07T06:51:17","Actor":"nighotatul","Number":"4302","RawContent":null,"Title":"how we visualize credit card fraud detection using anomaly detection trainer(PCA)?","State":"open","Body":"@eerhardt - how we represent best way credit card detection using anomaly detection method\r\ni.e. grid or charts.\r\nif grid then which column we added in that grid-\r\nexample-time,V1-V28,amount,probability,score as column\r\n\r\nand if charts then which column we take to draw the charts for x-axis and y-axis taken.\r\n\r\nplease helps us.","Url":"https://github.com/dotnet/machinelearning/issues/4302","RelatedDescription":"Open issue \"how we visualize credit card fraud detection using anomaly detection trainer(PCA)?\" (#4302)"},{"Id":"503034214","IsPullRequest":true,"CreatedAt":"2019-10-06T00:36:44","Actor":"codemzs","Number":"4301","RawContent":null,"Title":"[DO NOT REVIEW][TEMPORARY]","State":"open","Body":"DO NOT REVIEW, JUST A PR TO CREATE ANOTHER PR. WILL CLOSE SOON.","Url":"https://github.com/dotnet/machinelearning/pull/4301","RelatedDescription":"Open PR \"[DO NOT REVIEW][TEMPORARY]\" (#4301)"},{"Id":"502053943","IsPullRequest":false,"CreatedAt":"2019-10-05T13:54:04","Actor":"nighotatul","Number":"4281","RawContent":null,"Title":"after every execution recommendation result is continuously changes?","State":"closed","Body":"@eerhardt - after every execution of following code for Periodofstay-\"Mar-May\" and\r\ntraveler_type-\"Families\",recommendation result i.e. Score continuously changes.we need constant result not every time change score.\r\n\r\n var options = new Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer.Options\r\n                        {\r\n                            // MatrixColumnIndexColumnName = \"userIdEncoded\",\r\n                            // MatrixRowIndexColumnName = \"movieIdEncoded\",\r\n                            FeatureColumnName = \"Features\",\r\n\r\n                            NormalizeFeatures = false,\r\n                            LabelColumnName =\"Label\",// labelColumnName,\r\n                            LambdaLatent = 0.01f,\r\n                            LambdaLinear = 0.001f,\r\n                            LatentDimension = 16,\r\n                            NumberOfIterations = 20,\r\n                            LearningRate = 0.5f\r\n\r\n                            // ApproximationRank = 100\r\n                        };\r\n\r\n\r\n                        //  context.ml.Trainers.MatrixFactorization(options);\r\n\r\n\r\n                        // columnNames, columnTypes\r\n                        IEstimator<ITransformer> datapipeLine = context.Transforms.CopyColumns(\r\n                                       inputColumnName: labelColumnName,\r\n                                       outputColumnName: \"Label\");\r\n                        //                context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"TravelerType\")\r\n                        //.Append(context.Transforms.Categorical.OneHotEncoding(\"HotelOneHot\", \"Hotel\"))\r\n                        //.Append(context.Transforms.Concatenate(\"Features\", \"TravelerTypeOneHot\", \"HotelOneHot\"))\r\n                        //.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(new string[] { \"Features\" }));\r\n\r\n\r\n\r\n\r\n                        List<string> featuresColumns = new List<string>();\r\n\r\n                        for (int index = 0; index < columnNames.Count; ++index)\r\n                        {\r\n\r\n                            if (columnNames[index] == labelColumnName|| columnNames[index]==\"Time\"|| columnNames[index]==\"TimeStamp\"|| columnNames[index]== \"IdPreservationColumn\")\r\n                                continue;\r\n\r\n\r\n                            Type type = columnTypes[index];\r\n\r\n                            if (type == typeof(string) || type == typeof(char) || type == typeof(byte[]) || type == typeof(bool))\r\n                            {\r\n\r\n                                if (datapipeLine == null)\r\n                                {\r\n\r\n                                    datapipeLine = context.Transforms.Categorical.OneHotEncoding(columnNames[index] + \"OneHot\", columnNames[index]);//\"TravelerType\"\r\n\r\n\r\n                                }\r\n                                else\r\n                                {\r\n                                    datapipeLine = datapipeLine.Append(context.Transforms.Categorical.OneHotEncoding(columnNames[index] + \"OneHot\", columnNames[index]));//\"TravelerType\"\r\n\r\n                                }\r\n\r\n                                featuresColumns.Add(columnNames[index] + \"OneHot\");\r\n                            }\r\n                            else\r\n                            {\r\n                                featuresColumns.Add(columnNames[index]);\r\n\r\n                            }\r\n\r\n\r\n\r\n                        }\r\n\r\n\r\n                        datapipeLine = datapipeLine.Append(context.Transforms.Concatenate(\"Features\", featuresColumns.ToArray()));\r\n                        datapipeLine = datapipeLine.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(options));// new string[] { \"Features\" }, labelColumnName));\r\n\r\n                        //        foreach (string name in columnNames)\r\n                        //{\r\n                        //    if(columnTypes)\r\n                        //    pipeline = context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"TravelerType\")\r\n\r\n                        //}\r\n\r\n\r\n\r\n\r\n\r\n                        //var pipeline = context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(options);\r\n\r\n                        //                    var pipeline = context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"Traveler_type\")\r\n                        ////.Append(context.Transforms.Categorical.OneHotEncoding(\"SeasonOneHot\", \"Season\"))\r\n                        //.Append(context.Transforms.Categorical.OneHotEncoding(\"HotelOneHot\", \"Hotel_name\"))\r\n                        //.Append(context.Transforms.Concatenate(\"Features\", \"TravelerTypeOneHot\", \"HotelOneHot\"))\r\n                        //.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(new string[] { \"Features\" },labelColumnName));\r\n\r\n\r\n                        //                    var _model = pipeline.Fit(trainData);\r\n\r\n                        //                    var _transformedTrainingData = _model.Transform(inputtestData);\r\n\r\n\r\n                        // Train the model.\r\n                        var model = datapipeLine.Fit(trainData);\r\n\r\n\r\n\r\n                        // Run the model on training or test data set.\r\n                        var transformedTrainingData = model.Transform(trainData);\r\n\r\n\r\n                        // Measure the quality of the trained model.\r\n                        // var metrics = context.BinaryClassification.Evaluate(transformedTrainingData,);\r\n\r\n                        var metrics = context.BinaryClassification.Evaluate(transformedTrainingData,\"Label\" , \"Score\", \"Probability\", \"PredictedLabel\");//labelColumnName//Prediction Data send\r\n\r\n\r\n\r\n                        //  _predictionEngine = context.Model.pr(FfmRecommendationData, FfmRecommendationPrediction>(_model);\r\n\r\n\r\n                        var predictions2 = context.Data.CreateEnumerable<RecommendationResult>(transformedTrainingData, reuseRowObject: false).ToArray();\r\n\r\n\r\nI have attached data also.\r\n[hotelrecommandation.xlsx](https://github.com/dotnet/machinelearning/files/3686131/hotelrecommandation.xlsx)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4281","RelatedDescription":"Closed issue \"after every execution recommendation result is continuously changes?\" (#4281)"},{"Id":"502871807","IsPullRequest":true,"CreatedAt":"2019-10-05T00:57:05","Actor":"harshithapv","Number":"4298","RawContent":null,"Title":"Fixed documentation for ImageClassificationMetricsCallback to resolve the confusion in issue #4259","State":"closed","Body":"Fixed documentation for ImageClassificationMetricsCallback function to resolve the confusion in issue #4259\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4298","RelatedDescription":"Closed or merged PR \"Fixed documentation for ImageClassificationMetricsCallback to resolve the confusion in issue #4259\" (#4298)"},{"Id":"502863179","IsPullRequest":true,"CreatedAt":"2019-10-04T23:40:12","Actor":"frank-dong-ms","Number":"4297","RawContent":null,"Title":"Issue 4120","State":"closed","Body":"Follow up on Issue #4120 \r\n\r\n1. Use EditorBrowsable attribute to hide the default constructor from intellisense.\r\n2. Use Obsolete(\"XX\", false) instead of Obsolete(\"XX\", true) to be safe.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4297","RelatedDescription":"Closed or merged PR \"Issue 4120\" (#4297)"},{"Id":"502230174","IsPullRequest":false,"CreatedAt":"2019-10-04T23:19:42","Actor":"ashbhandare","Number":"4286","RawContent":null,"Title":"[Image Classification API] Wrong number of images processed in training. ","State":"closed","Body":"- **What did you do?**\r\nRun the sample \"ResnetV2101TransferLearningTrainTestSplit\" with different batch sizes(10, 100, 300). Added logging in the training loop just before batch is processed.\r\n- **What happened?**\r\nFrom second epoch onwards, number of images processed is more than total number of images in dataset.\r\n- **What did you expect?**\r\nNumber of images processed per epoch should be same.\r\n\r\n### Source code / logs\r\n[master_10.txt](https://github.com/dotnet/machinelearning/files/3687548/master_10.txt)\r\n[master_100.txt](https://github.com/dotnet/machinelearning/files/3687549/master_100.txt)\r\n[master_300.txt](https://github.com/dotnet/machinelearning/files/3687550/master_300.txt)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4286","RelatedDescription":"Closed issue \"[Image Classification API] Wrong number of images processed in training. \" (#4286)"},{"Id":"502267843","IsPullRequest":true,"CreatedAt":"2019-10-04T23:16:37","Actor":"ashbhandare","Number":"4289","RawContent":null,"Title":"Image Classification API: Fix processing incomplete batch(<batchSize), images processed per epoch , enable EarlyStopping without Validation Set. Fixes #4274 and #4286    ","State":"closed","Body":"1)Previously, if the images left were not enough to for a batch of batchSize, the batch would not be processed. Fixed to process incomplete batch in training and validation.\r\n2)There was a bug where the batchIndex was not getting reset when the last batch was incomplete(< batchSize). Fixed to reset batchIndex.\r\n3)EarlyStopping was not triggering when validation set is not provided. Fixed.\r\n\r\nfixes #4274 #4286","Url":"https://github.com/dotnet/machinelearning/pull/4289","RelatedDescription":"Closed or merged PR \"Image Classification API: Fix processing incomplete batch(<batchSize), images processed per epoch , enable EarlyStopping without Validation Set. Fixes #4274 and #4286    \" (#4289)"},{"Id":"502878212","IsPullRequest":true,"CreatedAt":"2019-10-04T23:06:34","Actor":"antoniovs1029","Number":"4300","RawContent":null,"Title":"Fixes #4299 related to ML.Samples and ML.Samples.GPU sharing the same Program.cs file","State":"open","Body":"A simple change to fix #4299 . Simply added a new Program.cs file to the ML.Samples.GPU, independent of the one in ML.Samples.","Url":"https://github.com/dotnet/machinelearning/pull/4300","RelatedDescription":"Open PR \"Fixes #4299 related to ML.Samples and ML.Samples.GPU sharing the same Program.cs file\" (#4300)"},{"Id":"502875147","IsPullRequest":false,"CreatedAt":"2019-10-04T22:52:37","Actor":"antoniovs1029","Number":"4299","RawContent":null,"Title":"Problems caused by ML.Samples and ML.Samples.GPU sharing the same Program.cs file","State":"open","Body":"### Issue\r\n\r\n**What did you do?**: I modified the Program.cs file in the ML.Samples project to run a sample that exists in the Samples.Dynamic.Trainers.Regression namespace.\r\n\r\n**What happened?**:\r\nSince ML.Samples and ML.Samples.GPU share the same Program.cs file, my changes in the Program.cs under ML.Samples had effects on the ML.Samples.GPU project.\r\n\r\nAn error appeared in the Program.cs file inside the ML.Samples.GPU project saying that the namespace Samples.Dynamic didn't have a name 'Trainers' and that I might have been missing an assembly reference. Also, while editing the Program.cs inside ML.Samples I received warning tooltips making reference to the errors in ML.Samples.GPU's Program.cs.\r\n\r\nAlthough this didn't prevent me to run the sample, it was odd to see that error messages. Also, later, when trying to run tests inside Visual Studio, I got a compiler errors because of this, and I couldn't run tests. I didn't use to have these compiler errors before, because ML.Samples.GPU was introduced in a recent commit to the master branch.\r\n\r\n**How to solve the problem?**\r\nEventhough ML.Samples has the correct settings to access the sample I was trying to run, ML.Samples.GPU doesn't. This problem might happen with other samples as well.\r\n\r\nSo to simply solve this problem, a new Program.cs file needs to be added to the ML.Samples.GPU project, that is independent to the one in ML.Samples.","Url":"https://github.com/dotnet/machinelearning/issues/4299","RelatedDescription":"Open issue \"Problems caused by ML.Samples and ML.Samples.GPU sharing the same Program.cs file\" (#4299)"},{"Id":"502348385","IsPullRequest":true,"CreatedAt":"2019-10-04T17:03:37","Actor":"harshithapv","Number":"4293","RawContent":null,"Title":"Buffer re-use using ArrayPool and a few more checks","State":"closed","Body":"Added ArrayPool for buffer re-use while reading images in ImageLoader.cs. A few commits for safety checks. \r\nContinuation to my previous commit #4242 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/4293","RelatedDescription":"Closed or merged PR \"Buffer re-use using ArrayPool and a few more checks\" (#4293)"},{"Id":"502698674","IsPullRequest":false,"CreatedAt":"2019-10-04T15:22:00","Actor":"HamzahIqbal765","Number":"4296","RawContent":null,"Title":"Far more weights than features when obtaining PFI Metrics for Binary Classification","State":"open","Body":"Windows 10 v. 1809\r\n- NET Core SDK (3.0.100): \r\n\r\n\r\nI have used trained model with numerical features, and this has successfully returned PFI metrics, whereby the number of weights is equivalent to the number of features.\r\nHowever, the issue arises when  I pass a dataset without numerical features. When the features are categorical and strings, I use one hot encoding to convert the features into the appropriate vectors. \r\nIn both the former and present case, I use a FastForest trainer. \r\nWhen I follow the documentation for PFI, the model is trained fine, but when I run the code:\r\n\r\n` VBuffer<float> weights = default;\r\nlinearPredictor.Model.SubModel.GetFeatureWeights(ref weights);`\r\n\r\nI get over 80 weights when I only have 12 features in my data. And I cannot continue following the documentation since it matches the index of the weights against the index of the feature.\r\n\r\nIs there a way to get the PFI when using OneHotEncoding?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4296","RelatedDescription":"Open issue \"Far more weights than features when obtaining PFI Metrics for Binary Classification\" (#4296)"},{"Id":"502370834","IsPullRequest":false,"CreatedAt":"2019-10-04T01:00:15","Actor":"frank-dong-ms","Number":"4294","RawContent":null,"Title":"Remove default constructor of OnnxSequenceType attribute on next major release","State":"open","Body":"Related to issue #4120 , the temp fix to add obsolete attribute on default constructor but the ideal fix should be remove the default constructor.\r\n\r\nAs this is break Public API change, we will do it on next major release.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4294","RelatedDescription":"Open issue \"Remove default constructor of OnnxSequenceType attribute on next major release\" (#4294)"},{"Id":"502329197","IsPullRequest":false,"CreatedAt":"2019-10-03T22:26:11","Actor":"antoniovs1029","Number":"4292","RawContent":null,"Title":"Use PFI with Binary Prediction Transformer and CalibratedModelParametersBase loaded from disk","State":"open","Body":"In my last accepted pull request (#4262 ) I addressed issue #3976 and was able to provide working samples and tests for using PFI with models loaded from disk except for the case of Binary Prediction Transformer. Here I open this issue about that specific problem.\r\n\r\n### Problem\r\nIn the [sample using PFI with binary classification](https://github.com/dotnet/machinelearning/blob/e19369b407e8630cfaa82b07f81f0576c9bbd145/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/PermutationFeatureImportance.cs#L40) the last transformer of the model (i.e. the linearPredictor) is of type `BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>`.\r\n\r\nProblem is that when saving and then loading that model from disk, a null reference is returned when trying to access the last transformer by casting it to the original type.\r\n```\r\n// linearPredictor is null:\r\nvar linearPredictor = (loadedmodel as TransformerChain<ITransformer>).LastTransformer as BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>; \r\n```\r\n\r\nHaving a null linearPredictor makes it unusable with PFI.\r\n\r\nIn version 1.3 of ML.Net the last transformer of the loaded model would actually be of type `BinaryPredictionTransformer<IPredictorProducing<float>>`\r\n\r\nWith the changes I made in my last PR (which will be available in version 1.4.0 preview 2) the loaded model's last transformer would be of type `BinaryPredictionTransformer<ParameterMixingCalibratedModelParameters<IPredictorProducing<float>, ICalibrator>>` which is a step forward in solving the problem, but is not yet enough.\r\n\r\nAs stated, in both cases, a cast to the original type would return null. In general, it would be expected that the user tries to make that cast in order to use PFI, failing to accomplish it.\r\n\r\nThis problem would be solved if the loaded model actually had a lastTransformer of the original type, or something castable to it.\r\n\r\n### Workaround\r\nBased on [this comment](https://github.com/dotnet/machinelearning/pull/4262#discussion_r330175774) made by @yaeldekel I've just made [this working sample of using PFI with a binary prediction transformer loaded from disk](https://gist.github.com/antoniovs1029/e5fdd86d5b7c8b6adf34cb5481ee20dd). It is pretty much the same as the original sample, only that it works with a model loaded from disk.\r\n\r\nThe key of the workaround is that the user should cast the lastTransformer not into a binary prediction transformer but rather into a `ISingleFeaturePredictionTransformer<object>`, and then do a series of casts to get whatever other object s/he may want to get from inside the lastTransformer.\r\n\r\nIn the sample I've just provided it works pretty much in this way:\r\n```\r\nvar linearPredictor = (loadedmodel as TransformerChain<ITransformer>).LastTransformer as ISingleFeaturePredictionTransformer<object>;\r\nvar predictorModel = linearPredictor.Model as CalibratedModelParametersBase;\r\nvar predictorSubModel = predictorModel.SubModel as LinearBinaryModelParameters;\r\n```\r\n\r\nNotice that this workaround worked even in ML.Net 1.3, and also works with the changes that I introduced in 1.4.0 preview 2.\r\n\r\nNotice that a similar workaround might help a user that tries to use PFI with any kind of prediction transformer loaded from disk. This would come useful if the user, for whatever reason, can not extract the linearPredictor by casting to the same type used in the original model.\r\n\r\n### Cause of the Problem\r\nThere are 3 main points that are related to the cause of this problem, all of which pertain the `Calibrator.cs ` file and aren't related to the binary prediction transformer itself:\r\n1. Unexpectedly, when loading a `ParameterMixingCalibratedModelParameters<>` its [Create method](https://github.com/dotnet/machinelearning/blob/e19369b407e8630cfaa82b07f81f0576c9bbd145/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L564) isn't called. I discovered this while debugging, and what actually happens is that, during loading, inside the [CreateInstanceCore method](https://github.com/dotnet/machinelearning/blob/7c067854b564275b0d6387ca59c0ec83e8fc91b9/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs#L197), it first looks for a constructor, and so it calls the constructor of `ParameterMixingCalibratedModelParameters<>` instead of the Create method.\r\n2. Currently, when loading a `ParameterMixingCalibratedModelParameters<>` model, a `ParameterMixingCalibratedModelParameters<IPredictorProducing<float>, ICalibrator>` is always loaded, no matter what the actual submodel and calibrator are. This doesn't change by fixing point 1). This point is similar to the [original problem found on the prediction transformers](https://github.com/dotnet/machinelearning/issues/3976#issuecomment-517862076), which I fixed in [my last pull request](https://github.com/dotnet/machinelearning/pull/4262); using a similar approach in this case would fix this point... that is, loading first the submodel and calibrator to then create a generic type at runtime with the correct parameter types.\r\n3. When fiting the model (i.e. before even saving it or loading it) the [SdcaLogisticRegressionBinaryTrainer ](https://github.com/dotnet/machinelearning/blob/46ede664e8cff585c450a7005c7069b64df5a6f1/src/Microsoft.ML.StandardTrainers/Standard/SdcaBinary.cs#L1606)creates a predictor of type `ParameterMixingCalibratedModelParameters<LinearBinaryModelParameters, PlattCalibrator>` (which I will now refer to as \"PMCMP\") but returns it as a `CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>` (let's call it \"CMPB\") this then is what makes the last transformer of the model to be a `BinaryPredictionTransformer<CMPB>` whereas the internal model of the last transformer is actually a PMCMP. When saving it to disk, it's saved as a PMCMP (i.e. it's saved using a LoaderSignature of \"PMixCaliPredExec\"), so when loading occurs, it calls the constructor of PMCMP but it doesn't cast it to a CMPB. This is different from the problem fixed in my last pull request; there, if a Regression prediction transformer was saved, then we expected to load a regression prediction transformer... whereas in here if a BPT<PMCMP> is saved we actually want to load a PMCMP with the correct type parameters, but actually create a BPT<CMPB> where the CMPB should also have the correct type parameters.\r\n\r\n### Trying to solve the problem\r\nSo far I've been able to solve problems 1) and 2) described above, but after trying out different approaches I haven't been able to solve problem 3). To solve those problems I've changed different things in the `Calibrator.cs` file. My attempt to solve this problem can be found in PR #4306\r\n\r\nWith those changes (along with the ones of my last PR), the loaded model's last transformer becomes a `BinaryPredictionTransformer<ParameterMixingCalibratedModelParameters<LinearBinaryModelParameters, PlattCalibrator>>`. Notice that even here a cast to `BPT<CMPB>` would be null, so it doesn't solve the problem. Also notice that since PMCMP is an internal class the user wouldn't be able to cast the last transformer to `BPT<PMCMP>` either, since s/he wouldn't have access to that class.\r\n\r\n### Further problems\r\nHere I've explained the specific case of loading a `BPT<CMPB>` with the specific problems that arise in CMPB and PMCMP classes because that is what is used in the sample of PFI with BPT, and in the tests of PFI with BPT. It could be possible that the problems here described are also present in other classes (for example in the other classes of [Calibrator.cs](https://github.com/dotnet/machinelearning/blob/18394c4f9e45b9c5ff41dfbabd30e31132ae4cdc/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1)) but they might not become a problem unless the user tries to access the last transformer of a model loaded from disk. In such a case the described workaround might help.","Url":"https://github.com/dotnet/machinelearning/issues/4292","RelatedDescription":"Open issue \"Use PFI with Binary Prediction Transformer and CalibratedModelParametersBase loaded from disk\" (#4292)"},{"Id":"502293780","IsPullRequest":true,"CreatedAt":"2019-10-03T22:09:47","Actor":"codemzs","Number":"4291","RawContent":null,"Title":"Update CodeCov uploader version.","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4291","RelatedDescription":"Closed or merged PR \"Update CodeCov uploader version.\" (#4291)"},{"Id":"502260817","IsPullRequest":false,"CreatedAt":"2019-10-03T19:44:45","Actor":"meesoft","Number":"4288","RawContent":null,"Title":"ScoreTensorFlowModel fails with null reference exception","State":"open","Body":"### System information\r\n\r\n- Win10 64bit\r\n- .net 4.6.1\r\n- Microsoft.ML.TensorFlow 1.3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nUsed LoadTensorFlowModel and ScoreTensorFlowModel on a pretrained model\r\n- **What happened?**\r\nScoreTensorFlowModel fails with null reference exception\r\n- **What did you expect?**\r\npipeline object\r\n\r\n### Source code / logs\r\n```\r\nvar estimator = mlContext.Model.LoadTensorFlowModel(\"saved_model.pb\");\r\nConsole.WriteLine(\"Inputs: \" + string.Join(\";\", estimator.GetInputSchema().Select(c => c.Name)));\r\nvar pipeline = estimator.ScoreTensorFlowModel(\r\n    new[] { \"denoised\" },\r\n    new[] { \"is_training\", \"noisy\" }, addBatchDimensionInput: true);\r\n```\r\n\r\n[saved_model.zip](https://github.com/dotnet/machinelearning/files/3687784/saved_model.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4288","RelatedDescription":"Open issue \"ScoreTensorFlowModel fails with null reference exception\" (#4288)"},{"Id":"502232611","IsPullRequest":false,"CreatedAt":"2019-10-03T18:43:26","Actor":"aslotte","Number":"4287","RawContent":null,"Title":"Model Builder | Selecting a file without file type crashes Visual Studio","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** I downloaded the data for spam detection (ML samples)\r\n- **What happened?** When I opened the Model Builder in Visual studio and selected the training file, Visual Studio hangs and eventually crashes. Setting the file type to .tsv makes it work.\r\n- **What did you expect?** A reasonable error message would be useful, e.g. \"Please indicate if this file is tab- or comma-separated\"\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4287","RelatedDescription":"Open issue \"Model Builder | Selecting a file without file type crashes Visual Studio\" (#4287)"},{"Id":"502229981","IsPullRequest":false,"CreatedAt":"2019-10-03T18:37:36","Actor":"CESARDELATORRE","Number":"4285","RawContent":null,"Title":"[Model management] Save/Load Model into a Relational Database (SQL Server)","State":"open","Body":"From feedback from a customer using SQL Server Functions and Stored Procedures implemented in C#:\r\n\r\nBasically, would be good to have an API like the following:\r\n\r\n.SaveModelToDb()\r\n.LoadModelFromDb()\r\n\r\nThe reasons and scenarios are because you run C# code only as code running within SQL Server such as a C# SQL Server Function or a Stored Procedure that is scoring an ML.NET model while doing a query or transactions.\r\n\r\nAnd not just for scoring but also for saving the model after training close to the database.. and since it is a table you could also have multiple model versions..\r\n\r\nAnother scenario would be for traditional client/server apps with the client apps directly accessing a database...\r\n\r\nDoing it that way everything would be held, and more importantly, **secured** in the database server without external dependencies.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4285","RelatedDescription":"Open issue \"[Model management] Save/Load Model into a Relational Database (SQL Server)\" (#4285)"},{"Id":"501989702","IsPullRequest":true,"CreatedAt":"2019-10-03T16:43:07","Actor":"codemzs","Number":"4279","RawContent":null,"Title":"Increment build version for 1.4.0-preview-2 and 0.16.0-preview-2 release","State":"closed","Body":"\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4279","RelatedDescription":"Closed or merged PR \"Increment build version for 1.4.0-preview-2 and 0.16.0-preview-2 release\" (#4279)"},{"Id":"502045120","IsPullRequest":false,"CreatedAt":"2019-10-03T12:48:06","Actor":"nighotatul","Number":"4280","RawContent":null,"Title":"we are getting more thane one score in spam detection?","State":"open","Body":"@eerhardt - please see this code,\r\n\r\n var dataProcessPipeline = context.Transforms.Conversion.MapValueToKey(\"Label\", \"Label\")\r\n                                                  .Append(context.Transforms.Text.FeaturizeText(\"FeaturesText\", new Microsoft.ML.Transforms.Text.TextFeaturizingEstimator.Options\r\n                                                  {\r\n                                                      WordFeatureExtractor = new Microsoft.ML.Transforms.Text.WordBagEstimator.Options { NgramLength = 2, UseAllLengths = true },\r\n                                                      CharFeatureExtractor = new Microsoft.ML.Transforms.Text.WordBagEstimator.Options { NgramLength = 3, UseAllLengths = false },\r\n                                                  }, \"Message\"))\r\n                                                  .Append(context.Transforms.CopyColumns(\"Features\", \"FeaturesText\"))\r\n                                                  .Append(context.Transforms.NormalizeLpNorm(\"Features\", \"Features\"))\r\n                                                  .AppendCacheCheckpoint(context);\r\n\r\n                        // Set the training algorithm \r\n                        var trainer = context.MulticlassClassification.Trainers.OneVersusAll(context.BinaryClassification.Trainers.AveragedPerceptron(labelColumnName: \"Label\", numberOfIterations: 10, featureColumnName: \"Features\"), labelColumnName: \"Label\")\r\n                                                  .Append(context.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\", \"PredictedLabel\"));\r\n                        var trainingPipeLine = dataProcessPipeline.Append(trainer);\r\n\r\n\r\n                        //Console.WriteLine(\"=============== Cross-validating to get model's accuracy metrics ===============\");\r\n                        //var crossValidationResults = mlContext.MulticlassClassification.CrossValidate(data: data, estimator: trainingPipeLine, numberOfFolds: 5);\r\n                        //ConsoleHelper.PrintMulticlassClassificationFoldsAverageMetrics(trainer.ToString(), crossValidationResults);\r\n\r\n                        // Now let's train a model on the full dataset to help us get better results\r\n                        var model = trainingPipeLine.Fit(trainData);\r\n\r\n\r\n                        IDataView predictions = model.Transform(trainData);\r\n\r\n\r\n                        List<SpamPrediction> predictedResults = context.Data.CreateEnumerable<SpamPrediction>(predictions, reuseRowObject: false).ToList();\r\n\r\nwe attached data also. then which one score we consider?\r\n[spamdata.xlsx](https://github.com/dotnet/machinelearning/files/3686067/spamdata.xlsx)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4280","RelatedDescription":"Open issue \"we are getting more thane one score in spam detection?\" (#4280)"},{"Id":"501839858","IsPullRequest":true,"CreatedAt":"2019-10-03T05:17:27","Actor":"codemzs","Number":"4278","RawContent":null,"Title":"Fix build breaks.","State":"closed","Body":"Build first broke with #4237 and remained broken until this change.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4278","RelatedDescription":"Closed or merged PR \"Fix build breaks.\" (#4278)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-10-08T05:30:39.9282275Z","RunDurationInMilliseconds":727}