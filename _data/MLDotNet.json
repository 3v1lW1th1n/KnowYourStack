{"Data":{"GitHub":{"Issues":[{"Id":"362458430","IsPullRequest":true,"CreatedAt":"2018-09-21T05:15:50","Actor":"sfilipi","Number":"974","RawContent":null,"Title":"undoing test changes","State":"open","Body":"Fixing merge errors on those two files, on the TreeEstimators PR. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/974","RelatedDescription":"Open PR \"undoing test changes\" (#974)"},{"Id":"362422753","IsPullRequest":true,"CreatedAt":"2018-09-21T01:18:18","Actor":"TomFinley","Number":"973","RawContent":null,"Title":"PredictionEngine uses IRowToRowMapper, ITransformer can create IRowToRowMapper","State":"open","Body":"In which we reduce the overhead of calls to `Predict` by avoiding the creation of cursors.\r\n\r\n`PredictionEngine` used to create a \"fake\" data view under the hood, by wrapping a `BatchPredictionEngine`, but only feeding in one item. This was a fairly heavy operation involving spooling up of cursors, including heavy reflection based processing on each row, etc. Now we are able to avoid this by using an existing interface `IRowToRowMapper`.\r\n\r\nThe other major part of the change is, of course, changing transformers so they *can* produce `IRowToRowMapper`, which they previously did not. In most cases this is relatively straightforward since nearly all transformers of interest are using these `IRowToRowMapper` under the hood to support their computation.\r\n\r\n* `IRowToRowMapper` enhancements, unification of some interfaces.\r\n* `ITransformer` has `IRowToRowMapper` accessor.\r\n* `PredictionEngine` now uses `IRowToRowMapper`\r\n\r\nThe effects of this are most dramatic using prediction engines *outside* of the ML.NET v0.1 pipeline API (e.g., using `IEstimator` based pipelines, pre-ML.NET v0.1 API, and so forth). The effect of this is that when predicting, now actual computation dominates the cost, as opposed to reflection based stuff. ðŸ˜„ Due to architectural limitations of pipeline API models, these do not see benefit.\r\n\r\nWill perhaps update with timings later.","Url":"https://github.com/dotnet/machinelearning/pull/973","RelatedDescription":"Open PR \"PredictionEngine uses IRowToRowMapper, ITransformer can create IRowToRowMapper\" (#973)"},{"Id":"362415808","IsPullRequest":true,"CreatedAt":"2018-09-21T00:33:43","Actor":"zeahmed","Number":"972","RawContent":null,"Title":" Converted LdaTransform into Transformer/Estimator.","State":"open","Body":"Please only review LDA related classes. The other text transform changes are being reviewed in #953. I will merge the branches once approved.\r\n\r\nTests are disabled because LdaNative.dll is missing","Url":"https://github.com/dotnet/machinelearning/pull/972","RelatedDescription":"Open PR \" Converted LdaTransform into Transformer/Estimator.\" (#972)"},{"Id":"362389288","IsPullRequest":false,"CreatedAt":"2018-09-20T22:21:43","Actor":"wschin","Number":"971","RawContent":null,"Title":"Potential bug in ONNX exporter of KeyToVectorTransform","State":"open","Body":"[KeyToVectorTransform](https://github.com/dotnet/machinelearning/blob/1e7b8be855210f2bd8adbd532396a1840a20541d/src/Microsoft.ML.Data/Transforms/KeyToVectorTransform.cs#L711) is mapped to a single [OneHotEncoder](https://github.com/onnx/onnx/blob/master/docs/Operators-ml.md#aionnxmlonehotencoder )in ONNX now. It's correct if `bag-` but if `bag+`, we need to sum up the produced one-hot vectors with one extra `ReduceSum`.","Url":"https://github.com/dotnet/machinelearning/issues/971","RelatedDescription":"Open issue \"Potential bug in ONNX exporter of KeyToVectorTransform\" (#971)"},{"Id":"362369718","IsPullRequest":true,"CreatedAt":"2018-09-20T21:13:38","Actor":"eerhardt","Number":"970","RawContent":null,"Title":"ComponentCatalog refactor","State":"open","Body":"This executes on the plan outlined in https://github.com/dotnet/machinelearning/issues/208#issuecomment-422136134 copied here for easy reading:\r\n\r\n## New Proposal\r\n\r\n1. We will move `ComponentCatalog` from being a static class to being an instance member on `Environment`. This has been a planned refactoring for ML.NET for a while, but hasn't been funded until now.\r\n2. We will completely remove any implicit scanning for components in `ComponentCatalog` itself. It will have public APIs to register components, but will not do any registering itself - neither by loading assemblies from disk, nor by scanning loaded assemblies.\r\n3. Other subsystems (like the GUI, command-line, Entry Points, and model loading) will be responsible for registering the components they require in the manner they require.\r\n4. During model saving, we will write the `Assembly.FullName` into the model file. We will then register that assembly with the `env.ComponentCatalog` when loading the model.\r\n    - Any model that was saved with a previous version of ML.NET, and loaded using the API, will need to explicitly register the components before loading the model. (Or they will need to save the model again with a current version of ML.NET that will save the assembly names.)\r\n\r\nUnder normal circumstances, API users won't have to explicitly register components with the `ComponentCatalog`. Using the API to train models won't require looking up components from a catalog - you just create .NET objects like normal. Loading a trained model from disk will register the components inside of it by loading the Assembly and scanning it for `LoadableClass` assembly attributes.\r\n\r\nFix #208","Url":"https://github.com/dotnet/machinelearning/pull/970","RelatedDescription":"Open PR \"ComponentCatalog refactor\" (#970)"},{"Id":"362363086","IsPullRequest":false,"CreatedAt":"2018-09-20T20:57:24","Actor":"zeahmed","Number":"969","RawContent":null,"Title":"TestEstimatorCore fails when training on EmptyDataView for Ngram based transforms.","State":"open","Body":"`TestEstimatorCore` method tests the schema of estimator that of transformer. It trains estimator on EmptyDataView and get the schema. Then, it fits the estimator on actual data, and get the schema from transformer.\r\n\r\nIt then verifies of both schema are same. However for the case of ngram transform, schema learnt from EmptyDataView is different from actually learned from data. The actual cause is size of ngram is zero in case of training on EmptyDataView which causes output vector type to be variable length. Additionally, some other meta are not filled properly in this case.\r\n\r\nBecause of this following tests are failing right now.\r\n\r\nWordBagWorkout\r\nNgramWorkout\r\n\r\nNeed to think how to fix it.","Url":"https://github.com/dotnet/machinelearning/issues/969","RelatedDescription":"Open issue \"TestEstimatorCore fails when training on EmptyDataView for Ngram based transforms.\" (#969)"},{"Id":"362359358","IsPullRequest":false,"CreatedAt":"2018-09-20T20:47:48","Actor":"wschin","Number":"968","RawContent":null,"Title":"Remove unreachable ONNX variables when saving as ONNX","State":"open","Body":"As title. Sometime, we end up with a computation graph with unreachable variables. We have `inputsToDrop` and `outputsToDrop` for manually removing them but it'd be better to have an automatic mechanism.","Url":"https://github.com/dotnet/machinelearning/issues/968","RelatedDescription":"Open issue \"Remove unreachable ONNX variables when saving as ONNX\" (#968)"},{"Id":"362059561","IsPullRequest":true,"CreatedAt":"2018-09-20T20:26:59","Actor":"sfilipi","Number":"963","RawContent":null,"Title":"enabling scanning the constructors with non-public visibility, and reâ€¦","State":"closed","Body":"enabling scanning the constructors with non-public visibility, and reducing the visibility of some of them to avoid confusing the users.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/963","RelatedDescription":"Closed or merged PR \"enabling scanning the constructors with non-public visibility, and reâ€¦\" (#963)"},{"Id":"362346066","IsPullRequest":true,"CreatedAt":"2018-09-20T20:08:25","Actor":"TomFinley","Number":"967","RawContent":null,"Title":"WIP: Binary train context with evaluation and SDCA","State":"open","Body":"Fixes #949. In which I provide a working sketch of the context object, for evaluation (both dynamic and otherwise). If we think this is a good idea then we can add more capabilities to it. (Either in this PR or future ones.)","Url":"https://github.com/dotnet/machinelearning/pull/967","RelatedDescription":"Open PR \"WIP: Binary train context with evaluation and SDCA\" (#967)"},{"Id":"362310803","IsPullRequest":false,"CreatedAt":"2018-09-20T18:35:09","Actor":"sfilipi","Number":"966","RawContent":null,"Title":"Use the actual argument name, in addition to the short name in error messages. ","State":"open","Body":"For TrainerEstimators, assigning a \"bad\" value to the arguments will result in an error like:\r\n\r\n\"Message: System.ArgumentOutOfRangeException : Illegal input value\r\nParameter name: p\"\r\n\r\nWhere p is the ShortName of the respective argument. \r\nIn addition to the short name, the error messages should also include the full argument name, because short names are not API user-facing.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/966","RelatedDescription":"Open issue \"Use the actual argument name, in addition to the short name in error messages. \" (#966)"},{"Id":"362266381","IsPullRequest":true,"CreatedAt":"2018-09-20T16:27:13","Actor":"wschin","Number":"965","RawContent":null,"Title":"Allow the creation of ONNX initializers","State":"open","Body":"This PR provides an ability of adding tensors into the `initializer` list of ONNX model. It may help the conversion of neural network based transforms and transforms which can be decomposed into matrix operators (some constant matrices would be saved as initializers).","Url":"https://github.com/dotnet/machinelearning/pull/965","RelatedDescription":"Open PR \"Allow the creation of ONNX initializers\" (#965)"},{"Id":"362245477","IsPullRequest":false,"CreatedAt":"2018-09-20T15:35:54","Actor":"eerhardt","Number":"964","RawContent":null,"Title":"Need to add SequenceClassifierEvaluator to ML.NET","State":"open","Body":"In EvaluatorUtils, we used to try to find a `SequenceClassifierEvaluator` Component using `SubComponent` instances. See\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/5a6fdedcc235deb02da72526097e5d0b9955ed2c/src/Microsoft.ML.Data/Evaluators/EvaluatorUtils.cs#L45-L47\r\n\r\nWhen removing `SubComponent` I discovered that this copmonent is not part of ML.NET, and so I couldn't make a `SequenceClassifierEvaluator` instance.\r\n\r\nWe should either port this evaluator to ML.NET, or remove the commented out line here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/86f4d932b47fbd5abc3e9df89dd7ab3d9aacd07b/src/Microsoft.ML.Data/Evaluators/EvaluatorUtils.cs#L47","Url":"https://github.com/dotnet/machinelearning/issues/964","RelatedDescription":"Open issue \"Need to add SequenceClassifierEvaluator to ML.NET\" (#964)"},{"Id":"362026208","IsPullRequest":true,"CreatedAt":"2018-09-20T05:42:16","Actor":"sfilipi","Number":"962","RawContent":null,"Title":"LightGBM,  Tweedie, and GAM trainers converted to tainerEstimators","State":"open","Body":"\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/962","RelatedDescription":"Open PR \"LightGBM,  Tweedie, and GAM trainers converted to tainerEstimators\" (#962)"},{"Id":"361983639","IsPullRequest":true,"CreatedAt":"2018-09-20T01:24:32","Actor":"zeahmed","Number":"961","RawContent":null,"Title":"Converted LpNorm, GcNorm and Whitening transforms into transformers/estimatorsâ€¦","State":"open","Body":"This PR fixes #959 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/961","RelatedDescription":"Open PR \"Converted LpNorm, GcNorm and Whitening transforms into transformers/estimatorsâ€¦\" (#961)"},{"Id":"361983424","IsPullRequest":true,"CreatedAt":"2018-09-20T01:23:13","Actor":"Zruty0","Number":"960","RawContent":null,"Title":"WIP API overview and samples","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/960","RelatedDescription":"Open PR \"WIP API overview and samples\" (#960)"},{"Id":"361983370","IsPullRequest":false,"CreatedAt":"2018-09-20T01:22:51","Actor":"zeahmed","Number":"959","RawContent":null,"Title":"Convert LpNorm, GcNorm and Whitening Transforms to transformers/estimators.","State":"open","Body":"\r\nIn this work item, following transforms will be converted into transformer/estimators.\r\n\r\n- LpNormNormalizerTransform\r\n- GcnTransform\r\n- WhiteningTransform","Url":"https://github.com/dotnet/machinelearning/issues/959","RelatedDescription":"Open issue \"Convert LpNorm, GcNorm and Whitening Transforms to transformers/estimators.\" (#959)"},{"Id":"361970644","IsPullRequest":false,"CreatedAt":"2018-09-20T00:04:26","Actor":"wschin","Number":"958","RawContent":null,"Title":"ONNX Conversion Framework Needs a Way to Create Tensors as ONNX Graph's Initializers","State":"open","Body":"As title. Currently, we're not able to create elements in [this field](https://github.com/onnx/onnx/blob/c0ec417e219ff4ce22b94998bbe570e9b9b0c34a/onnx/onnx-ml.proto#L256). #965 provides a solution.","Url":"https://github.com/dotnet/machinelearning/issues/958","RelatedDescription":"Open issue \"ONNX Conversion Framework Needs a Way to Create Tensors as ONNX Graph's Initializers\" (#958)"},{"Id":"361956442","IsPullRequest":true,"CreatedAt":"2018-09-19T22:50:10","Actor":"artidoro","Number":"957","RawContent":null,"Title":"WIP: Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators","State":"open","Body":"Fixes #956.\r\n\r\nConversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators by deriving the base class LbfgsTrainerBase from TrainerEstimatorBase.\r\n\r\nWorking on testing the converted classes using TestEstimatorCore. ","Url":"https://github.com/dotnet/machinelearning/pull/957","RelatedDescription":"Open PR \"WIP: Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators\" (#957)"},{"Id":"361956023","IsPullRequest":false,"CreatedAt":"2018-09-19T22:48:11","Actor":"artidoro","Number":"956","RawContent":null,"Title":"Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators","State":"open","Body":"Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators by deriving the base class LbfgsTrainerBase from TrainerEstimatorBase.","Url":"https://github.com/dotnet/machinelearning/issues/956","RelatedDescription":"Open issue \"Conversion of Logistic, Multiclass Logistic, and Poisson Regression to estimators\" (#956)"},{"Id":"361949146","IsPullRequest":false,"CreatedAt":"2018-09-19T22:18:09","Actor":"wschin","Number":"955","RawContent":null,"Title":"Experimental Exporter of CopyColumnTransform to ONNX","State":"open","Body":"Following the same strategy of converting ConvertTransform, we should be able export CopyColumnTransform to ONNX as well. #952 demonstrates a possible approach. Note that we assume that somehow the ONNX runtime used can recognize the unofficial operator we're producing.","Url":"https://github.com/dotnet/machinelearning/issues/955","RelatedDescription":"Open issue \"Experimental Exporter of CopyColumnTransform to ONNX\" (#955)"},{"Id":"361943367","IsPullRequest":true,"CreatedAt":"2018-09-19T21:57:20","Actor":"Anipik","Number":"954","RawContent":null,"Title":"different config files for train and predict benchmarks","State":"open","Body":"- different Config files for train and test\r\n- solves problem of long running time\r\n- train benchmarks contain only one iteration as it gives more idea on how the users will use. (with no warmup iteration)\r\n- predict config is the original version\r\n\r\ncc @danmosemsft @eerhardt @adamsitnik @justinormont \r\n","Url":"https://github.com/dotnet/machinelearning/pull/954","RelatedDescription":"Open PR \"different config files for train and predict benchmarks\" (#954)"},{"Id":"361930678","IsPullRequest":true,"CreatedAt":"2018-09-19T21:15:32","Actor":"zeahmed","Number":"953","RawContent":null,"Title":"Converted listed text transforms into transformers/estimators.","State":"open","Body":"This PR fixes #950.\r\n\r\nThe following transforms were converted in this PR.\r\n\r\n- Stopwords Remover Transform\r\n- Text Normalizer Transform \r\n- Word Bag Transform\r\n- Word Hash Bag Transform \r\n- Ngram Transform \r\n- Ngram Hash Transform \r\n","Url":"https://github.com/dotnet/machinelearning/pull/953","RelatedDescription":"Open PR \"Converted listed text transforms into transformers/estimators.\" (#953)"},{"Id":"361927915","IsPullRequest":true,"CreatedAt":"2018-09-19T21:06:59","Actor":"wschin","Number":"952","RawContent":null,"Title":"Export CopyColumnTransform to (unofficial) ONNX operator","State":"open","Body":"1. Add exporter for CopyColumnTransform. It only creates a ONNX node with a `type` field for encoding the transform's C# name.\r\n2. Remove duplicate definitions in ONNX graph. Currently, one variable may appear in both of graph-output list and intermediate-variable list.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/952","RelatedDescription":"Open PR \"Export CopyColumnTransform to (unofficial) ONNX operator\" (#952)"},{"Id":"361924820","IsPullRequest":false,"CreatedAt":"2018-09-19T20:57:52","Actor":"zeahmed","Number":"951","RawContent":null,"Title":"Develop a POC for training tensorflow model using TF#.","State":"open","Body":"There are couple of hurdles in implementing a transfer learning scenario (where tf model is actually modified) using TF#.\r\n\r\n- There is no way to serialized TF model back to file using TF C-API (also TF#).\r\n- It seems impossible to load checkpoint models using C-API (also TF#) because the graph saved with checkpoint models is saved in meta_graph format for which straightforward API is currently missing to load/save.\r\n- When using model created for the purpose of serving e.g. frozen model or un-frozen model ( saved with simple_save method in python) for training, there are no training ops like optimizations or loss operations.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/951","RelatedDescription":"Open issue \"Develop a POC for training tensorflow model using TF#.\" (#951)"},{"Id":"361919430","IsPullRequest":false,"CreatedAt":"2018-09-19T20:42:19","Actor":"zeahmed","Number":"950","RawContent":null,"Title":"Convert all text transforms into transformers/estimators.","State":"open","Body":"Following is the list of transforms that will converted in this work item.\r\n\r\n- Stopwords Remover Transform\r\n- Text Normalizer Transform \r\n- Word Bag Transform\r\n- Word Hash Bag Transform \r\n- Ngram Transform \r\n- Ngram Hash Transform \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/950","RelatedDescription":"Open issue \"Convert all text transforms into transformers/estimators.\" (#950)"},{"Id":"361903092","IsPullRequest":false,"CreatedAt":"2018-09-19T19:54:48","Actor":"TomFinley","Number":"949","RawContent":null,"Title":"API: Binary Classification Training Context","State":"open","Body":"There seems to be something appealing about a convenience object whose purpose is to help \"guide\" people on the path to a successful experiment. So for example, someone might have a pipeline where they featurize, then learn, then evaluate on a test set. Each of these is of course naturally implemented in separate classes, which is good. But it also means that the ingredients necessary to compose a successful experiment are naturally spread hither and yon.\r\n\r\nYou might imagine that in addition to the components, there might be some sort of \"task context\" object, like for example, a `BinaryClassifierContext`. This might have common facilities: for example, a common way to \"browse\" binary classifier trainers, and to evaluate binary classification outputs.\r\n\r\nThere is something appealing about doing this:\r\n\r\n```csharp\r\nvar data = ...\r\nvar ctx = new BinaryClassificationContext();\r\nvar prediction = ctx.Trainers.FastTree(data, ...);\r\nvar metrics = ctx.Evaluate(prediction, ...);\r\n```\r\n\r\nvs. this\r\n\r\n```csharp\r\nvar data = ...\r\nvar prediction = new FastTreeBinaryClassifierEstimator(data, ...);\r\nvar eval = new BinaryClasifierEvaluator(...);\r\nvar metrics = eval.Evaluate(prediction, ...)\r\n```\r\n\r\nThe latter case is certainly no less powerful, but if I imagine someone tooling around in intellisense, the sheer number of things you'll get by including the key namespaces and saying `new` is absolutely dizzying, vs. this context which can be very, very focused.\r\n\r\nIn the case of static pipelines the story is a little bit better, \"we provide extension methods on `Scalar<bool>`\", which is OK *if you know that*, but if you don't happen to know that, I see no reasonable way you could discover that without reading documentation and samples. (Of course for that matter I see ). But requiring knowledge at the level of, \"if you want to do something related to binary classifiers, please say `new BinaryClassifierContext`\" or something, that seems kind of reasonable to me.\r\n\r\nThis hypothetical `Context` object would contain at least two things: the first is a property. (It must be an actual instance because the only way external assemblies could \"add\" their learners to it would be via extension methods.) The second is one or more `Evaluate` methods to produce metrics.\r\n\r\nThese \"objects\" do have state in the sense that they must have an `IHostEnvironment`, but aside from this are more or less like \"namespaces,\" with the important difference possibly that you can't have a top level function as a namespace. (Though perhaps we don't care about doing functions.) There was some thought that if we also defined pipelines through them we could avoid having environments in the dynamic pipelines altogether (as we already do for static pipelines), but how this would be accomplished is not clear to me.\r\n\r\nAlso because the only reasonable way things can add themselves is via an extension method, this `Trainers` object would have to be an actual instance... now then, it needn't actually be instantiable -- one can call extension methods on the `null` of an object as well as anything so long as we don't want to get any information out of it -- but that is a little awkward. If we could just put extension methods on, say, a static class or something that would be nice, but we can't.\r\n\r\n# Work Item\r\n\r\nThe first thing I will do is create a binary classification training context object, as an exploration of the idea. If we like the idea, we can extend it to the other tasks as well.","Url":"https://github.com/dotnet/machinelearning/issues/949","RelatedDescription":"Open issue \"API: Binary Classification Training Context\" (#949)"},{"Id":"361876572","IsPullRequest":false,"CreatedAt":"2018-09-19T18:40:39","Actor":"wschin","Number":"948","RawContent":null,"Title":"Public space for accumulating knowledge about ML.NET","State":"open","Body":"Do we have any places like a Wiki? I'd like to have a place to share some small knowledge related to ML.NET. Here is an example.\r\nToday, I changed the signature of SaveOnnx and then got two tests failed, TestGeneratedCSharpAPI and EntryPointCatalog. The solution is very straightforward, when you know the answer.\r\n\r\nSolution:\r\n\r\n1. Open Microsoft.ML.sln under Visual Studio\r\n2. Go to Test Explorer\r\n3. Find the test code of `RegenerateEntryPointCatalog()` in TestEntryPoints.cs and change its `[Fact(Skip = \".....\")]` to `[Fact()]`' and then run it. Then, you will see (via `git diff`) core_mainfest.json gets changed. Include those changes into your commit. Note that with the existence of `Skip =`, Test Explorer may not execute your test anyway.\r\n4. Find the test code of `RegenerateCSharpApi()` in CSharpCodeGen.cs and change its `[Fact(skip = \".....\")]` to `[Fact()]` and also commit the changes (CSharpApi.cs) induced by running this test.\r\n\r\nI personally like GitHub issues with a better tag name such as \"knowledge\" so that we have one place for all.","Url":"https://github.com/dotnet/machinelearning/issues/948","RelatedDescription":"Open issue \"Public space for accumulating knowledge about ML.NET\" (#948)"},{"Id":"361861172","IsPullRequest":true,"CreatedAt":"2018-09-19T17:59:13","Actor":"wschin","Number":"947","RawContent":null,"Title":"Save ConvertTransform as ONNX Operator and Control the Use of Experimental Features with a Flag","State":"open","Body":"1. Introduce a new argument to SaveOnnx, which is OnnxVersion.\r\n   Two values are currently allowed, \"Latest\" and \"Experimental\".\r\n   Note that \"Latest\" means that the produced ONNX model meets\r\n   the latest ONNX release while \"Experimental\" may produce\r\n   things not officially supported in ONNX.\r\n2. For (1), the interface of saving ONNX is slightly changed. Now,\r\n   CanSaveOnnx requires an OnnxContext as its input argument,\r\n   because if a model can be saved to ONNX depends on the targeted\r\n   ONNX version now.\r\n3. Add exporter for ConvertTransform. It doesn't use standard\r\n   ONNX operator.","Url":"https://github.com/dotnet/machinelearning/pull/947","RelatedDescription":"Open PR \"Save ConvertTransform as ONNX Operator and Control the Use of Experimental Features with a Flag\" (#947)"},{"Id":"361856168","IsPullRequest":false,"CreatedAt":"2018-09-19T17:51:51","Actor":"wschin","Number":"946","RawContent":null,"Title":"Is NATransform still onnxable?","State":"closed","Body":"Just notice that the code of exporting NAReplaceTransform to ONNX is missing comparing with the version pointed by internal TLC. The root reason is that OneToOneTransformerBase doesn't have ITransformCanSaveOnnx anymore.","Url":"https://github.com/dotnet/machinelearning/issues/946","RelatedDescription":"Closed issue \"Is NATransform still onnxable?\" (#946)"},{"Id":"361849014","IsPullRequest":false,"CreatedAt":"2018-09-19T17:24:51","Actor":"wschin","Number":"945","RawContent":null,"Title":"Experimental Conversion of ConvertTransform to ONNX format","State":"open","Body":"We're experimenting for exporting more transforms to ONNX. ConvertTransform is the first one we're working on. #947 ","Url":"https://github.com/dotnet/machinelearning/issues/945","RelatedDescription":"Open issue \"Experimental Conversion of ConvertTransform to ONNX format\" (#945)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-09-21T05:30:37.6120907Z","RunDurationInMilliseconds":1201}