{"Data":{"GitHub":{"Issues":[{"Id":"589549115","IsPullRequest":false,"CreatedAt":"2020-03-28T10:21:54","Actor":"asif48","Number":"4980","RawContent":null,"Title":"How to Add Date column in the Input Class","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  VS 2019\r\n\r\n### Issue\r\n\r\n- **What did you do?** I tried to modify the TaxiFairExample ; Just copied the  code and include few fields \r\n1) Date \r\n2) Punctured \r\nto predict whether the taxi would likely to punctured in the coming date.\r\n\r\n- **What happened?**\r\nWhen I included Date column in the class and try to debug the code ; following errors rises\r\n\r\nSystem.ArgumentOutOfRangeException: 'Could not determine an IDataView type for member Date\r\nParameter name: rawType'\r\n\r\n![IDataView type for member Date](https://user-images.githubusercontent.com/7997380/77820851-31a79f00-7107-11ea-87d1-e6576edc073e.png)\r\n\r\n- **What did you expect?**\r\nI just expect to predict whether the Taxi is likely to puncture or not in the given date \r\n### Source code / logs\r\n\r\n```\r\n public class ItemStock\r\n    {\r\n        [Column(\"0\")]\r\n        public string CarID;\r\n\r\n        [Column(\"1\")]\r\n        public float LocID;\r\n\r\n        [Column(\"2\")]\r\n        public DateTime Date;\r\n\r\n        [Column(\"3\")]\r\n        public float Punctured;\r\n    }\r\n\r\n    public class itemStockQtyPrediction\r\n    {\r\n        [ColumnName(\"Score\")]\r\n        public float Punctured;\r\n    }\r\n```\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4980","RelatedDescription":"Open issue \"How to Add Date column in the Input Class\" (#4980)"},{"Id":"584001656","IsPullRequest":true,"CreatedAt":"2020-03-28T04:06:38","Actor":"frank-dong-ms","Number":"4953","RawContent":null,"Title":"test for benchmark test hanging","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4953","RelatedDescription":"Closed or merged PR \"test for benchmark test hanging\" (#4953)"},{"Id":"589503938","IsPullRequest":true,"CreatedAt":"2020-03-28T04:06:24","Actor":"frank-dong-ms","Number":"4979","RawContent":null,"Title":"try fix benchmark hanging","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4979","RelatedDescription":"Open PR \"try fix benchmark hanging\" (#4979)"},{"Id":"589427250","IsPullRequest":true,"CreatedAt":"2020-03-27T21:41:24","Actor":"mstfbl","Number":"4978","RawContent":null,"Title":"Fixed AutoFitImageClassificationTrainTest hanging by freeing old Tensor objects","State":"open","Body":"`AutoFitImageClassificationTrainTest` is occasionally hanging, even after PR #4939 . The issue here is that Tensor objects saved in `ITransformer model` (now renamed as 'estimatorModel`) are not being automatically freed by C#'s Garbage Collector, as these Tensor objects are made in TensorFlow's C libraries. \r\n\r\nThis PR frees these Tensor objects as part of a `finally` statement following the `try` and `catch` statements, so that in both cases where the estimator is trained with or without a thrown exception, Tensor objects are being cleaned up. I also changed its name to `estimatorModel` to avoid confusion with the declared return variable `ModelContainer model`, and I think it does a better job of explaining the model that is returned by a estimator.Fit() call.\r\n\r\nI confirmed that this fixes the hanging \"out of memory\" and/or \"long running test\" issues by running `AutoFitImageClassificationTrainTest` for 100 iterations, in addition to running all the other unit tests in [this build](https://dev.azure.com/dnceng/public/_build/results?buildId=576838&view=results). In all of these builds, none of the issues described occur. These builds all time-out because running 100 iterations of `AutoFitImageClassificationTrainTest` takes more than 1 hour.","Url":"https://github.com/dotnet/machinelearning/pull/4978","RelatedDescription":"Open PR \"Fixed AutoFitImageClassificationTrainTest hanging by freeing old Tensor objects\" (#4978)"},{"Id":"589039256","IsPullRequest":false,"CreatedAt":"2020-03-27T10:37:05","Actor":"lionelquirynen","Number":"4977","RawContent":null,"Title":"Schema mismatch for feature column 'Features': expected Vector<Single>, got VarVector<Single> '","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1 \r\n\r\n### Issue\r\n\r\n- **What did you do?** : Train a model from a json File\r\n- **What happened?** Schema mismatch for feature column 'Features': expected Vector<Single>, got VarVector<Single> '\r\n\r\n### Source code / logs\r\nHere is the code to train the model : \r\n` private static ITransformer trainWithJson(MLContext mlContext)\r\n        {\r\n            using (StreamReader r = new StreamReader(\"datasetCrewCleaned.json\"))\r\n            {\r\n                string json = r.ReadToEnd();\r\n                List<FilmModel> items = JsonConvert.DeserializeObject<List<FilmModel>>(json);\r\n                List<FilmModel> itemsTrain = new List<FilmModel>();\r\n                for (int i = 0; i < items.Count; i++)\r\n                {\r\n                    if (i > 24000)\r\n                    {\r\n                        break;\r\n                    }\r\n                    itemsTrain.Add(items[i]);\r\n                }\r\n                var data = mlContext.Data.LoadFromEnumerable(itemsTrain);\r\n                var pipeline = mlContext.Transforms.CopyColumns(outputColumnName: \"Label\",    inputColumnName: nameof(FilmModel.BoxOffice))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName:   \"NameEncoded\", inputColumnName: nameof(FilmModel.Name)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"DurationEncoded\", inputColumnName: nameof(FilmModel.Duration)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"ClassificationEncoded\", inputColumnName: nameof(FilmModel.Classification)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"GenreEncoded\", inputColumnName: nameof(FilmModel.Genre)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"StudioEncoded\", inputColumnName: nameof(FilmModel.Studio)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"BudgetEncoded\", inputColumnName: nameof(FilmModel.Budget)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"ReleaseDateEncoded\", inputColumnName: nameof(FilmModel.ReleaseDate)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"CrewEncoded\", inputColumnName: nameof(FilmModel.Crew)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"ActorsEncoded\", inputColumnName: nameof(FilmModel.Actors)))\r\n               .Append(mlContext.Transforms.Concatenate(\"Features\", \"NameEncoded\", \"ClassificationEncoded\", \"DurationEncoded\", \"GenreEncoded\", \"StudioEncoded\", \"BudgetEncoded\", \"ReleaseDateEncoded\", \"CrewEncoded\", \"ActorsEncoded\"))\r\n          .Append(mlContext.Regression.Trainers.LbfgsPoissonRegression());\r\n                var model = pipeline.Fit(data);\r\n                return model;\r\n            }\r\n        }`\r\n\r\nAnd here is the class I'm using to deSerialize the Json File:\r\n\r\n` public class FilmModel\r\n    {\r\n        public FilmModel(float boxOffice, string[] crew, string[] actors, string releaseDate = null, string  name = null, string classification = null, string duration = null, string genre = null, string studio =  null, string budget = null)\r\n          {\r\n            Name = name;\r\n            Classification = classification;\r\n            Duration = duration;\r\n            Genre = genre;\r\n            Studio = studio;\r\n            Budget = budget;\r\n            BoxOffice = boxOffice;\r\n            ReleaseDate = releaseDate;\r\n            Crew = crew;\r\n            Actors = actors;\r\n         }\r\n         public string Name { get; set; }\r\n         public string Classification { get; set; }\r\n         public string Duration { get; set; }\r\n         public string Genre { get; set; }\r\n         public string Studio { get; set; }\r\n         public string Budget { get; set; }\r\n         public float BoxOffice { get; set; }\r\n         public string ReleaseDate { get; set; }\r\n         public string[] Actors { get; set; }\r\n         public string[] Crew { get; set; }\r\n    }`\r\n\r\nThe [] Actors and Crew do not have the same length for each row. For instance a movie could have 4 crew members and another 8. I think that's the problem but I do not know how to fix this.","Url":"https://github.com/dotnet/machinelearning/issues/4977","RelatedDescription":"Open issue \"Schema mismatch for feature column 'Features': expected Vector<Single>, got VarVector<Single> '\" (#4977)"},{"Id":"588685807","IsPullRequest":true,"CreatedAt":"2020-03-27T01:36:42","Actor":"mstfbl","Number":"4976","RawContent":null,"Title":"Updated constructor of ImageLoadingTransformer to accept empty imageFolder paths","State":"closed","Body":"In certain ML.NET/ONNX samples, the provided path for the directory containing images for loading may be empty, and output the following exception:\r\n\r\n> System.ArgumentException: Directory \"\" does not exist.\r\n\r\nThis PR is so that the provided imageFolder path that is provided to the constructor of `ImageLoadingTransformer` may be null **or empty**.","Url":"https://github.com/dotnet/machinelearning/pull/4976","RelatedDescription":"Closed or merged PR \"Updated constructor of ImageLoadingTransformer to accept empty imageFolder paths\" (#4976)"},{"Id":"588019759","IsPullRequest":true,"CreatedAt":"2020-03-26T17:42:38","Actor":"mstfbl","Number":"4973","RawContent":null,"Title":"Disabled AutoFitImageClassificationTrainTest for test stability","State":"closed","Body":"Disabled `AutoFitImageClassificationTrainTest `from runs on CI, as it continues to hang on builds.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4973","RelatedDescription":"Closed or merged PR \"Disabled AutoFitImageClassificationTrainTest for test stability\" (#4973)"},{"Id":"588302413","IsPullRequest":false,"CreatedAt":"2020-03-26T10:12:14","Actor":"fourfruit","Number":"4975","RawContent":null,"Title":"How to generate faster_RCNN_Inception_V2 model in ML.NET?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows \r\n- **.NET Version (eg., dotnet --info)**:  .net core 2.1\r\n\r\n### Issue\r\n\r\n- Use faster_RCNN_Inception_V2 model  doing object detection \r\n-  There is no document about this model  with ML.NET\r\n- How to apply faster_RCNN_Inception_V2 model in ML.NET?\r\nThanks\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4975","RelatedDescription":"Open issue \"How to generate faster_RCNN_Inception_V2 model in ML.NET?\" (#4975)"},{"Id":"588055996","IsPullRequest":true,"CreatedAt":"2020-03-26T01:40:53","Actor":"Lynx1820","Number":"4974","RawContent":null,"Title":"Fixes OneHotEncoding Issue","State":"closed","Body":"OneHotEncoding always increases the dimension by one, which is causing issues with Nimbus.\r\nSee: https://github.com/microsoft/NimbusML/issues/472\r\n\r\n- Added shape info to make models more easy to read\r\n- Replaced ReduceSum with Squeeze (makes more sense imo)\r\n- Isolated KeyToVector test to verify several outputKind modes - Skipping OneHotEncodingEstimator.OutputKind.Binary for now, since this mode is not working and it'll require implementation of KeyToBinaryVector ","Url":"https://github.com/dotnet/machinelearning/pull/4974","RelatedDescription":"Closed or merged PR \"Fixes OneHotEncoding Issue\" (#4974)"},{"Id":"587180719","IsPullRequest":true,"CreatedAt":"2020-03-25T23:09:21","Actor":"antoniovs1029","Number":"4966","RawContent":null,"Title":"Updated OnnxScoringEstimator's documentation","State":"closed","Body":"PR #4919 changed the way users should work with the Onnxruntime's nugets, now they should include either Onnxruntime or Onnxruntime.Gpu nuget along the OnnxTransformer one.\r\n\r\nI also updated a couple of other things that weren't right anymore.\r\n\r\nPlease, let me know it I should update the docs anywhere else.\r\n\r\nFixes #4872 ","Url":"https://github.com/dotnet/machinelearning/pull/4966","RelatedDescription":"Closed or merged PR \"Updated OnnxScoringEstimator's documentation\" (#4966)"},{"Id":"587899751","IsPullRequest":true,"CreatedAt":"2020-03-25T18:23:57","Actor":"LittleLittleCloud","Number":"4972","RawContent":null,"Title":"Simplify CodeGen - phase 2","State":"open","Body":"This PR includes the following updates in CodeGen\r\n- switch train and evaluate order in ModelBuilder.cs. linked issue: [Train and Evaluate order](https://github.com/dotnet/machinelearning-modelbuilder/issues/421)\r\n- filter out ignored cols in programs.cs when printing column value to console. linked issue: [Filter out columns that in ignore-col in console output](https://github.com/dotnet/machinelearning-modelbuilder/issues/580)","Url":"https://github.com/dotnet/machinelearning/pull/4972","RelatedDescription":"Open PR \"Simplify CodeGen - phase 2\" (#4972)"},{"Id":"587321198","IsPullRequest":true,"CreatedAt":"2020-03-25T17:51:37","Actor":"frank-dong-ms","Number":"4968","RawContent":null,"Title":"upgrade benchmark dotnet package to latest version","State":"closed","Body":"As we have upgrade CI run from netcore 3.0 to netcore 3.1, we need also to upgrade benchmark dotnet to latest version which has netcore 3.1 support\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4968","RelatedDescription":"Closed or merged PR \"upgrade benchmark dotnet package to latest version\" (#4968)"},{"Id":"587689159","IsPullRequest":true,"CreatedAt":"2020-03-25T13:17:19","Actor":"antoniovs1029","Number":"4971","RawContent":null,"Title":"[WIP] Avoid propagating input columns when applying Onnx models","State":"open","Body":"The goal of this PR is to:\r\n1. Fix #4970 regarding `ColumnSelectingTransformer` onnx exported models not working as expected when applying it with ML.NET\r\n2. Avoid propagating the input columns through an `OnnxTransformer`. This is a new requirement that was discussed offline with @harishsk . The idea is that the output schema of the onnxtransformer should contain `only` a column for each output of the onnx model. Until now, since OnnxTransformer is a `RowToRowTransformer`, the input schema was propagated to the output.\r\n\r\nFixing point number 2 would actually fix point number 1, given the way that the onnx export works today for `ColumnSelectingTransformer `(where the dropped columns are removed from the onnx model output inside the onnx graph).\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4971","RelatedDescription":"Open PR \"[WIP] Avoid propagating input columns when applying Onnx models\" (#4971)"},{"Id":"587681463","IsPullRequest":false,"CreatedAt":"2020-03-25T13:04:12","Actor":"antoniovs1029","Number":"4970","RawContent":null,"Title":"ColumnSelectingTransformer exported onnx model doesn't work as expected","State":"open","Body":"The `ColumnSelectingTransformer` has the ability to drop columns that aren't desired by the user. The Onnx exported model eliminates those columns from the Onnx model graph output, but this isn't enough to remove them from the output `Schema`, so even if they're removed from the onnx model, those columns are still there in the output after using the `ApplyOnnxModel` method. The reason for this is that the `OnnxTransformer` (which is used by the `ApplyOnnxModel` method) is a `RowToRowTransformer`, and such transformers don't have the capacity to drop columns, only to add them to the input DataView.\r\n\r\n### Code\r\nThe existing test for ColumnSelectingTransformer can be used to notice this issue\r\nhttps://github.com/dotnet/machinelearning/blob/22c7ac8921fa0846717662181b334de3b41e9932/test/Microsoft.ML.Tests/OnnxConversionTest.cs#L1707-L1765\r\n\r\nBy setting a breakpoint, and inspecting into the schema of the outputs, I get the following result:\r\n![image](https://user-images.githubusercontent.com/38739674/77539211-385fb900-6e5e-11ea-9bd2-a276697bf264.png)\r\n\r\nIt shows that the undesired columns were correctly dropped by the `ColumnSelectingTransformer`, but not by the `OnnxModel`. This test should also include comparing both schemas, to make sure that the onnxmodel is actually dropping the undesired columns.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4970","RelatedDescription":"Open issue \"ColumnSelectingTransformer exported onnx model doesn't work as expected\" (#4970)"},{"Id":"587342172","IsPullRequest":true,"CreatedAt":"2020-03-25T00:51:41","Actor":"mstfbl","Number":"4969","RawContent":null,"Title":"Skip hanging TensorFlowImageClassificationEarlyStopping on Linux","State":"closed","Body":"The unit test `TensorFlowImageClassificationEarlyStopping`occasionally hangs on Linux builds. This PR is so that `TensorFlowImageClassificationEarlyStopping` is skipped on these builds.","Url":"https://github.com/dotnet/machinelearning/pull/4969","RelatedDescription":"Closed or merged PR \"Skip hanging TensorFlowImageClassificationEarlyStopping on Linux\" (#4969)"},{"Id":"587228816","IsPullRequest":true,"CreatedAt":"2020-03-24T23:10:21","Actor":"mstfbl","Number":"4967","RawContent":null,"Title":"Updated build docs for .NET Core 3.1","State":"closed","Body":"Updated Windows and Unix build docs for .NET Core 3.1.\r\n\r\nSome specific things to note:\r\n\r\n- In addition to other platforms, .NET Core 3.1 supports Ubuntu **16.04**+ and macOS 10.13 (High Sierra)\r\n- [Visual Studio 2019 Version **16.4 or higher** is needed for .NET Core 3.1.\r\n- /src files always build on both `netstandard2.0 `and `netcoreapp3.1`, and /tests only build on one target framework at a time: `netcoreapp2.1`, `net461 `or `netcoreapp3.1`","Url":"https://github.com/dotnet/machinelearning/pull/4967","RelatedDescription":"Closed or merged PR \"Updated build docs for .NET Core 3.1\" (#4967)"},{"Id":"586583823","IsPullRequest":true,"CreatedAt":"2020-03-24T19:44:57","Actor":"Lynx1820","Number":"4963","RawContent":null,"Title":"Fixes multiclass logistic regression","State":"closed","Body":"Fixes dimension bug for MulticlassLogisticRegression and SdcaMaximumEntropy in Nimbus (https://github.com/microsoft/NimbusML/issues/473)\r\nUnsqueeze was adding dimension 0 to the label tensor - to get shape (1,#samples), instead of the expected shape (#samples, 1).","Url":"https://github.com/dotnet/machinelearning/pull/4963","RelatedDescription":"Closed or merged PR \"Fixes multiclass logistic regression\" (#4963)"},{"Id":"587172628","IsPullRequest":false,"CreatedAt":"2020-03-24T18:03:45","Actor":"luisquintanilla","Number":"4965","RawContent":null,"Title":"Unable to score using PredictionEnginePool with a pipeline/model that contains custom transforms","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\n\r\n`PredictionEngine` is not thread safe. Therefore, in multi-threaded environments, it is *highly* recommended to use `PredictionEnginePool`.\r\n\r\nWhen you want to save a pipeline that contains custom transforms, you have to provide a contract name. If you want to use the saved pipeline / model, using your `MLContext`, you have to register the custom transform using the `CompontentCatalog.RegisterAssembly` method. \r\n\r\nFor more details, see [documentation on using custom transforms](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#how-can-i-define-my-own-transformation-of-data).\r\n\r\n`PredictionEnginePool` does not provide access to `MLContext`, therefore it's not possible to register the custom transforms using `CompontentCatalog.RegisterAssembly`. Therefore, you can't safely deploy models using `PredictionEnginePool`. This affects ASP.NET Core Web Apps (API,MVC,Blazor,Razor Pages) and Azure Functions. \r\n\r\n### Source code / logs\r\n\r\nPipeline:\r\n\r\n```csharp\r\nvar pipeline = mlContext.Transforms.LoadImages(\"ImageSource_featurized\", null, \"ImageSource\")\r\n                          .Append(mlContext.Transforms.ResizeImages(\"ImageSource_featurized\", 224, 224, \"ImageSource_featurized\"))\r\n                          .Append(mlContext.Transforms.ExtractPixels(\"ImageSource_featurized\", \"ImageSource_featurized\"))\r\n                          .Append(mlContext.Transforms.CustomMapping<NormalizeInput, NormalizeOutput>(\r\n                              (input, output) => NormalizeMapping.Mapping(input, output),\r\n                              contractName: nameof(NormalizeMapping)))\r\n                          .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: ONNX_MODEL))\r\n                          .Append(mlContext.Transforms.CustomMapping<LabelMappingInput, LabelMappingOutput>(\r\n                              (input, output) => LabelMapping.Mapping(input, output),\r\n                              contractName: nameof(LabelMapping)));\r\n```\r\n\r\nCreating PredictionEngine:\r\n\r\n```csharp\r\n// Create new MLContext\r\nMLContext mlContext = new MLContext();\r\n\r\n// Register NormalizeMapping\r\nmlContext.ComponentCatalog.RegisterAssembly(typeof(NormalizeMapping).Assembly);\r\n\r\n// Register LabelMapping\r\nmlContext.ComponentCatalog.RegisterAssembly(typeof(LabelMapping).Assembly);\r\n\r\n// Load model & create prediction engine\r\nstring modelPath = @\"C:\\Users\\luquinta.REDMOND\\AppData\\Local\\Temp\\MLVSTools\\LandUseUWPML\\LandUseUWPML.Model\\MLModel.zip\";\r\nITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);\r\n```\r\n\r\nCreate PredictionEnginePool:\r\n\r\n```csharp\r\n//Registered using dependency injection\r\nservices.AddPredictionEnginePool<ModelInput, ModelOutput>()\r\n                .FromFile(\"MLModel.zip\");\r\n```\r\n\r\nStack Trace from ASP.NET Core Web API:\r\n\r\n```text\r\nSystem.InvalidOperationException: Error during class instantiation\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.InvalidOperationException: Error during class instantiation\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.InvalidOperationException: Unable to locate an extension for the contract 'NormalizeMapping'. Ensure you have called ComponentCatalog.RegisterAssembly with the Assembly that contains a class decorated with a 'Microsoft.ML.Transforms.CustomMappingFactoryAttributeAttribute'.\r\n   at Microsoft.ML.Runtime.ComponentCatalog.GetExtensionValue(IHostEnvironment env, Type attributeType, String contractName)\r\n   at Microsoft.ML.Transforms.LambdaTransform.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.TransformerChain`1..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Data.TransformerChain.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at Microsoft.Extensions.ML.FileModelLoader.LoadModel()\r\n   at Microsoft.Extensions.ML.FileModelLoader.Start(String filePath, Boolean watchFile)\r\n   at Microsoft.Extensions.ML.BuilderExtensions.<>c__DisplayClass9_0`2.<FromFile>b__0(PredictionEnginePoolOptions`2 options, FileModelLoader loader)\r\n   at Microsoft.Extensions.Options.ConfigureNamedOptions`2.Configure(String name, TOptions options)\r\n   at Microsoft.Extensions.Options.OptionsFactory`1.Create(String name)\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2..ctor(IServiceProvider serviceProvider, IOptions`1 mlContextOptions, IOptionsFactory`1 predictionEngineOptions)\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeConstructorInfo.Invoke(BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.<>c__DisplayClass1_0.<RealizeService>b__0(ServiceProviderEngineScope scope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngine.GetService(Type serviceType, ServiceProviderEngineScope serviceProviderEngineScope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngineScope.GetService(Type serviceType)\r\n   at Microsoft.Extensions.DependencyInjection.ActivatorUtilities.GetService(IServiceProvider sp, Type type, Type requiredBy, Boolean isDefaultParameterRequired)\r\n   at lambda_method(Closure , IServiceProvider , Object[] )\r\n   at Microsoft.AspNetCore.Mvc.Controllers.ControllerActivatorProvider.<>c__DisplayClass4_0.<CreateActivator>b__0(ControllerContext controllerContext)\r\n   at Microsoft.AspNetCore.Mvc.Controllers.ControllerFactoryProvider.<>c__DisplayClass5_0.<CreateControllerFactory>g__CreateController|0(ControllerContext controllerContext)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeNextResourceFilter>g__Awaited|24_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Rethrow(ResourceExecutedContextSealed context)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.InvokeFilterPipelineAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Logged|17_1(ResourceInvoker invoker)\r\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\r\n   at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)\r\n   at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4965","RelatedDescription":"Open issue \"Unable to score using PredictionEnginePool with a pipeline/model that contains custom transforms\" (#4965)"},{"Id":"586951635","IsPullRequest":false,"CreatedAt":"2020-03-24T16:37:20","Actor":"infiniteloopltd","Number":"4964","RawContent":null,"Title":"Can't load type Microsoft.ML.IPredictorProducing`1[System.Single]","State":"closed","Body":"### System information\r\n\r\n- Windows 10 Home\r\n- .NET : .NET Core 2.1\r\n- ML.NET : 1.5-preview2\r\n- ML.FastTree : 1.5-preview2\r\n\r\n### Issue:\r\n\r\nThe following error occurs when reading from disk:\r\n\r\nCan't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\nModel is available here: https://github.com/infiniteloopltd/ML-Problem\r\n\r\nMay be related to [PR4385](https://github.com/dotnet/machinelearning/issues/4385)\r\n\r\n### Source code / logs\r\n\r\n````\r\nvar mlContext = new MLContext();\r\nvar modelPath = @\"MLModel.zip\";\r\nvar mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n````\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4964","RelatedDescription":"Closed issue \"Can't load type Microsoft.ML.IPredictorProducing`1[System.Single]\" (#4964)"},{"Id":"586448076","IsPullRequest":false,"CreatedAt":"2020-03-24T16:36:17","Actor":"nxtx","Number":"4961","RawContent":null,"Title":"Hierarchical clustering ","State":"closed","Body":"Is hierarchical clustering supported/implemented? \r\n","Url":"https://github.com/dotnet/machinelearning/issues/4961","RelatedDescription":"Closed issue \"Hierarchical clustering \" (#4961)"},{"Id":"585686510","IsPullRequest":true,"CreatedAt":"2020-03-24T00:12:22","Actor":"mstfbl","Number":"4957","RawContent":null,"Title":"Fixed path to Procdump files","State":"closed","Body":"Small bug fix in PowerShell command on the exact location where Procdump files are downloaded. The unzipping of a .zip file with `Expand-Archive` does not make a new folder specifically for the .zip file.","Url":"https://github.com/dotnet/machinelearning/pull/4957","RelatedDescription":"Closed or merged PR \"Fixed path to Procdump files\" (#4957)"},{"Id":"586517759","IsPullRequest":true,"CreatedAt":"2020-03-23T22:28:06","Actor":"frank-dong-ms","Number":"4962","RawContent":null,"Title":"enable 2 tests","State":"closed","Body":"these 2 tests not failed on full test set for 30 days so enable them:\r\nMulticlassLRTest\r\nBinaryClassifierLogisticRegressionBinNormTest\r\n\r\nhttps://dev.azure.com/dnceng/public/_test/analytics?definitionId=707&contextType=build\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4962","RelatedDescription":"Closed or merged PR \"enable 2 tests\" (#4962)"},{"Id":"584754079","IsPullRequest":true,"CreatedAt":"2020-03-23T17:48:32","Actor":"mstfbl","Number":"4955","RawContent":null,"Title":"Updated paths to test/sample datasets to local paths","State":"closed","Body":"There are a lot of datasets/sample files that are downloaded from previous commits through \"raw.githubusercontent\" links. Almost all of these datasets are already available locally in the `test/data` directory. This PR edits references to these datasets so that they are no longer downloaded, and instead simply referred to locally.\r\n\r\nAlso added one dataset (`adult.txt`, 3.67 MB) that was downloaded from a \"raw.githubusercontent\" link. This dataset is small enough to be in `test/data` (biggest local dataset in \"test/data\" is `taxi-fare-train.csv` (24.9 MB).","Url":"https://github.com/dotnet/machinelearning/pull/4955","RelatedDescription":"Closed or merged PR \"Updated paths to test/sample datasets to local paths\" (#4955)"},{"Id":"586012567","IsPullRequest":false,"CreatedAt":"2020-03-23T08:11:34","Actor":"suxi-ms","Number":"4960","RawContent":null,"Title":"Add root cause localization algorithm","State":"open","Body":"### New Algorithm\r\n\r\nAdd a decision tree based root cause localization algorithmm to detect the root causes of an incident on multi-dimensional time series at a timestamp.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4960","RelatedDescription":"Open issue \"Add root cause localization algorithm\" (#4960)"},{"Id":"585995175","IsPullRequest":true,"CreatedAt":"2020-03-23T07:40:18","Actor":"suxi-ms","Number":"4959","RawContent":null,"Title":"Suxi/refine code","State":"closed","Body":"test","Url":"https://github.com/dotnet/machinelearning/pull/4959","RelatedDescription":"Closed or merged PR \"Suxi/refine code\" (#4959)"},{"Id":"585723799","IsPullRequest":false,"CreatedAt":"2020-03-22T13:54:38","Actor":"mengaims","Number":"4958","RawContent":null,"Title":"Add new mode for SR anomaly detector","State":"open","Body":"### New mode for exisiting SR algorithm\r\n\r\nBy old SR(Spectral Residual) anomaly detection, user could only get whether the point is an anomaly or not, but has no way to set sensitivity value for the anomaly. Sometimes an anomaly do happens, but with a low sensitivity setting, it may not be a valid alert. With this new option, the SR anomaly detector will allow user to set sensitivity, and output margin for the point according to the sensitivity, so that when you get an an anomaly point, you could judge if it's a valid alert by comparing the value with margin.\r\n### Backward compatibility\r\n\r\nThis change is backward compatible. By default the SR anomaly detector will use AnomalyOnly mode, which have exactly the same intput and output with original method. And the user could also load old saved models with the new detector.\r\n\r\n### Benchmark report\r\n#### 1. Dataset\r\nWe evaluate on the Yahoo timeseries dataset, which has 367 timeseries and 572966 points in total.\r\n#### 2. Evaluation method\r\n\r\nWe calculate the Precision, Recall, and F1 score using the method of： [https://github.com/iopsai/iops/tree/master/evaluation](https://github.com/iopsai/iops/tree/master/evaluation).\r\n\r\nThis change did not modify the original anomaly detection part, so the scores remains the same between AnomalyOnly mode and AnomalyAndMargin mode.\r\n\r\nAnd we ran the two modes of SR on a machine with Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz, 16GB memory, x64 operating system.\r\n#### 3. Score and Latency:\r\nMode | Precision | Recall | F1 | #TruePositive | #Positives | #Anomalies | Average latency to   predict the whole dataset | Fine tuned   parameters\r\n-- | -- | -- | -- | -- | -- | -- | -- | --\r\nAnomalyOnly mode | 0.601 | 0.670 | 0.634 | 2625 | 4370 | 3915 | 21167ms | WindowSize=64,   BackAddWindowSize=5, LookaheadWindowSize=5, AveragingWindowSize=3,   JudgementWindowSize=64, Threshold=0.45\r\nAnomalyAndMargin mode | 0.601 | 0.670 | 0.634 | 2625 | 4370 | 3915 | 41717ms | WindowSize=64,   BackAddWindowSize=5, LookaheadWindowSize=5, AveragingWindowSize=3,   JudgementWindowSize=64, Threshold=0.45, Sensitivity=90","Url":"https://github.com/dotnet/machinelearning/issues/4958","RelatedDescription":"Open issue \"Add new mode for SR anomaly detector\" (#4958)"},{"Id":"585478512","IsPullRequest":true,"CreatedAt":"2020-03-21T11:14:52","Actor":"osaaso","Number":"4956","RawContent":null,"Title":"Created using Colaboratory","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4956","RelatedDescription":"Closed or merged PR \"Created using Colaboratory\" (#4956)"},{"Id":"583555577","IsPullRequest":true,"CreatedAt":"2020-03-19T18:03:56","Actor":"justinormont","Number":"4951","RawContent":null,"Title":"Pin hash in DownloadTensorFlowSentimentModel()","State":"closed","Body":"Changes `DownloadTensorFlowSentimentModel()` to download from a specific commit ID instead of master of the dotnet/machinelearning-testdata repo.\r\n\r\nOtherwise older versions of the ML.NET code will break when the remote repo is reorganized, or the files renamed.\r\n\r\nFurther explanation in comment below: https://github.com/dotnet/machinelearning/pull/4951#discussion_r395213145","Url":"https://github.com/dotnet/machinelearning/pull/4951","RelatedDescription":"Closed or merged PR \"Pin hash in DownloadTensorFlowSentimentModel()\" (#4951)"},{"Id":"584590656","IsPullRequest":false,"CreatedAt":"2020-03-19T17:49:32","Actor":"Zeraphil","Number":"4954","RawContent":null,"Title":"Unexpected WordEmbedding behavior as feature vector to a multi-class classifier","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n3.1.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nApply the WordEmbedding transformer to a multiclass prediction trainer.\r\n- **What happened?**\r\nCross validation resulted errors and NaN scores in multiclass predictions. \r\n- **What did you expect?**\r\nI expect to be able to use the word embedding feature vector, concatenate it with other features, and apply it to my classifier.\r\n\r\n### Source code / logs\r\n\r\nI'm trying to use either downloaded FastText word vectors or the built-in ones. My Data Processing pipeline looks like this:\r\n\r\n` Append(mlContext.Transforms.Text.FeaturizeText(\"FeaturesA\", options, \"Transcript\"))\r\n .Append(mlContext.Transforms.Text.TokenizeIntoWords(\"Tokens\", \"Transcript\"))\r\n .Append(mlContext.Transforms.Text.ApplyWordEmbedding(\"WordEmbeddings\", \"OutputTokens\", WordEmbeddingEstimator.PretrainedModelKind.GloVe50D))\r\n .Append(mlContext.Transforms.Text.ApplyWordEmbedding(\"WordEmbeddings\", WORDVECTOR_PATH, \"Tokens\"))\r\n.Append(mlContext.Transforms.NormalizeMinMax(\"FeaturesA\", \"FeaturesA\"))\r\n.Append(mlContext.Transforms.CopyColumns(\"FeaturesB\", \"WordEmbeddings\"))\r\n.Append(mlContext.Transforms.Concatenate(\"Features\", \"FeaturesA\", \"FeaturesB\"))\r\n.AppendCacheCheckpoint(mlContext);\r\n \r\nvar trainer = mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName: \"Label\", featureColumnName: \"Features\")\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\", \"PredictedLabel\"));\r\nvar trainingPipeline = dataProcessPipeline.Append(trainer);'\r\n\r\nI don't get a functioning model, the prediction scores are NaN. I have a couple of questions on this.\r\nI understand that ApplyWordEmbedding returns an estimator, but I had it understood it outputs the average/min/max of all the token vectors, so word vector dimensions *3. \r\n\r\n1) Why isn't this usable as a feature vector into a classifier? If I apply another transform, like NormalizeMinMax, it suddenly works, but that's squashing the values in a way that doesn't make sense.\r\n\r\n2) Why is the model size so small? I expected that, as part of the transform, the whole wordvector model would be included, but it seems like if the data doesn't contain the token, it's not included in the model. That doesn't make word embeddings that useful as part of the point of word vectors is to provide a language model. If I want to classify a sentence containing cat as \"Animal\" but my data doesn't contain dog, the model should still be able to featurize dog as part of the sentence, but it doesn't seem like the model would be able to do that. Apologies if I'm missing something very obvious, going through the WordEmbedding documentation has been a bit difficult for me.\r\n\r\n3) How can I select just the average features? It's not clear from the docs either.\r\n\r\nThank you!\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4954","RelatedDescription":"Open issue \"Unexpected WordEmbedding behavior as feature vector to a multi-class classifier\" (#4954)"},{"Id":"583898371","IsPullRequest":false,"CreatedAt":"2020-03-18T17:42:12","Actor":"francescomazzurco","Number":"4952","RawContent":null,"Title":"Request: expose Experiment._modelDirectory","State":"open","Body":"Hi all,\r\n\r\nIn AutoML, when configuring the `ExperimentSettings`, one can set a `CacheDirectory` where the intermediate models will be stored. However, the models are actually stored in a subfolder, called \"ExperimentXX\", where XX in an auto-increment integer in v.0.14.0, and some random characters in the recent preview releases. Navigating the source code, I found that this path is stored inside the private readonly field `_modelDirectory` belonging to the internal class `Experiment<TRunDetail, TMetrics>`. When running many experiments, there is no way to associate each experiment to each subfolder. \r\nIn my scenario, caching is necessary due to dataset size, and I would like to delete the temporary models at the end of the experiment without bothering other experiments that may be running simultaneously.\r\n\r\nThanks\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4952","RelatedDescription":"Open issue \"Request: expose Experiment._modelDirectory\" (#4952)"}],"ResultType":"GitHubIssue"}},"RunOn":"2020-03-29T05:30:37.9618725Z","RunDurationInMilliseconds":716}