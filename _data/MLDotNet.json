{"Data":{"GitHub":{"Issues":[{"Id":"579694210","IsPullRequest":false,"CreatedAt":"2020-03-12T05:01:15","Actor":"philiplai","Number":"4937","RawContent":null,"Title":"model.LastTransformer doesn't exist","State":"open","Body":"I was trying to implement Permutation Feature Importance (PFI) for Binary Classification.  But I was stuck on the following line of code.  This method simply doesn't exist.\r\n// Extract the predictor.\r\nvar linearPredictor = model.LastTransformer;\r\n\r\nI was following the example on https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet\r\n\r\nAny idea?\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 5ec45442-8e5f-a544-cc9a-58483a383513\r\n* Version Independent ID: 040169f9-d169-cbbd-099e-f04a7a5a6b3f\r\n* Content: [PermutationFeatureImportanceExtensions.PermutationFeatureImportance Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/4937","RelatedDescription":"Open issue \"model.LastTransformer doesn't exist\" (#4937)"},{"Id":"579681677","IsPullRequest":true,"CreatedAt":"2020-03-12T04:17:35","Actor":"harishsk","Number":"4936","RawContent":null,"Title":"Updated version to 1.5.0-preview3","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4936","RelatedDescription":"Open PR \"Updated version to 1.5.0-preview3\" (#4936)"},{"Id":"579653089","IsPullRequest":true,"CreatedAt":"2020-03-12T02:34:54","Actor":"frank-dong-ms","Number":"4935","RawContent":null,"Title":"Nightlybuild fix","State":"open","Body":"several issue here:\r\n1. delete useless folder to avoid no disk space\r\n2. add missing dependency for nightly build\r\n3. fix LD_LIBRARY_PATH for CentOS to set proper native reference path\r\n4. increase build time, seems it takes more time now for net core 3.0 to build","Url":"https://github.com/dotnet/machinelearning/pull/4935","RelatedDescription":"Open PR \"Nightlybuild fix\" (#4935)"},{"Id":"578821017","IsPullRequest":true,"CreatedAt":"2020-03-11T21:34:21","Actor":"Lynx1820","Number":"4928","RawContent":null,"Title":"Fix for MulticlassNaiveBayesTrainer export to Onnx","State":"closed","Body":"- Adding support for a batch input dimension\r\n- While ML.NET doesn't use this batch dimension, ORT does.  \r\n","Url":"https://github.com/dotnet/machinelearning/pull/4928","RelatedDescription":"Closed or merged PR \"Fix for MulticlassNaiveBayesTrainer export to Onnx\" (#4928)"},{"Id":"579469782","IsPullRequest":true,"CreatedAt":"2020-03-11T20:05:28","Actor":"najeeb-kazmi","Number":"4934","RawContent":null,"Title":"Improved documentation for LdSvmTrainer","State":"closed","Body":"Adds explanation of the algorithm, moves details to remarks, adds references to samples.","Url":"https://github.com/dotnet/machinelearning/pull/4934","RelatedDescription":"Closed or merged PR \"Improved documentation for LdSvmTrainer\" (#4934)"},{"Id":"579237248","IsPullRequest":false,"CreatedAt":"2020-03-11T12:44:08","Actor":"vslynko","Number":"4933","RawContent":null,"Title":"AccessViolationException PredictionEngine when 100-200 concurrent predictions running async","State":"open","Body":"### System information\r\n\r\n- Windows 10 64bit latest. 4 core CPU with hyperthreading.\r\n- Main app net48, that loads dependency in net472 that loads Microsoft.ML.Tensorflow 1.4: \r\n\r\n### Issue\r\n\r\n- Multiple concurrent tasks scheduled with `Task.WhenAll`. All tasks perform the same lambda, that involves calling PredictionEngineBase.Predict call. Number of tasks in parallel stacks window is about 100-200. \r\n- `AccessViolationException` thrown with message \"Attempted to read or write protected memory. This is often an indication that other memory is corrupt.\"\r\n- As in case when number of tasks is not that big, ~30-50 I would expect no exception.\r\n\r\n### Source code / logs\r\nTwo different stack traces point to about same location in the code. The difference is that I rearrange a little async workflow by switch couple of async tasts around.\r\n```stacktrace\r\n   at System.SpanHelpers.CopyTo[T](T& dst, Int32 dstLength, T& src, Int32 srcLength)\r\n   at System.Span`1.TryCopyTo(Span`1 destination)\r\n   at Microsoft.ML.TensorFlow.TensorTypeExtensions.CopyTo[T](Tensor tensor, Span`1 values)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at InstaFlow.TensorFlow.Gp2.TfGpBaseV2`1.Predict(TfGpSeriesV2 series)\r\n   at InstaFlow.TensorFlow.Gp2.TfGpBaseV2`1.CorrectInternal(T model, TfInput input)\r\n   at InstaFlow.TensorFlow.TfEstimatorV2.TimerAction[T](Func`1 func)\r\n   at InstaFlow.TensorFlow.TfEstimatorV2.EstimateAndEvaluate(TfInput input)\r\n```\r\n\r\n```stacktrace\r\n   at Tensorflow.c_api.TF_TensorByteSize(IntPtr tensor)\r\n   at Tensorflow.Tensor.get_bytesize()\r\n   at Tensorflow.Tensor.get_size()\r\n   at Microsoft.ML.TensorFlow.TensorTypeExtensions.CopyTo[T](Tensor tensor, Span`1 values)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at InstaFlow.TensorFlow.Estimator.TfEstimatorBase.Predict(TfSeries series) in C:\\src\\instaflow\\dotnet\\InstaFlow.TensorFlow\\Estimator\\TfEstimatorBase.cs:line 101\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4933","RelatedDescription":"Open issue \"AccessViolationException PredictionEngine when 100-200 concurrent predictions running async\" (#4933)"},{"Id":"579215175","IsPullRequest":false,"CreatedAt":"2020-03-11T12:04:26","Actor":"vslynko","Number":"4932","RawContent":null,"Title":"TensorFlowEstimator initialization info is missing","State":"open","Body":"`TensorFlowEstimator` is not static and has no public constructors. Therefore the link to the documentation on how to initialize `TensorFlowEstimator` is essential.\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 7366dd71-3899-63fb-690e-5e0d11a5bf13\r\n* Version Independent ID: 4e44da94-51eb-2617-135a-eb71186b4da9\r\n* Content: [TensorFlowEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowestimator?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/4932","RelatedDescription":"Open issue \"TensorFlowEstimator initialization info is missing\" (#4932)"},{"Id":"579104390","IsPullRequest":true,"CreatedAt":"2020-03-11T08:58:15","Actor":"mstfbl","Number":"4931","RawContent":null,"Title":"Added hanging test mem dump feature","State":"open","Body":"Added the option to automatically collect memory dumps on hanging and crashing tests through VSTest Tasks and ProcDump for when running specific tests through the tag \"RunSpecificTest\".\r\n\r\nAlso added an example VSTest version of the ColumnTypes XUnit test file, which demonstrates the difference between VSTest and XUnit versions of the same test, through the \"TestClass\", \"TestMethod\" vs [Fact] labels.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4931","RelatedDescription":"Open PR \"Added hanging test mem dump feature\" (#4931)"},{"Id":"575840698","IsPullRequest":true,"CreatedAt":"2020-03-10T23:38:47","Actor":"antoniovs1029","Number":"4919","RawContent":null,"Title":"Update to Onnxruntime 1.2 and reenable its support for GPU","State":"closed","Body":"Update dependencies in ML.NET for Onnxruntime.Managed 1.2 and reenable GPU support.\r\n\r\nFrom now on OnnxTransformer will take a dependency on OnnxRuntime.Managed nuget, instead of OnnxRuntime. And users of ML.NET will have the ability to either use OnnxRuntime nuget (for CPU) or OnnxRuntime.Gpu nuget, depending if they want their onnx models to be applied using cpu or gpu.\r\n\r\nNotice that in # #4416 support for GPU was disabled because of changes in onnxruntime nugets, and in here that same code is reenabled.","Url":"https://github.com/dotnet/machinelearning/pull/4919","RelatedDescription":"Closed or merged PR \"Update to Onnxruntime 1.2 and reenable its support for GPU\" (#4919)"},{"Id":"578885494","IsPullRequest":true,"CreatedAt":"2020-03-10T23:31:46","Actor":"frank-dong-ms","Number":"4929","RawContent":null,"Title":"add back lightgbm crash mitigation","State":"closed","Body":"we are seeing several crash so there might be more issue there, will remove this mitigation if we root cause and fix other remaining issue within lightgbm test\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4929","RelatedDescription":"Closed or merged PR \"add back lightgbm crash mitigation\" (#4929)"},{"Id":"578891508","IsPullRequest":true,"CreatedAt":"2020-03-10T22:11:18","Actor":"mstfbl","Number":"4930","RawContent":null,"Title":"Debugging hanging tests [Draft, WIP]","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4930","RelatedDescription":"Open PR \"Debugging hanging tests [Draft, WIP]\" (#4930)"},{"Id":"578394306","IsPullRequest":true,"CreatedAt":"2020-03-10T20:07:02","Actor":"frank-dong-ms","Number":"4927","RawContent":null,"Title":"fix LdaWorkoutEstimatorCore","State":"closed","Body":"fix LdaWorkoutEstimatorCore test.\r\n\r\nresetRandomGenerator needs to be true here as multiple compare will be performed later. \r\nIn lda_engine, a queue of samples with size of (num_of_threads - 2) will be created at first, each time a compare is performed the internal status of one sample (random number: rng_) is changed, so if size of queue is smaller the number of compare performed (in local workstation we have 12 cores thus the issue is not reproduced), dirty data will be used again for calculation and cause issue. set resetRandomGenerator to true will reset the random number rng_ every time before lda calculation thus fix the issue.","Url":"https://github.com/dotnet/machinelearning/pull/4927","RelatedDescription":"Closed or merged PR \"fix LdaWorkoutEstimatorCore\" (#4927)"},{"Id":"576588062","IsPullRequest":true,"CreatedAt":"2020-03-10T07:53:11","Actor":"frank-dong-ms","Number":"4921","RawContent":null,"Title":"test LdaWorkoutEstimatorCore","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4921","RelatedDescription":"Closed or merged PR \"test LdaWorkoutEstimatorCore\" (#4921)"},{"Id":"578330610","IsPullRequest":false,"CreatedAt":"2020-03-10T04:32:30","Actor":"artemiusgreat","Number":"4926","RawContent":null,"Title":"SdcaMaximumEntropy trainer goes into an infinite loop if it takes already transformed data view as an input","State":"open","Body":"### System information\r\n\r\n- **OS version**: Windows 10 Pro x64\r\n- **.NET Version**: .NET Core 3.0\r\n- **ML.NET**: 1.5.0-preview\r\n\r\n### Issue\r\n\r\n**What I did**\r\n- create data-preparation pipeline \r\n- create trainer SdcaMaximumEntropy \r\n- execute pipeline, e.g. to debug transformed data view \r\n- add trainer to the pipeline and execute pipeline again, with the trainer included \r\n \r\n**What happened**\r\n\r\nIf I execute pipeline once, e.g. load from enumerables into data view and then execute entire transformation chain that includes transformations and trainer, everything works fine. \r\n\r\nIf I execute pipeline twice, first time - separately, then - as a part of entire transformation chain, it consumes 3GB of RAM memory out of 16GB available, then **training hangs indefinitely** and never ends. \r\nFixed this temporarily by changing this `MaximumNumberOfIterations` option, but not sure if it's a good idea...  \r\n\r\n**What I expect**\r\n\r\nI expect training to stop eventually, no matter how many times I execute pipeline. \r\n**Check the comment on the last line in the core below.**\r\n\r\n### Source code \r\n\r\nSource code is taken from this issue https://github.com/dotnet/machinelearning/issues/4903\r\n\r\n```C#\r\n\r\npublic IEstimator<ITransformer> GetPipeline(IEnumerable<string> columns)\r\n{\r\n  var pipeline = Context\r\n    .Transforms\r\n    .Conversion\r\n    .MapValueToKey(new[] { new InputOutputColumnPair(\"Label\", \"Strategy\") })\r\n    .Append(Context.Transforms.Concatenate(\"Combination\", columns.ToArray())) // merge \"dynamic\" colums into single property\r\n    .Append(Context.Transforms.NormalizeMinMax(new[] { new InputOutputColumnPair(\"Features\", \"Combination\") })) // normalize merged columns into Features\r\n    .Append(Context.Transforms.SelectColumns(new string[] { \"Label\", \"Features\" })); // remove everything from data view, except transformed columns\r\n\r\n  return pipeline;\r\n}\r\n\r\npublic IEstimator<ITransformer> GetEstimator()\r\n{\r\n  var options = new SdcaMaximumEntropyMulticlassTrainer.Options\r\n  {\r\n    // MaximumNumberOfIterations = 100  // uncomment this to fix the issue\r\n  };\r\n\r\n  var estimator = Context\r\n    .MulticlassClassification\r\n    .Trainers\r\n    .SdcaMaximumEntropy(options)\r\n    .Append(Context.Transforms.Conversion.MapKeyToValue(new[]\r\n    {\r\n      new InputOutputColumnPair(\"Prediction\", \"PredictedLabel\") // set trainer to use Prediction property as output\r\n    }));\r\n\r\n  return estimator;\r\n}\r\n\r\npublic void TrainModel(IEnumerable<string> columns, IEnumerable<InputModel> items)\r\n{\r\n  var estimator = GetEstimator();\r\n  var pipeline = GetPipeline(columns);\r\n  var inputs = Context.Data.LoadFromEnumerable(items);  // create view \r\n\r\n  // If I stop execution here, everything is ok\r\n\r\n  var model = pipeline.Append(estimator).Fit(inputs);  // works fine for the data view loaded from enumerables\r\n\r\n  // Data preparation pipeline is a part of a transformation chain, so I don't need next 2 lines, but I don't understand why it's causing the issue\r\n  \r\n  var pipelineModel = pipeline.Fit(inputs);  \r\n  var pipelineView = pipelineModel.Transform(inputs); // execute pipeline before the training\r\n  var model = pipeline.Append(estimator).Fit(pipelineView); // use transformed pipelineView instead of initial inputs and ... go into infinite loop ... why?\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4926","RelatedDescription":"Open issue \"SdcaMaximumEntropy trainer goes into an infinite loop if it takes already transformed data view as an input\" (#4926)"},{"Id":"578280343","IsPullRequest":true,"CreatedAt":"2020-03-10T01:30:25","Actor":"suxi-ms","Number":"4925","RawContent":null,"Title":"add root cause localization transformer","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4925","RelatedDescription":"Open PR \"add root cause localization transformer\" (#4925)"},{"Id":"578260111","IsPullRequest":true,"CreatedAt":"2020-03-10T00:14:12","Actor":"frank-dong-ms","Number":"4924","RawContent":null,"Title":"Tensorflow crash issue","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4924","RelatedDescription":"Open PR \"Tensorflow crash issue\" (#4924)"},{"Id":"575279610","IsPullRequest":false,"CreatedAt":"2020-03-09T22:07:10","Actor":"nighotatul","Number":"4915","RawContent":null,"Title":"how we can show confusion matrix of Permutation Feature Importance so end user easily identify?","State":"closed","Body":"@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\n\r\nhow we can show score,probability,confusion matrix of Permutation Feature Importance?","Url":"https://github.com/dotnet/machinelearning/issues/4915","RelatedDescription":"Closed issue \"how we can show confusion matrix of Permutation Feature Importance so end user easily identify?\" (#4915)"},{"Id":"574851779","IsPullRequest":false,"CreatedAt":"2020-03-09T17:34:13","Actor":"leblancdavid","Number":"4911","RawContent":null,"Title":"Implementing a custom `IEstimator` and `ITransformer`","State":"closed","Body":"I am currently working on a custom algorithm to transform my data for my application. I would like to include this transform into my pipeline so I can save and load it along with the model. \r\n\r\nI started out by implementing the `IEstimator<ITransformer>` and `ITransformer` interfaces. The `Fit(...)` and `Transform(...)` methods were fairly easy to implement but I'm struggling with how these models can be saved. The `ModelSaveContext` in the `Save(...)` method contains only `internal` properties which I cannot access.\r\n\r\nI realize I could technically implement a `CustomMappingEstimator` but it doesn't really appear to do anything during the `Fit` part of the training. My algorithm generates data (just a list of indexes to determine with features to use), which is then passed to the `ITransformer`.\r\n\r\nAre there examples of how to do this?","Url":"https://github.com/dotnet/machinelearning/issues/4911","RelatedDescription":"Closed issue \"Implementing a custom `IEstimator` and `ITransformer`\" (#4911)"},{"Id":"576429602","IsPullRequest":false,"CreatedAt":"2020-03-09T17:16:56","Actor":"artemiusgreat","Number":"4920","RawContent":null,"Title":"Create DataView from IEnumerable<HashTable> or IEnumerable<IDictionary<string,dynamic>>","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro x64\r\n- **.NET Version**: .NET Core 3.0\r\n- **ML.NET Version**: 1.5.0-preview\r\n\r\n### Issue\r\n\r\n**What did you do?**\r\n\r\nTrying to create a data view from a list of IDictionary objects. \r\n\r\n- `IEnumerable<Expando>` or ...\r\n- `IEnumerable<HashTable>` or ...\r\n- `IEnumerable<Dictionary<string, object>>`\r\n- `IEnumerable<Dictionary<string, dynamic>>`\r\n\r\nIn this case, Keys would be used as column names, and Values as a data. \r\n\r\n**What happened?**\r\n\r\nWhen I add column names or implement ValueGetter, I need to specify a type of the column. \r\nThis code from ValueGetter gives an exception - could not cast type String to ReadOnlyMemory<char>\r\n\r\n```C#\r\n  return (ValueGetter<TValue>)_enumerator.Current[column.Name]\r\n```\r\n\r\nIn this code from data view constructor I don't know how to set column type as \"dynamic\". \r\n\r\n```C#\r\n  public DictionaryView(IEnumerable<HashTable> items)\r\n  {\r\n    Items = items;\r\n\r\n    var builder = new DataViewSchema.Builder();\r\n\r\n    foreach (var k in items.First().Keys)\r\n    {\r\n      builder.AddColumn(k, TextDataViewType.Instance); // not sure what data type to use here, because HashTable doesn't have type for its Values\r\n    }\r\n    \r\n    Schema = builder.ToSchema();\r\n  }\r\n```\r\n\r\n**What did you expect?**\r\n\r\n- how to define all columns as `object` or `dynamic` or ... \r\n- is it possible to implement custom column type for a data view, something like DataKind.MixedEnumerableFloatString or ... \r\n- define Switch-Case mapping between System.Type and DataView.Kind like in the pseudo-code below?\r\n\r\n```C#\r\npublic override ValueGetter<TValue> GetGetter<TValue>(DataViewSchema.Column column)\r\n{\r\n  // Ideally, would be good to have some generic delegate that could return some \"dynamic\" type instead of hardcoded type-casting \r\n  // If we iterate over data view collection using cursor, we don't need to know the type of the column \r\n\r\n  switch (column.GetType().Name)\r\n  {\r\n    case \"Float\": return (ValueGetter<float>)_enumerator.Current[column.Name];\r\n    case \"Boolean\": return (ValueGetter<bool>)_enumerator.Current[column.Name];\r\n    case \"String\": return (ValueGetter<ReadOnlyMemory<char>>)_enumerator.Current[column.Name];\r\n  }\r\n\r\n  if (column is IEnumerable) \r\n  {\r\n    return (ValueGetter<IEnumerable<float>>)_enumerator.Current[column.Name];\r\n  }\r\n\r\n  return (ValueGetter<TValue>)_enumerator.Current[column.Name];\r\n}\r\n```\r\n\r\n### Source code / logs\r\n\r\nUsing this guide as an example. \r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.idataview?view=ml-dotnet \r\n\r\n```C#\r\npublic class DictionaryView : IDataView\r\n{\r\n  public bool CanShuffle => false;\r\n  public long? GetRowCount() => 0;\r\n  public DataViewSchema Schema { get; }\r\n  public IEnumerable<HashTable> Items = null;\r\n\r\n  public DictionaryView(IEnumerable<HashTable> items)\r\n  {\r\n    Items = items;\r\n\r\n    var builder = new DataViewSchema.Builder();\r\n    builder.AddColumn(\"Label\", TextDataViewType.Instance); // add multiple properties dynamically from IDictionary or HashTable item \r\n    \r\n    //foreach (var k in items.First().Keys)\r\n    //{\r\n    //  builder.AddColumn(k, TextDataViewType.Instance); // not sure what data type to use here, because HashTable doesn't have type for its Values\r\n    //}\r\n    \r\n    //builder.AddColumn(\"Value\", TextDataViewType.Instance);\r\n    Schema = builder.ToSchema();\r\n  }\r\n\r\n  public DataViewRowCursor GetRowCursor(IEnumerable<DataViewSchema.Column> columns, Random seed = null) => new Cursor(this);\r\n  public DataViewRowCursor[] GetRowCursorSet(IEnumerable<DataViewSchema.Column> columns, int n, Random seed = null) => new[] { GetRowCursor(columns, seed) };\r\n\r\n  private sealed class Cursor : DataViewRowCursor\r\n  {\r\n    private long _position = -1;\r\n    private bool _inactive = false;\r\n    private readonly IEnumerator<HashTable> _enumerator = null;\r\n\r\n    public override long Batch => 0;\r\n    public override long Position => _position;\r\n    public override DataViewSchema Schema { get; } = null;\r\n    public override bool IsColumnActive(DataViewSchema.Column column) => true;\r\n    public override ValueGetter<DataViewRowId> GetIdGetter() => (ref DataViewRowId id) => id = new DataViewRowId();\r\n\r\n    public Cursor(DataViewManager view)\r\n    {\r\n      _position = -1;\r\n      _enumerator = view.Items.GetEnumerator();\r\n\r\n      //_getters = new Delegate[]\r\n      //{\r\n      //  (ValueGetter<ReadOnlyMemory<char>>)LabelGetterImplementation\r\n      //};\r\n\r\n      Schema = view.Schema;\r\n    }\r\n\r\n    //private readonly Delegate[] _getters;\r\n    //private void LabelGetterImplementation(ref ReadOnlyMemory<char> value) => value = $\"{ _enumerator.Current[\"Label\"] }\".AsMemory();\r\n\r\n    public override ValueGetter<TValue> GetGetter<TValue>(DataViewSchema.Column column)\r\n    {\r\n      if (_enumerator.Current == null)\r\n      {\r\n        MoveNext();\r\n      }\r\n\r\n      return (ValueGetter<TValue>)_enumerator.Current[column.Name]; // extract property by name from the current row of HashTable or IDictionary type\r\n\r\n      //return (ValueGetter<TValue>)_getters[column.Index];\r\n    }\r\n\r\n    protected override void Dispose(bool disposing)\r\n    {\r\n      if (_inactive)\r\n      {\r\n        return;\r\n      }\r\n\r\n      if (disposing)\r\n      {\r\n        _enumerator.Dispose();\r\n        _position = -1;\r\n      }\r\n\r\n      _inactive = true;\r\n\r\n      base.Dispose(disposing);\r\n    }\r\n\r\n    public override bool MoveNext()\r\n    {\r\n      if (_inactive)\r\n      {\r\n        return false;\r\n      }\r\n\r\n      if (_enumerator.MoveNext())\r\n      {\r\n        _position++;\r\n        return true;\r\n      }\r\n\r\n      Dispose();\r\n\r\n      return false;\r\n    }\r\n  }\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4920","RelatedDescription":"Closed issue \"Create DataView from IEnumerable<HashTable> or IEnumerable<IDictionary<string,dynamic>>\" (#4920)"},{"Id":"577382791","IsPullRequest":false,"CreatedAt":"2020-03-07T18:42:48","Actor":"artemiusgreat","Number":"4923","RawContent":null,"Title":"How Transformer converts structured or custom data view type into a feature value?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro x64\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.0\r\n- **ML.NET Version**: 1.5.0-preview\r\n\r\n### Question\r\n\r\nWhen implementing a custom data view type, how does transformer know what to use as a \"value\" of this type? Does it use `GetHashCode()` method for this?\r\n\r\n### Source code \r\n\r\nConsidering, we have this custom image type with properties Width and Height. \r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.ImageAnalytics/ImageType.cs \r\n\r\nThen, we have this transformer code that merges several columns into one called `Features`. \r\nOne of these columns has type `ImageType`. \r\n\r\n```C#\r\n  var pipeline = Context\r\n    .Transforms\r\n    .Conversion\r\n    .Append(Context.Transforms.Concatenate(\"Features\", new[] { \"ImageColumn\", \"Points\" }));\r\n```\r\n\r\nAs far as I understand, for ML engine to learn something from the provided data, `Features` should be an array of float values. So, the question is, how `ImageColumn` and `Points` will be converted to floats? \r\n\r\nAnother example that I found is this test for custom type registration. \r\nIt's also using GetHashCode method. \r\nhttps://github.com/dotnet/machinelearning/blob/release/1.5-preview/test/Microsoft.ML.Core.Tests/UnitTests/TestCustomTypeRegister.cs\r\n\r\n**I'd like somebody to confirm that whatever is returned from GetHashCode method will be used in training the model.**\r\n\r\n```C#\r\npublic override int GetHashCode() // unique value for ImageType\r\n{\r\n    return Hashing.CombineHash(Height.GetHashCode(), Width.GetHashCode());\r\n}\r\n```\r\n\r\nI'm asking because, e.g. OnnxMapType or OnnxSequenceType are completely different animals, whose GetHashCode method returns value based on a data type, not its value.\r\nhttps://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.OnnxTransformer/OnnxMapType.cs\r\n\r\n```C#\r\npublic override int GetHashCode() // uniquer value for OnnxMapType\r\n{\r\n    return RawType.GetHashCode();\r\n}\r\n```\r\n\r\n**Does it mean that ONNX types cannot be used for training because their hash code is based on a System.Type instead of actual observation?**","Url":"https://github.com/dotnet/machinelearning/issues/4923","RelatedDescription":"Open issue \"How Transformer converts structured or custom data view type into a feature value?\" (#4923)"},{"Id":"577092182","IsPullRequest":true,"CreatedAt":"2020-03-06T18:46:08","Actor":"LittleLittleCloud","Number":"4922","RawContent":null,"Title":"Add hasHeader flag in ColumnInference function","State":"closed","Body":"### This change will only affect the internal API.\r\n\r\nwhen hasHeader is true, AutoML will use the column name from dataset's header to indicate label/userId/itemId. else, it will use the default column name `col{i}` to indicate those information","Url":"https://github.com/dotnet/machinelearning/pull/4922","RelatedDescription":"Closed or merged PR \"Add hasHeader flag in ColumnInference function\" (#4922)"},{"Id":"575481194","IsPullRequest":false,"CreatedAt":"2020-03-06T13:43:41","Actor":"tomasfalt","Number":"4917","RawContent":null,"Title":"Error loading LightGBM model","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .Net Standard 2.0\r\n- **ML.Net version**: 1.4\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nBuild and trained a model with FastTree, saved it and finally load it and all worked. Changed to LightGBM and got an error when I try to load it.\r\n\r\nThe error is following:\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\n### Source code / logs\r\n\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Error during class instantiation\r\n  Source=Microsoft.ML.Core\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(String filePath, DataViewSchema& inputSchema)\r\n  \r\n\r\n  This exception was originally thrown at this call stack:\r\n\tMicrosoft.ML.Runtime.ComponentCatalog.TryGetIniters(System.Type, System.Type, System.Type[], out System.Reflection.MethodInfo, out System.Reflection.ConstructorInfo, out System.Reflection.MethodInfo, out bool)\r\n\tMicrosoft.ML.Runtime.ComponentCatalog.RegisterAssembly(System.Reflection.Assembly, bool)\r\n\tMicrosoft.ML.ModelLoadContext.EnsureLoaderAssemblyIsRegistered(Microsoft.ML.Runtime.ComponentCatalog)\r\n\tMicrosoft.ML.ModelLoadContext.TryLoadModelCore<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, object[])\r\n\tMicrosoft.ML.ModelLoadContext.TryLoadModel<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, Microsoft.ML.Repository.Entry, string, object[])\r\n\tMicrosoft.ML.ModelLoadContext.LoadModel<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, Microsoft.ML.Repository.Entry, string, object[])\r\n\tMicrosoft.ML.ModelLoadContext.LoadModelOrNull<TRes, TSig>(Microsoft.ML.Runtime.IHostEnvironment, out TRes, Microsoft.ML.RepositoryReader, string, object[])\r\n\r\nInner Exception 1:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 2:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nInner Exception 3:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 4:\r\nInvalidOperationException: Error during class instantiation\r\n\r\nInner Exception 5:\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\n\r\nInner Exception 6:\r\nInvalidOperationException: Can't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4917","RelatedDescription":"Closed issue \"Error loading LightGBM model\" (#4917)"},{"Id":"575808706","IsPullRequest":true,"CreatedAt":"2020-03-05T20:46:00","Actor":"frank-dong-ms","Number":"4918","RawContent":null,"Title":"LightGBM Crash issue","State":"closed","Body":"https://github.com/microsoft/LightGBM/issues/2820\r\n\r\nLightGBM has dependency on OpenMP multi-threading library. In our tests we are setting number of threads to be 1 for LightGBM and LightGBM also sets OpenMP to use only 1 thread. While OpenMP is also used by other native libraries and they also tend to set number of threads for OpenMP to use (by default this is number of cores, in our case it is 2 as we are using https://docs.microsoft.com/en-us/azure/virtual-machines/dv2-dsv2-series#dsv2-series). This setting(number of threads) is global in process and cause LightGBM referencing OpenMP from single threads to multi-threads. LightGBM is using number of threads for indexing and thus cause index out of range in native code and crash the process.\r\n\r\nBy this fix, we are not force single threading when run LightGBM related tests thus default behavior is applied and all the libraries use same number of threads for OpenMP.\r\n\r\nIdealy LightGBM better not to rely number of threads to do indexing as this setting is global and likely be override by other library.","Url":"https://github.com/dotnet/machinelearning/pull/4918","RelatedDescription":"Closed or merged PR \"LightGBM Crash issue\" (#4918)"},{"Id":"575301003","IsPullRequest":false,"CreatedAt":"2020-03-05T07:14:55","Actor":"nighotatul","Number":"4916","RawContent":null,"Title":"how we show score,probability associated with Permutation Feature Importance (PFI) so end user can easily identify?","State":"closed","Body":"@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\nreferences link:\r\n[how we show permutation slot associated with feature so end user easily identify? #4739](url)\r\n\r\nhow we can get score,probability of PFI?\r\nwe have get globally score and probability but we cannot get at PFI. how we can achieve this?","Url":"https://github.com/dotnet/machinelearning/issues/4916","RelatedDescription":"Closed issue \"how we show score,probability associated with Permutation Feature Importance (PFI) so end user can easily identify?\" (#4916)"},{"Id":"575066433","IsPullRequest":true,"CreatedAt":"2020-03-04T21:00:54","Actor":"LittleLittleCloud","Number":"4913","RawContent":null,"Title":"Update ConsumeModel.cs to enhance it's performance when being called for multiple times","State":"closed","Body":"#### Sample Code\r\n\r\n``` c#\r\n// This file was auto-generated by ML.NET Model Builder. \r\n\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing System.Text;\r\nusing Microsoft.ML;\r\nusing Test.Model;\r\n\r\nnamespace Test.Model\r\n{\r\n    public class ConsumeModel\r\n    {\r\n        private static Lazy<PredictionEngine<ModelInput, ModelOutput>> PredictionEngine = new Lazy<PredictionEngine<ModelInput, ModelOutput>>(CreatePredictionEngine);\r\n\r\n        // For more info on consuming ML.NET models, visit https://aka.ms/model-builder-consume\r\n        // Method for consuming model in your app\r\n        public static ModelOutput Predict(ModelInput input)\r\n        {\r\n            ModelOutput result = PredictionEngine.Value.Predict(input);\r\n            return result;\r\n        }\r\n\r\n        public static PredictionEngine<ModelInput, ModelOutput> CreatePredictionEngine()\r\n        {\r\n            // Create new MLContext\r\n            MLContext mlContext = new MLContext();\r\n\r\n            // Register LabelMapping\r\n            mlContext.ComponentCatalog.RegisterAssembly(typeof(LabelMapping).Assembly);\r\n\r\n            // Load model & create prediction engine\r\n            string modelPath = @\"\\path\\to\\model\";\r\n            ITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n            var predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);\r\n\r\n            return predEngine;\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n#### Related Issue\r\n- [Simplify CodeGen](https://app.zenhub.com/workspaces/mlnet-tools-5cde1c97e3106e39e8ae08fc/issues/dotnet/machinelearning-modelbuilder/558)","Url":"https://github.com/dotnet/machinelearning/pull/4913","RelatedDescription":"Closed or merged PR \"Update ConsumeModel.cs to enhance it's performance when being called for multiple times\" (#4913)"},{"Id":"575074859","IsPullRequest":false,"CreatedAt":"2020-03-04T01:32:46","Actor":"crvkumar","Number":"4914","RawContent":null,"Title":"WeakReference<IHost> memory leak?","State":"open","Body":"### System information\r\n\r\n- **ML.NET Version**: 1.4.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\n1. Created a pipeline of ImageLoadingEstimator + ImageResizingEstimator + ImagePixelExtractingEstimator + OnnxScoringEstimator.\r\n2. Create a ITransformer object by fitting the pipeline.\r\n3. Performed ITransformer.Transform multiple times.\r\n\r\nPS: Creating a PredictionEngine and performing PredictionEngine.Predict seems to lock the image as mentioned in issue [4585](https://github.com/dotnet/machinelearning/issues/4585 )\r\n\r\n- **What happened?** \r\n\r\nWeakReference<IHost> objects seems to accumulate.\r\n\r\nThe number of objects does not change even after performing GC.Collect()\r\n\r\nIs this possibly a memory leak?\r\nThe application is built is Release configuration.\r\n\r\n![image](https://user-images.githubusercontent.com/2994809/75835713-f44f3a80-5e02-11ea-8454-abea45097ecc.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4914","RelatedDescription":"Open issue \"WeakReference<IHost> memory leak?\" (#4914)"},{"Id":"574872193","IsPullRequest":false,"CreatedAt":"2020-03-03T18:56:08","Actor":"nighotatul","Number":"4912","RawContent":null,"Title":"how we show bins associated with numeric feature so end user can easily identify?","State":"open","Body":"@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\n\r\nthanks for giving example for each feature weights.\r\n\r\nwith the references below link with subject lines:-\r\nhow we show permutation slot associated with feature so end user easily identify?\r\n[https://github.com/dotnet/machinelearning/issues/4739](url)\r\n\r\n![Picture1](https://user-images.githubusercontent.com/37444019/75969231-a286dd00-5ef4-11ea-955f-60900fc8fdbe.png)\r\n\r\nsuppose if this is yearatcomapny feature is having numeric data how we can get bins with model weights if this data is continuous then how we can get scatter points? \r\n\r\n2) how we can get  score,probability,confusion matrix of PFI also?","Url":"https://github.com/dotnet/machinelearning/issues/4912","RelatedDescription":"Open issue \"how we show bins associated with numeric feature so end user can easily identify?\" (#4912)"},{"Id":"574621779","IsPullRequest":false,"CreatedAt":"2020-03-03T12:05:27","Actor":"ddobric","Number":"4910","RawContent":null,"Title":"Poor accuracy with non-US regional settings","State":"open","Body":"### System information\r\n\r\n- **OS Windows 10**:\r\n- **.NET Core 2.2**: \r\n\r\n### Issue\r\nGetting poor accuracy running the training code on a system with non-US regional settings. The issue is number format. After replacing ',' as decimal symbol to '.' all works fine.\r\n\r\nAccuracy with ',' decimal symbol:\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/75774084-754cfa00-5d4f-11ea-929e-891b85175b34.png)\r\n\r\nAccuracy with '.' decimal symbol:\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/75774069-6bc39200-5d4f-11ea-9274-bafc5bb4789d.png)\r\n\r\nIs there some way to take a control of localization in .NET ML?\r\n\r\nThanks\r\nDamir","Url":"https://github.com/dotnet/machinelearning/issues/4910","RelatedDescription":"Open issue \"Poor accuracy with non-US regional settings\" (#4910)"},{"Id":"574566993","IsPullRequest":false,"CreatedAt":"2020-03-03T10:30:01","Actor":"yaeldekel","Number":"4909","RawContent":null,"Title":"AppendCacheCheckpoint is ignored at the beginning of the pipeline","State":"open","Body":"When an empty `EstimatorChain` is created, and `AppendCacheCheckpoint` is called before adding any estimators, then no caching occurs. \r\nThe expected behavior should be to either cache the data before fitting the first estimator in the chain, or disallow calling `AppendCacheCheckpoint` on empty chains, so that the user knows to cache the data explicitly before fitting. (I think the first solution is preferable, but open to other opinions).","Url":"https://github.com/dotnet/machinelearning/issues/4909","RelatedDescription":"Open issue \"AppendCacheCheckpoint is ignored at the beginning of the pipeline\" (#4909)"},{"Id":"574478910","IsPullRequest":true,"CreatedAt":"2020-03-03T07:48:35","Actor":"mstfbl","Number":"4908","RawContent":null,"Title":"Debugging for VSTest Implementation","State":"open","Body":"Debugging CI builds for VSTest implementation to diagnose hanging/long-running tests","Url":"https://github.com/dotnet/machinelearning/pull/4908","RelatedDescription":"Open PR \"Debugging for VSTest Implementation\" (#4908)"}],"ResultType":"GitHubIssue"}},"RunOn":"2020-03-12T05:30:41.3267496Z","RunDurationInMilliseconds":635}