{"Data":{"GitHub":{"Issues":[{"Id":"422501891","IsPullRequest":true,"CreatedAt":"2019-03-19T01:24:31","Actor":"codemzs","Number":"3008","RawContent":null,"Title":"MLContext.Model.Load overloads that take file path instead of stream.","State":"open","Body":"fixes #2991\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3008","RelatedDescription":"Open PR \"MLContext.Model.Load overloads that take file path instead of stream.\" (#3008)"},{"Id":"422065516","IsPullRequest":true,"CreatedAt":"2019-03-19T01:01:58","Actor":"codemzs","Number":"2993","RawContent":null,"Title":"Include the save file action (.ZIP file) as part of model.SaveFile().","State":"closed","Body":"fixes #1689","Url":"https://github.com/dotnet/machinelearning/pull/2993","RelatedDescription":"Closed or merged PR \"Include the save file action (.ZIP file) as part of model.SaveFile().\" (#2993)"},{"Id":"421727275","IsPullRequest":true,"CreatedAt":"2019-03-19T00:47:47","Actor":"abgoswam","Number":"2985","RawContent":null,"Title":"OutputTokens option in FeaturizeText API","State":"closed","Body":"Fixes #2957\r\n\r\n- the PR follows the proposal https://github.com/dotnet/machinelearning/issues/2957#issuecomment-473568237 to fix the issue\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2985","RelatedDescription":"Closed or merged PR \"OutputTokens option in FeaturizeText API\" (#2985)"},{"Id":"422493636","IsPullRequest":false,"CreatedAt":"2019-03-19T00:40:54","Actor":"glebuk","Number":"3007","RawContent":null,"Title":"Perf: Optimization for DoubleParser (VTune)","State":"open","Body":"Benchmarking using VTune has found several bottlenecks in parsing Doubles from string in text reader\r\nPerhaps we should consider optimizing this method:\r\nFor example, for training a FM it takes almost 37% of all clock cycles:\r\n\r\nFunction | Module | CPU Time\r\n-- | -- | --\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParseCore | Microsoft.ML.Core.dll | 27.390s\r\nCalculateGradientAndUpdateNative | factorizationmachinenative.dll | 22.609s\r\nHelperImpl::FetchNextField | Microsoft.ML.Data.dll | 13.826s\r\nCalculateIntermediateVariablesNative | factorizationmachinenative.dll | 12.201s\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParse | Microsoft.ML.Core.dll | 9.666s\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3007","RelatedDescription":"Open issue \"Perf: Optimization for DoubleParser (VTune)\" (#3007)"},{"Id":"422492087","IsPullRequest":true,"CreatedAt":"2019-03-19T00:33:01","Actor":"zeahmed","Number":"3006","RawContent":null,"Title":"Added tests for text featurizer options (Part1).","State":"open","Body":"This PR partially address #2967. See the following list. Further tests will be added in the next PR.\r\n\r\nTest created for following parameters in options class\r\n\r\n* StopWordsRemover\r\n* CaseMode\r\n* KeepDiacritics\r\n* KeepPunctuations\r\n* KeepNumbers\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3006","RelatedDescription":"Open PR \"Added tests for text featurizer options (Part1).\" (#3006)"},{"Id":"422490989","IsPullRequest":false,"CreatedAt":"2019-03-19T00:27:15","Actor":"wschin","Number":"3005","RawContent":null,"Title":"Enum Name --- OneHotEncodingEstimator.OutputKind","State":"open","Body":"I personally prefer `OneHotEncodingEstimator.Representation` than `OneHotEncodingEstimator.OutputKind`. @sfilipi, @TomFinley, @rogancarr, any comment please?","Url":"https://github.com/dotnet/machinelearning/issues/3005","RelatedDescription":"Open issue \"Enum Name --- OneHotEncodingEstimator.OutputKind\" (#3005)"},{"Id":"422030394","IsPullRequest":true,"CreatedAt":"2019-03-19T00:23:53","Actor":"abgoswam","Number":"2990","RawContent":null,"Title":"Fix FeatureColumnName in the public API","State":"closed","Body":"Fixes #2975\r\n\r\n- also fixes an incorrect parameter name `featureColumn` parameter in ExplanabilityCatalog.cs","Url":"https://github.com/dotnet/machinelearning/pull/2990","RelatedDescription":"Closed or merged PR \"Fix FeatureColumnName in the public API\" (#2990)"},{"Id":"422490241","IsPullRequest":false,"CreatedAt":"2019-03-19T00:23:12","Actor":"glebuk","Number":"3004","RawContent":null,"Title":"Perf: Optimization for GAMs (VTune)","State":"open","Body":"Benchmarking using VTune has found several bottlenecks in GAMS\r\n\r\n- Significant CPU cycles spent in Interlocked.CompareExchange. \r\n- Call-stack & source code of CenterGraph shows Interlocked.CompareExchange in the inner loop, contributing to the high CPU cycles in CompareExchange. Look at reducing the calls to this intrinsic.\r\n- Next step: Look at re-jiggering the code in CenterGraph to avoid the CompareExchange in the inner loop\r\n\r\nTop HotSpots:\r\n\r\nFunction | Module | CPU Time\r\n-- | -- | --\r\nCOMInterlocked::CompareExchangeDouble | coreclr.dll | 55.754s\r\n<>c__DisplayClass46_0::<UpdateScoresForSet>b__0 | Microsoft.ML.FastTree.dll | 35.381s\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParseCore | Microsoft.ML.Core.dll | 30.808s\r\n<>c__DisplayClass49_0::<CenterGraph>b__0 | Microsoft.ML.FastTree.dll | 26.872s\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3004","RelatedDescription":"Open issue \"Perf: Optimization for GAMs (VTune)\" (#3004)"},{"Id":"422477405","IsPullRequest":false,"CreatedAt":"2019-03-18T23:22:39","Actor":"briacht","Number":"3003","RawContent":null,"Title":"MatrixFactorizationTrainer prints log statements to console even if Quiet = true","State":"open","Body":"Even when MatrixFactorizationTrainer option Quiet=true, the iterations print to console.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/481c37774afdbc6f8b1eab9c9f894c83f3ac984d/src/Microsoft.ML.Recommender/MatrixFactorizationTrainer.cs#L160\r\n\r\n![image](https://user-images.githubusercontent.com/10437687/54569846-8f07fc80-4999-11e9-8cec-b6808af726f8.png)","Url":"https://github.com/dotnet/machinelearning/issues/3003","RelatedDescription":"Open issue \"MatrixFactorizationTrainer prints log statements to console even if Quiet = true\" (#3003)"},{"Id":"422475837","IsPullRequest":false,"CreatedAt":"2019-03-18T23:16:05","Actor":"abgoswam","Number":"3002","RawContent":null,"Title":"Add check for collision of  `OutputTokensColumnName` with `OutputColumn` in `FeaturizeText`","State":"open","Body":"Add check for collision of  `OutputTokensColumnName` with `OutputColumn` in `FeaturizeText`\r\n\r\nhttps://github.com/dotnet/machinelearning/pull/2985#issuecomment-474100886\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3002","RelatedDescription":"Open issue \"Add check for collision of  `OutputTokensColumnName` with `OutputColumn` in `FeaturizeText`\" (#3002)"},{"Id":"422466180","IsPullRequest":false,"CreatedAt":"2019-03-18T22:39:45","Actor":"glebuk","Number":"3001","RawContent":null,"Title":"Perf: Optimization for MatrixFactorization","State":"open","Body":"Benchmarking using VTune has found several bottlenecks in Matrix Factorization training algorithm.\r\n-Experiment to find potential gain with AVX & SSE & Intrinsics  in matrixfactorizationnative.dll module\r\n-Based on result of above experiment, take a look at implementing this in the product [fat binary vs dynamic dispatch]\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3001","RelatedDescription":"Open issue \"Perf: Optimization for MatrixFactorization\" (#3001)"},{"Id":"422465049","IsPullRequest":false,"CreatedAt":"2019-03-18T22:35:35","Actor":"glebuk","Number":"3000","RawContent":null,"Title":"Perf: Optimization for FactorizationMachine","State":"open","Body":"Benchmarking using VTune has found several bottlenecks in Factrization Machine training algorithm.\r\n\r\n- Some phases training that are not parallelized. Consider adding parallel computation.\r\n- Evaluate using AVX/AVX2 (C++ or C# instrinsics) in factorizationmachinenative.dll which currently implements C++ SSE code\r\n- Consider optimizing the following hotspot\r\n\r\nFunction | Module | CPU Time\r\n-- | -- | --\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParseCore | Microsoft.ML.Core.dll | 27.390s\r\nCalculateGradientAndUpdateNative | factorizationmachinenative.dll | 22.609s\r\nHelperImpl::FetchNextField | Microsoft.ML.Data.dll | 13.826s\r\nCalculateIntermediateVariablesNative | factorizationmachinenative.dll | 12.201s\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParse | Microsoft.ML.Core.dll | 9.666s\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3000","RelatedDescription":"Open issue \"Perf: Optimization for FactorizationMachine\" (#3000)"},{"Id":"422445892","IsPullRequest":true,"CreatedAt":"2019-03-18T21:35:16","Actor":"shmoradims","Number":"2999","RawContent":null,"Title":"Added samples for tree regression trainers.","State":"open","Body":"Related to #2522.\r\n\r\nSamples for tree regression trainers: GAM, FastTree, FastForest, FastTreeTweedie.","Url":"https://github.com/dotnet/machinelearning/pull/2999","RelatedDescription":"Open PR \"Added samples for tree regression trainers.\" (#2999)"},{"Id":"422428280","IsPullRequest":false,"CreatedAt":"2019-03-18T20:50:11","Actor":"sfilipi","Number":"2998","RawContent":null,"Title":"The result of the weights calculation in the build definitions making use of Intrinsics are different from the other builds. ","State":"open","Body":"I am adding [a test](https://github.com/dotnet/machinelearning/pull/2048/files#r266634629) in [this PR](https://github.com/dotnet/machinelearning/pull/2048) and it is failing in the following definitions:\r\n\r\n* core30 Build_Debug_Intrinsics\r\n* core30 Build_Release_Intrinsics\r\n* CentOS Build_Debug_Intrinsics\r\n* Ubuntu Build_Release_Intrinsics\r\n\r\nThe weight calculation for MulticlassLR in those build definitions are different from the ones in the other definitions. \r\n\r\nweights in windows x64\r\n[0, 0.5247429, -2.43042159, -0.490746975],\r\n[0.210617781, 0, 0, -0.370147228],\r\n[1.62008985E-06, -0.002228372, 2.49340868, 1.77681744]\r\n\r\nweights in windows core30_debug_Intrinsics:\r\n[0, 0.621862, -2.38398933, -0.427630424],\r\n[0.108599916, 0, 0, -0.372884184],\r\n[-0.106881194, -0.0351369865, 2.42675567, 1.80688608]","Url":"https://github.com/dotnet/machinelearning/issues/2998","RelatedDescription":"Open issue \"The result of the weights calculation in the build definitions making use of Intrinsics are different from the other builds. \" (#2998)"},{"Id":"422424814","IsPullRequest":false,"CreatedAt":"2019-03-18T20:41:48","Actor":"glebuk","Number":"2997","RawContent":null,"Title":"Add support for cancelling of training","State":"open","Body":"Once the cancellation mechanism is available, we need to enable cancellation of training for the following learners:\r\n- RegressionCatalog.Trainers.StochasticDualCoordinateAscent\r\n- RegressionCatalog.Trainers.FastTree\r\n- BinaryClassificationCatalog.Trainers.FastTree\r\n- BinaryClassificationCatalog.Trainers.LogisticRegression\r\n\r\nThis is continuation of #2795 \r\n\r\nAt the very least we should be able to check for cancellation at the beginning of training and at the beginning of each iteration.\r\n\r\n## Pri2: Also do this for:\r\n- Normalization\r\n- OneHotEncoding","Url":"https://github.com/dotnet/machinelearning/issues/2997","RelatedDescription":"Open issue \"Add support for cancelling of training\" (#2997)"},{"Id":"422396695","IsPullRequest":false,"CreatedAt":"2019-03-18T19:32:08","Actor":"yaeldekel","Number":"2996","RawContent":null,"Title":"Cannot create TextLoader without loading assemblies into ComponentCatalog","State":"open","Body":"In the `TextLoader` constructor, it is allows to pass a null `Options`, or an `Options` object with a null `Columns` (see https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1095 and https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1111).\r\nWhen this is the case, the constructor goes to `TryParseSchema` which uses the `ComponentCatalog` to load the schema, so we get a null reference exception here: https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/DataLoadSave/Text/TextLoader.cs#L1293, if no assemblies are loaded.","Url":"https://github.com/dotnet/machinelearning/issues/2996","RelatedDescription":"Open issue \"Cannot create TextLoader without loading assemblies into ComponentCatalog\" (#2996)"},{"Id":"422063660","IsPullRequest":true,"CreatedAt":"2019-03-18T17:37:58","Actor":"rauhs","Number":"2992","RawContent":null,"Title":"Fix spelling: normazlize","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/2992","RelatedDescription":"Closed or merged PR \"Fix spelling: normazlize\" (#2992)"},{"Id":"422060532","IsPullRequest":true,"CreatedAt":"2019-03-18T17:12:22","Actor":"codemzs","Number":"2991","RawContent":null,"Title":"Add MLContext.Model.Load overload that takes a file path.","State":"closed","Body":"fixes #2983\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2991","RelatedDescription":"Closed or merged PR \"Add MLContext.Model.Load overload that takes a file path.\" (#2991)"},{"Id":"421720910","IsPullRequest":false,"CreatedAt":"2019-03-18T17:12:22","Actor":"eerhardt","Number":"2983","RawContent":null,"Title":"Add MLContext.Model.Load overload that takes a file path","State":"closed","Body":"Today, the only way to load a model is by using a `Stream`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/e2464f606c69357898572aac8e4d8d3c1451c92f/src/Microsoft.ML.Data/Model/ModelOperationsCatalog.cs#L36-L41\r\n\r\nWe should add an overload that takes a `string filePath` as a convenience API over top of this. That way all the callers don't need to open a `FileStream` and dispose of it, etc, just to load a model.\r\n\r\n@TomFinley @CESARDELATORRE @sfilipi @shauheen ","Url":"https://github.com/dotnet/machinelearning/issues/2983","RelatedDescription":"Closed issue \"Add MLContext.Model.Load overload that takes a file path\" (#2983)"},{"Id":"421741781","IsPullRequest":true,"CreatedAt":"2019-03-18T17:06:43","Actor":"eerhardt","Number":"2987","RawContent":null,"Title":"Move IDataView into Microsoft.ML namespace","State":"closed","Body":"Fix #2974\r\n\r\nHere's the steps I took:\r\n\r\n1. Rename the folders and files for the `src\\Microsoft.Data.DataView` and `pkg\\Microsoft.Data.DataView` to `Microsoft.ML.DataView`.\r\n2. Rename the namespaces in that assembly:\r\n    - IDataView.cs and DataViewSchema.cs move to the `Microsoft.ML` namespace.\r\n    - Everything else in the assembly move to the `Microsoft.ML.Data` namespace.\r\n3. Find all `using Microsoft.Data.DataView;` lines and delete them.\r\n4. Compile, and fix any build errors to add `using Microsoft.ML.Data;` lines.\r\n5. In the Parquet files, there were some full namespace usages that I removed.\r\n6. Find all \"Microsoft.Data\" in the repo, and change as appropriate (it was only docs). \r\n   - there is only 1 place left - which was there before we made this change\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/87ede9ef39c10b8511fc7f14f97d1250bbd2b951/src/Microsoft.ML.Core/ComponentModel/AssemblyLoadingUtils.cs#L121","Url":"https://github.com/dotnet/machinelearning/pull/2987","RelatedDescription":"Closed or merged PR \"Move IDataView into Microsoft.ML namespace\" (#2987)"},{"Id":"421703060","IsPullRequest":true,"CreatedAt":"2019-03-18T16:58:59","Actor":"shmoradims","Number":"2979","RawContent":null,"Title":"In-memory & self-contained sample template.","State":"closed","Body":"Related to #2726 I created this in-memory and self-contained sample for FastTree. I'll use the final version from this PR as template for the following samples.","Url":"https://github.com/dotnet/machinelearning/pull/2979","RelatedDescription":"Closed or merged PR \"In-memory & self-contained sample template.\" (#2979)"},{"Id":"422216588","IsPullRequest":true,"CreatedAt":"2019-03-18T13:26:23","Actor":"yaeldekel","Number":"2995","RawContent":null,"Title":"Clean up the SchemaDefinition class","State":"open","Body":"Fixes #2978 .","Url":"https://github.com/dotnet/machinelearning/pull/2995","RelatedDescription":"Open PR \"Clean up the SchemaDefinition class\" (#2995)"},{"Id":"422083705","IsPullRequest":false,"CreatedAt":"2019-03-18T08:05:03","Actor":"bpietroiu","Number":"2994","RawContent":null,"Title":"I want to convert a text classification sample from ML 0.4 to ML 0.11 and cannot find equivalent code for calling Transforms.Text.FeaturizeText","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**: 4.7.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI want to convert a text classification sample from ML 0.4 to ML 0.11\r\n- **What happened?**\r\nI cannot find equivalent parameters for TextFeaturizer, there are no CharFeatureExtractor and WordFeatureExtractor NgramExtractors in 0.11 Transforms.Text.FeaturizeText arguments\r\n\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\n**0.4 version**\r\n\r\n```\r\n                new TextFeaturizer(\"Features\", \"TextColumn\")\r\n                {\r\n                    KeepDiacritics = false,\r\n                    KeepPunctuations = false,\r\n                    OutputTokens = true,\r\n                    Language = TextFeaturizingEstimatorLanguage.English,\r\n                    VectorNormalizer = TextFeaturizingEstimatorTextNormKind.L2,\r\n                    TextCase = TextNormalizingEstimatorCaseNormalizationMode.Lower,\r\n                    CharFeatureExtractor = new NGramNgramExtractor() {NgramLength = 3, AllLengths = false},\r\n                    WordFeatureExtractor = new NGramNgramExtractor() {NgramLength = 3, AllLengths = true}\r\n                }, \r\n\r\n```\r\n\r\n\r\n**0.11 version**\r\n\r\n```\r\nvar transform mlContext.Transforms.Text.FeaturizeText(outputColumnName: \"TextColumnFeaturized\",\r\n                        options: new TextFeaturizingEstimator.Options()\r\n                        {\r\n                            KeepDiacritics = false,\r\n                            KeepPunctuations = false,\r\n                            OutputTokens = true,\r\n                            TextLanguage = TextFeaturizingEstimator.Language.English,\r\n                            VectorNormalizer = TextFeaturizingEstimator.TextNormKind.L2,\r\n                            TextCase = TextNormalizingEstimator.CaseNormalizationMode.Lower,\r\n                            UseWordExtractor = true,\r\n                            UseCharExtractor = true\r\n                        }, inputColumnNames: new []{ \"TextColumn\" });\r\n```\r\n\r\nI see that CharFeatureExtractor and WordFeatureExtractor parameters are gone, and instead two we have boolean properties, UseWordExtractor and UseCharExtractor.\r\n\r\nThe models trained using the above code and the same train data perform differently, namly the 0.4 version has a better classsification performace.\r\n\r\nHow do I configure a pipeline to achieve the same results as in 0.4 version?\r\n\r\n\r\nThank you!\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2994","RelatedDescription":"Open issue \"I want to convert a text classification sample from ML 0.4 to ML 0.11 and cannot find equivalent code for calling Transforms.Text.FeaturizeText\" (#2994)"},{"Id":"421788246","IsPullRequest":false,"CreatedAt":"2019-03-16T09:22:59","Actor":"Alex-fbr","Number":"2989","RawContent":null,"Title":"DateTime  ERROR","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:  Windows 10 Home\r\n- **.NET Version (eg., dotnet --info)**:  .net core 2.2.0\r\n\r\n### Issue\r\nI updated Nuget package from ML 0.8 to 0.11. I have a truble. \r\nMy csv File contain:\r\n\r\nSECID,CurrentDate,OpenPrice,FareClosePrice\r\nLKOH,2019-01-01,4984.00,5007.00\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\n  _textLoader = mlContext.Data.CreateTextLoader(\r\n                separatorChar: ',',\r\n                hasHeader: true,\r\n                columns: new TextLoader.Column[]\r\n                {\r\n                    new TextLoader.Column(\"SECID\", DataKind.String, 0),\r\n                    new TextLoader.Column(\"CurrentDate\", DataKind.DateTime, 1),\r\n                    new TextLoader.Column(\"OpenPrice\", DataKind.Double, 2),\r\n                    new TextLoader.Column(\"FareClosePrice\", DataKind.Double, 3)\r\n                });\r\n\r\n           IDataView dataView = _textLoader.Load(dataPath);\r\n            var pipeline = mlContext.Transforms.CopyColumns(\"Label\", \"FareClosePrice\")\r\n                .Append(mlContext.Transforms.Categorical.OneHotEncoding(\"SECID\"))\r\n                .Append(mlContext.Transforms.Concatenate(\"Features\", \"SECID\", \"CurrentDate\", \"OpenPrice\", \"FareClosePrice\"))\r\n            .Append(mlContext.Regression.Trainers.FastTree());\r\n\r\n// An error occurs here:  System.InvalidOperationException: \"Column 'CurrentDate' has values of // DateTimewhich is not the same as earlier observed type of R4.\"\r\n\r\n            var model = pipeline.Fit(dataView);\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2989","RelatedDescription":"Open issue \"DateTime  ERROR\" (#2989)"},{"Id":"421742554","IsPullRequest":true,"CreatedAt":"2019-03-15T23:55:23","Actor":"jwood803","Number":"2988","RawContent":null,"Title":"Load a model by path","State":"closed","Body":"Updates for #2983.\r\n\r\nOpening as draft for any discussion.","Url":"https://github.com/dotnet/machinelearning/pull/2988","RelatedDescription":"Closed or merged PR \"Load a model by path\" (#2988)"},{"Id":"421740613","IsPullRequest":false,"CreatedAt":"2019-03-15T23:41:05","Actor":"eerhardt","Number":"2986","RawContent":null,"Title":"Co-locate VBuffer and VectorType with IDataView","State":"open","Body":"Once we do #2974, to move `IDataView` into the `ML` namespace, we should move `VBuffer`, `VectorType` and `KeyType` into the same assembly/package as `IDataView`.\r\n\r\n`VBuffer` and `KeyType` were left in `Microsoft.ML` because they were too specific to machine learning usages to be in `Microsoft.Data`. If we are moving `IDataView` back into the `Microsoft.ML` namespace, then we should be able to locate these types in the same package.\r\n\r\ncc @TomFinley @shauheen @glebuk ","Url":"https://github.com/dotnet/machinelearning/issues/2986","RelatedDescription":"Open issue \"Co-locate VBuffer and VectorType with IDataView\" (#2986)"},{"Id":"421724812","IsPullRequest":true,"CreatedAt":"2019-03-15T22:21:24","Actor":"rogancarr","Number":"2984","RawContent":null,"Title":"Add functional tests for ONNX scenarios","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the ONNX functionality we want fully supported in V1.\r\n\r\nScenarios:\r\n- I can take an existing ONNX model and get predictions from it (as both final output and as input to downstream pipelines)\r\n- P1: I can export ML.NET models to ONNX (limited to the existing internal functionality) (In Model Files section, but can be fleshed out a bit better with other ONNX tests)\r\n\r\nFixes #2963","Url":"https://github.com/dotnet/machinelearning/pull/2984","RelatedDescription":"Open PR \"Add functional tests for ONNX scenarios\" (#2984)"},{"Id":"421720200","IsPullRequest":false,"CreatedAt":"2019-03-15T22:02:15","Actor":"rogancarr","Number":"2982","RawContent":null,"Title":"ONNX Transform changes output types","State":"open","Body":"Serializing and deserializing a model to and from ONNX not only changes the names of the output (#2980) but also changes the types of the output. For example, a `Score` column produced by a model (`R4`/`float`) becomes a `Vec<R4, 1, 1>`.","Url":"https://github.com/dotnet/machinelearning/issues/2982","RelatedDescription":"Open issue \"ONNX Transform changes output types\" (#2982)"},{"Id":"421716798","IsPullRequest":false,"CreatedAt":"2019-03-15T21:49:23","Actor":"rogancarr","Number":"2981","RawContent":null,"Title":"Cannot fit an Onnx Transform as part of a pipeline","State":"open","Body":"It is possible to fit an ONNX model by itself:\r\n\r\n```cs\r\nvar onnxEstimator = mlContext.Transforms.ApplyOnnxModel(modelPath)\r\nvar onnxModel = onnxEstimator.Fit(data);\r\n```\r\n\r\nBut it throws when it is part of a pipeline:\r\n```cs\r\nvar onnxEstimator = mlContext.Transforms.ApplyOnnxModel(modelPath)\r\n    // TODO #2980: ONNX outputs don't match the outputs of the model, so we must hand-correct this for now.\r\n    .Append(mlContext.Transforms.CopyColumns(\"Score\", \"Score0\"));\r\n    .Append(mlContext.Transforms.CopyColumns(\"Label\", \"Fable\"));\r\n    .Append(mlContext.Transforms.NormalizeLpNorm(\"Features2\", \"Features\", LpNormNormalizingEstimatorBase.NormFunction.L2));\r\nvar onnxModel = onnxEstimator.Fit(data);\r\n```\r\nAny of these `Append` statements cause a throw. They do not affect the ONNX model at all, and use either the result of the calculation (`Score0`), rows unused by the model (`Label`) or rows also used by the transform (`Features`).\r\n\r\nIn this case, the error message is:\r\n`System.ArgumentOutOfRangeException : Schema mismatch for input column 'Label': expected vector, got R4\r\nParameter name: inputSchema`","Url":"https://github.com/dotnet/machinelearning/issues/2981","RelatedDescription":"Open issue \"Cannot fit an Onnx Transform as part of a pipeline\" (#2981)"},{"Id":"421712433","IsPullRequest":false,"CreatedAt":"2019-03-15T21:33:20","Actor":"rogancarr","Number":"2980","RawContent":null,"Title":"ONNX outputs don't match model outputs after serialization","State":"open","Body":"When I save a model to ONNX, load, and apply it with `ApplyOnnxModel`, it adds a zero as a suffix to all columns, including the expected output. This includes input columns, so the resulting `IDataView` now has double the columns, plus the output. To top it off, it's not clear how to find the output because it's been renamed.\r\n\r\nExample:\r\nML.NET model\r\n  Input:  `Features`\r\n  Output: `Score`\r\n  Resulting Schema: `Features`, `Score`\r\n\r\nAfter Onnx Serialization / Deserialization:\r\n  Input: `Features`\r\n  Output: `Features0`, `Score0`\r\n  Resulting Schema: `Features`, `Features0`, `Score0`\r\n\r\nI am not sure if this is by design, but it feels like a bug.","Url":"https://github.com/dotnet/machinelearning/issues/2980","RelatedDescription":"Open issue \"ONNX outputs don't match model outputs after serialization\" (#2980)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-03-19T05:30:33.3987656Z","RunDurationInMilliseconds":533}