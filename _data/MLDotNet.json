{"Data":{"GitHub":{"Issues":[{"Id":"490129313","IsPullRequest":false,"CreatedAt":"2019-09-06T04:55:46","Actor":"CESARDELATORRE","Number":"4180","RawContent":null,"Title":"[Clustering] Create/Add an additional trainer for Clustering: Affinity Propagation","State":"open","Body":"In ML.NET we currently only have the [KMeansTrainer](https://docs.microsoft.com/en-us/dotnet/machine-learning/resources/tasks#clustering).\r\n\r\nThe main challenge with that clustering trainer is that you need to provide the number of clusters to use (numberOfClusters param also known as k), and that's a very difficult number to figure out. THere are methods that can help, like the Elbow method, but still it is a challenge.\r\n\r\nThere are other clustering algorithms that doesn’t require in input the number of expected clusters like the **Affinity Propagation** algorithm. \r\nIt is relatively new (Presented in 2007) and it works by measuring the affinity between data items.\r\n\r\nFurther info about it:\r\nhttps://towardsdatascience.com/unsupervised-machine-learning-affinity-propagation-algorithm-explained-d1fef85f22c8 \r\n\r\nThe function that measures affinity between data items is one of the hyperparameters of the algorithm. \r\n\r\n**Affinity Propagation is an unsupervised machine learning algorithm that is particularly well suited for problems where we don’t know the optimal number of clusters.**\r\n\r\nAs an additional note, consider that K-means was first proposed for application in the field of statistics back in 1955.\r\n\r\nI suggest that, when possible, we implement and offer this additional clustering algorithm, especially when we currently just have one algorithm for Clustering (KMeansTrainer).","Url":"https://github.com/dotnet/machinelearning/issues/4180","RelatedDescription":"Open issue \"[Clustering] Create/Add an additional trainer for Clustering: Affinity Propagation\" (#4180)"},{"Id":"490039346","IsPullRequest":true,"CreatedAt":"2019-09-05T22:29:29","Actor":"LittleLittleCloud","Number":"4179","RawContent":null,"Title":"pack CodeGen into mlnet","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4179","RelatedDescription":"Open PR \"pack CodeGen into mlnet\" (#4179)"},{"Id":"488745561","IsPullRequest":false,"CreatedAt":"2019-09-05T13:24:50","Actor":"dradoaica","Number":"4172","RawContent":null,"Title":"MulticlassClassification: different predict results depending on the environment the train took place","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10/Azure\r\n- **.NET Version (eg., dotnet --info)**: .NET Core v2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI extracted the code from the MulticlassClassification-GitHubLabeler into a Azure WebJob\r\n- **What happened?**\r\nFirst I run it on my local machine (Windows 10) and after I run it in an app service in Azure\r\n- **What did you expect?**\r\nEven though the \"seed\" param of the \"MLContext\" class is set, the predict results are not the same. The model trained on Windows 10 should be the same with the model trained in Azure. ML.NET takes decisions based on the environment (ProcessorCount , Is64BitProcess, etc.)? \r\n### Source code / logs\r\n\r\n[dotnet/machinelearning-samples MulticlassClassification-GitHubLabeler\r\n](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/end-to-end-apps/MulticlassClassification-GitHubLabeler/GitHubLabeler/GitHubLabelerConsoleApp/Program.cs)","Url":"https://github.com/dotnet/machinelearning/issues/4172","RelatedDescription":"Closed issue \"MulticlassClassification: different predict results depending on the environment the train took place\" (#4172)"},{"Id":"489653381","IsPullRequest":false,"CreatedAt":"2019-09-05T10:00:51","Actor":"larsbeck","Number":"4178","RawContent":null,"Title":"TfIdf setting in ProduceNGrams throws Exception","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro\r\n- **.NET Version (eg., dotnet --info)**: 3.0.0-preview8-28405-07\r\n\r\n### Issue\r\nProduceNGrams throws an InvalidOperationException \"The specified documents are all empty in column 'Tokens'\"\r\n\r\n- **What did you do?**\r\nChanged the parameter setting 'weighting' of type 'WeightingCriteria' from the standard 'WeightingCriteria.Tf' to 'WeightingCriteria.TfIdf' and then ran the code again.\r\n\r\n- **What happened?**\r\nThe exception gets thrown as described above\r\n\r\n- **What did you expect?**\r\nThe code, specifically the line 'var transformer = pipeline.Fit(dataview);' to run just as it did with setting WeightingCriteria.Tf.\r\n\r\n### Source code / logs\r\n\r\n```\r\nvar pipeline = _mlContext.Transforms.Text.NormalizeText(nameof(TransformedTextData.NormalizedText),\r\n                nameof(Profile.Text))\r\n                .Append(_mlContext.Transforms.Text.TokenizeIntoWords(nameof(TransformedTextData.Words),\r\n                    nameof(TransformedTextData.NormalizedText)))\r\n                .Append(_mlContext.Transforms.Text.RemoveDefaultStopWords(nameof(TransformedTextData.Words), nameof(TransformedTextData.Words), StopWordsRemovingEstimator.Language.German))\r\n                .Append(_mlContext.Transforms.Text.RemoveStopWords(nameof(TransformedTextData.Words), null, \"kontext\", \"&\"))\r\n                .Append(_mlContext.Transforms.Conversion.MapValueToKey(nameof(TransformedTextData.Tokens), nameof(TransformedTextData.Words)))\r\n                .Append(_mlContext.Transforms.Text.ProduceNgrams(nameof(TransformedTextData.Tokens), weighting: NgramExtractingEstimator.WeightingCriteria.TfIdf))\r\n                .Append(_mlContext.Transforms.Text.LatentDirichletAllocation(\r\n                    nameof(TransformedTextData.Features), nameof(TransformedTextData.Tokens), numberOfTopics: 10, numberOfSummaryTermsPerTopic:10));\r\n\r\n            // Fit to data.\r\n            var transformer = pipeline.Fit(dataview);\r\n```\r\n\r\nDoes ProduceNGrams not support the setting TfIdf as weighting? If it doesn't, which Transformer would one use to generate NGrams for LatentDirichletAllocation ?","Url":"https://github.com/dotnet/machinelearning/issues/4178","RelatedDescription":"Open issue \"TfIdf setting in ProduceNGrams throws Exception\" (#4178)"},{"Id":"489648560","IsPullRequest":false,"CreatedAt":"2019-09-05T09:51:37","Actor":"yaeldekel","Number":"4177","RawContent":null,"Title":"Change the DnnImageFeaturizers packages to use models from the ONNX model zoo","State":"open","Body":"We should use the models from the [model zoo](https://github.com/onnx/models) to ensure compatibility with future versions of ONNX runtime.\r\n\r\nWe should also add tests for these packages, to ensure they work correctly.\r\n\r\n•\tAlexNet\r\n•\tResNet101\r\n•\tResNet50\r\n•\tResNet18\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4177","RelatedDescription":"Open issue \"Change the DnnImageFeaturizers packages to use models from the ONNX model zoo\" (#4177)"},{"Id":"489282428","IsPullRequest":false,"CreatedAt":"2019-09-04T17:03:46","Actor":"vera-dania","Number":"4176","RawContent":null,"Title":"System.AccessViolationException -- Loading tensorflow model","State":"open","Body":"### System information\r\n\r\n- **Windows 10 Pro for Workstations - 1809**:\r\n- **3.0.100-preview3-010431**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am loading a tensorflow model using ML.NET Model.LoadTensorFlowModel method.\r\nReceived this exception:\r\n\r\n- **What happened?**\r\nSystem.AccessViolationException: Attempted to read or write protected memory. This is often an indication that other memory is corrupt. I am unable to locate the source of this exception. I only receive this error when running the application in debug mode.\r\n\r\n- **What did you expect?**\r\nMy model to successfully load and be able to make predictions.\r\n\r\n\r\n### Source code / logs\r\n\r\n      var pipline = context.Transforms.Conversion.MapValueToKey(\"LabelKey\", \"Label\")\r\n        .Append(context.Transforms.LoadImages(\"input\", \"images\", nameof(ImageData.ImagePath)))\r\n        .Append(context.Transforms.ResizeImages(\"input\", GenderSettings.ImageHeight, GenderSettings.ImageWidth, \"input\"))\r\n        .Append(context.Model.LoadTensorFlowModel(\"./modelGender/tensorflow_gender__graph.pb\")\r\n          .ScoreTensorFlowModel(new[] {\"cross_entropy\"}, new[] {\"input\"}, addBatchDimensionInput: true))\r\n        .Append(context.Transforms.Conversion.MapKeyToValue(\"PredictedLabelValue\", \"PredictedLabel\"))\r\n        .AppendCacheCheckpoint(context);\r\n\r\n\r\nIt is not showing any stacktrace or log.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4176","RelatedDescription":"Open issue \"System.AccessViolationException -- Loading tensorflow model\" (#4176)"},{"Id":"488769998","IsPullRequest":false,"CreatedAt":"2019-09-04T06:18:51","Actor":"LittleLittleCloud","Number":"4173","RawContent":null,"Title":"Should use dll location instead of app domain in ResNet18/50/128 packages","State":"closed","Body":"We find out that in  `Resnet18Extension.cs`, It uses `AppDomain.CurrentDomain` to get the DLL location, which could causes some unexpected behavior in Vsix packaging. (in Vsix AppDomain.CurrentDomain returns VS executables, which is `C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Preview\\Common7\\IDE`, so it won't be able to find the right onnx file). It's better to use `GetAssembly.Loaction` to get the DLL location. You can see the following PR to see the suggest fix\r\n\r\n#4174 ","Url":"https://github.com/dotnet/machinelearning/issues/4173","RelatedDescription":"Closed issue \"Should use dll location instead of app domain in ResNet18/50/128 packages\" (#4173)"},{"Id":"488770734","IsPullRequest":true,"CreatedAt":"2019-09-04T06:18:40","Actor":"LittleLittleCloud","Number":"4174","RawContent":null,"Title":"Using `GetAssembly` to get DLL loaction in ResNet18","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4174","RelatedDescription":"Closed or merged PR \"Using `GetAssembly` to get DLL loaction in ResNet18\" (#4174)"},{"Id":"488860362","IsPullRequest":false,"CreatedAt":"2019-09-03T22:54:37","Actor":"MattGal","Number":"4175","RawContent":null,"Title":"Don't create local SQL Database files inside the build workspace","State":"open","Body":"Code like this: https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/DatabaseLoaderTests.cs#L170\r\n\r\n(where you're running tests as part of the build) has been leading to, when the build machine is reused, errors like:\r\n```\r\nMsg 5120, Level 16, State 101, Server <machine name>\\LOCALDB#<somehex>, Line 1\r\nUnable to open the physical file \"F:\\workspace.7\\_work\\1\\s\\bin\\AnyCPU.Release-netcoreapp3_0\\Microsoft.ML.Tests\\netcoreapp3.0\\TestDatabases\\iris.mdf\". Operating system error 3: \"3(The system cannot find the path specified.)\".\r\n```\r\n... this is because workspaces are automatically cleaned up (by deletion) but this leaves SQL server in a bad state.  Ideally this shouldn't happen at all, but if it must it'd be good to use the current user's profile directory;  I don't care where other than the workspace folder is not a good place for it.  This happens even to other teams' builds who also test using local SQL DBs \r\n\r\n### System information\r\n\r\n- **OS version/distro**:  Windows Client and Server\r\n- **.NET Version (eg., dotnet --info)**:  All (test bug)\r\n\r\n### Issue\r\n\r\n- **What did you do?** : Talk to other teams who need local SQL DBs to work\r\n- **What happened?** : I found the code creating MDF files in a guaranteed-to-be-deleted place\r\n- **What did you expect?** : Testing should occur outside builds.  Failing that, invariant cleanup should happen.  Failing that, put the files outside the workspace directory.\r\n\r\n### Source code / logs\r\n\r\nSee https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/DatabaseLoaderTests.cs#L170.  When run as part of the build, the path this resolves is `bin\\Arch.Config-TargetFramework\\Microsoft.ML.Tests\\netcoreapp3.0\\TestDatabases\\iris.mdf` inside the workspace. ","Url":"https://github.com/dotnet/machinelearning/issues/4175","RelatedDescription":"Open issue \"Don't create local SQL Database files inside the build workspace\" (#4175)"},{"Id":"488435937","IsPullRequest":false,"CreatedAt":"2019-09-03T07:24:19","Actor":"jankozeleny","Number":"4171","RawContent":null,"Title":"Error in Microsoft.ML.Extensions (Attempted to divide by zero.) when running in Azure","State":"open","Body":"### System information\r\n\r\n- Azure AppService\r\n- .NET Core 2.2, 64-bit\r\n\r\n### Issue\r\n\r\nDeploy the unmodified E2E sample https://github.com/dotnet/machinelearning-samples/tree/v1.2/samples/csharp/end-to-end-apps/DeepLearning_ObjectDetection_Onnx\r\ninto Azure AppService.\r\nNote that you must switch to 64-bit because the AppService will not even start (I suppose that this is a problem with Core 2.2 in-process hosting but I am not sure).\r\nAlso you must modifiy the relative path in the Get action in the ObjectDetectionController\r\n`string imageFileRelativePath = @\"assets\" + url;`\r\n\r\n**The code stops at the unhandled division by zero exception** (\"Attempted to divide by zero.\") at line:\r\n`            var probs = model.Predict(imageInputData).PredictedLabels;`\r\nin the ObjectDetectionService in the DetectObjectsUsingModel method.\r\n\r\n**The application runs without problem when running locally.**\r\n\r\nStack trace:\r\n\r\n```\r\n   at Microsoft.ML.OnnxRuntime.NativeMethods.OrtRun(IntPtr session, IntPtr runOptions, String[] inputNames, IntPtr[] inputValues, UInt64 inputCount, String[] outputNames, UInt64 outputCount, IntPtr[] outputValues)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs, IReadOnlyCollection`1 outputNames, RunOptions options)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs, IReadOnlyCollection`1 outputNames)\r\n   at Microsoft.ML.OnnxRuntime.InferenceSession.Run(IReadOnlyCollection`1 inputs)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, INamedOnnxValueGetter[] srcNamedOnnxValueGetters, String[] activeOutputColNames, OnnxRuntimeOutputCacher outputCache)\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.<>c__DisplayClass11_0`1.<MakeTensorGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolExtensions.Predict[TData,TPrediction](PredictionEnginePool`2 predictionEnginePool, String modelName, TData example)\r\n   at OnnxObjectDetectionE2EAPP.Services.ObjectDetectionService.DetectObjectsUsingModel(ImageInputData imageInputData) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Services\\ObjectDetectionService.cs:line 29\r\n   at OnnxObjectDetectionE2EAPP.Controllers.ObjectDetectionController.DetectAndPaintImage(ImageInputData imageInputData, String imageFilePath) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Controllers\\ObjectDetectionController.cs:line 125\r\n   at OnnxObjectDetectionE2EAPP.Controllers.ObjectDetectionController.Get(String url) in C:\\p\\test\\DeepLearning_ObjectDetection_Onnx\\OnnxObjectDetectionE2EAPP\\Controllers\\ObjectDetectionController.cs:line 59\r\n```\r\n\r\nI am now clueless and I even don't know how .NET DivideByZeroException can be raised in the C interop call. Where does it come from?\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4171","RelatedDescription":"Open issue \"Error in Microsoft.ML.Extensions (Attempted to divide by zero.) when running in Azure\" (#4171)"},{"Id":"488337706","IsPullRequest":true,"CreatedAt":"2019-09-02T23:36:10","Actor":"codemzs","Number":"4170","RawContent":null,"Title":"Release notes for 1.4.0-preview and 0.16.0-preview.","State":"open","Body":"\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4170","RelatedDescription":"Open PR \"Release notes for 1.4.0-preview and 0.16.0-preview.\" (#4170)"},{"Id":"488308696","IsPullRequest":false,"CreatedAt":"2019-09-02T20:15:49","Actor":"CESARDELATORRE","Number":"4169","RawContent":null,"Title":"[Image Classification DNN Transfer Learning] - Use PredictedLabel as String/Value instead of an UInt32 (Index))","State":"open","Body":"I think it'd be simpler for users and also consistent with other ML.NET APIs if the returned PredictedLabel is a string/value (categorial value) instead UInt32 (Index).\r\n\r\nThat way, simply by having a .MapKeyToValue() at the end of the pipeline, the user will have it as the value being looked for instead of an index which is what we currently get:\r\n\r\n```\r\n//pipeline code\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: \"Label\" , inputColumnName: \"LabelAsKey\"));\r\n```\r\n\r\nAs currently implemented, when the user is simply predicting in an end-user app, you need to find out the real label value by using code based on the schema API, like this:\r\n\r\n```\r\nvar prediction = predictionEngine.Predict(imageToPredict);\r\n\r\nvar index = prediction.PredictedLabel;\r\n\r\n// Obtain the original label names to map through the predicted label-index\r\nVBuffer<ReadOnlyMemory<char>> keys = default;\r\npredictionEngine.OutputSchema[\"LabelAsKey\"].GetKeyValues(ref keys);\r\nvar originalLabels = keys.DenseValues().ToArray();\r\n\r\nConsole.WriteLine($\"ImageFile : [{Path.GetFileName(imageToPredict.ImagePath)}], \" +\r\n                    $\"Scores : [{string.Join(\",\", prediction.Score)}], \" +\r\n                    $\"Predicted Label : {originalLabels[index]}\");\r\n```\r\n\r\nIf the PredictedLabel was already the string/value, the user won't usually need to use the additional `VBuffer `and `OutputSchema `APIs above.\r\n\r\nAlso, this way would be consistent with other multi-class classification algorithms in ML.NET.","Url":"https://github.com/dotnet/machinelearning/issues/4169","RelatedDescription":"Open issue \"[Image Classification DNN Transfer Learning] - Use PredictedLabel as String/Value instead of an UInt32 (Index))\" (#4169)"},{"Id":"487248604","IsPullRequest":true,"CreatedAt":"2019-09-02T18:26:25","Actor":"codemzs","Number":"4158","RawContent":null,"Title":"Increment build version for 1.4-preview and 0.16-preview release.","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4158","RelatedDescription":"Closed or merged PR \"Increment build version for 1.4-preview and 0.16-preview release.\" (#4158)"},{"Id":"488259360","IsPullRequest":false,"CreatedAt":"2019-09-02T16:20:02","Actor":"CBrauer","Number":"4168","RawContent":null,"Title":"I don't understand these predictions","State":"open","Body":"Hey, \r\n\r\nI'm trying to compute the probabilities of the predictions on my dataset.\r\nI am using the 1.3.1 code at: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog.calibratorscatalog.platt?view=ml-dotnet\r\nMy modified code is as follows:\r\n\r\n```\r\n    public static void Run() {\r\n      var mlContext = new MLContext(0);\r\n      var dataPoints = GetDataPoints(@\"/HedgeTools/Datasets/rocket-train-classify.csv\");\r\n      var trainingData = mlContext.Data.LoadFromEnumerable(dataPoints);\r\n\r\n      var testDataPoints = GetDataPoints(@\"/HedgeTools/Datasets/rocket-test-classify.csv\");\r\n      var testData = mlContext.Data.LoadFromEnumerable(testDataPoints);\r\n\r\n      var options = new FastTreeBinaryTrainer.Options {\r\n        EarlyStoppingMetric = EarlyStoppingMetric.L2Norm, // Use L2Norm for early stopping.\r\n        FeatureFirstUsePenalty = 0.1,  // Create a simpler model by penalizing usage of new features.\r\n        NumberOfTrees = 50\r\n      };\r\n\r\n      var pipeline = mlContext.BinaryClassification.Trainers.FastTree(options);\r\n\r\n      var model = pipeline.Fit(trainingData);\r\n      var transformedTestData = model.Transform(testData);\r\n      var outScores = mlContext.Data.CreateEnumerable<ScoreValue>(transformedTestData,\r\n                                                                  reuseRowObject: false);\r\n      var calibratorEstimator = mlContext.BinaryClassification.Calibrators.Platt();\r\n\r\n      // Convert IDataView object to a list.\r\n      var predictions = mlContext.Data.CreateEnumerable<Prediction>(transformedTestData, false).ToList();\r\n      var calibratorTransformer = calibratorEstimator.Fit(transformedTestData);\r\n      var finalData = calibratorTransformer.Transform(transformedTestData);\r\n      var outScoresAndProbabilities = mlContext.Data.CreateEnumerable<ScoreAndProbabilityValue>(finalData, false);\r\n\r\n      Console.WriteLine(\"\\nFirst 10 acutals that are true\");\r\n      Console.WriteLine(\"Actual Predicted     score   probability\");\r\n      Console.WriteLine(\"------ --------- ----------  -----------\");\r\n      var loop = 1;\r\n      for (var index = 0; index < predictions.Count(); index++) {\r\n        var p1 = predictions.ElementAt(index);\r\n        if (!p1.Label) continue;\r\n        var p2 = outScoresAndProbabilities.ElementAt(index);\r\n        Console.WriteLine(\"{0, 6} {1, 9} {2, 10}  {3, 11}\", p1.Label, p1.PredictedLabel, p2.Score, p2.Probability);\r\n        if (++loop > 10) break;\r\n      }\r\n\r\n      var metrics = mlContext.BinaryClassification.Evaluate(transformedTestData);\r\n      PrintMetrics(metrics);\r\n    }\r\n```\r\n\r\nThe results I get are as follows:\r\n\r\n\r\n```\r\nFirst 10 actuals that are true\r\nActual Predicted     score   probability\r\n------ --------- ----------  -----------\r\n  True     False  -6.288363   0.06514609\r\n  True     False  -7.417452   0.03533126\r\n  True     False  -6.883083    0.0473095\r\n  True      True   2.404708    0.9079463\r\n  True     False  -5.611444   0.09295245\r\n  True      True  0.2836371    0.7465712\r\n  True     False   -1.93054    0.4548629\r\n  True     False  -3.087828    0.3014578\r\n  True      True  0.2553135    0.7435061\r\n  True     False  -5.725763   0.08760489\r\n\r\nAccuracy.............0.912087912087912\r\nAUC..................0.748737797056458\r\nF1 Score.............0.147208121827411\r\nNegative Precision...0.913221503103949\r\nNegative Recall......0.997835185452446\r\nPositive Precision...0.794520547945205\r\nPositive Recall......0.0811188811188811\r\n\r\nTEST POSITIVE RATIO:    0.0935 (715.0/(715.0+6929.0))\r\nConfusion table\r\n          ||======================\r\nPREDICTED || positive | negative | Recall\r\nTRUTH     ||======================\r\n positive ||       58 |      657 | 0.0811\r\n negative ||       15 |    6 914 | 0.9978\r\n          ||======================\r\nPrecision ||   0.7945 |   0.9132 |\r\n\r\n```\r\nThe \"Actual\" column is a \"ground truth label\". \r\nWhy am I getting a False prediction when the probability is less than 0.5?\r\nI'm obviously confused.  Please help.\r\n\r\nCharles\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4168","RelatedDescription":"Open issue \"I don't understand these predictions\" (#4168)"},{"Id":"487955473","IsPullRequest":false,"CreatedAt":"2019-09-02T01:23:17","Actor":"ashgadala","Number":"4167","RawContent":null,"Title":"Price PredictionML add projects adding namespaces with space","State":"open","Body":"when I try to add projects after training the price prediction Model. \r\n\r\nCheck the namespace here with auto generated code.\r\n\r\n\r\n`using Microsoft.ML.Data;\r\n\r\nnamespace **Price PredictionML.**Model.DataModels\r\n{\r\n    public class ModelInput\r\n{\r\n    [ColumnName(\"vendor_id\"), LoadColumn(0)]\r\n    public string Vendor_id { get; set; }\r\n\r\n\r\n    [ColumnName(\"rate_code\"), LoadColumn(1)]\r\n    public float Rate_code { get; set; }\r\n\r\n\r\n    [ColumnName(\"passenger_count\"), LoadColumn(2)]\r\n    public float Passenger_count { get; set; }\r\n\r\n\r\n    [ColumnName(\"trip_time_in_secs\"), LoadColumn(3)]\r\n    public float Trip_time_in_secs { get; set; }\r\n\r\n\r\n    [ColumnName(\"trip_distance\"), LoadColumn(4)]\r\n    public float Trip_distance { get; set; }\r\n\r\n\r\n    [ColumnName(\"payment_type\"), LoadColumn(5)]\r\n    public string Payment_type { get; set; }\r\n\r\n\r\n    [ColumnName(\"fare_amount\"), LoadColumn(6)]\r\n    public float Fare_amount { get; set; }\r\n\r\n\r\n}\r\n}`\r\n\r\n\r\n### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4167","RelatedDescription":"Open issue \"Price PredictionML add projects adding namespaces with space\" (#4167)"},{"Id":"487937641","IsPullRequest":true,"CreatedAt":"2019-09-01T22:26:17","Actor":"LittleLittleCloud","Number":"4166","RawContent":null,"Title":"WIP - Refactor on Code Gen","State":"open","Body":"- [x] refactor on `TransformGenerator` derived Class","Url":"https://github.com/dotnet/machinelearning/pull/4166","RelatedDescription":"Open PR \"WIP - Refactor on Code Gen\" (#4166)"},{"Id":"487923285","IsPullRequest":false,"CreatedAt":"2019-09-01T19:39:51","Actor":"CBrauer","Number":"4165","RawContent":null,"Title":"Please do an example","State":"open","Body":"Please do an example of how the probability is computed and used.\n\n---\n#### Document Details\n\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\n\n* ID: 79a06280-21c8-0ae1-c5d0-17ef5d8d6774\n* Version Independent ID: 4047f033-7557-9533-7626-2c8aeafce38b\n* Content: [DatasetUtils.CalibratedBinaryClassifierOutput.Probability Field (Microsoft.ML.SamplesUtils)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.samplesutils.datasetutils.calibratedbinaryclassifieroutput.probability?view=ml-dotnet-preview)\n* Content Source: [dotnet/xml/Microsoft.ML.SamplesUtils/DatasetUtils+CalibratedBinaryClassifierOutput.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.SamplesUtils/DatasetUtils+CalibratedBinaryClassifierOutput.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/4165","RelatedDescription":"Open issue \"Please do an example\" (#4165)"},{"Id":"487642015","IsPullRequest":false,"CreatedAt":"2019-08-30T19:39:44","Actor":"luisquintanilla","Number":"4164","RawContent":null,"Title":"[Object Detection] Internalize Model Pre/Post-Processing","State":"open","Body":"When doing object detection (especially on pre-trained models), there are some pre-processing and post-processing steps that are required to get the input in the format expected by the model as well as to make sense of the output. Ultimately, while these steps are required to prepare the data and interpret the outputs, they are not directly related to the training / prediction task. With state-of-the-art models, this process is mainly boiler-plate and writing the code is often left up to the user to implement every time. A good example of this can be seen when making predictions using the Tiny YOLOv2 pre-trained model. \r\n\r\n[Create Parser](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/object-detection-onnx#create-a-parser-to-post-process-model-outputs)\r\n\r\nIn this tutorial, a significant portion is boilerplate code to create a parser that extracts the values output by the model (1-D Tensor into bounding box dimensions, confidence score and class probabilities). Internalizing some of these steps as part of a high-level API, especially for pre-trained state-of-the-art models where the inputs / outputs are well-defined would make it easier for users to use these types of models.  \r\n\r\n__Problem:__\r\n\r\n- Pre-Processing/Post-Processing boilerplate code is required when performing object detection to prepare input/output for the model. Although the process is model-specific, the expected inputs and outputs have already been pre-defined for state-of-the-art pre-trained models. Therefore, it doesn't make sense to keep re-writing the same code every time when it is already a solved problem.\r\n- No consistent way to interpret model outputs\r\n\r\n__Proposal:__\r\n\r\n- Internalize pre-processing/post-processing boiler plate code as part of high-level API\r\n\t- Provide option for user to select the model architecture (i.e. SSD, YOLO, Fast R-CNN) they're interested in using to train / score with. Based on the selection, the appropriate pre-processing/post-processing transformations will take place to produce a simple and consistent output for the user. \r\n- Provide a consistent way to interpret outputs\r\n\t- Currently, models like binary classification have output column names (i.e. PredictedLabel, Probability, Score) that the user can access to get the result of training/scoring. Something similar should exist for object detection models. Typical output features include the dimensions of the bounding boxes detected, the probabilities or labels of objects detected in the bounding boxes and the confidence that there is an object inside the bounding box. These could be made available as part of the output schema for the user to access once the scored output produced by the model is post-processed.\r\n\r\n__Resources:__\r\n\r\nTF provides an object detection API which allows the user to extract the class probabilities, bounding box dimensions and objectness scores from the model outputs. \r\n\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\r\nhttps://github.com/tensorflow/models/tree/master/research/object_detection\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\r\n\r\nWindows ML uses LearningModelEvaluationResult which the user can extract the respective outputs from the model. In the case of ML.NET, this could expose the output schema for an object detection prediction.\r\n\r\nhttps://docs.microsoft.com/en-us/windows/ai/windows-ml/evaluate-model-inputs - \r\nhttps://docs.microsoft.com/en-us/uwp/api/windows.ai.machinelearning.learningmodelevaluationresult","Url":"https://github.com/dotnet/machinelearning/issues/4164","RelatedDescription":"Open issue \"[Object Detection] Internalize Model Pre/Post-Processing\" (#4164)"},{"Id":"487616633","IsPullRequest":true,"CreatedAt":"2019-08-30T18:29:14","Actor":"LittleLittleCloud","Number":"4163","RawContent":null,"Title":"Image featurization","State":"closed","Body":"\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4163","RelatedDescription":"Closed or merged PR \"Image featurization\" (#4163)"},{"Id":"487363555","IsPullRequest":true,"CreatedAt":"2019-08-30T14:05:07","Actor":"Adishone","Number":"4162","RawContent":null,"Title":"Fixed typo in ML.NET Cookbook","State":"closed","Body":"Fixing one small typo\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4162","RelatedDescription":"Closed or merged PR \"Fixed typo in ML.NET Cookbook\" (#4162)"},{"Id":"487288045","IsPullRequest":true,"CreatedAt":"2019-08-30T05:07:45","Actor":"harishsk","Number":"4161","RawContent":null,"Title":"Added onnx export functionality for LpNormNormalizingTransformer","State":"open","Body":"Fixes #4159 ","Url":"https://github.com/dotnet/machinelearning/pull/4161","RelatedDescription":"Open PR \"Added onnx export functionality for LpNormNormalizingTransformer\" (#4161)"},{"Id":"487285402","IsPullRequest":true,"CreatedAt":"2019-08-30T04:55:54","Actor":"harishsk","Number":"4160","RawContent":null,"Title":"Added export functionality for LpNormNormalizingTransformer","State":"closed","Body":"Fixes #4159 ","Url":"https://github.com/dotnet/machinelearning/pull/4160","RelatedDescription":"Closed or merged PR \"Added export functionality for LpNormNormalizingTransformer\" (#4160)"},{"Id":"487283571","IsPullRequest":false,"CreatedAt":"2019-08-30T04:46:44","Actor":"harishsk","Number":"4159","RawContent":null,"Title":"LpNormNormalizingTransformer does not support exporting to Onnx","State":"open","Body":"- **What did you do?**\r\nCreated a pipeline from NormalizeLpNorm and tried to export it to Onnx with ConvertToOnnxProtobuf. \r\n\r\n- **What happened?**\r\nThe transform wasn't saved in the onnx graph\r\n\r\n- **What did you expect?**\r\nThe transform should be saved in the onnx graph\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4159","RelatedDescription":"Open issue \"LpNormNormalizingTransformer does not support exporting to Onnx\" (#4159)"},{"Id":"486645395","IsPullRequest":true,"CreatedAt":"2019-08-30T00:59:58","Actor":"codemzs","Number":"4151","RawContent":null,"Title":"Image classification preview 2.","State":"closed","Body":"This change improves the in-preview image classification API further:\r\n\r\n1. Increases DNN training speed by 10x.\r\n2. Reduced and constant memory footprint.\r\n3. Simplifies the API by not requiring the user to pre-process the image.\r\n4. Introduces callback to provide metrics during training such as accuracy, cross-entropy.\r\n5. Improved image classification sample.\r\n\r\nfixes #4090, #4087, #4084, #4134","Url":"https://github.com/dotnet/machinelearning/pull/4151","RelatedDescription":"Closed or merged PR \"Image classification preview 2.\" (#4151)"},{"Id":"487215039","IsPullRequest":true,"CreatedAt":"2019-08-29T23:14:40","Actor":"michaelgsharp","Number":"4157","RawContent":null,"Title":"[WIP] Transformers for AutoML","State":"open","Body":"This is still a work in progress, but will be updated and finished over the next several hours. \r\n\r\nIn order for AutoML to take a full dependency on ML.NET, several pieces of functionality need to be added. This PR is the first step in that process adding in 3 new transformers. The actual implementation of the transformers is done in C++. This code is currently in another repo, but will be turned in a Nuget package that ML.Net can take a binary dependency on. The code going into ML.Net is mostly wrapper code dealing with data interop and, since the binary is exposed via C api's with no overloading, code to call the correct methods based on the data type.\r\n\r\nToStringTransformer - Takes in a column and converts it into an appropriate string representation. It currently supports all integer types, float, double, bool, and string. This is fully done, and should be reviewed first.\r\n\r\nCategoryImputer - Fill in missing values with the most common value in the column.  It currently supports all integer types, float, double, bool, and string. 0's are treated as missing for integer types. This is done except for a small piece of the c++ interop.\r\n\r\nDateTimeTransformer - Splits a column into its appropriate date time components (20 columns total are added). Takes a Long that represents seconds since 1970. The c++ interop will be added for this tonight and can be reviewed last.\r\n\r\nUntil we get the binary added as an official dependency, the constructors of the estimator will throw an error if the correct .dll is not found. This allows us to do a private drop for now. The tests will also be disabled currently for that reason.","Url":"https://github.com/dotnet/machinelearning/pull/4157","RelatedDescription":"Open PR \"[WIP] Transformers for AutoML\" (#4157)"},{"Id":"487207612","IsPullRequest":false,"CreatedAt":"2019-08-29T22:44:09","Actor":"tannergooding","Number":"4156","RawContent":null,"Title":"Create a tests database for the DatabaseLoader tests on macOS and Linux","State":"open","Body":"https://github.com/dotnet/machinelearning/pull/4138 added support for testing against an actual database by attaching a SQL mdf file. However, that functionality is only available on Windows.\r\n\r\nA database file that is supported on Linux and macOS should be created (likely MySQL) so that the tests can successfully run there as well.","Url":"https://github.com/dotnet/machinelearning/issues/4156","RelatedDescription":"Open issue \"Create a tests database for the DatabaseLoader tests on macOS and Linux\" (#4156)"},{"Id":"487124417","IsPullRequest":true,"CreatedAt":"2019-08-29T19:00:08","Actor":"ganik","Number":"4155","RawContent":null,"Title":"Implement ONNX conversion for TypeConverting transform","State":"open","Body":"fixes #4004 \r\nTests TBD.","Url":"https://github.com/dotnet/machinelearning/pull/4155","RelatedDescription":"Open PR \"Implement ONNX conversion for TypeConverting transform\" (#4155)"},{"Id":"486677148","IsPullRequest":false,"CreatedAt":"2019-08-29T17:27:16","Actor":"LittleLittleCloud","Number":"4154","RawContent":null,"Title":"Is there a way to use `CreatePredictionEngine` dynamically","State":"closed","Body":"To use `CreatePredictionEngine`, I need to define input and output class first. But what if I don't want to do that. ( because my data has too many dimensions, it's just painful to put it as class), is there a way to call into that `CreatePredictionEngine` method using data format like dictionary or dynamic object?","Url":"https://github.com/dotnet/machinelearning/issues/4154","RelatedDescription":"Closed issue \"Is there a way to use `CreatePredictionEngine` dynamically\" (#4154)"},{"Id":"486673799","IsPullRequest":false,"CreatedAt":"2019-08-29T00:33:15","Actor":"CESARDELATORRE","Number":"4153","RawContent":null,"Title":"[Image Classification DNN Transfer Learning] - Support training and scoring with in-memory images","State":"open","Body":"The new DNN-Transfer-Learning is very nicely simplified (and it'll be even more simplified), however, the way it is now doesn't support to train and score with in-memory images, therefore, if you train with image filepaths, the model for scoring also requires image paths...\r\n\r\nThat's limiting in-memory images scenarios that we really need to support.\r\n\r\nFor instance, in the code below, the API ImageClassification() is expecting image filepaths, only.\r\n\r\n```\r\n    public class ImageData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string ImagePath;\r\n\r\n        [LoadColumn(1)]\r\n        public string Label;\r\n    }\r\n\r\n//...\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"LabelAsKey\", \r\n                                                                inputColumnName: \"Label\",\r\n                                                                keyOrdinality: ValueToKeyMappingEstimator.KeyOrdinality.ByValue)\r\n            .Append(mlContext.Model.ImageClassification(\"ImagePath\", \"LabelAsKey\",\r\n                            arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n                            epoch: 100,     //An epoch is one learning cycle where the learner sees the whole training data set.\r\n                            batchSize: 100, // batchSize sets the number of images to feed the model at a time. It needs to divide the training set evenly or the remaining part won't be used for training. Use 10 for hundreds of images, 100 for thousands of images                             \r\n                            metricsCallback: (metrics) => Console.WriteLine(metrics),\r\n                            reuseTrainSetBottleneckCachedValues: false,\r\n                            reuseValidationSetBottleneckCachedValues: false,\r\n                            validationSet: transformedValidationDataView));\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4153","RelatedDescription":"Open issue \"[Image Classification DNN Transfer Learning] - Support training and scoring with in-memory images\" (#4153)"},{"Id":"486664786","IsPullRequest":false,"CreatedAt":"2019-08-28T23:57:22","Actor":"CESARDELATORRE","Number":"4152","RawContent":null,"Title":"[Image Classification DNN] - Need to support additional image formats, not just JPEG","State":"open","Body":"The current implementation only supports JPEG images for the dataset since it only has `JpegDecoding `etc. internally.\r\n\r\nIdeally, we need to support the same image formats than the ones supported by each Architecture (InceptionV3, ResNet, etc.)\r\n\r\nSee in PR: https://github.com/dotnet/machinelearning/pull/4151/files#diff-37f2285ba1483af56ae20862631502ecR177","Url":"https://github.com/dotnet/machinelearning/issues/4152","RelatedDescription":"Open issue \"[Image Classification DNN] - Need to support additional image formats, not just JPEG\" (#4152)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-09-06T05:30:37.7181492Z","RunDurationInMilliseconds":774}