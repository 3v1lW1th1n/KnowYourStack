{"Data":{"GitHub":{"Issues":[{"Id":"423030948","IsPullRequest":true,"CreatedAt":"2019-03-20T02:00:24","Actor":"artidoro","Number":"3033","RawContent":null,"Title":"Refactoring of Options for ImagePixelExtractingEstimator","State":"open","Body":"This PR is an example solution for #2884. Once I receive feedback on this, I will continue with the rest of the transforms.\r\n\r\nThe purpose of this PR is twofold:\r\n\r\n- does the ground work to more easily enable the refactoring of `Options`  in other transforms (commit 1)\r\n    - most of the work is in the file ColumnBindingsBase.cs.\r\n    - made `OneToOneColumn` public, removed empty class\r\n    - renamed `Name` and `Source` to `OutputColumnName` and `InputColumnName`\r\n    - added implicit operators to `OneToOneColumn` to simplify the multicolumn mapping scenario\r\n- refactors the `Options` class for `ImagePixelExtractingEstimator` (commit 2)\r\n    - moved immutable `ColumnOptions` to transformer and renamed `ColumnInfo`\r\n    - moved `Options` and `Column` to estimator\r\n    - refactored extension and constructors\r\n\r\nThe third commit fixes tests and entrypoint catalog.\r\n\r\n\r\nNote that with the combination of the implicit operators on `OneToOneColumn` and the constructor taking `OneToOneColumn` in the `Options` class, it is easier to define the multicolumn mapping scenario where the columns don't require column specific settings. For an example of the behavior see the test TestImagePixelExtractOptions in ImagesTests.cs:\r\n\r\n```csharp\r\n// options1 and 2 should be exactly the same.\r\nvar options1 = new ImagePixelExtractingEstimator.Options\r\n{\r\n    ColumnOptions = new[]\r\n    {\r\n        new ImagePixelExtractingEstimator.ColumnOptions { OutputColumnName = \"outputColumn1\", InputColumnName = \"inputColumn1\" },\r\n        new ImagePixelExtractingEstimator.ColumnOptions { OutputColumnName = \"outputColumn2\", InputColumnName = \"inputColumn2\" },\r\n        new ImagePixelExtractingEstimator.ColumnOptions { OutputColumnName = \"outputColumn3\", InputColumnName = \"inputColumn3\" }\r\n    }\r\n};\r\nvar options2 = new ImagePixelExtractingEstimator.Options((\"outputColumn1\", \"inputColumn1\"), (\"outputColumn2\", \"inputColumn2\"), (\"outputColumn3\", \"inputColumn3\"));\r\n// options3 has the same OutputColumnName as the previous two.\r\nvar options3 = new ImagePixelExtractingEstimator.Options(\"outputColumn1\", \"outputColumn2\", \"outputColumn3\");\r\n\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3033","RelatedDescription":"Open PR \"Refactoring of Options for ImagePixelExtractingEstimator\" (#3033)"},{"Id":"423022848","IsPullRequest":true,"CreatedAt":"2019-03-20T01:18:30","Actor":"codemzs","Number":"3032","RawContent":null,"Title":"Add cancellation checkpoint in logistic regression.","State":"open","Body":"fixes #3031\r\n\r\nPlease read the issue before reviewing this PR.","Url":"https://github.com/dotnet/machinelearning/pull/3032","RelatedDescription":"Open PR \"Add cancellation checkpoint in logistic regression.\" (#3032)"},{"Id":"423022552","IsPullRequest":false,"CreatedAt":"2019-03-20T01:17:14","Actor":"codemzs","Number":"3031","RawContent":null,"Title":"Cancellation checkpoints in LogisticRegression","State":"open","Body":"**Goal:**\r\nImplement a way to a cancel Logistic Regression training during runtime without impacting the performance too much.\r\n\r\n**Solution proposal:**\r\nIdentify code paths that are CPU intensive such as tight loops and place a check in them for cancellation signal. \r\n\r\nBelow is the performance graphs of Logistic Regression run from [this ](https://github.com/dotnet/machinelearning/blob/3af9a5d96ade88e888894af23baef8fe4598f826/docs/samples/Microsoft.ML.Samples/Dynamic/LogisticRegression.cs#L8) example. The graph will have a function selected and red stripes indicate the position in the graph it is called.\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54652127-f0e86500-4a72-11e9-9fad-8fd034ee2a5f.png)\r\n\r\nThe checkpoint should be at `cursor.MoveNext()` in `TrainCore` method. As we can see in the graph this function is called periodically in the training process. Everything before this is CPU cycles consumed by the transforms and it is not related to Logistic Regression training cycles.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3031","RelatedDescription":"Open issue \"Cancellation checkpoints in LogisticRegression\" (#3031)"},{"Id":"423022083","IsPullRequest":true,"CreatedAt":"2019-03-20T01:14:59","Actor":"wschin","Number":"3030","RawContent":null,"Title":"Polish train catalog (renaming only)","State":"open","Body":"Related to #3029 (for StandardTrainersCatalog.cs) but for TrainCatalog.cs.\r\n\r\n- Rename `topK` to `topPredictionCount`\r\n- Rename `k` to `falsePositiveCount`\r\n- Rename `samplingKeyColumnName` to `partitionKeyColumnName`\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3030","RelatedDescription":"Open PR \"Polish train catalog (renaming only)\" (#3030)"},{"Id":"423019489","IsPullRequest":true,"CreatedAt":"2019-03-20T01:01:42","Actor":"wschin","Number":"3029","RawContent":null,"Title":"Polish standard trainers' catalog","State":"open","Body":"To fix #2680, we rename several parameters and improve some doc strings.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3029","RelatedDescription":"Open PR \"Polish standard trainers' catalog\" (#3029)"},{"Id":"423015452","IsPullRequest":true,"CreatedAt":"2019-03-20T00:40:59","Actor":"codemzs","Number":"3028","RawContent":null,"Title":"Add cancellation signal checkpoints in FastTree.","State":"open","Body":"fixes #3027\r\n\r\nPlease read the issue before reviewing this PR.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3028","RelatedDescription":"Open PR \"Add cancellation signal checkpoints in FastTree.\" (#3028)"},{"Id":"423014771","IsPullRequest":false,"CreatedAt":"2019-03-20T00:37:39","Actor":"codemzs","Number":"3027","RawContent":null,"Title":"Cancellation checkpoints in FastTree","State":"open","Body":"**Goal:**\r\nImplement a way to a cancel FastTree training during runtime without impacting the performance too much.\r\n\r\n**Solution proposal:**\r\nIdentify code paths that are CPU intensive such as tight loops and place a check in them for cancellation signal. \r\n\r\nBelow are the performance graphs of FastTree run from [this ](https://github.com/dotnet/machinelearning/blob/c38f81b3957fed6aa88ea0e6b295522d5bf3f9ec/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/FastTree.cs#L12) example. The graph will have a function selected and red stripes indicate the position in the graph it is called.\r\n\r\nThe first checkpoint would be **`InitializeBins`** as evident from the below graph. We see before training there is the data prep step that is CPU intensive. In this step transpose of the dataset is created in-memory and binning of features is done. \r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54650437-c646de00-4a6b-11e9-860e-c92b014b4105.png)\r\n\r\nThe second place would be somewhere in the Feature Flock creation. Here we think `CreateFlocksCore` would be ideal. Based on the below graph.\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54650452-db237180-4a6b-11e9-9aa1-9584d8732b3c.png)\r\n\r\n\r\nThe third place would be at `FeatureHistogram` ctr called by `CreateSufficientStats`. This function is called by constructor of `LeastSquaresRegressionTreeLearner` within a loop that creates `CreateSufficientStats`. We will just place a checkpoint in this loop.\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54650724-0c507180-4a6d-11e9-9ac2-7708ba680e6f.png)\r\n\r\nThe last place would be somewhere we do the splitting of the nodes and partitioning of the data to construct the tree. We see that **`FindBestThresholdForFlockThreadWorker()`** seems to be a good place to check for cancellation signal as it seems to consume bulk of CPU cycles as evident from the red stripes in the graph. We can also place the checkpoints into the functions that it calls such as `FindBestThresholdFromHistogram`, `Sumup`, `SubtractCore`, `FillSplitCandidates`, `FindBestSplitForFeature` but I think place checks in the inner function could degrade the performance. \r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54649487-a7464d00-4a67-11e9-9253-2a20b9ddb67e.png)\r\n\r\nCC: @TomFinley , @eerhardt , @shauheen , @glebuk \r\n","Url":"https://github.com/dotnet/machinelearning/issues/3027","RelatedDescription":"Open issue \"Cancellation checkpoints in FastTree\" (#3027)"},{"Id":"422997963","IsPullRequest":true,"CreatedAt":"2019-03-19T23:25:23","Actor":"codemzs","Number":"3026","RawContent":null,"Title":"Add cancellation checkpoints in SDCA.","State":"open","Body":"fixes #3024\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3026","RelatedDescription":"Open PR \"Add cancellation checkpoints in SDCA.\" (#3026)"},{"Id":"422997644","IsPullRequest":false,"CreatedAt":"2019-03-19T23:24:09","Actor":"TomFinley","Number":"3025","RawContent":null,"Title":"About models, ITransform, and IDataLoader, saving/loading","State":"open","Body":"So, I had a conversation with @eerhardt and @yaeldekel, about the nature of models, in particular relating to the saving and loading routines. This is very important for us to get right, since the artifacts of what we learn and how we transform data, and their persistability, is probably the most important thing we have to do correctly.\r\n\r\nWe take the view initially that the model is the `ITransformer` (note that a chain of `ITransformer`s is itself an `ITransformer`). But, by itself this is an insufficient description, was we saw in in #2663 and its subsequent \"child\" #2735, from the point of view of model being practically \"the stuff you need to keep,\" there's a lot more to a machine learning model than merely just the `ITransformer` chain -- you also need to preserve some notion of what the input is to that. So we added these things to take either a loader, or the input schema, to be saved as part of the model.\r\n\r\nYet, is the loader a model itself? Sometimes that's precisely what we call it:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c38f81b3957fed6aa88ea0e6b295522d5bf3f9ec/src/Microsoft.ML.Data/Model/ModelOperationsCatalog.cs#L36\r\n\r\nAnd in the same file we call it something else:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c38f81b3957fed6aa88ea0e6b295522d5bf3f9ec/src/Microsoft.ML.Data/Model/ModelOperationsCatalog.cs#L65\r\n\r\nIt is a model in one sense because it is yet another things that takes input data and produces output data -- the fact that `ITransformer` does it specifically over `IDataView` as input *specifically* does not give it some magical, special status to allow it to be called a model, and yet not. If I take a loader, and append a transform to it, then the whole aggregate thing is *still* a loader. If it isn't a model, it only isn't one by the mere skin of its teeth. Hence the presence of the original thing, and why we have in the model operations catalog operations to save and load `IDataLoader` itself specifically.\r\n\r\nBut at the same time this duality of the term \"model\" is, as I understand @eerhardt, confusing. We have two things we're calling model. In an ideal world, I feel like if we *can* get away with just one story of what the model is, we should take it, and if there must be only one it must be `ITransformer`. We even have the situation where if you have `mlContext.Model.Save(`, the first thing that pops up is the `IDataLoader` thing, which is kind of strange.\r\n\r\nI am not quite sure what I think, since in this case I agree with whoever talks to me last with an even a vaguely convincing argument. But I think in this case I will see about getting rid of the `IDataLoader`-only APIs -- people can, if it is important, continue to save and load such things by using empty `ITransformer` chains (again, any chain of `ITransformer` is itself an `ITransformer`, including the empty chain).\r\n\r\nSince we are approaching v1, I view it as a bit more important to be conservative w.r.t. potentially confusing additions to the API, especially around something as central as the saving and loading of models. We might be able to add it back later if there's some really compelling scenario for them, that we somehow did not anticipate.\r\n\r\nWe will of course retain the saving and loading of transformers *with* loaders, since that is really important to be able to capture, but I think being consistent around the story that \"models are transformers\" as we are most places is kind of important.","Url":"https://github.com/dotnet/machinelearning/issues/3025","RelatedDescription":"Open issue \"About models, ITransform, and IDataLoader, saving/loading\" (#3025)"},{"Id":"422993685","IsPullRequest":false,"CreatedAt":"2019-03-19T23:08:26","Actor":"codemzs","Number":"3024","RawContent":null,"Title":"Cancellation checkpoint in StochasticDualCoordinateAscent ","State":"open","Body":"**Goal:**\r\nImplement a way to a cancel SDCA training during runtime without impacting the performance too much.\r\n\r\n**Solution proposal:**\r\nIdentify code paths that are CPU intensive such as tight loops and place a check in them for cancellation signal. \r\n\r\nBelow is the performance graph of SDCA run from [this ](https://github.com/dotnet/machinelearning/blob/c38f81b3957fed6aa88ea0e6b295522d5bf3f9ec/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/Regression/StochasticDualCoordinateAscent.cs#L9)example.\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54647615-63037e80-4a60-11e9-9c91-a24c1cb5728f.png)\r\n\r\nWe see that **MoveNext() in TrainWithoutLock** seems to be a good place to check for cancellation signal as it seems to consume bulk of CPU cycles as evident from the red stripes in the graph.\r\n\r\nThe second checkout point would be **CheckConvergence** as evident from the below graph (look for red stripes):\r\n\r\n![image](https://user-images.githubusercontent.com/1211949/54647749-fdfc5880-4a60-11e9-8ec6-aec689a7abb1.png)\r\n\r\nCC: @TomFinley , @eerhardt , @shauheen , @glebuk \r\n","Url":"https://github.com/dotnet/machinelearning/issues/3024","RelatedDescription":"Open issue \"Cancellation checkpoint in StochasticDualCoordinateAscent \" (#3024)"},{"Id":"422991070","IsPullRequest":true,"CreatedAt":"2019-03-19T22:58:28","Actor":"singlis","Number":"3023","RawContent":null,"Title":"Adds the openmp library to the MklRedist nuget package.","State":"open","Body":"Adds the openmp library to the MklRedist nuget package.\r\nFixes #3015\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3023","RelatedDescription":"Open PR \"Adds the openmp library to the MklRedist nuget package.\" (#3023)"},{"Id":"422989138","IsPullRequest":true,"CreatedAt":"2019-03-19T22:51:20","Actor":"eerhardt","Number":"3022","RawContent":null,"Title":"Move KeyType, VectorType and VBuffer to ML.DataView","State":"open","Body":"Fix #2986 \r\n\r\nEasiest to review commit-by-commit. Major changes:\r\n\r\n1. Moved the types into the ML.DataView assembly.\r\n2. Renamed KeyType and VectorType to have `DataViewType` suffixes.\r\n3. VBufferEditor had an \"internal-only\" option that is now public: `maxValuesCapacity`. This was needed so VBufferUtils could operate effectively. If VBufferUtils needs it, chances are someone else will need it.\r\n4. Removed VectorType's constructor that takes a `VectorType template`, and replaced it with a new constructor that takes an `ImmutableArray<int> dims`.","Url":"https://github.com/dotnet/machinelearning/pull/3022","RelatedDescription":"Open PR \"Move KeyType, VectorType and VBuffer to ML.DataView\" (#3022)"},{"Id":"422984999","IsPullRequest":true,"CreatedAt":"2019-03-19T22:36:27","Actor":"sfilipi","Number":"3021","RawContent":null,"Title":"Data catalog done","State":"open","Body":"Towards #1209 \r\n\r\nAdding a sample for TrainTestSplit. \r\nAdding doc strings for the CreateFromeEnumerable\r\nMinor fixes to xml formatting. ","Url":"https://github.com/dotnet/machinelearning/pull/3021","RelatedDescription":"Open PR \"Data catalog done\" (#3021)"},{"Id":"422984304","IsPullRequest":true,"CreatedAt":"2019-03-19T22:34:03","Actor":"Ivanidzo4ka","Number":"3020","RawContent":null,"Title":"WIP Align with code in LightGBM for Categorical features","State":"open","Body":"Potentially fixes https://github.com/dotnet/machinelearning/issues/1625\r\nHonestly have no idea what I'm doing here, so I would appreciate any feedback.\r\n\r\nNeed tests.","Url":"https://github.com/dotnet/machinelearning/pull/3020","RelatedDescription":"Open PR \"WIP Align with code in LightGBM for Categorical features\" (#3020)"},{"Id":"422951696","IsPullRequest":true,"CreatedAt":"2019-03-19T21:01:12","Actor":"codemzs","Number":"3019","RawContent":null,"Title":"Rename Save API for DataLoader to SaveDataLoader.","State":"open","Body":"towards #2991\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3019","RelatedDescription":"Open PR \"Rename Save API for DataLoader to SaveDataLoader.\" (#3019)"},{"Id":"422949235","IsPullRequest":true,"CreatedAt":"2019-03-19T20:59:03","Actor":"codemzs","Number":"3018","RawContent":null,"Title":"Rename Save API for DataLoader to SaveDataLoader.","State":"closed","Body":"towards #2991\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3018","RelatedDescription":"Closed or merged PR \"Rename Save API for DataLoader to SaveDataLoader.\" (#3018)"},{"Id":"422745476","IsPullRequest":true,"CreatedAt":"2019-03-19T20:58:56","Actor":"eerhardt","Number":"3010","RawContent":null,"Title":"Updating the FunctionalTests to clearly explain why they are not strong named signed.","State":"closed","Body":"See https://github.com/dotnet/machinelearning/pull/2858#discussion_r264738643 for an example of why this is necessary.","Url":"https://github.com/dotnet/machinelearning/pull/3010","RelatedDescription":"Closed or merged PR \"Updating the FunctionalTests to clearly explain why they are not strong named signed.\" (#3010)"},{"Id":"422944550","IsPullRequest":true,"CreatedAt":"2019-03-19T20:44:37","Actor":"zeahmed","Number":"3017","RawContent":null,"Title":"[WIP] TT Template for managing samples...","State":"open","Body":"As we are going along with making sample standalone, I have been observing that there is a lot of code duplication in the sample. I am proposing to use tt template for managing our samples.\r\n\r\nThe code in this PR shows how to make a template for samples to reduce the copy-paste of common code as well as minimize the code to review every time someone pushes a sample.\r\n\r\nPlease do not merge this PR. I have already tagged it as WIP.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3017","RelatedDescription":"Open PR \"[WIP] TT Template for managing samples...\" (#3017)"},{"Id":"422933332","IsPullRequest":false,"CreatedAt":"2019-03-19T20:17:54","Actor":"wschin","Number":"3016","RawContent":null,"Title":"The \"Binary\" in \"LogisticRegressionBInaryTrainer\" Looks Redundant","State":"open","Body":"As title. Logistic regression is clearly a binary classifier, so we can consider dropping \"Binary\" among \"LogisticRegressionBinaryTrainer\".","Url":"https://github.com/dotnet/machinelearning/issues/3016","RelatedDescription":"Open issue \"The \"Binary\" in \"LogisticRegressionBInaryTrainer\" Looks Redundant\" (#3016)"},{"Id":"422896100","IsPullRequest":false,"CreatedAt":"2019-03-19T18:47:48","Actor":"singlis","Number":"3015","RawContent":null,"Title":"Missing libompd library for MklRedist nuget","State":"open","Body":"### Issue\r\nWith the latest changes to add openmp back with mkl, the libompd library for windows needs to be packaged as part of the MklRedist nuget package.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3015","RelatedDescription":"Open issue \"Missing libompd library for MklRedist nuget\" (#3015)"},{"Id":"422888031","IsPullRequest":false,"CreatedAt":"2019-03-19T18:28:48","Actor":"eyadek","Number":"3014","RawContent":null,"Title":"Can't find CollectionDataSource class ","State":"open","Body":"### System information\r\n\r\n- **OS Windows**\r\n- **.NET Version 4.7.2**: \r\n\r\n### Issue\r\n\r\nHi, I'm using ML.NET 0.11 in an ASP.Net MVC 5 Web App. the .Net version is 4.7.2 and I can use the CollectionDataSource to load data from list to the pipeline. How can I use it?\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3014","RelatedDescription":"Open issue \"Can't find CollectionDataSource class \" (#3014)"},{"Id":"422877546","IsPullRequest":false,"CreatedAt":"2019-03-19T18:05:05","Actor":"artidoro","Number":"3013","RawContent":null,"Title":"All transforms extensions should be tested","State":"open","Body":"PR #2959 introduces new extensions and internalizes all the ones that rely on `ColumnOptions`.\r\nMost new extensions call the same constructor as the ones that were made internal. \r\n\r\nHowever, it would be best to make sure that all transforms extensions are being used in some tests.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3013","RelatedDescription":"Open issue \"All transforms extensions should be tested\" (#3013)"},{"Id":"422874003","IsPullRequest":false,"CreatedAt":"2019-03-19T17:57:11","Actor":"vinodshanbhag","Number":"3012","RawContent":null,"Title":"Need public constructor and settable properties on RegressionMetrics and their sibling classes ","State":"open","Body":"AutoML API returns Metric for each hypothesis it builds and runs.\r\nWhen data is small autoML API internally does cross validate (instead of train validate) and the metric it wants to return is the average of the metric from training each fold.\r\nCurrently it is not possible to build a new metric object and populate it with average values since the RegressionMetric and their siblings etc don't have public constructor.\r\n\r\nCan we please provide a public constructor to these Metric classes?\r\nIt will be great if we can accomadate for 0.12 release.\r\n\r\n@TomFinley @shauheen  \r\n","Url":"https://github.com/dotnet/machinelearning/issues/3012","RelatedDescription":"Open issue \"Need public constructor and settable properties on RegressionMetrics and their sibling classes \" (#3012)"},{"Id":"422864934","IsPullRequest":true,"CreatedAt":"2019-03-19T17:37:22","Actor":"yaeldekel","Number":"3011","RawContent":null,"Title":"Fix bug in TextLoader","State":"open","Body":"Fixes #2996.","Url":"https://github.com/dotnet/machinelearning/pull/3011","RelatedDescription":"Open PR \"Fix bug in TextLoader\" (#3011)"},{"Id":"422733361","IsPullRequest":false,"CreatedAt":"2019-03-19T13:31:13","Actor":"rudi3999","Number":"3009","RawContent":null,"Title":"Can't find the constructor for MulticlassClassificationTrainers(ctx) (v0.10)","State":"open","Body":"Hello \r\n\r\nwhere is the constructor for a call like:\r\n\r\nvar sdcaContext = new MulticlassClassificationCatalog(ctx);\r\n\r\nbeen moved in 0.11? \r\n","Url":"https://github.com/dotnet/machinelearning/issues/3009","RelatedDescription":"Open issue \"Can't find the constructor for MulticlassClassificationTrainers(ctx) (v0.10)\" (#3009)"},{"Id":"422501891","IsPullRequest":true,"CreatedAt":"2019-03-19T01:24:31","Actor":"codemzs","Number":"3008","RawContent":null,"Title":"MLContext.Model.Load overloads that take file path instead of stream.","State":"open","Body":"fixes #2991\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3008","RelatedDescription":"Open PR \"MLContext.Model.Load overloads that take file path instead of stream.\" (#3008)"},{"Id":"422493636","IsPullRequest":false,"CreatedAt":"2019-03-19T00:40:54","Actor":"glebuk","Number":"3007","RawContent":null,"Title":"Perf: Optimization for DoubleParser (VTune)","State":"open","Body":"Benchmarking using VTune has found several bottlenecks in parsing Doubles from string in text reader\r\nPerhaps we should consider optimizing this method:\r\nFor example, for training a FM it takes almost 37% of all clock cycles:\r\n\r\nFunction | Module | CPU Time\r\n-- | -- | --\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParseCore | Microsoft.ML.Core.dll | 27.390s\r\nCalculateGradientAndUpdateNative | factorizationmachinenative.dll | 22.609s\r\nHelperImpl::FetchNextField | Microsoft.ML.Data.dll | 13.826s\r\nCalculateIntermediateVariablesNative | factorizationmachinenative.dll | 12.201s\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParse | Microsoft.ML.Core.dll | 9.666s\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3007","RelatedDescription":"Open issue \"Perf: Optimization for DoubleParser (VTune)\" (#3007)"},{"Id":"422492087","IsPullRequest":true,"CreatedAt":"2019-03-19T00:33:01","Actor":"zeahmed","Number":"3006","RawContent":null,"Title":"Added tests for text featurizer options (Part1).","State":"open","Body":"This PR partially address #2967. See the following list. Further tests will be added in the next PR.\r\n\r\nTest created for following parameters in options class\r\n\r\n* StopWordsRemover\r\n* CaseMode\r\n* KeepDiacritics\r\n* KeepPunctuations\r\n* KeepNumbers\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3006","RelatedDescription":"Open PR \"Added tests for text featurizer options (Part1).\" (#3006)"},{"Id":"422490989","IsPullRequest":false,"CreatedAt":"2019-03-19T00:27:15","Actor":"wschin","Number":"3005","RawContent":null,"Title":"Enum Name --- OneHotEncodingEstimator.OutputKind","State":"open","Body":"I personally prefer `OneHotEncodingEstimator.Representation` than `OneHotEncodingEstimator.OutputKind`. @sfilipi, @TomFinley, @rogancarr, any comment please?","Url":"https://github.com/dotnet/machinelearning/issues/3005","RelatedDescription":"Open issue \"Enum Name --- OneHotEncodingEstimator.OutputKind\" (#3005)"},{"Id":"422490241","IsPullRequest":false,"CreatedAt":"2019-03-19T00:23:12","Actor":"glebuk","Number":"3004","RawContent":null,"Title":"Perf: Optimization for GAMs (VTune)","State":"open","Body":"Benchmarking using VTune has found several bottlenecks in GAMS\r\n\r\n- Significant CPU cycles spent in Interlocked.CompareExchange. \r\n- Call-stack & source code of CenterGraph shows Interlocked.CompareExchange in the inner loop, contributing to the high CPU cycles in CompareExchange. Look at reducing the calls to this intrinsic.\r\n- Next step: Look at re-jiggering the code in CenterGraph to avoid the CompareExchange in the inner loop\r\n\r\nTop HotSpots:\r\n\r\nFunction | Module | CPU Time\r\n-- | -- | --\r\nCOMInterlocked::CompareExchangeDouble | coreclr.dll | 55.754s\r\n<>c__DisplayClass46_0::<UpdateScoresForSet>b__0 | Microsoft.ML.FastTree.dll | 35.381s\r\nMicrosoft::ML::Internal::Utilities::DoubleParser::TryParseCore | Microsoft.ML.Core.dll | 30.808s\r\n<>c__DisplayClass49_0::<CenterGraph>b__0 | Microsoft.ML.FastTree.dll | 26.872s\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3004","RelatedDescription":"Open issue \"Perf: Optimization for GAMs (VTune)\" (#3004)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-03-20T05:30:33.3419704Z","RunDurationInMilliseconds":609}