{"Data":{"GitHub":{"Issues":[{"Id":"555161340","IsPullRequest":true,"CreatedAt":"2020-01-26T01:00:40","Actor":"harishsk","Number":"4710","RawContent":null,"Title":"Draft modification to redirect logs to test output","State":"open","Body":"Currently when running tests the channel output doesn't appear in the test logs. This is a draft change to enable that functionality in order to get better logging to debug tests better.\r\n\r\nAt its core there are two changes. The first allows overriding the IHostEnvironment used in MLContext with a custom one. I am not completely sure of this change. The change to MLContext might be a breaking one and there is very likely a better way to do this that I am missing. \r\n\r\nThe second change is to add a custom TextWriter derived class that gets added to ConsoleEnvironment to redirect logs to test output if it has been configured to do so.\r\n\r\nI am putting this PR up for review for two purposes. \r\nThe first is for general verification of the code and concept. And while the code reviews are in progress I am also using this to try and debug the failure in BinaryClassifierSymSgdTest in the CI builds. (I will back out the changes related to BinaryClassifierSymSgdTest before this PR gets submitted)\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4710","RelatedDescription":"Open PR \"Draft modification to redirect logs to test output\" (#4710)"},{"Id":"555099972","IsPullRequest":false,"CreatedAt":"2020-01-25T15:46:07","Actor":"Cyrus-Sushiant","Number":"4709","RawContent":null,"Title":"Save method on asp.net core get an error that access denied path","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NetCore 3.1.1\r\n\r\n### Issue\r\n\r\nWhen I want save trained model with the Save Method on asp.net core, I get an error that access denied path. I used other way instead of it.\r\n[Follow here](https://github.com/Cyrus-Sushiant/MLDotNetTitanic/blob/master/MLDotNetTitanic/ML/ModelBuilder.cs#L68).\r\n\r\n### Source code / logs\r\n\r\n`mlContext.Model.Save(mlModel, modelInputSchema, modelPath);`\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4709","RelatedDescription":"Open issue \"Save method on asp.net core get an error that access denied path\" (#4709)"},{"Id":"555056662","IsPullRequest":false,"CreatedAt":"2020-01-25T07:56:42","Actor":"mauryflag","Number":"4708","RawContent":null,"Title":"Tensorflow.TensorflowException Can't copy 64064 bytes of a tensor into another with 32032 bytes buffer","State":"open","Body":"### System information\r\n\r\n- **Windows 10 pro**:\r\n- **.NET Version .net core 3.1**: \r\n\r\n### Issue\r\n\r\n- **I've generated model for image classification by using ML.Net Model builder , 2 labels (OK & NG) 10 images in total , model was correctly created together with the C# code **\r\n- **I've checked that everything was working fine then i've added SciSharp.TensorFlow.Redist-Windows-GPU in order to check the behavior with GPU**\r\n- **I was expecting that the model will be generated just simply more fast by using GPU , unfortunately it goes in error . attached source code and snip of the error .*\r\n\r\n[ML.zip](https://github.com/dotnet/machinelearning/files/4111726/ML.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4708","RelatedDescription":"Open issue \"Tensorflow.TensorflowException Can't copy 64064 bytes of a tensor into another with 32032 bytes buffer\" (#4708)"},{"Id":"554985537","IsPullRequest":false,"CreatedAt":"2020-01-24T22:30:35","Actor":"najeeb-kazmi","Number":"4707","RawContent":null,"Title":"OnnxTransformer docs xml code sample should use latest dynamic API","State":"open","Body":"It currently uses the old static API\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/53fba319042f27efc64ef45889c9d9467ac20785/src/Microsoft.ML.OnnxTransformer/doc.xml#L49-L62\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4707","RelatedDescription":"Open issue \"OnnxTransformer docs xml code sample should use latest dynamic API\" (#4707)"},{"Id":"554983812","IsPullRequest":true,"CreatedAt":"2020-01-24T22:25:31","Actor":"najeeb-kazmi","Number":"4706","RawContent":null,"Title":"Update cookbook to latest API","State":"open","Body":"Fixes #3849 ","Url":"https://github.com/dotnet/machinelearning/pull/4706","RelatedDescription":"Open PR \"Update cookbook to latest API\" (#4706)"},{"Id":"554916246","IsPullRequest":true,"CreatedAt":"2020-01-24T19:36:42","Actor":"najeeb-kazmi","Number":"4705","RawContent":null,"Title":"Correct KMeans scoring function doc","State":"open","Body":"Fixes #4011 ","Url":"https://github.com/dotnet/machinelearning/pull/4705","RelatedDescription":"Open PR \"Correct KMeans scoring function doc\" (#4705)"},{"Id":"554854878","IsPullRequest":true,"CreatedAt":"2020-01-24T17:11:28","Actor":"gvashishtha","Number":"4704","RawContent":null,"Title":"[Mn] Roadmap update","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4704","RelatedDescription":"Open PR \"[Mn] Roadmap update\" (#4704)"},{"Id":"554795631","IsPullRequest":false,"CreatedAt":"2020-01-24T15:19:42","Actor":"francois-dorin","Number":"4703","RawContent":null,"Title":"Bottleneck phase produces bad files (invalid or with poor accuracy results) on some configuration","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**: 3.1.101\r\n- **ML.NET Version**: 1.4.0 \r\n- **CPU : AMD Ryzen 9 3900X 12-Core**\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRunning a simple example of image classification, based on https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/image-classification-api-transfer-learning\r\n\r\n- **What happened?**\r\nUsing only CPU, the process completes but provides a very poor accuracy (0.014)\r\nUsing GPU, the process passes the bottleneck phase but cannot begin the train due to an error.\r\n\r\n- **What did you expect?**\r\nUsing only CPU, I expect a better result (around 0.70).\r\nUsing GPU, I expect the process to continue and train.\r\n\r\n- **Additionnal informations**\r\nThe same program with the same dataset works fine on another computer (Intel based CPU) and have a correct accuracy (0.70).\r\nNo problem occurs when using the GPU.\r\nIf I copy/paste the cached files from the working computer to my computer, the process is working fine (with or without GPU) and have the expected accuracy (0.70).\r\nSo, I guess the problem relies in the files generated during the bottleneck phase and is related to the hardware configuration, since same program with same dataset have very different behaviours.\r\n\r\n### Source code / logs\r\nComplete logs (CPU Only) when using generated cached files during the bottleneck phase\r\n```\r\n*** Training the image classification model with DNN Transfer Learning on top of the selected pre-trained model/architecture ***\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0083464.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n2020-01-24 16:03:09.939754: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nSaver not created because there are no variables in the graph to restore\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:       0,01 Epoch:   0, Accuracy:  0,6121079, Cross-Entropy: 4,300151E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   0, Accuracy: 0,01333781\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:       0,01 Epoch:   1, Accuracy:  0,6213207, Cross-Entropy: 3,970512E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   1, Accuracy: 0,01346435\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:     0,0094 Epoch:   2, Accuracy:  0,6239617, Cross-Entropy: 3,621145E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   2, Accuracy: 0,01293448\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:     0,0094 Epoch:   3, Accuracy:  0,6224542, Cross-Entropy: 3,632903E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   3, Accuracy: 0,01363834\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:   0,008836 Epoch:   4, Accuracy:  0,6240405, Cross-Entropy: 3,406656E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   4, Accuracy: 0,01359484\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate:   0,008836 Epoch:   5, Accuracy:  0,6223006, Cross-Entropy: 3,40876E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   5, Accuracy: 0,01343272\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,008305839 Epoch:   6, Accuracy:  0,6249708, Cross-Entropy: 3,204811E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   6, Accuracy:  0,0134169\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,008305839 Epoch:   7, Accuracy:  0,6249651, Cross-Entropy: 3,184228E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   7, Accuracy: 0,01392107\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,007807489 Epoch:   8, Accuracy:  0,6232149, Cross-Entropy: 3,004976E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   8, Accuracy: 0,01329432\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,007807489 Epoch:   9, Accuracy:  0,6227242, Cross-Entropy: 3,030696E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:   9, Accuracy: 0,01335956\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,00733904 Epoch:  10, Accuracy:  0,6246268, Cross-Entropy: 2,813951E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  10, Accuracy: 0,01338527\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,00733904 Epoch:  11, Accuracy:  0,6228801, Cross-Entropy: 2,828588E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  11, Accuracy: 0,01380046\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006898697 Epoch:  12, Accuracy:  0,6257862, Cross-Entropy: 2,645051E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  12, Accuracy: 0,01335957\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006898697 Epoch:  13, Accuracy:  0,6236802, Cross-Entropy: 2,659039E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  13, Accuracy: 0,01352564\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006484775 Epoch:  14, Accuracy:  0,6229582, Cross-Entropy: 2,493187E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  14, Accuracy: 0,01385187\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006484775 Epoch:  15, Accuracy:  0,6234171, Cross-Entropy: 2,496486E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  15, Accuracy: 0,01407331\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006095689 Epoch:  16, Accuracy:  0,6221284, Cross-Entropy: 2,340333E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  16, Accuracy: 0,01392898\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,006095689 Epoch:  17, Accuracy:  0,6231769, Cross-Entropy: 2,359828E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  17, Accuracy: 0,01311638\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,005729948 Epoch:  18, Accuracy:  0,6233777, Cross-Entropy: 2,180089E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  18, Accuracy: 0,01357309\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,005729948 Epoch:  19, Accuracy:  0,6225668, Cross-Entropy: 2,219908E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  19, Accuracy: 0,01381233\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 0,005386151 Epoch:  20, Accuracy:  0,6234834, Cross-Entropy: 2,070789E+12\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch:  20, Accuracy: 0,01392503\r\nSaver not created because there are no variables in the graph to restore\r\n```\r\n\r\nEnd logs (CPU Only) when using cached files from a working computer (more epoch and better results)\r\n```Phase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 222, Accuracy:  0,7872852\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 1,040379E-05 Epoch: 223, Accuracy:  0,8063375, Cross-Entropy:  0,7515593\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 223, Accuracy:  0,7873719\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 9,779563E-06 Epoch: 224, Accuracy:  0,8058808, Cross-Entropy:  0,7523516\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 224, Accuracy:  0,7878902\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 9,779563E-06 Epoch: 225, Accuracy:  0,8060154, Cross-Entropy:  0,7517532\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 225, Accuracy:  0,7882423\r\nPhase: Training, Dataset used:      Train, Batch Processed Count: 9177, Learning Rate: 9,19279E-06 Epoch: 226, Accuracy:  0,8054689, Cross-Entropy:  0,7526353\r\nPhase: Training, Dataset used: Validation, Batch Processed Count: 2299, Epoch: 226, Accuracy:   0,788062\r\n```\r\n\r\nLogs when using GPU\r\n```\r\n*** Training the image classification model with DNN Transfer Learning on top of the selected pre-trained model/architecture ***\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel started\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel finished. Elapsed 00:00:00.0088906.\r\n[Source=ImageClassificationTrainer; Ensuring meta files are present., Kind=Trace] Channel disposed\r\n2020-01-24 16:11:47.949314: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-01-24 16:11:47.960130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\r\n2020-01-24 16:11:47.998004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.785\r\npciBusID: 0000:2d:00.0\r\n2020-01-24 16:11:48.000866: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-01-24 16:11:48.003049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2020-01-24 16:11:49.018802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-01-24 16:11:49.020743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\r\n2020-01-24 16:11:49.021869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\r\n2020-01-24 16:11:49.023948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6290 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5)\r\nSaver not created because there are no variables in the graph to restore\r\n2020-01-24 16:11:49.891634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.785\r\npciBusID: 0000:2d:00.0\r\n2020-01-24 16:11:49.894813: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-01-24 16:11:49.897236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2020-01-24 16:11:49.899756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-01-24 16:11:49.902237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\r\n2020-01-24 16:11:49.903756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\r\n2020-01-24 16:11:49.906049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6290 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5)\r\nCan't copy 160160 bytes of a tensor into another with 80080 bytes buffer.\r\n         [[{{node _arg_input_1/BottleneckInputPlaceholder_0_0}}]]\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4703","RelatedDescription":"Open issue \"Bottleneck phase produces bad files (invalid or with poor accuracy results) on some configuration\" (#4703)"},{"Id":"554785554","IsPullRequest":true,"CreatedAt":"2020-01-24T15:01:27","Actor":"yaeldekel","Number":"4702","RawContent":null,"Title":"Disallow bad input types in FeatureSelection estimator's GetOutputSchema method","State":"open","Body":"Related to #4693 .\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4702","RelatedDescription":"Open PR \"Disallow bad input types in FeatureSelection estimator's GetOutputSchema method\" (#4702)"},{"Id":"554761949","IsPullRequest":true,"CreatedAt":"2020-01-24T14:18:51","Actor":"mstfbl","Number":"4701","RawContent":null,"Title":"Changed type of CustomGains to double[] for consistency","State":"open","Body":"Fixes #3708 ","Url":"https://github.com/dotnet/machinelearning/pull/4701","RelatedDescription":"Open PR \"Changed type of CustomGains to double[] for consistency\" (#4701)"},{"Id":"554489330","IsPullRequest":false,"CreatedAt":"2020-01-24T00:47:21","Actor":"antoniovs1029","Number":"4700","RawContent":null,"Title":"Using PlattCalibratorTransformer with custon name for Score Column","State":"open","Body":"### Issue\r\n\r\n- **What did you do?**\r\nI tried to create a model with a PlattCalibratorEstimator that uses a `scoreColumnName` with a name different from \"Score\" (as done through [this API](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.binaryclassificationcatalog.calibratorscatalog.platt?view=ml-dotnet#Microsoft_ML_BinaryClassificationCatalog_CalibratorsCatalog_Platt_System_String_System_String_System_String_))\r\n\r\n- **What happened?**\r\nAfter fitting the estimator, and while trying to transform the input dataview, the following exception is thrown:\r\n`System.InvalidOperationException: 'The data to calibrate contains no 'Score' column'`\r\n\r\n- **What did you expect?**\r\nThe model to work the same way as if I had used the name \"Score\" for my score column\r\n\r\nFurthermore, I couldn't find any sample or test that actually used the optional parameter `scoreColumnName` of PlattCalibratorEstimator, or the other parameters (such as labelColumnName). So adding such tests might be also necessary (if my PR #4700 gets in, then fixing this issue in here would also require to add onnx tests to check that PlattCalibrator with custom scoreColumnName is saved correctly to onnx). Checking if this problem also occurs in the other CalibratorTransformers would also be relevant.\r\n\r\nNotice that a simple workaround for this would be to copy the column that holds the score into a new column called Score, and specify Score as the scoreColumnName.\r\n\r\n### Source code / logs\r\nIn EXAMPLE 1 I show that it works if my score column is named \"Score\". But if I change the name, then it doesn't work.\r\n\r\n```C#\r\nusing Microsoft.ML;\r\n\r\nnamespace Platt2\r\n{\r\n    public static class Platt2\r\n    {\r\n\r\n        class ModelInput\r\n        {\r\n            public bool Label { get; set; }\r\n            public float Score { get; set; }\r\n        }\r\n\r\n        class ModelInput2\r\n        {\r\n            public bool Label { get; set; }\r\n            public float ScoreX { get; set; }\r\n        }\r\n\r\n        public static void Main()\r\n        {\r\n            var mlContext = new MLContext(seed: 0);\r\n\r\n            // EXAMPLE 1 - Works\r\n            IDataView data = mlContext.Data.LoadFromEnumerable<ModelInput>(\r\n                new ModelInput[]\r\n                {\r\n                                new ModelInput { Score = 10, Label = true },\r\n                                new ModelInput { Score = 15, Label = false },\r\n                }\r\n            );\r\n\r\n            var calibratorEstimator = mlContext.BinaryClassification.Calibrators\r\n                .Platt();\r\n\r\n            var calibratorTransformer = calibratorEstimator.Fit(data);\r\n            var finalData = calibratorTransformer.Transform(data);\r\n            var prev = finalData.Preview();\r\n\r\n\r\n            // EXAMPLE 2 - Doesn't Work\r\n            IDataView data2 = mlContext.Data.LoadFromEnumerable<ModelInput2>(\r\n                new ModelInput2[]\r\n                {\r\n                                new ModelInput2 { ScoreX = 10, Label = true },\r\n                                new ModelInput2 { ScoreX = 15, Label = false },\r\n                }\r\n            );\r\n\r\n            calibratorEstimator = mlContext.BinaryClassification.Calibrators\r\n                .Platt(scoreColumnName: \"ScoreX\");\r\n\r\n            calibratorTransformer = calibratorEstimator.Fit(data2);\r\n            finalData = calibratorTransformer.Transform(data2); // Throws exception\r\n            prev = finalData.Preview();\r\n\r\n        }\r\n\r\n    }\r\n}\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4700","RelatedDescription":"Open issue \"Using PlattCalibratorTransformer with custon name for Score Column\" (#4700)"},{"Id":"554485803","IsPullRequest":true,"CreatedAt":"2020-01-24T00:33:23","Actor":"antoniovs1029","Number":"4699","RawContent":null,"Title":"Added Onnx Export to PlattCalibratorTransformer","State":"open","Body":"`PlattCalibrator` already had a `SaveAsOnnx` method ([link](https://github.com/dotnet/machinelearning/blob/2267f8d709ad053a5db5867abb396c960173d6ef/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1739)) which was called when saving to Onnx a `PlattCalibrator` through a `CalibratedModelParameter` class (such as in [here](https://github.com/dotnet/machinelearning/blob/2267f8d709ad053a5db5867abb396c960173d6ef/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L391)). This would happen when saving a model produced by a calibrated binary classifier.\r\n\r\nBesides being part of calibrated binary classifiers, a PlattCalibrator can also be used independently, through a `PlattCalibratorTransformer`. So in this PR I add the necessary code so to also make it possible to save as Onnx a model that used a `PlattCalibratorTransformer`.\r\n\r\nI added 2 tests where a PlattCalibratorTransformer is added at the end of the model (in one test it's added on top of binary classifiers, in the other test no binary classifiers were used).\r\n\r\nI also fixed a bug in the SaveAsOnnx method of PlattCalibrator. For some reason, it was hardcoded to use \"-0.0000001f\" as the value of the Offset, ignoring the actual offset that the calibrator had. This worked with the existing tests because in them the offset was actually \"0\", but that isn't always the case, and so in the tests that I am adding the offset is not 0.","Url":"https://github.com/dotnet/machinelearning/pull/4699","RelatedDescription":"Open PR \"Added Onnx Export to PlattCalibratorTransformer\" (#4699)"},{"Id":"554472705","IsPullRequest":true,"CreatedAt":"2020-01-23T23:48:53","Actor":"Lynx1820","Number":"4698","RawContent":null,"Title":"Fix for OneVersusAll Multiclass trainer","State":"open","Body":"Also adding tests for OVA with FastForest, LinearSVM, and AveragedPerceptron.","Url":"https://github.com/dotnet/machinelearning/pull/4698","RelatedDescription":"Open PR \"Fix for OneVersusAll Multiclass trainer\" (#4698)"},{"Id":"554445158","IsPullRequest":true,"CreatedAt":"2020-01-23T22:30:54","Actor":"natke","Number":"4697","RawContent":null,"Title":"Fix #4611 broken xrefs in ExpressionTransformer","State":"open","Body":"Re-fix #4611 \r\n\r\n#4647 tried to fix this but some problems remained","Url":"https://github.com/dotnet/machinelearning/pull/4697","RelatedDescription":"Open PR \"Fix #4611 broken xrefs in ExpressionTransformer\" (#4697)"},{"Id":"554243517","IsPullRequest":true,"CreatedAt":"2020-01-23T15:50:53","Actor":"yaeldekel","Number":"4696","RawContent":null,"Title":"Fix bug in WordBagEstimator when training on empty data","State":"open","Body":"Fixes #969 .\r\nRelated to issue #4693 .","Url":"https://github.com/dotnet/machinelearning/pull/4696","RelatedDescription":"Open PR \"Fix bug in WordBagEstimator when training on empty data\" (#4696)"},{"Id":"554130086","IsPullRequest":true,"CreatedAt":"2020-01-23T12:34:56","Actor":"mstfbl","Number":"4695","RawContent":null,"Title":"Update LightGbmTrainerBase.cs","State":"open","Body":"Fixes #4681 , and also adds the ability to use the numerical value (0) as missing value with LightGBM.","Url":"https://github.com/dotnet/machinelearning/pull/4695","RelatedDescription":"Open PR \"Update LightGbmTrainerBase.cs\" (#4695)"},{"Id":"553892271","IsPullRequest":true,"CreatedAt":"2020-01-23T01:42:36","Actor":"antoniovs1029","Number":"4694","RawContent":null,"Title":"Remove obsolete code in BinaryClassifierEvaluator","State":"open","Body":"As mentioned in [here](https://github.com/dotnet/machinelearning/pull/4673#discussion_r368178117), the code that I am removing in this PR makes use of `IRowCursor` and `XYPlot`, which existed back in TLC but doesn't exist in ML.NET. The only reason they don't cause a problem when building ML.NET was because they're wrapped around an `#if !CORECLR` directive.","Url":"https://github.com/dotnet/machinelearning/pull/4694","RelatedDescription":"Open PR \"Remove obsolete code in BinaryClassifierEvaluator\" (#4694)"},{"Id":"553194291","IsPullRequest":true,"CreatedAt":"2020-01-23T00:58:11","Actor":"frank-dong-ms","Number":"4684","RawContent":null,"Title":"fix reg path when take memory dump","State":"closed","Body":"seeing below error from CI, fix the path format:\r\n\r\n\"C:\\Windows\\system32\\cmd.exe\" /D /E:ON /V:OFF /S /C \"CALL \"F:\\workspace\\_work\\_temp\\12c42bfd-4cdb-4cfb-ab8c-35ee6b913464.cmd\"\"\r\nERROR: Invalid key name.\r\nType \"REG ADD /?\" for usage.\r\nERROR: Invalid key name.\r\nType \"REG ADD /?\" for usage.\r\nERROR: Invalid key name.\r\nType \"REG ADD /?\" for usage.\r\nERROR: Invalid key name.\r\nType \"REG ADD /?\" for usage.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4684","RelatedDescription":"Closed or merged PR \"fix reg path when take memory dump\" (#4684)"},{"Id":"553863174","IsPullRequest":false,"CreatedAt":"2020-01-22T23:56:22","Actor":"nsingal","Number":"4693","RawContent":null,"Title":"SelectFeaturesBasedOn* Transformers are not outputing vectors of known size.","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n**Code that failed:**\r\n\r\nContext.Transforms.Text.TokenizeIntoWords(\"TextFeature\")                                   .Append(Context.Transforms.FeatureSelection.SelectFeaturesBasedOnCount(\"TextFeature\", \"TextFeature\", 10)).\r\nAppend(Context.Transforms.FeatureSelection.SelectFeaturesBasedOnMutualInformation(\"TextFeature\", \"TextFeature\", \"Label\", 5000))\r\n.Append(Context.Transforms.NormalizeLpNorm(\"TextFeature\", \"TextFeature\", Microsoft.ML.Transforms.LpNormNormalizingEstimatorBase.NormFunction.L2, true));\r\n\r\n**Error:**\r\nAt NormalizeLpNorm, it fails with\r\nSchema mismatch for input column 'TextFeature': expected Expected Single or known-size vector of Single, got VarVector<Single>\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4693","RelatedDescription":"Open issue \"SelectFeaturesBasedOn* Transformers are not outputing vectors of known size.\" (#4693)"},{"Id":"553703564","IsPullRequest":false,"CreatedAt":"2020-01-22T18:00:54","Actor":"lefig","Number":"4692","RawContent":null,"Title":"AutoML: Binary classification - AUC is not defined","State":"open","Body":"\r\nHi,\r\n\r\nI am struggling with this baffling exception. My data label is binary and I have 1,0 in the csv. I am sure that I have enough data and the splitter is able training and testing data to include positive values.\r\n\r\nIs there anything that I can try?\r\n\r\nThanks\r\n\r\n\r\n=============== Running AutoML experiment ===============\r\n#########################################################\r\nRunning AutoML bin classification experiment...\r\nPress any key to stop the experiment run...\r\n|     Trainer                              Accuracy      AUC    AUPRC  F1-score  Duration                        |\r\nException during AutoML iteration: System.ArgumentOutOfRangeException: AUC is not defined when there is no positive class in the data\r\nParameter name: PosSample\r\n   at Microsoft.ML.Data.EvaluatorBase`1.AucAggregatorBase`1.ComputeWeightedAuc(Double& unweighted)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Aggregator.Finish()\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.<>c__DisplayClass32_0.<GetAggregatorConsolidationFuncs>b__0(UInt32 stratColKey, ReadOnlyMemory`1 stratColVal, Aggregator agg)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.ProcessData(IDataView data, RoleMappedSchema schema, Func`2 activeColsIndices, TAgg aggregator, AggregatorDictionaryBase[] dictionaries)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.BinaryClassifierEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.AutoML.BinaryMetricsAgent.EvaluateMetrics(IDataView data, String labelColumn)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)","Url":"https://github.com/dotnet/machinelearning/issues/4692","RelatedDescription":"Open issue \"AutoML: Binary classification - AUC is not defined\" (#4692)"},{"Id":"553472855","IsPullRequest":true,"CreatedAt":"2020-01-22T11:15:28","Actor":"mstfbl","Number":"4691","RawContent":null,"Title":"Fixes cases of invalid image folder path and input column name","State":"open","Body":"Fixes #4429 \r\n\r\nInput column names and image folders can no longer be empty or null.","Url":"https://github.com/dotnet/machinelearning/pull/4691","RelatedDescription":"Open PR \"Fixes cases of invalid image folder path and input column name\" (#4691)"},{"Id":"553425752","IsPullRequest":true,"CreatedAt":"2020-01-22T09:52:02","Actor":"yaeldekel","Number":"4690","RawContent":null,"Title":"Make SVM Light loader create the correct schema in case of indices greater than int.MaxValue","State":"open","Body":"Fixes #4689 .","Url":"https://github.com/dotnet/machinelearning/pull/4690","RelatedDescription":"Open PR \"Make SVM Light loader create the correct schema in case of indices greater than int.MaxValue\" (#4690)"},{"Id":"553416639","IsPullRequest":false,"CreatedAt":"2020-01-22T09:35:16","Actor":"yaeldekel","Number":"4689","RawContent":null,"Title":"SVM Light loader bug","State":"open","Body":"When SVM Light loader encounters a feature index greater than `int.MaxValue` it ignores the value with this index, but it creates a schema where the length of the Features column is `int.MaxValue`. However, if the file is saved with the SVM Light saver, and then loaded again with SVM Light loader, the feature with that index will not be there, so the new loader will have a different length for the Features column. \r\nSaving and reloading should give the same data and the same schema, so SVM Light loader should not assign `int.MaxValue` as the length of the Features column, but instead it should assign the maximum valid index in the file.","Url":"https://github.com/dotnet/machinelearning/issues/4689","RelatedDescription":"Open issue \"SVM Light loader bug\" (#4689)"},{"Id":"553348546","IsPullRequest":true,"CreatedAt":"2020-01-22T07:01:34","Actor":"frank-dong-ms","Number":"4688","RawContent":null,"Title":"separate build pipelines","State":"open","Body":"1. new outer loop pipeline that runs all tests\r\n2. remove flaky tests from CI\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4688","RelatedDescription":"Open PR \"separate build pipelines\" (#4688)"},{"Id":"553103631","IsPullRequest":true,"CreatedAt":"2020-01-22T06:57:46","Actor":"frank-dong-ms","Number":"4683","RawContent":null,"Title":"retry more times on tensorflow test","State":"closed","Body":"retry more times on tensorflow tests\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4683","RelatedDescription":"Closed or merged PR \"retry more times on tensorflow test\" (#4683)"},{"Id":"553345588","IsPullRequest":true,"CreatedAt":"2020-01-22T06:53:20","Actor":"harishsk","Number":"4687","RawContent":null,"Title":"Updated langversion to 8.0","State":"open","Body":"Fixes #3786\r\n\r\nWe cannot use 7.3 because Utilities\\ThreadUtils.cs uses static local functions which is available only in 8.0. I also had to set the langVersion to 4.7 for the F# project.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4687","RelatedDescription":"Open PR \"Updated langversion to 8.0\" (#4687)"},{"Id":"553229574","IsPullRequest":false,"CreatedAt":"2020-01-22T00:15:34","Actor":"frank-dong-ms","Number":"4686","RawContent":null,"Title":"upload procdump to Tools repro","State":"open","Body":"Upload procdump.exe tool to Tools repro","Url":"https://github.com/dotnet/machinelearning/issues/4686","RelatedDescription":"Open issue \"upload procdump to Tools repro\" (#4686)"},{"Id":"553212201","IsPullRequest":true,"CreatedAt":"2020-01-21T23:34:42","Actor":"deanna-cs","Number":"4685","RawContent":null,"Title":"Fix typos in README.md","State":"open","Body":"Copy edited the following:\r\n\r\n- Added serial commas \r\n- Added comma after introductory phrase \"for example\"\r\n- Fix typo: in this separated page > in this separate page\r\n- Fix typo and sentence structure under \"ML.NET videos playlist at YouTube\" section\r\n- Fix wording: or alternatively > alternatively \r\n\r\n<hr>\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4685","RelatedDescription":"Open PR \"Fix typos in README.md\" (#4685)"},{"Id":"553078711","IsPullRequest":true,"CreatedAt":"2020-01-21T19:24:37","Actor":"LittleLittleCloud","Number":"4682","RawContent":null,"Title":"update Assembly Key in AutoML and CodeGen","State":"open","Body":"Since mlnet and mlnet.test are already moved into modelbuilder's repo, update assembly key in AutoML and CodeGenerator project to allow mlnet to visit internal classes from those two projects\r\n\r\nRelated Issue:\r\n[Update mlnet and mlnet.test assembly key to match modelbuilder's](https://github.com/dotnet/machinelearning-modelbuilder/issues/453)","Url":"https://github.com/dotnet/machinelearning/pull/4682","RelatedDescription":"Open PR \"update Assembly Key in AutoML and CodeGen\" (#4682)"},{"Id":"552717639","IsPullRequest":false,"CreatedAt":"2020-01-21T09:11:54","Actor":"rauhs","Number":"4681","RawContent":null,"Title":"LightGBM trainer filters out rows with NaN features","State":"open","Body":"LightGBM (binary trainer) will filter out NaN (feature)-values even though we have the option of `HandleMissingValue` which allows LightGBM to properly deal with missing values:\r\n\r\nhttps://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7a4372e1dda8f5d5c070ffce6bd1929216939d90/src/Microsoft.ML.LightGbm/LightGbmTrainerBase.cs#L178\r\n\r\nI think this:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7a4372e1dda8f5d5c070ffce6bd1929216939d90/src/Microsoft.ML.LightGbm/LightGbmTrainerBase.cs#L439\r\n\r\n\r\nshould also specify the flag \"AllFeatures\" so they're allowed through.","Url":"https://github.com/dotnet/machinelearning/issues/4681","RelatedDescription":"Open issue \"LightGBM trainer filters out rows with NaN features\" (#4681)"}],"ResultType":"GitHubIssue"}},"RunOn":"2020-01-26T05:30:38.6221606Z","RunDurationInMilliseconds":879}