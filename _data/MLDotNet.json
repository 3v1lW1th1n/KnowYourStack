{"Data":{"GitHub":{"Issues":[{"Id":"591555128","IsPullRequest":true,"CreatedAt":"2020-04-01T01:43:33","Actor":"frank-dong-ms","Number":"4991","RawContent":null,"Title":"test tensorflow test hanging","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4991","RelatedDescription":"Open PR \"test tensorflow test hanging\" (#4991)"},{"Id":"591498284","IsPullRequest":true,"CreatedAt":"2020-03-31T23:14:23","Actor":"frank-dong-ms","Number":"4990","RawContent":null,"Title":"trouble shoot ssaforecast","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4990","RelatedDescription":"Open PR \"trouble shoot ssaforecast\" (#4990)"},{"Id":"591454369","IsPullRequest":true,"CreatedAt":"2020-03-31T21:50:03","Actor":"harishsk","Number":"4989","RawContent":null,"Title":"Added the assembly name of the custom transform to the model file","State":"open","Body":"Fixes #4965 \r\nRight now when a custom transformer is used, the model file retains the name of the transformer as a string. This is not enough information to re-instantiate the custom transformer when the model is loaded from file. If the assembly containing the custom transformer is not already registered with the component catalog, then the model will fail to load. \r\nTo fix this, I have incremented the model version and am now saving the assembly name of the transform with the model. \r\n","Url":"https://github.com/dotnet/machinelearning/pull/4989","RelatedDescription":"Open PR \"Added the assembly name of the custom transform to the model file\" (#4989)"},{"Id":"591359897","IsPullRequest":true,"CreatedAt":"2020-03-31T21:20:27","Actor":"frank-dong-ms","Number":"4988","RawContent":null,"Title":"enable and disable tests","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4988","RelatedDescription":"Closed or merged PR \"enable and disable tests\" (#4988)"},{"Id":"591301510","IsPullRequest":false,"CreatedAt":"2020-03-31T17:52:05","Actor":"luisquintanilla","Number":"4987","RawContent":null,"Title":"Caching discrepancy between API docs and TrainerInfo.WantCaching property","State":"open","Body":"There are discrepancies in the docs for trainers on whether caching is required or not.\r\n\r\nFor example: [MatrixFactorizationTrainer](https://github.com/dotnet/machinelearning/blob/fbd1b93065b451401b1e3276e5ac65b9f303f90b/src/Microsoft.ML.Recommender/MatrixFactorizationTrainer.cs)\r\n\r\nIn the documentation, it says caching is required:\r\n\r\n| Is caching required? | Yes |\r\n\r\nHowever, the `TrainerInfo.WantCaching` property is set to false.\r\n\r\n```csharp\r\n_info = new TrainerInfo(normalization: false, caching: false);\r\n```\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/fbd1b93065b451401b1e3276e5ac65b9f303f90b/src/Microsoft.ML.Recommender/MatrixFactorizationTrainer.cs#L370\r\n\r\nTo-Do:\r\n\r\n- [ ] Get list of trainers these discrepancies occur.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4987","RelatedDescription":"Open issue \"Caching discrepancy between API docs and TrainerInfo.WantCaching property\" (#4987)"},{"Id":"590777775","IsPullRequest":true,"CreatedAt":"2020-03-31T16:58:55","Actor":"frank-dong-ms","Number":"4985","RawContent":null,"Title":"fix benchmark test hanging issue","State":"closed","Body":"benchmark test is hanging sometime on dotnet core 3.0 and 3.1 like below:\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=568308&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&t=42ea9add-ee54-581f-d033-310ec15a7ff0\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=565081&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&t=42ea9add-ee54-581f-d033-310ec15a7ff0\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=563397&view=logs&j=11c3dbcc-a5f4-5edd-335b-a8af5aa47d46&t=42ea9add-ee54-581f-d033-310ec15a7ff0\r\n\r\n\r\nthe reason of hanging is explained in comments like below:\r\n        // Don't use BaseTestClass's GetDataPath method instead for benchmark.\r\n        // BaseTestClass's static constructor is not guaranteed to be called before\r\n        // benchmark running (depending on CLR version this has different behaviour).\r\n        // The problem with executing BaseTestClass's static constructor when benchmark\r\n        // is running is it sometime cause process hanging when the constructor trying \r\n        // to load MKL, this is related to below issue:\r\n        // https://github.com/dotnet/machinelearning/issues/1073\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4985","RelatedDescription":"Closed or merged PR \"fix benchmark test hanging issue\" (#4985)"},{"Id":"590683567","IsPullRequest":true,"CreatedAt":"2020-03-31T16:36:08","Actor":"gvashishtha","Number":"4984","RawContent":null,"Title":"Remove March survey link","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4984","RelatedDescription":"Closed or merged PR \"Remove March survey link\" (#4984)"},{"Id":"590920427","IsPullRequest":false,"CreatedAt":"2020-03-31T08:53:19","Actor":"Balu2","Number":"4986","RawContent":null,"Title":"Retrain same data results in different accuracy","State":"open","Body":"### System information\r\n\r\n- Windows 10\r\n- .NET Core 3.1\r\n\r\n### Issue: When I retrain the data with the ML.Net Model Builder with the same data and training parameters, there is a difference in Micro- and Macro-Accuracy.\r\n\r\n- **What did you do?\r\nUsing the Model Builder to train a data set\r\n\r\n- **What happened?**\r\nWhen I retrain the same data (by pressing the Start training button again) with the same label, features and training time, I see a difference in accuracy. Is there a reason why this is?\r\n\r\n- **What did you expect?**\r\nI expected more or less the same accuracy because all data and parameters are identical.\r\n\r\n### Source code / logs\r\n\r\n**First training:**\r\n\r\n|                                              Top 5 models explored                                             |\r\n------------------------------------------------------------------------------------------------------------------\r\n|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n|1    FastTreeOva                                 0.8575         0.7943      23.3          1                     |\r\n|2    LightGbmMulti                               0.8568         0.8002       3.8          2                     |\r\n|3    FastTreeOva                                 0.8538         0.7843      27.0          3                     |\r\n|4    FastForestOva                               0.8513         0.7889      26.5          4                     |\r\n|5    LightGbmMulti                               0.8511         0.7808       6.4          5                     |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\n\r\n\r\n**Second training**\r\n\r\n|                                              Top 5 models explored                                             |\r\n------------------------------------------------------------------------------------------------------------------\r\n|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n|1    FastTreeOva                                 0.9016         0.7241      44.8          1                     |\r\n|2    FastForestOva                               0.8847         0.6465      42.9          2                     |\r\n|3    AveragedPerceptronOva                       0.8575         0.6175      13.3          3                     |\r\n|4    SymbolicSgdLogisticRegressionOva            0.8387         0.4301       7.1          4                     |\r\n|5    SdcaMaximumEntropyMulti                     0.8331         0.3212       5.1          5                     |\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4986","RelatedDescription":"Open issue \"Retrain same data results in different accuracy\" (#4986)"},{"Id":"589039256","IsPullRequest":false,"CreatedAt":"2020-03-31T04:26:03","Actor":"lionelquirynen","Number":"4977","RawContent":null,"Title":"Schema mismatch for feature column 'Features': expected Vector<Single>, got VarVector<Single> '","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1 \r\n\r\n### Issue\r\n\r\n- **What did you do?** : Train a model from a json File\r\n- **What happened?** Schema mismatch for feature column 'Features': expected Vector<Single>, got VarVector<Single> '\r\n\r\n### Source code / logs\r\nHere is the code to train the model : \r\n` private static ITransformer trainWithJson(MLContext mlContext)\r\n        {\r\n            using (StreamReader r = new StreamReader(\"datasetCrewCleaned.json\"))\r\n            {\r\n                string json = r.ReadToEnd();\r\n                List<FilmModel> items = JsonConvert.DeserializeObject<List<FilmModel>>(json);\r\n                List<FilmModel> itemsTrain = new List<FilmModel>();\r\n                for (int i = 0; i < items.Count; i++)\r\n                {\r\n                    if (i > 24000)\r\n                    {\r\n                        break;\r\n                    }\r\n                    itemsTrain.Add(items[i]);\r\n                }\r\n                var data = mlContext.Data.LoadFromEnumerable(itemsTrain);\r\n                var pipeline = mlContext.Transforms.CopyColumns(outputColumnName: \"Label\",    inputColumnName: nameof(FilmModel.BoxOffice))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName:   \"NameEncoded\", inputColumnName: nameof(FilmModel.Name)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"DurationEncoded\", inputColumnName: nameof(FilmModel.Duration)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"ClassificationEncoded\", inputColumnName: nameof(FilmModel.Classification)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"GenreEncoded\", inputColumnName: nameof(FilmModel.Genre)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"StudioEncoded\", inputColumnName: nameof(FilmModel.Studio)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"BudgetEncoded\", inputColumnName: nameof(FilmModel.Budget)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"ReleaseDateEncoded\", inputColumnName: nameof(FilmModel.ReleaseDate)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"CrewEncoded\", inputColumnName: nameof(FilmModel.Crew)))\r\n               .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"ActorsEncoded\", inputColumnName: nameof(FilmModel.Actors)))\r\n               .Append(mlContext.Transforms.Concatenate(\"Features\", \"NameEncoded\", \"ClassificationEncoded\", \"DurationEncoded\", \"GenreEncoded\", \"StudioEncoded\", \"BudgetEncoded\", \"ReleaseDateEncoded\", \"CrewEncoded\", \"ActorsEncoded\"))\r\n          .Append(mlContext.Regression.Trainers.LbfgsPoissonRegression());\r\n                var model = pipeline.Fit(data);\r\n                return model;\r\n            }\r\n        }`\r\n\r\nAnd here is the class I'm using to deSerialize the Json File:\r\n\r\n` public class FilmModel\r\n    {\r\n        public FilmModel(float boxOffice, string[] crew, string[] actors, string releaseDate = null, string  name = null, string classification = null, string duration = null, string genre = null, string studio =  null, string budget = null)\r\n          {\r\n            Name = name;\r\n            Classification = classification;\r\n            Duration = duration;\r\n            Genre = genre;\r\n            Studio = studio;\r\n            Budget = budget;\r\n            BoxOffice = boxOffice;\r\n            ReleaseDate = releaseDate;\r\n            Crew = crew;\r\n            Actors = actors;\r\n         }\r\n         public string Name { get; set; }\r\n         public string Classification { get; set; }\r\n         public string Duration { get; set; }\r\n         public string Genre { get; set; }\r\n         public string Studio { get; set; }\r\n         public string Budget { get; set; }\r\n         public float BoxOffice { get; set; }\r\n         public string ReleaseDate { get; set; }\r\n         public string[] Actors { get; set; }\r\n         public string[] Crew { get; set; }\r\n    }`\r\n\r\nThe [] Actors and Crew do not have the same length for each row. For instance a movie could have 4 crew members and another 8. I think that's the problem but I do not know how to fix this.","Url":"https://github.com/dotnet/machinelearning/issues/4977","RelatedDescription":"Closed issue \"Schema mismatch for feature column 'Features': expected Vector<Single>, got VarVector<Single> '\" (#4977)"},{"Id":"589503938","IsPullRequest":true,"CreatedAt":"2020-03-31T04:20:54","Actor":"frank-dong-ms","Number":"4979","RawContent":null,"Title":"try fix benchmark hanging","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4979","RelatedDescription":"Closed or merged PR \"try fix benchmark hanging\" (#4979)"},{"Id":"587899751","IsPullRequest":true,"CreatedAt":"2020-03-31T03:27:09","Actor":"LittleLittleCloud","Number":"4972","RawContent":null,"Title":"Simplify CodeGen - phase 2","State":"closed","Body":"This PR includes the following updates in CodeGen\r\n- switch train and evaluate order in ModelBuilder.cs. linked issue: [Train and Evaluate order](https://github.com/dotnet/machinelearning-modelbuilder/issues/421)\r\n- filter out ignored cols in programs.cs when printing column value to console. linked issue: [Filter out columns that in ignore-col in console output](https://github.com/dotnet/machinelearning-modelbuilder/issues/580)","Url":"https://github.com/dotnet/machinelearning/pull/4972","RelatedDescription":"Closed or merged PR \"Simplify CodeGen - phase 2\" (#4972)"},{"Id":"590674449","IsPullRequest":true,"CreatedAt":"2020-03-30T23:47:03","Actor":"gvashishtha","Number":"4983","RawContent":null,"Title":"Remove survey link, clean up README","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4983","RelatedDescription":"Closed or merged PR \"Remove survey link, clean up README\" (#4983)"},{"Id":"590581883","IsPullRequest":false,"CreatedAt":"2020-03-30T20:42:12","Actor":"luisquintanilla","Number":"4982","RawContent":null,"Title":"TextLoader Load From Multiple Files Inconsistent Behavior","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1\r\n- **ML.NET Version (eg., dotnet --info)**: 1.5.0-preview2\r\n\r\n### Issue\r\n\r\nWhen loading data that is in multiple files, whether the data is in a single folder or multiple folders, the behavior in inconsistent. When the data is in a single folder, wildcards can be used. That, however is not the case when the data is in separate folders/subfolders.\r\n\r\nThe non-working examples don't work for various reasons. However, in general, the behavior appears inconsistent depending on the structure of the folder.\r\n\r\n### Source code / logs\r\nData Folder Structure:\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/77959332-6735bf00-72a4-11ea-9657-618e6fd1e44c.png)\r\n\r\nData Sample:\r\n\r\n```text\r\nSize (Sq. ft.), HistoricalPrice1 ($), HistoricalPrice2 ($), HistoricalPrice3 ($), Current Price ($)\r\n700, 100000, 3000000, 250000, 500000\r\n```\r\n\r\nSource code:\r\n\r\n```csharp\r\nclass Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            MLContext ctx = new MLContext();\r\n\r\n            TextLoader textLoader = ctx.Data.CreateTextLoader<HousingData>(separatorChar: ',', hasHeader: true);\r\n\r\n            IDataView dvSingleFolder = textLoader.Load(\"Data/*\");\r\n            IDataView dvMultipleFoldersNotWorking = textLoader.Load(\"DataFolder/*/*\");\r\n            IDataView dvMultipleFoldersNotWorking2 = textLoader.Load(\"DataFolder/SubFolder1/*\", \"DataFolder/SubFolder2/*\");\r\n            IDataView dvMultileFoldersWorking = textLoader.Load(\"DataFolder/SubFolder1/1.csv\", \"DataFolder/SubFolder2/2.csv\");\r\n\r\n            var singleFolderPreview = dvSingleFolder.Preview();\r\n            var multipleFolderPreview = dvMultipleFoldersNotWorking.Preview();\r\n            var multipleFolderPreview2 = dvMultipleFoldersNotWorking2.Preview();\r\n            var multipleFoldersWorkingPreview = dvMultileFoldersWorking.Preview();\r\n        }\r\n    }\r\n\r\npublic class HousingData\r\n    {\r\n        [LoadColumn(0)]\r\n        public float Size { get; set; }\r\n\r\n        [LoadColumn(1, 3)]\r\n        [VectorType(3)]\r\n        public float[] HistoricalPrices { get; set; }\r\n\r\n        [LoadColumn(4)]\r\n        [ColumnName(\"Label\")]\r\n        public float CurrentPrice { get; set; }\r\n    }\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4982","RelatedDescription":"Open issue \"TextLoader Load From Multiple Files Inconsistent Behavior\" (#4982)"},{"Id":"590143327","IsPullRequest":false,"CreatedAt":"2020-03-30T09:39:32","Actor":"strikene","Number":"4981","RawContent":null,"Title":"PredictionEnginePool.GetPredictionEngine is not thread safe","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:Windows 10 Server 2019 \r\n- **.NET Version (eg., dotnet --info)**: core 3.0 \r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nInvoked PredictionEnginePool.Predict(\"MyModelName\", example) from multiple threads.\r\n- **What happened?**\r\nCollection was modified; enumeration operation may not execute. \r\n- **What did you expect?**\r\nMethod is thread safe \r\n### Source code / logs\r\n\r\nPackage\r\nMicrosoft.Azure.Functions.Extensions Version=\"1.0.0\"\r\nMicrosoft.Extensions.MLVersion=\"1.5.0-preview2\" or 1.40\r\nMicrosoft.ML Version=\"1.5.0-preview2\" or 1.40\r\nMicrosoft.NET.Sdk.Functions Version=\"3.0.3\"\r\n\r\n\r\nin startup \r\n\r\n builder.Services.AddPredictionEnginePool<Input, PredictedEngineOutput>().FromFile(\"ModelName\", \"ModelPath\", true);\r\n\r\nin function \r\n             var re = _PredictionEnginePool.Predict(\"ModelName\", new Input() {String = str });\r\n\r\nException\r\n\r\n```\r\n   at System.Collections.Generic.List`1.Enumerator.MoveNextRare()\r\n   at System.Linq.Enumerable.Any[TSource](IEnumerable`1 source, Func`2 predicate)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolPolicy`2.Return(PredictionEngine`2 obj)\r\n   at Microsoft.Extensions.ObjectPool.DefaultObjectPool`1.Return(T obj)\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2.ReturnPredictionEngine(String modelName, PredictionEngine`2 engine)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolExtensions.Predict[TData,TPrediction](PredictionEnginePool`2 predictionEnginePool, String modelName, TData example)\r\n   at BLDM_F.F.Predict(HttpRequest req, ILogger log) in C:\\tfs\\BLDM_F\\Function1.cs:line 148\r\n```\r\n\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4981","RelatedDescription":"Open issue \"PredictionEnginePool.GetPredictionEngine is not thread safe\" (#4981)"},{"Id":"589549115","IsPullRequest":false,"CreatedAt":"2020-03-28T10:21:54","Actor":"asif48","Number":"4980","RawContent":null,"Title":"How to Add Date column in the Input Class","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  VS 2019\r\n\r\n### Issue\r\n\r\n- **What did you do?** I tried to modify the TaxiFairExample ; Just copied the  code and include few fields \r\n1) Date \r\n2) Punctured \r\nto predict whether the taxi would likely to punctured in the coming date.\r\n\r\n- **What happened?**\r\nWhen I included Date column in the class and try to debug the code ; following errors rises\r\n\r\nSystem.ArgumentOutOfRangeException: 'Could not determine an IDataView type for member Date\r\nParameter name: rawType'\r\n\r\n![IDataView type for member Date](https://user-images.githubusercontent.com/7997380/77820851-31a79f00-7107-11ea-87d1-e6576edc073e.png)\r\n\r\n- **What did you expect?**\r\nI just expect to predict whether the Taxi is likely to puncture or not in the given date \r\n### Source code / logs\r\n\r\n```\r\n public class ItemStock\r\n    {\r\n        [Column(\"0\")]\r\n        public string CarID;\r\n\r\n        [Column(\"1\")]\r\n        public float LocID;\r\n\r\n        [Column(\"2\")]\r\n        public DateTime Date;\r\n\r\n        [Column(\"3\")]\r\n        public float Punctured;\r\n    }\r\n\r\n    public class itemStockQtyPrediction\r\n    {\r\n        [ColumnName(\"Score\")]\r\n        public float Punctured;\r\n    }\r\n```\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4980","RelatedDescription":"Open issue \"How to Add Date column in the Input Class\" (#4980)"},{"Id":"589427250","IsPullRequest":true,"CreatedAt":"2020-03-27T21:41:24","Actor":"mstfbl","Number":"4978","RawContent":null,"Title":"Fixed & Reactivated AutoFitImageClassificationTrainTest hanging by freeing old Tensor objects","State":"open","Body":"`AutoFitImageClassificationTrainTest` is occasionally hanging, even after PR #4939 . The issue here is that Tensor objects saved in `ITransformer model` (now renamed as 'estimatorModel`) are not being automatically freed by C#'s Garbage Collector, as these Tensor objects are made in TensorFlow's C libraries. \r\n\r\nThis PR frees these Tensor objects as part of a `finally` statement following the `try` and `catch` statements, so that in both cases where the estimator is trained with or without a thrown exception, Tensor objects are being cleaned up. I also changed its name to `estimatorModel` to avoid confusion with the declared return variable `ModelContainer model`, and I think it does a better job of explaining the model that is returned by a estimator.Fit() call.\r\n\r\nI confirmed that this fixes the hanging \"out of memory\" and/or \"long running test\" issues by running `AutoFitImageClassificationTrainTest` for 100 iterations, in addition to running all the other unit tests in [this build](https://dev.azure.com/dnceng/public/_build/results?buildId=576838&view=results). In all of these builds, none of the issues described occur. These builds all time-out because running 100 iterations of `AutoFitImageClassificationTrainTest` takes more than 1 hour.\r\n\r\nI have also reactivated the `AutoFitImageClassificationTrainTest` unit test with this fix.","Url":"https://github.com/dotnet/machinelearning/pull/4978","RelatedDescription":"Open PR \"Fixed & Reactivated AutoFitImageClassificationTrainTest hanging by freeing old Tensor objects\" (#4978)"},{"Id":"588685807","IsPullRequest":true,"CreatedAt":"2020-03-27T01:36:42","Actor":"mstfbl","Number":"4976","RawContent":null,"Title":"Updated constructor of ImageLoadingTransformer to accept empty imageFolder paths","State":"closed","Body":"In certain ML.NET/ONNX samples, the provided path for the directory containing images for loading may be empty, and output the following exception:\r\n\r\n> System.ArgumentException: Directory \"\" does not exist.\r\n\r\nThis PR is so that the provided imageFolder path that is provided to the constructor of `ImageLoadingTransformer` may be null **or empty**.","Url":"https://github.com/dotnet/machinelearning/pull/4976","RelatedDescription":"Closed or merged PR \"Updated constructor of ImageLoadingTransformer to accept empty imageFolder paths\" (#4976)"},{"Id":"588019759","IsPullRequest":true,"CreatedAt":"2020-03-26T17:42:38","Actor":"mstfbl","Number":"4973","RawContent":null,"Title":"Disabled AutoFitImageClassificationTrainTest for test stability","State":"closed","Body":"Disabled `AutoFitImageClassificationTrainTest `from runs on CI, as it continues to hang on builds.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4973","RelatedDescription":"Closed or merged PR \"Disabled AutoFitImageClassificationTrainTest for test stability\" (#4973)"},{"Id":"588302413","IsPullRequest":false,"CreatedAt":"2020-03-26T10:12:14","Actor":"fourfruit","Number":"4975","RawContent":null,"Title":"How to generate faster_RCNN_Inception_V2 model in ML.NET?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows \r\n- **.NET Version (eg., dotnet --info)**:  .net core 2.1\r\n\r\n### Issue\r\n\r\n- Use faster_RCNN_Inception_V2 model  doing object detection \r\n-  There is no document about this model  with ML.NET\r\n- How to apply faster_RCNN_Inception_V2 model in ML.NET?\r\nThanks\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4975","RelatedDescription":"Open issue \"How to generate faster_RCNN_Inception_V2 model in ML.NET?\" (#4975)"},{"Id":"588055996","IsPullRequest":true,"CreatedAt":"2020-03-26T01:40:53","Actor":"Lynx1820","Number":"4974","RawContent":null,"Title":"Fixes OneHotEncoding Issue","State":"closed","Body":"OneHotEncoding always increases the dimension by one, which is causing issues with Nimbus.\r\nSee: https://github.com/microsoft/NimbusML/issues/472\r\n\r\n- Added shape info to make models more easy to read\r\n- Replaced ReduceSum with Squeeze (makes more sense imo)\r\n- Isolated KeyToVector test to verify several outputKind modes - Skipping OneHotEncodingEstimator.OutputKind.Binary for now, since this mode is not working and it'll require implementation of KeyToBinaryVector ","Url":"https://github.com/dotnet/machinelearning/pull/4974","RelatedDescription":"Closed or merged PR \"Fixes OneHotEncoding Issue\" (#4974)"},{"Id":"587180719","IsPullRequest":true,"CreatedAt":"2020-03-25T23:09:21","Actor":"antoniovs1029","Number":"4966","RawContent":null,"Title":"Updated OnnxScoringEstimator's documentation","State":"closed","Body":"PR #4919 changed the way users should work with the Onnxruntime's nugets, now they should include either Onnxruntime or Onnxruntime.Gpu nuget along the OnnxTransformer one.\r\n\r\nI also updated a couple of other things that weren't right anymore.\r\n\r\nPlease, let me know it I should update the docs anywhere else.\r\n\r\nFixes #4872 ","Url":"https://github.com/dotnet/machinelearning/pull/4966","RelatedDescription":"Closed or merged PR \"Updated OnnxScoringEstimator's documentation\" (#4966)"},{"Id":"587321198","IsPullRequest":true,"CreatedAt":"2020-03-25T17:51:37","Actor":"frank-dong-ms","Number":"4968","RawContent":null,"Title":"upgrade benchmark dotnet package to latest version","State":"closed","Body":"As we have upgrade CI run from netcore 3.0 to netcore 3.1, we need also to upgrade benchmark dotnet to latest version which has netcore 3.1 support\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4968","RelatedDescription":"Closed or merged PR \"upgrade benchmark dotnet package to latest version\" (#4968)"},{"Id":"587689159","IsPullRequest":true,"CreatedAt":"2020-03-25T13:17:19","Actor":"antoniovs1029","Number":"4971","RawContent":null,"Title":"[WIP] Avoid propagating input columns when applying Onnx models","State":"open","Body":"The goal of this PR is to:\r\n1. Fix #4970 regarding `ColumnSelectingTransformer` onnx exported models not working as expected when applying it with ML.NET\r\n2. Avoid propagating the input columns through an `OnnxTransformer`. This is a new requirement that was discussed offline with @harishsk . The idea is that the output schema of the onnxtransformer should contain `only` a column for each output of the onnx model. Until now, since OnnxTransformer is a `RowToRowTransformer`, the input schema was propagated to the output.\r\n\r\nFixing point number 2 would actually fix point number 1, given the way that the onnx export works today for `ColumnSelectingTransformer `(where the dropped columns are removed from the onnx model output inside the onnx graph).\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4971","RelatedDescription":"Open PR \"[WIP] Avoid propagating input columns when applying Onnx models\" (#4971)"},{"Id":"587681463","IsPullRequest":false,"CreatedAt":"2020-03-25T13:04:12","Actor":"antoniovs1029","Number":"4970","RawContent":null,"Title":"ColumnSelectingTransformer exported onnx model doesn't work as expected","State":"open","Body":"The `ColumnSelectingTransformer` has the ability to drop columns that aren't desired by the user. The Onnx exported model eliminates those columns from the Onnx model graph output, but this isn't enough to remove them from the output `Schema`, so even if they're removed from the onnx model, those columns are still there in the output after using the `ApplyOnnxModel` method. The reason for this is that the `OnnxTransformer` (which is used by the `ApplyOnnxModel` method) is a `RowToRowTransformer`, and such transformers don't have the capacity to drop columns, only to add them to the input DataView.\r\n\r\n### Code\r\nThe existing test for ColumnSelectingTransformer can be used to notice this issue\r\nhttps://github.com/dotnet/machinelearning/blob/22c7ac8921fa0846717662181b334de3b41e9932/test/Microsoft.ML.Tests/OnnxConversionTest.cs#L1707-L1765\r\n\r\nBy setting a breakpoint, and inspecting into the schema of the outputs, I get the following result:\r\n![image](https://user-images.githubusercontent.com/38739674/77539211-385fb900-6e5e-11ea-9bd2-a276697bf264.png)\r\n\r\nIt shows that the undesired columns were correctly dropped by the `ColumnSelectingTransformer`, but not by the `OnnxModel`. This test should also include comparing both schemas, to make sure that the onnxmodel is actually dropping the undesired columns.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4970","RelatedDescription":"Open issue \"ColumnSelectingTransformer exported onnx model doesn't work as expected\" (#4970)"},{"Id":"587342172","IsPullRequest":true,"CreatedAt":"2020-03-25T00:51:41","Actor":"mstfbl","Number":"4969","RawContent":null,"Title":"Skip hanging TensorFlowImageClassificationEarlyStopping on Linux","State":"closed","Body":"The unit test `TensorFlowImageClassificationEarlyStopping`occasionally hangs on Linux builds. This PR is so that `TensorFlowImageClassificationEarlyStopping` is skipped on these builds.","Url":"https://github.com/dotnet/machinelearning/pull/4969","RelatedDescription":"Closed or merged PR \"Skip hanging TensorFlowImageClassificationEarlyStopping on Linux\" (#4969)"},{"Id":"587228816","IsPullRequest":true,"CreatedAt":"2020-03-24T23:10:21","Actor":"mstfbl","Number":"4967","RawContent":null,"Title":"Updated build docs for .NET Core 3.1","State":"closed","Body":"Updated Windows and Unix build docs for .NET Core 3.1.\r\n\r\nSome specific things to note:\r\n\r\n- In addition to other platforms, .NET Core 3.1 supports Ubuntu **16.04**+ and macOS 10.13 (High Sierra)\r\n- Visual Studio 2019 Version **16.4 or higher** is needed for .NET Core 3.1.\r\n- /src files always build on both `netstandard2.0 `and `netcoreapp3.1`, and /tests only build on one target framework at a time: `netcoreapp2.1`, `net461 `or `netcoreapp3.1`","Url":"https://github.com/dotnet/machinelearning/pull/4967","RelatedDescription":"Closed or merged PR \"Updated build docs for .NET Core 3.1\" (#4967)"},{"Id":"586583823","IsPullRequest":true,"CreatedAt":"2020-03-24T19:44:57","Actor":"Lynx1820","Number":"4963","RawContent":null,"Title":"Fixes multiclass logistic regression","State":"closed","Body":"Fixes dimension bug for MulticlassLogisticRegression and SdcaMaximumEntropy in Nimbus (https://github.com/microsoft/NimbusML/issues/473)\r\nUnsqueeze was adding dimension 0 to the label tensor - to get shape (1,#samples), instead of the expected shape (#samples, 1).","Url":"https://github.com/dotnet/machinelearning/pull/4963","RelatedDescription":"Closed or merged PR \"Fixes multiclass logistic regression\" (#4963)"},{"Id":"587172628","IsPullRequest":false,"CreatedAt":"2020-03-24T18:03:45","Actor":"luisquintanilla","Number":"4965","RawContent":null,"Title":"Unable to score using PredictionEnginePool with a pipeline/model that contains custom transforms","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\n\r\n`PredictionEngine` is not thread safe. Therefore, in multi-threaded environments, it is *highly* recommended to use `PredictionEnginePool`.\r\n\r\nWhen you want to save a pipeline that contains custom transforms, you have to provide a contract name. If you want to use the saved pipeline / model, using your `MLContext`, you have to register the custom transform using the `CompontentCatalog.RegisterAssembly` method. \r\n\r\nFor more details, see [documentation on using custom transforms](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#how-can-i-define-my-own-transformation-of-data).\r\n\r\n`PredictionEnginePool` does not provide access to `MLContext`, therefore it's not possible to register the custom transforms using `CompontentCatalog.RegisterAssembly`. Therefore, you can't safely deploy models using `PredictionEnginePool`. This affects ASP.NET Core Web Apps (API,MVC,Blazor,Razor Pages) and Azure Functions. \r\n\r\n### Source code / logs\r\n\r\nPipeline:\r\n\r\n```csharp\r\nvar pipeline = mlContext.Transforms.LoadImages(\"ImageSource_featurized\", null, \"ImageSource\")\r\n                          .Append(mlContext.Transforms.ResizeImages(\"ImageSource_featurized\", 224, 224, \"ImageSource_featurized\"))\r\n                          .Append(mlContext.Transforms.ExtractPixels(\"ImageSource_featurized\", \"ImageSource_featurized\"))\r\n                          .Append(mlContext.Transforms.CustomMapping<NormalizeInput, NormalizeOutput>(\r\n                              (input, output) => NormalizeMapping.Mapping(input, output),\r\n                              contractName: nameof(NormalizeMapping)))\r\n                          .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: ONNX_MODEL))\r\n                          .Append(mlContext.Transforms.CustomMapping<LabelMappingInput, LabelMappingOutput>(\r\n                              (input, output) => LabelMapping.Mapping(input, output),\r\n                              contractName: nameof(LabelMapping)));\r\n```\r\n\r\nCreating PredictionEngine:\r\n\r\n```csharp\r\n// Create new MLContext\r\nMLContext mlContext = new MLContext();\r\n\r\n// Register NormalizeMapping\r\nmlContext.ComponentCatalog.RegisterAssembly(typeof(NormalizeMapping).Assembly);\r\n\r\n// Register LabelMapping\r\nmlContext.ComponentCatalog.RegisterAssembly(typeof(LabelMapping).Assembly);\r\n\r\n// Load model & create prediction engine\r\nstring modelPath = @\"C:\\Users\\luquinta.REDMOND\\AppData\\Local\\Temp\\MLVSTools\\LandUseUWPML\\LandUseUWPML.Model\\MLModel.zip\";\r\nITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);\r\n```\r\n\r\nCreate PredictionEnginePool:\r\n\r\n```csharp\r\n//Registered using dependency injection\r\nservices.AddPredictionEnginePool<ModelInput, ModelOutput>()\r\n                .FromFile(\"MLModel.zip\");\r\n```\r\n\r\nStack Trace from ASP.NET Core Web API:\r\n\r\n```text\r\nSystem.InvalidOperationException: Error during class instantiation\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.InvalidOperationException: Error during class instantiation\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.InvalidOperationException: Unable to locate an extension for the contract 'NormalizeMapping'. Ensure you have called ComponentCatalog.RegisterAssembly with the Assembly that contains a class decorated with a 'Microsoft.ML.Transforms.CustomMappingFactoryAttributeAttribute'.\r\n   at Microsoft.ML.Runtime.ComponentCatalog.GetExtensionValue(IHostEnvironment env, Type attributeType, String contractName)\r\n   at Microsoft.ML.Transforms.LambdaTransform.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.TransformerChain`1..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Data.TransformerChain.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at Microsoft.Extensions.ML.FileModelLoader.LoadModel()\r\n   at Microsoft.Extensions.ML.FileModelLoader.Start(String filePath, Boolean watchFile)\r\n   at Microsoft.Extensions.ML.BuilderExtensions.<>c__DisplayClass9_0`2.<FromFile>b__0(PredictionEnginePoolOptions`2 options, FileModelLoader loader)\r\n   at Microsoft.Extensions.Options.ConfigureNamedOptions`2.Configure(String name, TOptions options)\r\n   at Microsoft.Extensions.Options.OptionsFactory`1.Create(String name)\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2..ctor(IServiceProvider serviceProvider, IOptions`1 mlContextOptions, IOptionsFactory`1 predictionEngineOptions)\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeConstructorInfo.Invoke(BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.<>c__DisplayClass1_0.<RealizeService>b__0(ServiceProviderEngineScope scope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngine.GetService(Type serviceType, ServiceProviderEngineScope serviceProviderEngineScope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngineScope.GetService(Type serviceType)\r\n   at Microsoft.Extensions.DependencyInjection.ActivatorUtilities.GetService(IServiceProvider sp, Type type, Type requiredBy, Boolean isDefaultParameterRequired)\r\n   at lambda_method(Closure , IServiceProvider , Object[] )\r\n   at Microsoft.AspNetCore.Mvc.Controllers.ControllerActivatorProvider.<>c__DisplayClass4_0.<CreateActivator>b__0(ControllerContext controllerContext)\r\n   at Microsoft.AspNetCore.Mvc.Controllers.ControllerFactoryProvider.<>c__DisplayClass5_0.<CreateControllerFactory>g__CreateController|0(ControllerContext controllerContext)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeNextResourceFilter>g__Awaited|24_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Rethrow(ResourceExecutedContextSealed context)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.InvokeFilterPipelineAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Logged|17_1(ResourceInvoker invoker)\r\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\r\n   at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)\r\n   at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4965","RelatedDescription":"Open issue \"Unable to score using PredictionEnginePool with a pipeline/model that contains custom transforms\" (#4965)"},{"Id":"586951635","IsPullRequest":false,"CreatedAt":"2020-03-24T16:37:20","Actor":"infiniteloopltd","Number":"4964","RawContent":null,"Title":"Can't load type Microsoft.ML.IPredictorProducing`1[System.Single]","State":"closed","Body":"### System information\r\n\r\n- Windows 10 Home\r\n- .NET : .NET Core 2.1\r\n- ML.NET : 1.5-preview2\r\n- ML.FastTree : 1.5-preview2\r\n\r\n### Issue:\r\n\r\nThe following error occurs when reading from disk:\r\n\r\nCan't load type Microsoft.ML.IPredictorProducing`1[System.Single], because it has both create and constructor methods with the same visibility. Please indicate which one should be used by changing either the signature or the visibility of one of them.\r\n\r\nModel is available here: https://github.com/infiniteloopltd/ML-Problem\r\n\r\nMay be related to [PR4385](https://github.com/dotnet/machinelearning/issues/4385)\r\n\r\n### Source code / logs\r\n\r\n````\r\nvar mlContext = new MLContext();\r\nvar modelPath = @\"MLModel.zip\";\r\nvar mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n````\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4964","RelatedDescription":"Closed issue \"Can't load type Microsoft.ML.IPredictorProducing`1[System.Single]\" (#4964)"},{"Id":"586517759","IsPullRequest":true,"CreatedAt":"2020-03-23T22:28:06","Actor":"frank-dong-ms","Number":"4962","RawContent":null,"Title":"enable 2 tests","State":"closed","Body":"these 2 tests not failed on full test set for 30 days so enable them:\r\nMulticlassLRTest\r\nBinaryClassifierLogisticRegressionBinNormTest\r\n\r\nhttps://dev.azure.com/dnceng/public/_test/analytics?definitionId=707&contextType=build\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4962","RelatedDescription":"Closed or merged PR \"enable 2 tests\" (#4962)"}],"ResultType":"GitHubIssue"}},"RunOn":"2020-04-01T05:30:38.5580283Z","RunDurationInMilliseconds":621}