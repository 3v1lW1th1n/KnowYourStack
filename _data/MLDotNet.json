{"Data":{"GitHub":{"Issues":[{"Id":"381435820","IsPullRequest":true,"CreatedAt":"2018-11-16T03:54:36","Actor":"eerhardt","Number":"1650","RawContent":null,"Title":"Complete VBuffer redesign","State":"open","Body":"This completes the redesign work for `VBuffer` by removing `.Values` and `.Indices` public arrays and converts all their usages to the new pattern. This is proposed change (4) in https://github.com/dotnet/machinelearning/issues/608#issuecomment-433185895.\r\n\r\n> Change the public T[] Values and public int[] Indices to public ReadOnlySpan<T> GetValues() and public ReadOnlySpan<int> GetIndices().\r\n\r\nFixes #608\r\n\r\n(NOTE: I currently have 1 place left to fix that I will work on in the morning, then the Values and Indices properties can be removed.)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1650","RelatedDescription":"Open PR \"Complete VBuffer redesign\" (#1650)"},{"Id":"381419309","IsPullRequest":false,"CreatedAt":"2018-11-16T02:23:18","Actor":"wschin","Number":"1649","RawContent":null,"Title":"Tensorflow Transform Doesn't Accept Key-typed Labels","State":"open","Body":"In the current Tensorflow tests, I tried changing its label type from I8 to U4[0:9] but then I couldn't retrain Tensorflow anymore.","Url":"https://github.com/dotnet/machinelearning/issues/1649","RelatedDescription":"Open issue \"Tensorflow Transform Doesn't Accept Key-typed Labels\" (#1649)"},{"Id":"381417223","IsPullRequest":false,"CreatedAt":"2018-11-16T02:12:28","Actor":"eerhardt","Number":"1648","RawContent":null,"Title":"Change FastTree BinFinder to use floats and remove one data copy","State":"open","Body":"See the conversation here: https://github.com/dotnet/machinelearning/pull/1580#discussion_r233672947\r\n\r\nWith the above change, I made it so the FastTree `BinFinder.FindDistinctCounts` was no longer destructive of the `values` VBuffer during `CalculateBins`.\r\n\r\nNow that it no longer destroys the buffer, we no longer need to copy it here:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cb9effcd091c60fa291aad96cc18c14ddf841b6f/src/Microsoft.ML.FastTree/FastTree.cs#L1475-L1478\r\n\r\nHowever, I couldn't easily remove this copy because doing the copy also changed the VBuffer from `float` to `double`. This should also be changed, as recognized by this `REVIEW` comment in the code:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/cb9effcd091c60fa291aad96cc18c14ddf841b6f/src/Microsoft.ML.FastTree/FastTree.cs#L2408\r\n\r\nThis issue is to fix both of these things. First, change BinFinder to work on `float` instead of `double`. Then, we can remove this extra copy and just pass in the normal `VBuffer<float>` to `BinFinder`, without worrying if it will destroy the buffer.\r\n\r\n/cc @Zruty0 @TomFinley ","Url":"https://github.com/dotnet/machinelearning/issues/1648","RelatedDescription":"Open issue \"Change FastTree BinFinder to use floats and remove one data copy\" (#1648)"},{"Id":"381412208","IsPullRequest":true,"CreatedAt":"2018-11-16T01:45:59","Actor":"Zruty0","Number":"1647","RawContent":null,"Title":"Adding custom mapping to cookbook","State":"open","Body":"Added custom mapping example to cookbook","Url":"https://github.com/dotnet/machinelearning/pull/1647","RelatedDescription":"Open PR \"Adding custom mapping to cookbook\" (#1647)"},{"Id":"381400077","IsPullRequest":true,"CreatedAt":"2018-11-16T00:44:19","Actor":"Ivanidzo4ka","Number":"1646","RawContent":null,"Title":"WIP stop and custom words remover to estimator","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/1646","RelatedDescription":"Open PR \"WIP stop and custom words remover to estimator\" (#1646)"},{"Id":"381392159","IsPullRequest":false,"CreatedAt":"2018-11-16T00:05:39","Actor":"rogancarr","Number":"1645","RawContent":null,"Title":"Add Documentation for GAM Trainers","State":"open","Body":"As @sfilipi pointed out on a PR #1642, the GAM trainers don't have samples available in the dynamic API. I suggest that we add samples to show how to use these learners.\r\n\r\n@sfilipi 's comment:\r\n```\r\nMy new comment on every PR that touches the catalogs: how do you feel about writing a sample for this, and referencing it here :)\r\n\r\nsee: https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/SDCA.cs\r\n\r\nand its reference:\r\nhttps://github.com/dotnet/machinelearning/src/Microsoft.ML.StandardLearners/StandardLearnersCatalog.cs\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/1645","RelatedDescription":"Open issue \"Add Documentation for GAM Trainers\" (#1645)"},{"Id":"381384611","IsPullRequest":false,"CreatedAt":"2018-11-15T23:33:56","Actor":"rogancarr","Number":"1644","RawContent":null,"Title":"WhatTheFeature Scorer is Missing in ML.NET","State":"open","Body":"The ML.NET codebase has definitions for `IWhatTheFeatureValueMapper` and implementations for linear models and tree models. I would like to see a scorer in ML.NET that can produce these feature importance scores.","Url":"https://github.com/dotnet/machinelearning/issues/1644","RelatedDescription":"Open issue \"WhatTheFeature Scorer is Missing in ML.NET\" (#1644)"},{"Id":"381378302","IsPullRequest":false,"CreatedAt":"2018-11-15T23:08:41","Actor":"yaeldekel","Number":"1643","RawContent":null,"Title":"GenerateCodeCommand bug","State":"open","Body":"This command has a replacementMap dictionary, and it uses it to find the keys in the generated code template and replace them with the values. But there is one pair in the dictionary with a key that doesn't exist in the template.","Url":"https://github.com/dotnet/machinelearning/issues/1643","RelatedDescription":"Open issue \"GenerateCodeCommand bug\" (#1643)"},{"Id":"381375266","IsPullRequest":true,"CreatedAt":"2018-11-15T22:57:49","Actor":"rogancarr","Number":"1642","RawContent":null,"Title":"Fix GAM default options and values","State":"open","Body":"This PR updates the `TreeTrainerCatalog` entries for `GAMs` to use better choices for default (non-advanced) parameters, and updates the default values for GAMs be those specified in the GAMs `Arguments` class.\r\n\r\nFixes #1630 ","Url":"https://github.com/dotnet/machinelearning/pull/1642","RelatedDescription":"Open PR \"Fix GAM default options and values\" (#1642)"},{"Id":"381372509","IsPullRequest":true,"CreatedAt":"2018-11-15T22:47:42","Actor":"yaeldekel","Number":"1641","RawContent":null,"Title":"Fix StopWordRemoverTransform bugs","State":"open","Body":"Fixes #1629 .\r\nAlso fix a bug with splitting a comma separated list of stop words into tokens.","Url":"https://github.com/dotnet/machinelearning/pull/1641","RelatedDescription":"Open PR \"Fix StopWordRemoverTransform bugs\" (#1641)"},{"Id":"381360916","IsPullRequest":false,"CreatedAt":"2018-11-15T22:10:07","Actor":"daholste","Number":"1640","RawContent":null,"Title":"'Ignore' not respected in schema","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nRan MML command line: execgraph \"C:\\Benchmarking\\automl_graph.json\"\r\n\r\nContents of automl_.graph.json:\r\n\r\n```json\r\n{\r\n  \"Inputs\": {\r\n    \"file_train\": \"D:\\\\SplitDatasets\\\\ExcitementFG2_train.csv\",\r\n    \"file_test\": \"D:\\\\SplitDatasets\\\\ExcitementFG2_valid.csv\"\r\n  },\r\n  \"Nodes\": [\r\n    {\r\n      \"Inputs\": {\r\n        \"CustomSchema\": \"sep=, col=Label:R4:0 col=Features:R4:1-13 col=Cat:TX:14 col=Cat01:TX:15 col=Ignore:TX:16,25 col=Cat02:TX:17 col=Cat03:TX:18 col=Cat04:TX:19 col=Cat05:TX:20 col=Cat06:TX:21 col=Cat07:TX:22 col=Cat08:TX:23 col=Cat09:TX:24 col=Cat10:TX:26 col=Cat11:TX:27 col=Cat12:TX:28 col=Cat13:TX:29 col=Cat14:TX:30 col=Cat15:TX:31 col=Cat16:TX:32 col=Cat17:TX:33 col=Cat18:TX:34 col=Cat19:TX:35 col=Cat20:TX:36 col=Cat21:TX:37 col=Cat22:TX:38 col=Cat23:TX:39\",\r\n        \"InputFile\": \"$file_train\"\r\n      },\r\n      \"Name\": \"Data.CustomTextLoader\",\r\n      \"Outputs\": {\r\n        \"Data\": \"$data_train\"\r\n      }\r\n    },\r\n    {\r\n      \"Inputs\": {\r\n        \"CustomSchema\": \"sep=, col=Label:R4:0 col=Features:R4:1-13 col=Cat:TX:14 col=Cat01:TX:15 col=Ignore:TX:16,25 col=Cat02:TX:17 col=Cat03:TX:18 col=Cat04:TX:19 col=Cat05:TX:20 col=Cat06:TX:21 col=Cat07:TX:22 col=Cat08:TX:23 col=Cat09:TX:24 col=Cat10:TX:26 col=Cat11:TX:27 col=Cat12:TX:28 col=Cat13:TX:29 col=Cat14:TX:30 col=Cat15:TX:31 col=Cat16:TX:32 col=Cat17:TX:33 col=Cat18:TX:34 col=Cat19:TX:35 col=Cat20:TX:36 col=Cat21:TX:37 col=Cat22:TX:38 col=Cat23:TX:39\",\r\n        \"InputFile\": \"$file_test\"\r\n      },\r\n      \"Name\": \"Data.CustomTextLoader\",\r\n      \"Outputs\": {\r\n        \"Data\": \"$data_test\"\r\n      }\r\n    },\r\n    {\r\n      \"Inputs\": {\r\n        \"BatchSize\": 3,\r\n        \"StateArguments\": {\r\n          \"Name\": \"AutoMlState\",\r\n          \"Settings\": {\r\n            \"Engine\": {\r\n              \"Name\": \"Rocket\",\r\n              \"Settings\": {}\r\n            },\r\n            \"Metric\": \"Accuracy\",\r\n            \"TerminatorArgs\": {\r\n              \"Name\": \"IterationLimited\",\r\n              \"Settings\": {\r\n                \"FinalHistoryLength\": 100\r\n              }\r\n            },\r\n            \"TrainerKind\": \"SignatureBinaryClassifierTrainer\"\r\n          }\r\n        },\r\n        \"TestingData\": \"$data_test\",\r\n        \"TrainingData\": \"$data_train\"\r\n      },\r\n      \"Name\": \"Models.PipelineSweeper\",\r\n      \"Outputs\": {\r\n        \"Results\": \"$output_data\",\r\n        \"State\": \"$xyz\"\r\n      }\r\n    }\r\n  ],\r\n  \"Outputs\": {\r\n    \"output_data\": \"C:\\\\Benchmarking\\\\01-ResultsOut.csv\"\r\n  }\r\n}\r\n```\r\n\r\n- **What happened?**\r\nEven though Ignore:TX:16,25 is specified in the schema, the learners start expensive / slow text transforms / n-gram extractions on the columns\r\n\r\n- **What did you expect?**\r\nThe columns to be ignored","Url":"https://github.com/dotnet/machinelearning/issues/1640","RelatedDescription":"Open issue \"'Ignore' not respected in schema\" (#1640)"},{"Id":"381360693","IsPullRequest":false,"CreatedAt":"2018-11-15T22:09:25","Actor":"rogancarr","Number":"1639","RawContent":null,"Title":"Precedence between main arguments and advancedSettings","State":"open","Body":"In some learnings, for example [GAM](https://github.com/dotnet/machinelearning/blob/8a45f37cf87e380a93146d08acac19f215648f9a/src/Microsoft.ML.FastTree/GamTrainer.cs#L135), the [APIs specify a set of default values](https://github.com/dotnet/machinelearning/blob/8a45f37cf87e380a93146d08acac19f215648f9a/src/Microsoft.ML.FastTree/TreeTrainersCatalog.cs#L110), with an optional advanced settings argument.\r\n\r\nOftentimes, as is the case with GAMs, this means that there are two ways to specify the value for a parameter -- as a main line item, or in the advanced settings. In the GAM code, the main line items are applied, followed by the advanced settings. There is no normalization that occurs., meaning that options in the advanced settings can override options set in the main line items.\r\n\r\nIs there supposed to be precedence here, or is there any way to make the APIs simpler so that there is only one way to specify a parameter? I'd love to hear people's thoughts on this.\r\n\r\nI don't know of any bugs caused by this, but this seems like the kind of thing that can cause unintentional behavior.","Url":"https://github.com/dotnet/machinelearning/issues/1639","RelatedDescription":"Open issue \"Precedence between main arguments and advancedSettings\" (#1639)"},{"Id":"381346952","IsPullRequest":true,"CreatedAt":"2018-11-15T21:28:56","Actor":"rogancarr","Number":"1638","RawContent":null,"Title":"Fix the name for GAMs in the API Catalog","State":"open","Body":"This is a short fix that renames GAM Trainers in the catalog to `GeneralizedAdditiveModels` from `GeneralizedAdditiveMethods` to be consistent with the common nomenclature [1].\r\n\r\n[1] Hastie and Tibshirani are generally considered to have introduced the methodology, for example in Hastie, Trevor and Tibshirani, Robert. (1986), [Generalized Additive Models](https://www.jstor.org/stable/2245459), Statistical Science, Vol. 1, No 3, 297-318.\r\n\r\nFixes #1623 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/1638","RelatedDescription":"Open PR \"Fix the name for GAMs in the API Catalog\" (#1638)"},{"Id":"381333888","IsPullRequest":true,"CreatedAt":"2018-11-15T20:50:58","Actor":"wschin","Number":"1637","RawContent":null,"Title":"[WIP] Remove the uses of CreatePredictionEngine","State":"open","Body":"Fixes #1409. Those tests are full of copy-and-paste, so I also clean them a bit.","Url":"https://github.com/dotnet/machinelearning/pull/1637","RelatedDescription":"Open PR \"[WIP] Remove the uses of CreatePredictionEngine\" (#1637)"},{"Id":"381317493","IsPullRequest":false,"CreatedAt":"2018-11-15T20:01:28","Actor":"rogancarr","Number":"1636","RawContent":null,"Title":"Recovering ITransformers from Predictor Objects","State":"open","Body":"Oftentimes it is necessary to have an actual object of a predictor, such as a `RegressionGAMPredictor` or `LinearRegressionPredictor` to access methods particular to the predictor. However, it is a bit cumbersome to get back to the `ITransformer` interface. One must manually create a `RegressionPredictionTransformer` like so:\r\n\r\n```\r\nvar linearTransformer = new RegressionPredictionTransformer<LinearRegressionPredictor>(mlContext, linearPredictor, trainSet.Schema, \"Features\");\r\n```\r\n\r\nI'd like to see all the predictor objects support a method like `AsTransformer()` to return an `ITransformer`. It seems like the predictor objects have enough information to automate the process, and it would make the APIs much easier to use.","Url":"https://github.com/dotnet/machinelearning/issues/1636","RelatedDescription":"Open issue \"Recovering ITransformers from Predictor Objects\" (#1636)"},{"Id":"381317275","IsPullRequest":false,"CreatedAt":"2018-11-15T20:00:50","Actor":"petterton","Number":"1635","RawContent":null,"Title":"TrainTestSplit random seed","State":"open","Body":"I am repeatedly calling `TrainTestSplit` for a data set (for cross validation) and see that the resulting split is the same every call. In sklearn, the `train_test_split` function has the possibility of taking a seed for a random number generator as an input. Could this be added also in ML.NET?","Url":"https://github.com/dotnet/machinelearning/issues/1635","RelatedDescription":"Open issue \"TrainTestSplit random seed\" (#1635)"},{"Id":"381315599","IsPullRequest":false,"CreatedAt":"2018-11-15T19:56:01","Actor":"rogancarr","Number":"1634","RawContent":null,"Title":"Normalization option, FixZero, is not available in high-level APIs","State":"open","Body":"When I perform minmax normalization on dense datasets, I like to turn off \"fixzero\". This option is not available in the high-level APIs, e.g. `mlContext.Transforms.Normalize()`.\r\n\r\nTo use this, you need to go back and create `AffineColumn` and `MinMaxArguments` objects and use the old-style `Create` API:\r\n```\r\nvar column = new NormalizeTransform.AffineColumn() { Name = \"Index0\", FixZero = false };\r\nvar minMaxArgs = new NormalizeTransform.MinMaxArguments() { FixZero = false, Column = new NormalizeTransform.AffineColumn[1] { column } };\r\nIDataView transform = NormalizeTransform.Create(mlContext, minMaxArgs, loader);\r\n```\r\n\r\nI think these old-style APIs are very confusing to use, especially since there are two ways to specify `FixZero`, and it's unclear which one is used and if there is precedence between them.","Url":"https://github.com/dotnet/machinelearning/issues/1634","RelatedDescription":"Open issue \"Normalization option, FixZero, is not available in high-level APIs\" (#1634)"},{"Id":"381309646","IsPullRequest":false,"CreatedAt":"2018-11-15T19:38:30","Actor":"yaeldekel","Number":"1633","RawContent":null,"Title":"Marshal.Invoke cannot be called with a method that has a generic return type","State":"open","Body":"In DataViewConstructionUtils.cs there is a method GetGetterDelegate() that calls Marshal.Invoke with GetGetter<int> that has a generic return type (ValueGetter<TDst>).\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1633","RelatedDescription":"Open issue \"Marshal.Invoke cannot be called with a method that has a generic return type\" (#1633)"},{"Id":"381306251","IsPullRequest":false,"CreatedAt":"2018-11-15T19:28:19","Actor":"yaeldekel","Number":"1632","RawContent":null,"Title":"NGramHashTransform doesn't provide slot names","State":"open","Body":"There is an argument in the Arguments class to provide slot names, however the resulting schema doesn't contain this metadata.","Url":"https://github.com/dotnet/machinelearning/issues/1632","RelatedDescription":"Open issue \"NGramHashTransform doesn't provide slot names\" (#1632)"},{"Id":"381302940","IsPullRequest":false,"CreatedAt":"2018-11-15T19:18:39","Actor":"rogancarr","Number":"1631","RawContent":null,"Title":"The top-level APIs do not support validation sets","State":"open","Body":"For learners that take validation sets like `GAM` and `FastTree`, there is no way to specify a `validation` set during `Fit()`.\r\n\r\nThis may be by design (because what does a validation set mean to a whole pipeline?), but it is very cumbersome to work around.\r\n\r\nDoes anyone have thoughts on how we can make the `validation` process easy to use and simple to understand?","Url":"https://github.com/dotnet/machinelearning/issues/1631","RelatedDescription":"Open issue \"The top-level APIs do not support validation sets\" (#1631)"},{"Id":"381301341","IsPullRequest":false,"CreatedAt":"2018-11-15T19:14:13","Actor":"rogancarr","Number":"1630","RawContent":null,"Title":"GAM Default Arguments in the Dynamic API are incompatible with GAMs","State":"open","Body":"The new high-level APIs for GAMs are incorrect and not descriptive of the common choices someone will make.\r\n\r\nIncorrect: They contain parameters that don't belong to the learner and contain duplicate parameters:\r\n- `NumTrees` is not a parameter for GAM\r\n- `NumLeaves` is not a parameter for GAM\r\n- There are two options for tuning the learning rate: `learningRate` and `advancedSettings.LearningRates`, each with a different default. It is unclear which one will be used, but the default value for `learningRate` will tend to produce poor fits.\r\n\r\nNot descriptive: The API puts the most basic and most used options into `advancedSettings`:\r\n- `NumIterations`: How many iterations to use to fit\r\n- `NumBins`: How densely to draw the curves.","Url":"https://github.com/dotnet/machinelearning/issues/1630","RelatedDescription":"Open issue \"GAM Default Arguments in the Dynamic API are incompatible with GAMs\" (#1630)"},{"Id":"381289112","IsPullRequest":false,"CreatedAt":"2018-11-15T18:38:23","Actor":"yaeldekel","Number":"1629","RawContent":null,"Title":"StopWordsRemoverTransform uses a dictionary with ReadOnlyMemory<char> keys","State":"open","Body":"This transform contains a dictionary to find the language of each example, and this bug causes the language to not be found in the dictionary.","Url":"https://github.com/dotnet/machinelearning/issues/1629","RelatedDescription":"Open issue \"StopWordsRemoverTransform uses a dictionary with ReadOnlyMemory<char> keys\" (#1629)"},{"Id":"381286268","IsPullRequest":false,"CreatedAt":"2018-11-15T18:29:30","Actor":"yaeldekel","Number":"1628","RawContent":null,"Title":"Bug in PKPD","State":"open","Body":"In the GetMapper() method of PkpdPredictor, there is a double[] buffer that holds the scores of each individual predictor, however it is initialized to be the length of _numClasses instead of _mappers.Length.","Url":"https://github.com/dotnet/machinelearning/issues/1628","RelatedDescription":"Open issue \"Bug in PKPD\" (#1628)"},{"Id":"381286178","IsPullRequest":false,"CreatedAt":"2018-11-15T18:29:17","Actor":"najeeb-kazmi","Number":"1627","RawContent":null,"Title":"Binary Saving and Loading from MLContext","State":"open","Body":"MLContext should have extensions for creating a binary reader, and loading and saving binary files, like it currently has for text files. Specifically, add:\r\n\r\n- `MLContext.Data.BinaryReader`, corresponding to `MLContext.Data.TextReader`\r\n- `MLContext.Data.SaveAsBinary`, corresponding to `MLContext.Data.SaveAsText`\r\n- `MLContext.Data.ReadFromBinaryFile`, corresponding to `MLContext.Data.ReadFromTextFile`","Url":"https://github.com/dotnet/machinelearning/issues/1627","RelatedDescription":"Open issue \"Binary Saving and Loading from MLContext\" (#1627)"},{"Id":"380927216","IsPullRequest":true,"CreatedAt":"2018-11-15T17:33:06","Actor":"wschin","Number":"1621","RawContent":null,"Title":"Remove lazy parameters for GetRowCount","State":"closed","Body":"Fixes #1531. In most cases, the `GetRowCount` is as lazy as before but in some places such as `CacheDataView` in `CacheDataView.cs`, it could need more than O(1) time to wait until the actual number of rows is available.","Url":"https://github.com/dotnet/machinelearning/pull/1621","RelatedDescription":"Closed or merged PR \"Remove lazy parameters for GetRowCount\" (#1621)"},{"Id":"381065303","IsPullRequest":true,"CreatedAt":"2018-11-15T09:12:17","Actor":"TomFinley","Number":"1626","RawContent":null,"Title":"Movement and Internalization Phase 2","State":"open","Body":"Continuation of the work of #1587, which itself is part of the ongoing work of #1519.\r\n\r\nThe changes are certainly best digested commit by commit, rather than just reviewing the last commit. The commmit descriptions are intended to be informative.\r\n\r\nPlease do not be afraid of the seemingly large line count. Discounting whitespace changes (mostly on account of not using `ConsoleEnvironment` in many places), the number of *actually* changed lines is really more like only 600 additions/900 deletions, as opposed to what git is reporting on my screen as on the order of ~4000 of these.","Url":"https://github.com/dotnet/machinelearning/pull/1626","RelatedDescription":"Open PR \"Movement and Internalization Phase 2\" (#1626)"},{"Id":"380997843","IsPullRequest":false,"CreatedAt":"2018-11-15T04:42:31","Actor":"daholste","Number":"1625","RawContent":null,"Title":"LightGBM trainer exception","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** \r\nRan MML command line: execgraph \"C:\\Benchmarking\\automl_graph.json\"\r\n\r\nContents of automl_.graph.json:\r\n\r\n```json\r\n{\r\n  \"Inputs\": {\r\n    \"file_train\": \"D:\\\\SplitDatasets\\\\ExcitementFG2_train.csv\",\r\n    \"file_test\": \"D:\\\\SplitDatasets\\\\ExcitementFG2_valid.csv\"\r\n  },\r\n  \"Nodes\": [\r\n    {\r\n      \"Inputs\": {\r\n        \"CustomSchema\": \"sep=, col=Label:R4:78 col=Features1:R4:0-77 col=Features2:R4:79-202 header=+\",\r\n        \"InputFile\": \"$file_train\"\r\n      },\r\n      \"Name\": \"Data.CustomTextLoader\",\r\n      \"Outputs\": {\r\n        \"Data\": \"$data_train\"\r\n      }\r\n    },\r\n    {\r\n      \"Inputs\": {\r\n        \"CustomSchema\": \"sep=, col=Label:R4:78 col=Features1:R4:0-77 col=Features2:R4:79-202 header=+\",\r\n        \"InputFile\": \"$file_test\"\r\n      },\r\n      \"Name\": \"Data.CustomTextLoader\",\r\n      \"Outputs\": {\r\n        \"Data\": \"$data_test\"\r\n      }\r\n    },\r\n    {\r\n      \"Inputs\": {\r\n        \"BatchSize\": 3,\r\n        \"StateArguments\": {\r\n          \"Name\": \"AutoMlState\",\r\n          \"Settings\": {\r\n            \"Engine\": {\r\n              \"Name\": \"Rocket\",\r\n              \"Settings\": {}\r\n            },\r\n            \"Metric\": \"Accuracy\",\r\n            \"TerminatorArgs\": {\r\n              \"Name\": \"IterationLimited\",\r\n              \"Settings\": {\r\n                \"FinalHistoryLength\": 100\r\n              }\r\n            },\r\n            \"TrainerKind\": \"SignatureBinaryClassifierTrainer\"\r\n          }\r\n        },\r\n        \"TestingData\": \"$data_test\",\r\n        \"TrainingData\": \"$data_train\",\r\n\t\t\"IgnoreColumns\": [\"cost\"]\r\n      },\r\n      \"Name\": \"Models.PipelineSweeper\",\r\n      \"Outputs\": {\r\n        \"Results\": \"$output_data\",\r\n        \"State\": \"$xyz\"\r\n      }\r\n    }\r\n  ],\r\n  \"Outputs\": {\r\n    \"output_data\": \"C:\\\\Benchmarking\\\\01-ResultsOut.csv\"\r\n  }\r\n}\r\n```\r\n\r\n- **What happened?**\r\nEncountered an exception in LightGBM trainer\r\n\r\n- **What did you expect?**\r\nA run to completion, w/o exception\r\n\r\n### Source code / logs\r\n\r\n--- Command line args ---\r\n`dotnet MML.dll execgraph C:\\Benchmarking\\automl_graph.json`\r\n\r\n--- Exception message ---\r\n```\r\nSystem.InvalidOperationException\r\n  HResult=0x80131509\r\n  Message=Categorical split features is zero length\r\n  Source=Microsoft.ML.Core\r\n  StackTrace:\r\n   at Microsoft.ML.Runtime.Contracts.Check(Boolean f, String msg) in C:\\MLDotNet\\src\\Microsoft.ML.Core\\Utilities\\Contracts.cs:line 497\r\n   at Microsoft.ML.Trainers.FastTree.Internal.RegressionTree.CheckValid(Action`2 checker) in C:\\MLDotNet\\src\\Microsoft.ML.FastTree\\TreeEnsemble\\RegressionTree.cs:line 469\r\n   at Microsoft.ML.Trainers.FastTree.Internal.RegressionTree..ctor(Int32[] splitFeatures, Double[] splitGain, Double[] gainPValue, Single[] rawThresholds, Single[] defaultValueForMissing, Int32[] lteChild, Int32[] gtChild, Double[] leafValues, Int32[][] categoricalSplitFeatures, Boolean[] categoricalSplit) in C:\\MLDotNet\\src\\Microsoft.ML.FastTree\\TreeEnsemble\\RegressionTree.cs:line 223\r\n   at Microsoft.ML.Trainers.FastTree.Internal.RegressionTree.Create(Int32 numLeaves, Int32[] splitFeatures, Double[] splitGain, Single[] rawThresholds, Single[] defaultValueForMissing, Int32[] lteChild, Int32[] gtChild, Double[] leafValues, Int32[][] categoricalSplitFeatures, Boolean[] categoricalSplit) in C:\\MLDotNet\\src\\Microsoft.ML.FastTree\\TreeEnsemble\\RegressionTree.cs:line 189\r\n   at Microsoft.ML.Runtime.LightGBM.Booster.GetModel(Int32[] categoricalFeatureBoudaries) in C:\\MLDotNet\\src\\Microsoft.ML.LightGBM\\WrappedLightGbmBooster.cs:line 241\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbmTrainerBase`3.TrainCore(IChannel ch, IProgressChannel pch, Dataset dtrain, CategoricalMetaData catMetaData, Dataset dvalid) in C:\\MLDotNet\\src\\Microsoft.ML.LightGBM\\LightGbmTrainerBase.cs:line 378\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbmTrainerBase`3.TrainModelCore(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.LightGBM\\LightGbmTrainerBase.cs:line 126\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Train(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 92\r\n   at Microsoft.ML.Runtime.Training.TrainerEstimatorBase`2.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 158\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, RoleMappedData validData, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 254\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.Train(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, IComponentFactory`1 calibrator, Int32 maxCalibrationExamples) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\Commands\\TrainCommand.cs:line 223\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples) in C:\\MLDotNet\\src\\Microsoft.ML.Data\\EntryPoints\\InputBase.cs:line 189\r\n   at Microsoft.ML.Runtime.LightGBM.LightGbm.TrainBinary(IHostEnvironment env, LightGbmArguments input) in C:\\MLDotNet\\src\\Microsoft.ML.LightGBM\\LightGbmBinaryTrainer.cs:line 189\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/1625","RelatedDescription":"Open issue \"LightGBM trainer exception\" (#1625)"},{"Id":"380972938","IsPullRequest":true,"CreatedAt":"2018-11-15T02:31:00","Actor":"Ivanidzo4ka","Number":"1624","RawContent":null,"Title":"Convert MissingValueDroppingTransformer to estimator","State":"open","Body":"Convert MissingValueDroppingTransformer to estimator","Url":"https://github.com/dotnet/machinelearning/pull/1624","RelatedDescription":"Open PR \"Convert MissingValueDroppingTransformer to estimator\" (#1624)"},{"Id":"380946591","IsPullRequest":false,"CreatedAt":"2018-11-15T00:25:57","Actor":"rogancarr","Number":"1623","RawContent":null,"Title":"GeneralizedAdditiveModels is referred to as GeneralizedAdditiveMethods","State":"open","Body":"`Generalized Additive Models` (aka `GAM`) are referred to as `Generalized Additive Methods` in the new API. See [here](https://github.com/dotnet/machinelearning/blob/851558d93f509372769ba802e0c81364fa6d55ed/src/Microsoft.ML.FastTree/TreeTrainersCatalog.cs#L110) for classification, [here](https://github.com/dotnet/machinelearning/blob/851558d93f509372769ba802e0c81364fa6d55ed/src/Microsoft.ML.FastTree/TreeTrainersCatalog.cs#L133) for regression.\r\n\r\nThe API should be `GeneralizedAdditiveModels`.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1623","RelatedDescription":"Open issue \"GeneralizedAdditiveModels is referred to as GeneralizedAdditiveMethods\" (#1623)"},{"Id":"380933190","IsPullRequest":false,"CreatedAt":"2018-11-14T23:29:59","Actor":"abgoswam","Number":"1622","RawContent":null,"Title":"Calibration estimators in ML.NET","State":"open","Body":"In the discussions for #1579,  one of the  proposals was to introduce calibration estimators in ML.NET.  \r\n\r\n<snip>  (from #1579)\r\n\r\n.... a calibrator is just one peculiar form of trainer: it learns a monotonous function that transforms 'scores' into 'probabilities', with the goal to minimize the log-loss against the 'target label'. So, it is actually a univariate classification trainer. We should create a `PlattCalibrationEstimator` to train Platt calibrators and a `PavCalibrationEstimator` to train PAV calibrators.\r\n\r\n</snip>\r\n\r\n@Zruty0  @yaeldekel ","Url":"https://github.com/dotnet/machinelearning/issues/1622","RelatedDescription":"Open issue \"Calibration estimators in ML.NET\" (#1622)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-11-16T05:30:32.9086724Z","RunDurationInMilliseconds":1116}