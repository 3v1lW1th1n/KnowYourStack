{"Data":{"GitHub":{"Issues":[{"Id":"434080430","IsPullRequest":true,"CreatedAt":"2019-04-18T05:09:18","Actor":"daholste","Number":"3373","RawContent":null,"Title":"[AutoML] Migrate AutoML back to its own solution, w/ NuGet dependencies","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3373","RelatedDescription":"Closed or merged PR \"[AutoML] Migrate AutoML back to its own solution, w/ NuGet dependencies\" (#3373)"},{"Id":"434547044","IsPullRequest":true,"CreatedAt":"2019-04-18T01:06:10","Actor":"shmoradims","Number":"3391","RawContent":null,"Title":"Fixed xref links in AveragedPerceptron","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3391","RelatedDescription":"Open PR \"Fixed xref links in AveragedPerceptron\" (#3391)"},{"Id":"434545131","IsPullRequest":false,"CreatedAt":"2019-04-18T00:55:37","Actor":"glebuk","Number":"3390","RawContent":null,"Title":"Increase Native build warning level to W3 and fix build warnings ","State":"open","Body":"Before, we actually only reported W1 warning level during native build.\r\nNow we warn on L3 warnings\r\nFixed three warnings from downcasting variables. In all cases the downcasting was deemed safe and replaced with static_cast<>\r\nNote that all those warnings were deemed required to fix for compliance criteria.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3390","RelatedDescription":"Open issue \"Increase Native build warning level to W3 and fix build warnings \" (#3390)"},{"Id":"434544879","IsPullRequest":true,"CreatedAt":"2019-04-18T00:54:04","Actor":"wschin","Number":"3389","RawContent":null,"Title":"Add XML to LBFGS Maximum Entropy Classifier","State":"open","Body":"Toward #2522 following #3218.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3389","RelatedDescription":"Open PR \"Add XML to LBFGS Maximum Entropy Classifier\" (#3389)"},{"Id":"434535772","IsPullRequest":true,"CreatedAt":"2019-04-18T00:06:44","Actor":"najeeb-kazmi","Number":"3388","RawContent":null,"Title":"Towards #3204 - Documentation for MLContext.Transforms.Categorical","State":"open","Body":"Documentation for Categorical transforms using template given in #3204 and implemented in #3316.","Url":"https://github.com/dotnet/machinelearning/pull/3388","RelatedDescription":"Open PR \"Towards #3204 - Documentation for MLContext.Transforms.Categorical\" (#3388)"},{"Id":"434525422","IsPullRequest":true,"CreatedAt":"2019-04-17T23:18:42","Actor":"ganik","Number":"3387","RawContent":null,"Title":"Docs 2nd pass for NaiveBayes, KMeans, OVA, Pairwise","State":"open","Body":"part of #2522 ","Url":"https://github.com/dotnet/machinelearning/pull/3387","RelatedDescription":"Open PR \"Docs 2nd pass for NaiveBayes, KMeans, OVA, Pairwise\" (#3387)"},{"Id":"434487695","IsPullRequest":true,"CreatedAt":"2019-04-17T21:10:19","Actor":"Ivanidzo4ka","Number":"3386","RawContent":null,"Title":"Update documentation for MissingValues","State":"open","Body":"towards #3204 \r\nMissingValues","Url":"https://github.com/dotnet/machinelearning/pull/3386","RelatedDescription":"Open PR \"Update documentation for MissingValues\" (#3386)"},{"Id":"434487345","IsPullRequest":true,"CreatedAt":"2019-04-17T21:09:20","Actor":"wschin","Number":"3385","RawContent":null,"Title":"Add LR XML doc","State":"open","Body":"Toward #2522 following #3218.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3385","RelatedDescription":"Open PR \"Add LR XML doc\" (#3385)"},{"Id":"434437020","IsPullRequest":true,"CreatedAt":"2019-04-17T20:51:10","Actor":"codemzs","Number":"3379","RawContent":null,"Title":"DataOperations: Replace PREVIEW API usage with proper IDataView based Enumerable API.","State":"closed","Body":"fixes #3350\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3379","RelatedDescription":"Closed or merged PR \"DataOperations: Replace PREVIEW API usage with proper IDataView based Enumerable API.\" (#3379)"},{"Id":"434469218","IsPullRequest":true,"CreatedAt":"2019-04-17T20:22:25","Actor":"yaeldekel","Number":"3384","RawContent":null,"Title":"Towards #3204 - documentation for FeatureContributionCalculatingEstimator","State":"open","Body":"Adhering to the template in #3204 (comment) for the ColumnCopying estimator extensions, estimator, transformer.","Url":"https://github.com/dotnet/machinelearning/pull/3384","RelatedDescription":"Open PR \"Towards #3204 - documentation for FeatureContributionCalculatingEstimator\" (#3384)"},{"Id":"434452675","IsPullRequest":true,"CreatedAt":"2019-04-17T19:40:02","Actor":"Dmitry-A","Number":"3383","RawContent":null,"Title":"[AutoML] publish AutoML package","State":"open","Body":"Add build scripts for AutoML nuget, set version to 0.2, disable building ml.net projects and nuget publishing for them.","Url":"https://github.com/dotnet/machinelearning/pull/3383","RelatedDescription":"Open PR \"[AutoML] publish AutoML package\" (#3383)"},{"Id":"434451508","IsPullRequest":false,"CreatedAt":"2019-04-17T19:36:58","Actor":"PeterPann23","Number":"3382","RawContent":null,"Title":"Documentation missing on prepairing training data","State":"open","Body":"### Issue\r\n\r\nThe cookbook has plenty of samples of how to do steps, there is however no documentation that I found on how to approach the configuring a pipeline. \r\nThere is no mention on the the choices of:\r\n- Is it better to load all columns of a csv in separate named fields or in a single vector\r\n- Should one normalize each field, when should one normalize it\r\n- Should one combine all in one vector and normalize the whole vector\r\n- how many fields are supported, \r\n\r\n**Error:**\r\nI tried and played a Little with it and found that  when loading data as a vector or when loading the data via individual fieldnames one gets different metrics on the same data (tested against 1.6m rows).\r\nWhen loading via a vector. no issue\r\nwhen loading via fields, no issue\r\nwhen loading it via properties the frameworks complains at the loader with a message stating that there are to many properties and it's not supported. \r\n\r\n**Expect**\r\nI expect that all 3 would cause the same error, or all 3 would work as the resulting vector has the same size (35,630 elements). \r\n\r\nI would hope that the documentation gets updated reflecting the above points.\r\n\r\n**Code*\r\n\r\n```\r\nIDataView GetDataView(MLContext mlContext, FileInfo trainingFile)\r\n{\r\n    var loader = mlContext.Data.CreateTextLoader<Mapper>(separatorChar:'|',hasHeader:false);\r\n    return loader.Load(trainingFile.FullName);\r\n}\r\n\r\n\r\npublic void ExecuteSDCA()\r\n{\r\n    var file = new FileInfo(@\"data\\Rows_100_.data\");\r\n    var dataView = GetDataView(mlContext, file);           \r\n\r\n\r\n    var pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: KeyColumn, inputColumnName: Label)\r\n            .Append(mlContext.Transforms.Concatenate(Features, Mapper.GetFieldNames()))\r\n            //.Append(mlContext.Transforms.NormalizeMinMax(outputColumnName:Features, inputColumnName:RawFeatures))\r\n            .Append(mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName: KeyColumn, featureColumnName: Features, maximumNumberOfIterations:1))\r\n            .Append(mlContext.Transforms.Conversion.MapKeyToValue(inputColumnName: KeyColumn, outputColumnName: PredictedLabel))\r\n            .Append(mlContext.Transforms.CopyColumns(outputColumnName: Scores, inputColumnName: Score));\r\n    //.AppendCacheCheckpoint(mlContext);\r\n\r\n    var model = pipeline.Fit(dataView);           \r\n\r\n}         \r\n\r\n```\r\nI have added the data and auto-generated class as well\r\n\r\n[Mapper.zip](https://github.com/dotnet/machinelearning/files/3091256/Mapper.zip)\r\n\r\n\r\n[Rows_100_.zip](https://github.com/dotnet/machinelearning/files/3091223/Rows_100_.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3382","RelatedDescription":"Open issue \"Documentation missing on prepairing training data\" (#3382)"},{"Id":"434441572","IsPullRequest":false,"CreatedAt":"2019-04-17T19:10:37","Actor":"clauren42","Number":"3381","RawContent":null,"Title":"No readme / guidance in Microsoft.ML.Samples","State":"open","Body":"Samples in https://github.com/dotnet/machinelearning/tree/master/docs/samples/Microsoft.ML.Samples\r\nshould have readme explaining available samples and how to use","Url":"https://github.com/dotnet/machinelearning/issues/3381","RelatedDescription":"Open issue \"No readme / guidance in Microsoft.ML.Samples\" (#3381)"},{"Id":"434439843","IsPullRequest":false,"CreatedAt":"2019-04-17T19:06:28","Actor":"TomFinley","Number":"3380","RawContent":null,"Title":"Relationship between SchemaShape from IEstimator and DataViewSchema from its ITransformer, and resulting fallout","State":"open","Body":"I was attempting to write documentation for `IEstimator`  and `ITransformer`. One of the core responsibilities of these is, as expressed in #581, schema propagation, so as to, among other benefits, do the sort of \"pre-fit validation\" scenario that has proven so troublesome to us in the past (this w.r.t. #267).\r\n\r\nHowever, what I find is that I struggled to detect a meaningful unifying \"principle\" behind `IEstimator` and `ITransformer`. I think the people that worked on it thought there was a principle, but when I encountered what people though tit was (something about annotations being a 'subset' of one or the other), it seemed like there were numerous \"exceptions\" that made the principle meaningless. . Indeed, I'm starting to suspect that there was no scenario by the original designer aside from \"work until things compile and run on what we have so far,\" which is not really an acceptable state for something like `IEstimator` and `ITransformer` which are core concepts of this API, especially if we hope to describe them in such a way that people can implement these interfaces on their own.\r\n\r\nIn this issue I outline the trouble that I have observed. The points here are ***subtle***, but they are important insofar as resolving them is, I think, crucial for us to define the relationship between `IEstimator` and the `ITransformer` returned by fitting that estimator.\r\n\r\nCCing @artidoro, @shauheen since I know they had some interest in this problem... going to mark as the unusual step of both bug and code-sanitation, since it both touches upon our need to have a consistent architectural story among these key structures, as well as there having been some genuine bugs that have been uncovered.\r\n\r\n# A Troublesome Example\r\n\r\nSo, I'll start with the same seemingly innocuous code that led me to think there is something architecturally wrong at stake here: Consider the `IsNormalized` annotation, in the `KeyToVectorMappingEstimator`, here is the condition where this annotation is mentioned as coming:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/73e29c8acf63418ce1f89ef78296d52d775dafe3/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L803-L804\r\n\r\nMeanwhile, the resulting transformer has subtly different logic. If the input source value count is `1`, which of course happens when something is scalar, but also happens when the input is vector and happens to have vector size of one. (A concept that has no meaning in `SchemaShape`, and is basically unknowable.)\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/73e29c8acf63418ce1f89ef78296d52d775dafe3/src/Microsoft.ML.Data/Transforms/KeyToVector.cs#L339-L345\r\n\r\nThis leads to an interesting decision, because from a certain perspective, the addition of the metadata in the `ITransformer` code is correct (and, at the time it was originally written, some years I believe before the concept of `IEstimator` and `SchemaShape` was introduced, was in fact unambiguously correct, since there was no concept as we have now of pre-`Fit` schema validation.) But in the world of `IEstimator`, we are using some information that in some cases could be used *post*-`Fit` in the sense that it can only be expressed in a `DataViewSchema`, not a `SchemaShape` -- that this is a vector type that happens to have length exactly one -- and that in many cases could not even be known pre-`Fit` under some circumstnaces. (E.g., consider a value-to-key mapping estimator that winds up finding only one value.)\r\n\r\nSo, the `IEstimator` makes no claim that the `IsNormalized` data is there, but due to runtime logic that had existed prior to this time, it *is* in fact there.\r\n\r\nThis was known, I believe, the originators of the concept of `IEstimator` and `SchemaShape`, which at one point was deliberately made as, \"all right, we consider the claim in `SchemaShape` to be, in the area of annotations specifically, a *subset* of what is actually present among the non-hidden columns of `DatavViewSchema`. This is in fact what the relevant method called from `TestEstimatorCore` does. (Though, it is reversed from what is actually in the comment -- what it actually tests is that what is delivered is a superset of what is promised).\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3b576fe058ed4f4331018bbc3eabc1ac26219644/test/Microsoft.ML.TestFramework/DataPipe/TestDataPipeBase.cs#L151-L163\r\n\r\nThis notion of \"subsetting\" being the requirement is mentioned in the documentation and testing I could find on the relationship between `IEstimator` and `ITransformer` (see also here). But is superset actually the right thing? Let's consider another very important transformer: key-to-value. In that case, the estimators *relies* on a complete description of the `KeyValue` annotation to detect what the input type is! So in that case this mere talk of superset and subset becomes increasingly complex, because sometimes it is necessary, and sometimes it is not.\r\n\r\nIf we want an `ITransformer` and `IEstimator` to be paired, this suggests a mutuality of information. One of the core tenants of `IDataView` is composability, but the foundation of that composibility isn't because we've just created a system that works to just accomodate the set of components we ourselves wrote. (Indeed, this is [one thing that I argue](https://github.com/dotnet/machinelearning/blob/master/docs/code/IDataViewImplementation.md#urgency-in-adhering-to-invariants) in one of our documents about the `IDataView` system and why it works.)\r\n\r\nSo right now we have this system where *sometimes* annotations are subsets, but possibly not, depending on whether we consider a combination of annotations and estimators and transformers valuable. But, that seems like a pretty ad hoc way of engineering a system. How is it possible at all to make any meaningful statements about such a thing like, \"we have this requirement, but possibly not, it only depends on if we've written anything yet that cares.\"\r\n\r\nWhat does that mean? Are we prepared to make as part of the contract of `IEstimator` and `ITransformer` that some sorts of annotations are allowed to impact the schema (`KeyValues` must!), but that some are not (we effectively were having the assumption in a few places that `SlotNames` and `IsNormalized` could not, based on our uneven propagation of them)? That doesn't seem like a good idea. Are we allowed to evolve that definition in any way? So I wanted something much simpler, which leads me to this:\r\n\r\n# Proposed Schema Relationship Between an Estimator and its Transformer\r\n\r\nSo, to make the proposed relationship concrete, I'll consider the following code (for any `est` and `data`):\r\n\r\n```csharp\r\nIEstimator est = ...;\r\nIDataView data = ...;\r\nvar schema = data.Schema;\r\n\r\nvar promisedShape = est.GetOutputSchema(SchemaShape.Create(schema));\r\nvar deliveredShape = SchemaShape.Create(est.Fit(data).GetOutputSchema(schema));\r\n```\r\n\r\n1. If both constructions of `promisedShape` and `deliveredShape` succeed, they should be the same, that is, the two constructed `SchemaShape` objects should be indistinguishable (besides, of course, say, tests on reference equality).\r\n\r\n2. If the construction of `deliveredShape` would succeed, then the construction of `promisedShape` should succeed as well. (That is, the schema-propagation logic of an estimator should be no more strict than the schema-propagation logic of its produced transformer.)\r\n\r\nBoth represent a somewhat more \"restrictive\" view of the relationship of paired `IEstimator` and `ITransformer`. The previous state was sort of an ad hoc free for all. I have not yet\r\n established that it will be completely possible to do this; I know it will require some changes of behavior of some `ITransformer`s, *especially* around their annotations, but so far I have not seen any \"show stoppers.\" Maybe I will though.\r\n\r\n# Bugs\r\n\r\nUnfortunately due to the fact that this \"requirement\" is meaningless unless we test for it, it is best if I introduce the stricter test, *and* test for this, all at the same time. Doing so results in several test failures -- some were due to stricter requirements, but some were due to the fact that some `IEstimator` implementations were just plain wrong. I will outline in comments below those bugs that I have found, since I have not completed that work yet. (I have only fixed two tests so far, and each takes me a few hours. Regrettably, given the subtlety of the issues at stake, this is one of those situations that requires more finesse and consideration than other changes.)/+\r\n+\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3380","RelatedDescription":"Open issue \"Relationship between SchemaShape from IEstimator and DataViewSchema from its ITransformer, and resulting fallout\" (#3380)"},{"Id":"433988148","IsPullRequest":true,"CreatedAt":"2019-04-17T18:48:04","Actor":"wschin","Number":"3362","RawContent":null,"Title":"Upgrade matrix factorization samples","State":"closed","Body":"One more step toward #2522.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3362","RelatedDescription":"Closed or merged PR \"Upgrade matrix factorization samples\" (#3362)"},{"Id":"434428466","IsPullRequest":false,"CreatedAt":"2019-04-17T18:37:39","Actor":"PeterPann23","Number":"3378","RawContent":null,"Title":"Should I provide the schemas when creating a prediction engine?","State":"open","Body":"\r\n[Enter feedback here]\r\ncurrently, it takes quite a while to generate a prediction engine (56,863 ms). \r\nWould serialize and providing the schemas generated by the training improve the load times?\r\n\r\nA single prediction takes 1,452 ms. I have an I7 CPU with sufficient ram, is there a way to speed it up?\r\n\r\nI have added the input class. \r\n\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 992ff2a9-37e1-54ce-947b-67103207ce8e\r\n* Version Independent ID: 584449fa-50f6-85af-4c4c-3fb33cdedfbd\r\n* Content: [ModelOperationsCatalog.CreatePredictionEngine Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.modeloperationscatalog.createpredictionengine?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/ModelOperationsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/ModelOperationsCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/3378","RelatedDescription":"Open issue \"Should I provide the schemas when creating a prediction engine?\" (#3378)"},{"Id":"434426572","IsPullRequest":true,"CreatedAt":"2019-04-17T18:33:10","Actor":"yaeldekel","Number":"3377","RawContent":null,"Title":"Towards #3204 - documentation for ApproximatedKernelMappingEstimator","State":"open","Body":"Adhering to the template in #3204 (comment) for the ApproximatedKernelMapping estimator extensions, estimator, transformer.","Url":"https://github.com/dotnet/machinelearning/pull/3377","RelatedDescription":"Open PR \"Towards #3204 - documentation for ApproximatedKernelMappingEstimator\" (#3377)"},{"Id":"434416383","IsPullRequest":true,"CreatedAt":"2019-04-17T18:07:51","Actor":"Ivanidzo4ka","Number":"3376","RawContent":null,"Title":"Update xml documentation for Image estimators","State":"open","Body":"towards https://github.com/dotnet/machinelearning/issues/3204\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3376","RelatedDescription":"Open PR \"Update xml documentation for Image estimators\" (#3376)"},{"Id":"434406673","IsPullRequest":false,"CreatedAt":"2019-04-17T17:43:27","Actor":"singlis","Number":"3375","RawContent":null,"Title":"Add OnnxTransform test for variable length vectors","State":"open","Body":"## Issue\r\nWe need a test for OnnxTransform that uses variable length vectors as input.\r\n\r\n## Details\r\nThe OnnxTransform does not allow for input that is of variable length vector type, however variable length vectors are supported in ONNX. This check could be removed if we have tests that use a model that has a variable length vector. \r\n\r\nI initially tried via sci-kit learn to create an onnx model using the CountVectorizer which would result in variable length vectors, however loading this model in ml.net failed due to missing string support. \r\n\r\nNext attempt is to create a simple ONNX model using argmax and have it take multiple inputs, script is here for reference:\r\n\r\n```\r\nimport onnx\r\nfrom onnx import helper\r\nfrom onnx import AttributeProto, TensorProto, GraphProto\r\n\r\nheight=1\r\nwidth=1\r\nisize = height * width\r\n\r\ninput = helper.make_tensor_value_info('input', TensorProto.FLOAT , [-1, -1])\r\nargmax = helper.make_tensor_value_info('argmax', TensorProto.INT64, [-1])\r\nnodea = helper.make_node(\r\n    'ArgMax',  # node name\r\n    ['input'],  # inputs\r\n    ['argmax'],  # outputs\r\n    axis = 1,\r\n    keepdims = 0\r\n)\r\n\r\n# Create the graph (GraphProto)\r\ngraph_def = helper.make_graph(\r\n    [nodea],\r\n    'argmax',\r\n    [input],\r\n    [argmax]\r\n)\r\n\r\n# Create the model (ModelProto)\r\nmodel_def = helper.make_model(graph_def, producer_name='AIInfra')\r\n#\r\n#print('The model is:\\n{}'.format(model_def))\r\nonnx.save(model_def, 'test_unknowndimensions_float.onnx')\r\n```\r\n\r\nIf this does work, we will need to add the ONNX model to https://github.com/dotnet/machinelearning-testdata\r\n\r\nAs this generates the nuget file that contains our onnx test models.\r\n\r\nCC @jignparm ","Url":"https://github.com/dotnet/machinelearning/issues/3375","RelatedDescription":"Open issue \"Add OnnxTransform test for variable length vectors\" (#3375)"},{"Id":"434397048","IsPullRequest":true,"CreatedAt":"2019-04-17T17:19:24","Actor":"wschin","Number":"3374","RawContent":null,"Title":"FFM XML Doc","State":"open","Body":"Toward #2522 following #3218. \r\n","Url":"https://github.com/dotnet/machinelearning/pull/3374","RelatedDescription":"Open PR \"FFM XML Doc\" (#3374)"},{"Id":"434016423","IsPullRequest":true,"CreatedAt":"2019-04-17T15:47:43","Actor":"wschin","Number":"3368","RawContent":null,"Title":"Check size before allocation","State":"closed","Body":"This PR fixes #3361 by incorporating a minor fix from LIBMF.","Url":"https://github.com/dotnet/machinelearning/pull/3368","RelatedDescription":"Closed or merged PR \"Check size before allocation\" (#3368)"},{"Id":"434015508","IsPullRequest":true,"CreatedAt":"2019-04-17T14:57:02","Actor":"shauheen","Number":"3367","RawContent":null,"Title":"Setting metadata back to defaults for Microsoft.ML.DataView","State":"closed","Body":"Fixes #3366 ","Url":"https://github.com/dotnet/machinelearning/pull/3367","RelatedDescription":"Closed or merged PR \"Setting metadata back to defaults for Microsoft.ML.DataView\" (#3367)"},{"Id":"434011822","IsPullRequest":false,"CreatedAt":"2019-04-17T14:57:02","Actor":"shauheen","Number":"3366","RawContent":null,"Title":"Microsoft.ML.DataView metadat needs to be fixed","State":"closed","Body":"In #2974 we moved IDataView back to Microsoft.ML, but did not update the logo for the nuget back to ML.NET","Url":"https://github.com/dotnet/machinelearning/issues/3366","RelatedDescription":"Closed issue \"Microsoft.ML.DataView metadat needs to be fixed\" (#3366)"},{"Id":"434080076","IsPullRequest":true,"CreatedAt":"2019-04-17T03:53:10","Actor":"daholste","Number":"3372","RawContent":null,"Title":"[AutoML] Migrate AutoML back to its own solution, w/ NuGet dependencies","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3372","RelatedDescription":"Closed or merged PR \"[AutoML] Migrate AutoML back to its own solution, w/ NuGet dependencies\" (#3372)"},{"Id":"434048893","IsPullRequest":true,"CreatedAt":"2019-04-17T02:33:20","Actor":"srsaggam","Number":"3371","RawContent":null,"Title":"[AutoML] Minor changes to generated project in CLI based on feedback","State":"closed","Body":"\r\n1) Match the filenames with classes\r\n2) Dynamic generation of nuget packages for generated project\r\n3) nit picks in UI ","Url":"https://github.com/dotnet/machinelearning/pull/3371","RelatedDescription":"Closed or merged PR \"[AutoML] Minor changes to generated project in CLI based on feedback\" (#3371)"},{"Id":"434047461","IsPullRequest":true,"CreatedAt":"2019-04-17T01:08:30","Actor":"glebuk","Number":"3370","RawContent":null,"Title":"Increase Native build warning level  to W3 and fix build warnings","State":"open","Body":"Before, we actually only reported W1 warning level during native build.\r\nNow we warn on L3 warnings\r\nFixed three warnings from downcasting variables. In all cases the downcasting was deemed safe and replaced with ```static_cast<>```\r\nNote that all those warnings were deemed required to fix for compliance criteria.\r\nThis tracks #3370 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3370","RelatedDescription":"Open PR \"Increase Native build warning level  to W3 and fix build warnings\" (#3370)"},{"Id":"433999149","IsPullRequest":true,"CreatedAt":"2019-04-16T23:15:22","Actor":"daholste","Number":"3364","RawContent":null,"Title":"[AutoML] Rev AutoML public API; add required native references to AutoML projects","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3364","RelatedDescription":"Closed or merged PR \"[AutoML] Rev AutoML public API; add required native references to AutoML projects\" (#3364)"},{"Id":"434020866","IsPullRequest":false,"CreatedAt":"2019-04-16T22:59:57","Actor":"CESARDELATORRE","Number":"3369","RawContent":null,"Title":"Example code on how to load in-memory images into ONNX models and TensorFlow models","State":"open","Body":"I'm reviving these issues. Basically, we need example code on how  to load in-memory images into pipeline (for ONNX and TensorFlow models):\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/2495\r\n\r\nhttps://github.com/dotnet/machinelearning/issues/2121\r\n\r\nThere are many scenarios that require that way instead of loading from image files on the drive.\r\n\r\nScenarios:\r\n- Live-streaming images coming from a laptop camera for object detection ONNX models\r\n- Web/Service Http apps where images come through HTTP and need to be processed directly\r\n\r\nCan the team create example code of ONNX model and a second for a TensorFlow model where in-memory images are provided instead of loading from files on the drive?\r\n ","Url":"https://github.com/dotnet/machinelearning/issues/3369","RelatedDescription":"Open issue \"Example code on how to load in-memory images into ONNX models and TensorFlow models\" (#3369)"},{"Id":"434007827","IsPullRequest":false,"CreatedAt":"2019-04-16T22:11:30","Actor":"artidoro","Number":"3365","RawContent":null,"Title":"RowGroupColumnName of ranking trainers options class defaults to null","State":"open","Body":"The `Options` class of the ranking trainers (`FastTree` and `LightGbm`) defaults to `RowGroupColumnName = null`.\r\n\r\nThis is:\r\n1. Inconsistent with the simple constructor where `RowGroupColumnName` defaults to `GroupId`\r\n2. Not desirable as in ranking the row group is very important for correct training\r\n\r\nHere are the lines where the row group column name is set:\r\nhttps://github.com/dotnet/machinelearning/blob/738e5d5a5b90f8c3a93c391bb8b2e0bcdad35cd0/src/Microsoft.ML.Data/Training/TrainerInputBase.cs#L106-L110\r\n\r\nWe need to update the default and align it with the simple constructor.","Url":"https://github.com/dotnet/machinelearning/issues/3365","RelatedDescription":"Open issue \"RowGroupColumnName of ranking trainers options class defaults to null\" (#3365)"},{"Id":"433998658","IsPullRequest":true,"CreatedAt":"2019-04-16T21:43:14","Actor":"daholste","Number":"3363","RawContent":null,"Title":"[AutoML] Rev AutoML public API; add required native references to AutoML projects","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3363","RelatedDescription":"Closed or merged PR \"[AutoML] Rev AutoML public API; add required native references to AutoML projects\" (#3363)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-04-18T05:30:32.699829Z","RunDurationInMilliseconds":646}