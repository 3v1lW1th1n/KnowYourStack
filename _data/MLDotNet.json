{"Data":{"GitHub":{"Issues":[{"Id":"339677302","IsPullRequest":true,"CreatedAt":"2018-07-10T03:09:58","Actor":"dan-drews","Number":"514","RawContent":null,"Title":"WIP Remove Extra Code Comments","State":"open","Body":"Fixes #513\r\n\r\nThis is the first go-around at finding extra commented code sitting around. I'll circle back on more when I have a chance.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/514","RelatedDescription":"Open PR \"WIP Remove Extra Code Comments\" (#514)"},{"Id":"339673667","IsPullRequest":false,"CreatedAt":"2018-07-10T02:47:01","Actor":"dan-drews","Number":"513","RawContent":null,"Title":"Remove commented code","State":"open","Body":"While digging into the source code, I discovered a large amount of commented out code throughout the solution.\r\n\r\nUnless there is a reason behind this that I am not aware of, I think it is best to remove this. In a worst-case scenario, we have the git history to take care of this.\r\n\r\nOne example is in UnbufferedStream.cs, the following code is all commented out:\r\n\r\n    //}\r\n    //if (checkStream == null)\r\n    //{\r\n    //    checkStream = new FileStream(fileName, FileMode.Open, FileAccess.Read, FileShare.Read);\r\n    //}\r\n    //byte[] cbuf = new byte[count];\r\n    //int checkRead = checkStream.Read(cbuf, 0, cbuf.Length);\r\n    //if (checkRead != read)\r\n    //{\r\n    //    Console.WriteLine(\"!!! bytes read mismatch at \" + fileName + \": \"  + checkStream.Position + \" / \" + Position + \": \" +\r\n    //        \"read = \" + read + \"; checkRead = \" + checkRead);\r\n    //}\r\n    //else\r\n    //{\r\n    //    Console.WriteLine(\">>> bytes read match at \" + fileName + \": \" + checkStream.Position + \" / \" + Position + \": \" +\r\n    //        \"read = \" + read + \"; checkRead = \" + checkRead);\r\n    //}\r\n\r\nI haven't yet discovered the extent of this, but I think some work should be done on this.","Url":"https://github.com/dotnet/machinelearning/issues/513","RelatedDescription":"Open issue \"Remove commented code\" (#513)"},{"Id":"339640745","IsPullRequest":false,"CreatedAt":"2018-07-09T23:24:12","Actor":"mjmckp","Number":"512","RawContent":null,"Title":"Make grid search of parameter space more efficient","State":"open","Body":"The ML.Net library suffers from a lack of decoupling between data preparation and model training, required to do an efficient grid search over training parameters.\r\n\r\nThat is, ideally the API should be structured in such a way that it is possible to do the following:\r\n\r\n1. Prepare the data set once, so that it can be **re-used multiple times**.  As much as possible, any pre-training calculations should be done up front (or perhaps cached to be re-used).  For large data sets, the overhead of repeating this step each time is significant, taking as long or longer than the training itself.\r\n2. For algorithms with multiple training iterations, it should be straightforward to **retain the intermediate trained models** at each iteration (or at a specified set of iterations).  This way, it is then easy to compute metrics for the intermediate models on training and validation data sets, and ultimately select one of the intermediate models for use in production without having to re-run the training.\r\n\r\nFor example, consider training a LightGBM model.  This is the training method in `LightGbmTrainerBase.cs`:\r\n```\r\n        public void Train(RoleMappedData data)\r\n        {\r\n            Dataset dtrain;\r\n            CategoricalMetaData catMetaData;\r\n            using (var ch = Host.Start(\"Loading data for LightGBM\"))\r\n            {\r\n                using (var pch = Host.StartProgressChannel(\"Loading data for LightGBM\"))\r\n                    dtrain = LoadTrainingData(ch, data, out catMetaData);\r\n                ch.Done();\r\n            }\r\n            using (var ch = Host.Start(\"Training with LightGBM\"))\r\n            {\r\n                using (var pch = Host.StartProgressChannel(\"Training with LightGBM\"))\r\n                    TrainCore(ch, pch, dtrain, catMetaData);\r\n                ch.Done();\r\n            }\r\n            dtrain.Dispose();\r\n            DisposeParallelTraining();\r\n        }\r\n```\r\n\r\nIn order to address point 1) above, the `dtrain` object returned by `LoadTrainingData` should be available to be re-used.  This would require that the configuration parameters for data preparation are specified separately to those for training, instead of all thrown in together into the `LightGbmArguments` type.\r\n\r\nNow, in regards to point 2) above, note that the `TrainCore` method calls `WrappedLightGBMTraining.Train`, which has the following structure:\r\n```\r\n        public static Booster Train(IChannel ch, IProgressChannel pch,\r\n            Dictionary<string, object> parameters, Dataset dtrain, Dataset dvalid = null, int numIteration = 100,\r\n            bool verboseEval = true, int earlyStoppingRound = 0)\r\n        {\r\n            // create Booster.\r\n            Booster bst = new Booster(parameters, dtrain, dvalid);\r\n\r\n            for (int iter = 0; iter < numIteration; ++iter)\r\n            {\r\n                // training logic\r\n            }\r\n            return bst;\r\n        }\r\n```\r\nIn order to get the intermediate models, this method should return `Booster []` instead of just the final `Booster` (or perhaps instead in this case, the `Booster` object should support extraction of a prediction model which only contains the first `N` trees of the ensemble).\r\n\r\nPerhaps there is already the facility to do this in ML.Net, but I'm unable to find anything from my reading of the source or any of the examples.\r\n\r\nI think 99.9% of all machine learning research requires doing a parameter grid search at some stage, and hence this is essential functionality that should be as efficient as possible.","Url":"https://github.com/dotnet/machinelearning/issues/512","RelatedDescription":"Open issue \"Make grid search of parameter space more efficient\" (#512)"},{"Id":"339118249","IsPullRequest":false,"CreatedAt":"2018-07-09T22:59:41","Actor":"MrCSharp22","Number":"504","RawContent":null,"Title":"[BUG] Unable to load model file in MVC project. Same file works in console app.","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 1803 (17134.112)\r\n- **.NET Version (eg., dotnet --info)**: .Net Framework 4.6.1 (ASP.Net MVC hosted in local IIS, Console App)\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI have a console application that trains a ML model then writes it to a specific location. The model file is then used by an ASP.Net MVC website.\r\n\r\n- **What happened?**\r\nWhen the website calls ```PredictionModel.ReadAsync<T1, T2>(filePath);``` to load the model I get the following exception:\r\n\r\n\"Message\": \"An error has occurred.\",\r\n                            \"ExceptionMessage\": \"Couldn't load model: 'DataLoaderModel\\\\Transform_005\\\\SchemaBindableMapper\\\\InnerMapper\\\\Predictor'\",\r\n                            \"ExceptionType\": \"System.FormatException\",\r\n                            \"StackTrace\": \"   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\\r\\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\\r\\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\\r\\n   at Microsoft.ML.Runtime.Data.SchemaBindablePredictorWrapperBase..ctor(IHostEnvironment env, ModelLoadContext ctx)\\r\\n   at Microsoft.ML.Runtime.Data.SchemaBindablePredictorWrapper.Create(IHostEnvironment env, ModelLoadContext ctx)\"\r\n\r\n\r\n- **What did you expect?**\r\nI expected the model to load from the file as it has done in my initial tests in the console app.\r\nAfter getting that exception, I tried to load the model from a different console app to simply run a prediction and the same model file loaded successfully and provided me with predictions.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/504","RelatedDescription":"Closed issue \"[BUG] Unable to load model file in MVC project. Same file works in console app.\" (#504)"},{"Id":"338698075","IsPullRequest":true,"CreatedAt":"2018-07-09T20:53:00","Actor":"sharwell","Number":"499","RawContent":null,"Title":"Validate XML comments in test sources during builds","State":"closed","Body":"* CS1573, CS1591, and CS1712 are disabled in test code (documentation is not required)\r\n* Other documentation warnings are enabled (documentation, when included, must be syntactically and semantically correct)\r\n* Fixes cases where comments were incorrect in the current code\r\n\r\nRelated to #434\r\n\r\n⚠️ ~~Please do not rewrite/rebase/squash this pull request during the merge.~~ Edit: relaxing this request for this pull request. ⚠️ ","Url":"https://github.com/dotnet/machinelearning/pull/499","RelatedDescription":"Closed or merged PR \"Validate XML comments in test sources during builds\" (#499)"},{"Id":"339553215","IsPullRequest":false,"CreatedAt":"2018-07-09T18:09:58","Actor":"tauheedul","Number":"511","RawContent":null,"Title":"Suggestion - Make Machine Learning Models explainable by design with ML.NET","State":"open","Body":"It's often difficult to understand how Machine Learning applications come to a decision. Some Developers reuse model samples without knowing how it works and is considered a black box to many.\r\n\r\nThis is an opportunity for ML.NET to stand out and automatically make models explainable. \r\n- ML.NET framework could keep a stack trace of some kind that keeps an audit of decisions\r\n- This could be output to the application upon request. Much like you can output a trace of an Exception.\r\n- Extend these peek abilities in Visual Studio so you can inspect what 3rd party models are doing (just like Resharpers decompile capabilities with libraries)\r\n\r\nA framework that automatically keeps a self-audit of decisions would be way ahead of the rest and could help developers understand what the model is doing under the hood. Especially if they are relying on models supplied by third parties.\r\n\r\nThis could boost the development of ML using ML.NET and is exactly the kind of thing that made .NET such an easy framework to work with.","Url":"https://github.com/dotnet/machinelearning/issues/511","RelatedDescription":"Open issue \"Suggestion - Make Machine Learning Models explainable by design with ML.NET\" (#511)"},{"Id":"339547248","IsPullRequest":true,"CreatedAt":"2018-07-09T17:51:07","Actor":"sfilipi","Number":"510","RawContent":null,"Title":"XML strings for the documentation should live outside of the src code, in xml files. ","State":"open","Body":"Resolves #477  by moving the strings with the XML remarks, examples etc into a separate XML file. \r\nNow the actual classes and their C# Api counterparts share the path to the XML node that contains the documentation and the respective example. \r\n\r\nOn this PR, there are only two examples that are separate from the rest of the descriptive xml: the LogisticRegressionBinaryClassifier and LogisticRegressionClassifier, to give an idea of the infrastructure. \r\n\r\nThe rest of the examples are coming in the next PR, together with the rest of the documentation. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/510","RelatedDescription":"Open PR \"XML strings for the documentation should live outside of the src code, in xml files. \" (#510)"},{"Id":"339537461","IsPullRequest":false,"CreatedAt":"2018-07-09T17:19:14","Actor":"TomFinley","Number":"509","RawContent":null,"Title":"Direct API discussion: ITrainer proposed changes","State":"open","Body":"There are two changes proposed here for `ITrainer`. Due to the nature of the changes, assuming we agree they are good ideas, it really makes sense that they ought to happen in one go, since they involve changes to the same core functionality.\r\n\r\nI am quite certain the first thing is a good idea, but the second thing I am less certain about. (Of course my confidence could be misplaced. :smile:) People that occur to me as potentially being good contributors to the discussion would be @eerhardt , @zeahmed , @shauheen , @ericstj , @glebuk . (To be clear, this is not exclusionary. Anyone can and should feel free to comment. I just want these people to get flagged is all. :smile: )\r\n\r\n## `ITrainer<TData, TPred>.Train` ought to return the predictor\r\n\r\nCurrently in order to train a predictor, there is a two step process. You call `ITrainer.Train` then call `ITrainer.GetPredictor`. As near as I can tell this arrangement was meant as some scheme to support [online training](https://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L164), but of course that vision never came to pass, and if we were to actually support online training I have to imagine it would be through some separate interface anyway.\r\n\r\nThis arrangement seems unambiguously bad. It necessitates making `ITrainer` objects stateful for no particularly good reason. This complicates both the implementation and usage of the class, since (1) the caller can't do things like call `Train` multiple times even though a developer, seeing this interface, might reasonably suppose such a thing were possible and (2) the author of the `ITrainer` component has to protect against that misuse.\r\n\r\n## Get rid of `IValidatingTrainer`, `IIncrementalTrainer`, `IValidatingIncrementalTrainer`\r\n\r\n### The problem\r\n\r\nFirst let's talk about the problem...\r\n\r\nMost (all?) trainers implement `ITrainer<RoleMappedData>`, based on this interface here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L105\r\n\r\nWe have historically followed adding more inputs to the training process by declaring specialized interfaces that represent the Cartesian product of all possible permutations of inputs, as we see:\r\n\r\n* There was a discussion about adding a validation set. So we *doubled* the number of interfaces to two, `ITrainer`, and `IValidatingTrainer`.\r\n\r\n* Later on there was a discussion about adding continued training based on an initialization. So we again doubled the number of interfaces, introducing `IIncrementalTrainer` and `IValidatingIncrementalTrainer`.\r\n\r\n* There have been discussions of adding a test set to allow computing metrics as training progresses. Following the same strategy we would of course again double the number of interfaces (the full set being represented, perhaps, by `IValidatingIncrementalTestingTrainer`), for a total of eight.\r\n\r\n* If hypothetically we were to somehow allow for one more input beyond that, we'd have a total of sixteen interfaces.\r\n\r\nEtc. etc. That there is this exponential cost makes clear something is misdesigned. This has cost not only here and in the implementations of `ITrainer`, but in the usage as well. [Here we see a method that explores the cartesian product of possible interfaces so it can call the right one.](https://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Data/Commands/TrainCommand.cs#L287) It seems to me something is wrong here when just calling \"train\" requires a fairly non-obvious utility method to make sure we call the \"right\" train.\r\n\r\nThis issue incidentally is the primary reason why we haven't done anything like add support for test set metrics during training (despite the many requests). That is, it is not any technical difficulty with the idea itself, it's just that writing such a thing would make the code unmaintainable.\r\n\r\n### The possible solution(s)\r\n\r\n***So***: instead we might just have one interface, with one required input (the training dataset), and all these other things are optional.\r\n\r\nThere are two obvious ways I could imagine doing this, first explicitly as part of the method signature on `ITrainer<...>`:\r\n\r\n```csharp\r\npublic interface ITrainer<TDataset, TPredictor> {\r\n    TPredictor Train(TDataset train, TDataset validation = null, TDataset testSet = null, IPredictor initPredictor = null); }\r\n```\r\n\r\nOr else have some sort of context object. (I'm not married to any of these names, to be clear. :smile: )\r\n\r\n```csharp\r\npublic sealed class TrainContext {\r\n    public RoleMappedData Train { get; }\r\n    public RoleMappedData Validation { get; }\r\n    public RoleMappedData Test { get; }\r\n    public IPredictor InitPredictor { get; }\r\n}\r\n```\r\n\r\nand all trainers implement `ITrainer<TrainContext>` instead of `ITrainer<RoleMappedData>`.\r\n\r\nThe latter is perhaps a bit more awkward since it involves the addition of a new abstraction (the hypothetical `TrainContext`), but it is more flexible in a forward-looking sense, since if we add more \"stuff\" to how we initialize trainers, we won't break all existing `ITrainer` implementations. (My expectation is that trainers that can't support something would simply ignore.)","Url":"https://github.com/dotnet/machinelearning/issues/509","RelatedDescription":"Open issue \"Direct API discussion: ITrainer proposed changes\" (#509)"},{"Id":"339362364","IsPullRequest":false,"CreatedAt":"2018-07-09T08:59:52","Actor":"petterton","Number":"508","RawContent":null,"Title":"How to mix categorical and numerical features in LightGbm?","State":"open","Body":"I am implementing a LightGBM example where I have a mix of categorical and numerical features, and can't figure how this should be done in ML.NET.\r\n\r\nIn Python, LightGBM accepts a 'categorical_feature' parameter, giving the possibility to specify if a feature should be handled as categorical or numerical/ordinal. I can not find that this parameter is available in the ML.NET version. Could this be added?","Url":"https://github.com/dotnet/machinelearning/issues/508","RelatedDescription":"Open issue \"How to mix categorical and numerical features in LightGbm?\" (#508)"},{"Id":"339336146","IsPullRequest":false,"CreatedAt":"2018-07-09T07:34:17","Actor":"justinormont","Number":"507","RawContent":null,"Title":"PipelineInference creates invalid JSON","State":"open","Body":"Currently, PipelineInference creates an EntryPoint JSON graph beginning with:\r\n```json\r\n{'Nodes' : [{\r\n  \"Name\": \"TextAnalytics.TextTransform\",\r\n  \"Inputs\": {\r\n    \"Column\": {\r\n      \"Name\": \"text_tf\",\r\n      \"Source\": [\r\n        \"text\"\r\n      ]\r\n    },\r\n    \r\n}}]}\r\n```\r\n\r\nThe initial `'Nodes'` should have double-quotes like `\"Nodes\"`. JSON spec requires double quotes on keys. \r\n\r\nAs is, this fails a JSON.parse(), which makes the created JSON difficult to work with in NodeJS.\r\n\r\nSource of the issue:\r\nhttps://github.com/dotnet/machinelearning/blob/9d19d0e7058e328ead93f549205e5c329324ec05/src/Microsoft.ML.PipelineInference/PipelinePattern.cs#L276\r\n","Url":"https://github.com/dotnet/machinelearning/issues/507","RelatedDescription":"Open issue \"PipelineInference creates invalid JSON\" (#507)"},{"Id":"339287199","IsPullRequest":false,"CreatedAt":"2018-07-09T02:43:45","Actor":"g7rhythm","Number":"506","RawContent":null,"Title":"the link error","State":"open","Body":"Hi, the link “https://dot.net/ml” on the top is error ， add  some space in the end ，“https://dot.net/ml%20%20%20%20%20%20%20”","Url":"https://github.com/dotnet/machinelearning/issues/506","RelatedDescription":"Open issue \"the link error\" (#506)"},{"Id":"339284398","IsPullRequest":true,"CreatedAt":"2018-07-09T02:23:03","Actor":"CESARDELATORRE","Number":"505","RawContent":null,"Title":"Update Onnx Convert documentation, limited to ONNX-ML target platforms","State":"open","Body":"This PR is just updating the documentation/comments for the ML.NET Convert/export to ONNX.\r\nThe ML.NET export/convert feature uses ONNX-ML (not the regular ONNX specification). \r\nCurrently, the only target platform supported by ONNX-ML is Windows ML.\r\nThe current comments in the documentation have examples mentioning Apple CoreML and TensorFlow, which are currently not supported by ONNX-ML. \r\nThis PR is simply fixing the comments/documentation.\r\n\r\nFurther details on ONNX and ONNX-ML:\r\nONNX is not a single specification but two different variations of the standard. The neural-network-only (DNN) ONNX variant recognizes only tensors as input and output types, while ONNX-ML is a classical Machine Learning variant. \r\nONNX-ML is part of the ONNX standard that provides functionality for classic ML and pipelines. It is a superset of core ONNX.\r\nFrameworks like Caffe2 and CNTK will not support ONNX-ML since they are focused on DNN. \r\n\r\nApple CoreML and other ONNX backends might support ONNX-ML in the future, but they currently don't, so our example should not mention Apple CoreML and TensorFlow as sample target platforms to use after exporting the ONNX file. At least, not yet.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/505","RelatedDescription":"Open PR \"Update Onnx Convert documentation, limited to ONNX-ML target platforms\" (#505)"},{"Id":"339002308","IsPullRequest":false,"CreatedAt":"2018-07-06T16:38:57","Actor":"gilnahmias","Number":"503","RawContent":null,"Title":"Example of multiclass classification with random forest?","State":"open","Body":"Looking to train multiclass classification with random forest and hyperparameter tuning.\r\n\r\nTried (on dotnetcore with either the latest [LightGbm nuget](https://www.nuget.org/packages/Microsoft.ML.LightGBM/) or cloning the repo directly):\r\n```C#\r\nvar pipeline = new LearningPipeline();\r\n\r\npipeline.Add(new TextLoader(_dataFilePath).CreateFrom<MyDataClass>());\r\n\r\n // for features\r\npipeline.Add(new TextFeaturizer(\"My_Feature1_Vectorized\",\"My_Feature1\"));\r\npipeline.Add(new TextFeaturizer(\"My_Feature2_Vectorized\",\"My_Feature2\"));\r\n\r\n// for the label\r\npipeline.Add(new TextFeaturizer(\"Label_Vectorized\", \"Label\"));\r\n\r\n// ** CAN'T FIND FAST FOREST MULTI CLASS CLASSIFIER ** //\r\npipeline.Add(new LightGbmClassifier() { NumLeaves = 5, NumTrees = 5, MinDocumentsInLeafs = 2 });\r\n\r\nvar model = pipeline.Train<MyDataClass, MyPredictionClass>();\r\n```\r\n\r\nThis code crashes with `System.InvalidOperationException: Entry point 'Trainers.LightGbmClassifier' not found`\r\n\r\nAlso, if I'm missing any crucial steps (say around conversion from numbers to text or vice versa), please point them out.","Url":"https://github.com/dotnet/machinelearning/issues/503","RelatedDescription":"Open issue \"Example of multiclass classification with random forest?\" (#503)"},{"Id":"338929031","IsPullRequest":false,"CreatedAt":"2018-07-06T12:56:01","Actor":"rauhs","Number":"502","RawContent":null,"Title":"How to ignore a column","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Win 10\r\n- **.NET Version (eg., dotnet --info)**:  2.1.201\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI added a custom column in my input data type. It holds a `DateTime`. I need it for stats but not for learning. I never \"copy\" it to the `\"Features\"` column. I also added\r\n\r\n```\r\nnew ColumnDropper() { Column = new []{ \"PlannedStart\"} }\r\n```\r\n\r\n- **What happened?**\r\nI got an `ArgumentOutOfRangeException`: Could not determine an IDataView type for member ...\r\n\r\n- **What did you expect?**\r\n\r\nI expected it to just ignore the column.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/502","RelatedDescription":"Open issue \"How to ignore a column\" (#502)"},{"Id":"338798894","IsPullRequest":false,"CreatedAt":"2018-07-06T04:10:12","Actor":"nsulikowski","Number":"501","RawContent":null,"Title":"Load data without a class?","State":"open","Body":"Is there a way to load data without creating a c# class before?\r\nIn this case I had to create the class SentimentData ahead of time:\r\n\r\n`...CreateFrom<SentimentData>(separator: ',')`\r\n\r\nWhat if I want to determine the fields/data types at run time. E.g. From an excel range, or from a DataTable","Url":"https://github.com/dotnet/machinelearning/issues/501","RelatedDescription":"Open issue \"Load data without a class?\" (#501)"},{"Id":"338618669","IsPullRequest":true,"CreatedAt":"2018-07-05T23:41:58","Actor":"TomFinley","Number":"496","RawContent":null,"Title":"Role mapped improvements","State":"closed","Body":"Fixes #445.\r\n\r\n* Generally, favors creating `RoleMappedSchema`/`RoleMappedData` by actual constructors, since that's how objects are generally created.\r\n* Concentrated the actual globally useful \"conveniences\" inside the classes themselves, rather than in completely undiscoverable `Utils` classes.\r\n* Got rid of the `Create` and `CreateOpt` idiom that required that we declare every creation method *twice* in favor of a simpler `bool` parameter on the constructors.\r\n* Added documentation.","Url":"https://github.com/dotnet/machinelearning/pull/496","RelatedDescription":"Closed or merged PR \"Role mapped improvements\" (#496)"},{"Id":"338702162","IsPullRequest":false,"CreatedAt":"2018-07-05T19:42:51","Actor":"mjmckp","Number":"500","RawContent":null,"Title":"GPU support for LightGBM wrapper","State":"open","Body":"The LightGBM wrapper currently only allows CPU based training, however it is possible to build an instance of the LightGBM dlls which [support GPU training.](https://github.com/Microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-gpu-version).","Url":"https://github.com/dotnet/machinelearning/issues/500","RelatedDescription":"Open issue \"GPU support for LightGBM wrapper\" (#500)"},{"Id":"338644435","IsPullRequest":false,"CreatedAt":"2018-07-05T16:27:16","Actor":"ErcinDedeoglu","Number":"498","RawContent":null,"Title":"Which model type should I use for financial price prediction?","State":"open","Body":"First of all thank you for the great library!\r\nMy question is simple: I want to predict next period price with pre-computed history values.\r\nI have over 30 rows data for each price.\r\nPrice and datas are decimal.\r\n\r\nFor example history:\r\nIndicator1 - Indicator 2 - Indicator 3 - Price - **Trend**\r\n10,01121 - 23,56540 - 12.00001 - 12,23321 - UP\r\n9,00001 - 3,00040 - 2.00001 - 1,23300 - DOWN\r\n...\r\n...\r\nAnd data to predict coming like\r\n8,11211 - 1,00020 - 0.00021 - 3,5555 - ?\r\nI want to get **TREND** field.\r\n\r\nWhich model should I use? Any example will be perfect?\r\nRegards!","Url":"https://github.com/dotnet/machinelearning/issues/498","RelatedDescription":"Open issue \"Which model type should I use for financial price prediction?\" (#498)"},{"Id":"338641876","IsPullRequest":false,"CreatedAt":"2018-07-05T16:19:57","Actor":"shauheen","Number":"497","RawContent":null,"Title":"Missing MKL","State":"open","Body":"Issue #234 , was resolved by disabling the modules that had a dependance on MKL. We need to address the missing MKL issue.","Url":"https://github.com/dotnet/machinelearning/issues/497","RelatedDescription":"Open issue \"Missing MKL\" (#497)"},{"Id":"338584198","IsPullRequest":false,"CreatedAt":"2018-07-05T13:52:10","Actor":"BernhardGlueck","Number":"495","RawContent":null,"Title":"Time Series support","State":"open","Body":"Quick question: I know that right now there is no real support for time series.... ( both on the data input side as well as in the implemented Learners ) \r\n\r\nHowever before i could often solve my case by windowing over the sequential stream of events i wanted to base my prediction on e.g \r\n\r\nFor this i would need Collection support for columns... is this possible right now ? \r\n\r\nE.g \r\n\r\nclass MeasurementTick  {\r\n\r\n   DateTime TimeStamp { get; set; }\r\n   float Temperature { get; set; }\r\n   float Pressure { get; set; }\r\n}\r\n\r\nclass FixedSizeMeasureMentWindow {\r\n   IList<MeasurementTick> Ticks { get; set; }\r\n}\r\n\r\nUsing FixedSizeMeasureMentWindow as my input data type.... \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/495","RelatedDescription":"Open issue \"Time Series support\" (#495)"},{"Id":"338487375","IsPullRequest":false,"CreatedAt":"2018-07-05T09:05:59","Actor":"petterton","Number":"494","RawContent":null,"Title":"Not able to use LightGBM in .NET Framework 4.6.1","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n.NET Framework 4.6.1\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am using the 0.3.0 version NuGet package.\r\nI tried to replicate the example at https://www.microsoft.com/net/learn/apps/machine-learning-and-ai/ml-dotnet/get-started/windows, with the small change of replacing the classifier with a LightGbmClassifier. I was able to do this with a .NET Core application (after I understood I had to add the Microsoft.ML.LightGBM Nuget package). But I need to run this in a full .NET framework application. So I followed the same procedure for a .NET Framework 4.6.1 console application. But this failed when I tried to add the Microsoft.ML.LightGBM Nuget package.\r\n\r\n- **What happened?**\r\nMicrosoft.ML.LightGBM depends on 'LightGBM 2.1.2.2', and I get the following error:\r\n\r\n\"Could not install package 'LightGBM 2.1.2.2'. You are trying to install this package into a project that targets '.NETFramework,Version=v4.6.1', but the package does not contain any assembly references or content files that are compatible with that framework. For more information, contact the package author.\"\r\n\r\n\r\n- **What did you expect?**\r\nI expected this to work, ML.NET generally works on .NET Framework 4.6.1, right?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/494","RelatedDescription":"Open issue \"Not able to use LightGBM in .NET Framework 4.6.1\" (#494)"},{"Id":"338425893","IsPullRequest":false,"CreatedAt":"2018-07-05T04:47:12","Actor":"hellothere33","Number":"493","RawContent":null,"Title":"Concatenating a range of columns in the data class into the \"Features\" column will lead to exception thrown","State":"open","Body":"Hello!\r\n\r\nI often have CSV files with more than 50 float columns, so it's not feasible to specify each of them individually. I've failed to load them in one shot using a range/sweep specifier. To test things out in smaller scale, I used the Iris example because it ends with 4 float columns.\r\n\r\nHere's the data class, I only added 2 lines at the end:\r\n\r\n```\r\n    public class IrisData\r\n    {\r\n        [Column(\"0\")]\r\n        public float Label;\r\n\r\n        [Column(\"1\")]\r\n        public float SepalLength;\r\n\r\n        [Column(\"2\")]\r\n        public float SepalWidth;\r\n\r\n        [Column(\"3\")]\r\n        public float PetalLength;\r\n\r\n        [Column(\"4\")]\r\n        public float PetalWidth;\r\n\r\n        [Column(\"1-*\", name: \"Features\")] // New\r\n        public float[] Features; // New\r\n    }\r\n```\r\n\r\nHere's the simplified pipeline, I only commented out the normal way with ColumnConcatenator:\r\n```\r\n            var pipeline = new LearningPipeline();\r\n            pipeline.Add(new TextLoader(DataPath).CreateFrom<IrisData>(useHeader: true, separator: '\\t'));\r\n            //pipeline.Add(new ColumnConcatenator(\"Features\",\r\n            //                                    \"SepalLength\",\r\n            //                                    \"SepalWidth\",\r\n            //                                    \"PetalLength\",\r\n            //                                    \"PetalWidth\"));\r\n            pipeline.Add(new KMeansPlusPlusClusterer() { K = 3 });\r\n            var model = pipeline.Train<IrisData, ClusterPrediction>();\r\n```\r\n\r\nSo it worked when I load each column individually and then concatenate them in the pipeline, like the sample code says. But it always throws an exception when I use my above code:\r\n\r\n```\r\nSystem.Reflection.TargetInvocationException: 'Exception has been thrown by the target of an invocation.'\r\nInner Exception:\r\nInvalidOperationException: Column 'Features' is a vector of variable size, which is not supported for normalizers\r\n```\r\n\r\nPlease help! Thank you!\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n=============================================================\r\n### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .Net Framework 4.7.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**: trying to load a CSV's multiple float columns by specifying a range in the data class's declaration, for example: \"1-4\"\r\n- **What happened?**: I got an exception on the Features' size. \r\n- **What did you expect?**: that concatenating columns by specifying a range would work the same as adding a ColumnConcatenator to the pipeline.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/493","RelatedDescription":"Open issue \"Concatenating a range of columns in the data class into the \"Features\" column will lead to exception thrown\" (#493)"},{"Id":"338413394","IsPullRequest":true,"CreatedAt":"2018-07-05T03:10:36","Actor":"mjmckp","Number":"492","RawContent":null,"Title":"Add options to enable use of GPU with LightGBM","State":"open","Body":"Note: requires a [build of LightGBM with GPU support](https://github.com/Microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-gpu-version).  Addresses #500","Url":"https://github.com/dotnet/machinelearning/pull/492","RelatedDescription":"Open PR \"Add options to enable use of GPU with LightGBM\" (#492)"},{"Id":"338102214","IsPullRequest":true,"CreatedAt":"2018-07-04T01:32:11","Actor":"zeahmed","Number":"491","RawContent":null,"Title":"Added convenience constructors for set of transforms.","State":"open","Body":"This PR fixes #487.\r\n\r\nConvenience constructors are added for the following transforms. \r\n\r\n- ChooseColumnsTransform.cs\r\n- ConvertTransform.cs\r\n- DropSlotsTransform.cs\r\n- GenerateNumberTransform.cs\r\n- HashTransform.cs\r\n- KeyToValueTransform.cs\r\n- KeyToVectorTransform.cs\r\n- LabelConvertTransform.cs\r\n- LabelIndicatorTransform.cs\r\n- RangeFilter.cs\r\n- ShuffleTransform.cs\r\n- SkipTakeFilter.cs\r\n- TermTransform.cs\r\n","Url":"https://github.com/dotnet/machinelearning/pull/491","RelatedDescription":"Open PR \"Added convenience constructors for set of transforms.\" (#491)"},{"Id":"338012530","IsPullRequest":true,"CreatedAt":"2018-07-03T22:29:43","Actor":"Ivanidzo4ka","Number":"488","RawContent":null,"Title":"Hide argument object in ensemble multivoting","State":"closed","Body":"fixes #443 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/488","RelatedDescription":"Closed or merged PR \"Hide argument object in ensemble multivoting\" (#488)"},{"Id":"338061231","IsPullRequest":true,"CreatedAt":"2018-07-03T22:03:07","Actor":"JoshuaLight","Number":"490","RawContent":null,"Title":"Removed `data` solution-folder from solution files.","State":"closed","Body":"As mentioned in #475, files in `data` solution-folder currently are not presented in repository, so it's probably worth to remove them.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/490","RelatedDescription":"Closed or merged PR \"Removed `data` solution-folder from solution files.\" (#490)"},{"Id":"338041406","IsPullRequest":false,"CreatedAt":"2018-07-03T20:20:13","Actor":"Ivanidzo4ka","Number":"489","RawContent":null,"Title":"Image support in IDataView and transforms.","State":"open","Body":"Currently only way to work with images is by manually loading pixels arrays into array field in the class and wrap that class into collection data source. Which is not pleasant.\r\n\r\nI propose to add support for type Image in DataView type system which can be based on System.Drawing.Bitmap This way user can specify Bitmap image in their class and it will be properly consumed by CollectionDataSource. \r\n\r\nAlso I suggest to implement transform which would accept column with file paths and load this images during pipeline execution. Which allow you to save memory in case of streaming dataview, some trainers support streaming structure of data, and this way you need to keep in memory only one image for current row instead of images for all rows.\r\n\r\nSince quite often you need to modify images (Re-scale them, transform image into Grayscale, etc) it make sense to keep Image format as \"image\" and not directly convert it into vector of floats which we require for learners. Which means we need transform which would convert Image type into feature vector.\r\n\r\nTo summarize I propose to create following:\r\n\r\nImage type based on Bitmap.\r\nImageLoader transform\r\nImageResizer transform\r\nImageGrayscale transform\r\nImageToPixels transform \r\n\r\n@shauheen @TomFinley  @glebuk \r\n","Url":"https://github.com/dotnet/machinelearning/issues/489","RelatedDescription":"Open issue \"Image support in IDataView and transforms.\" (#489)"},{"Id":"338010262","IsPullRequest":false,"CreatedAt":"2018-07-03T18:32:00","Actor":"zeahmed","Number":"487","RawContent":null,"Title":"[Part 2] Create convenience constructor for the listed Transforms.","State":"open","Body":"This work item is related to #371 and is the 2nd work item in series of creating convenience constructor (cf. #380). In this work item, convenience constructors will be created following set of transforms. \r\n\r\n- ChooseColumnsTransform.cs\r\n- ConvertTransform.cs\r\n- DropSlotsTransform.cs\r\n- GenerateNumberTransform.cs\r\n- HashTransform.cs\r\n- KeyToValueTransform.cs\r\n- KeyToVectorTransform.cs\r\n- LabelConvertTransform.cs\r\n- LabelIndicatorTransform.cs\r\n- RangeFilter.cs\r\n- ShuffleTransform.cs\r\n- SkipTakeFilter.cs\r\n- TermTransform.cs\r\n","Url":"https://github.com/dotnet/machinelearning/issues/487","RelatedDescription":"Open issue \"[Part 2] Create convenience constructor for the listed Transforms.\" (#487)"},{"Id":"337997566","IsPullRequest":true,"CreatedAt":"2018-07-03T18:19:26","Actor":"zeahmed","Number":"486","RawContent":null,"Title":"Reverted 'new' modifier to be first in statement.","State":"closed","Body":"This is a small fix left over from PR 478. Following [C# documentation](https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-studio-2010/435f1dw2(v%3dvs.100)), placing 'new' modifier to be first in the statement.","Url":"https://github.com/dotnet/machinelearning/pull/486","RelatedDescription":"Closed or merged PR \"Reverted 'new' modifier to be first in statement.\" (#486)"},{"Id":"337976972","IsPullRequest":true,"CreatedAt":"2018-07-03T16:44:21","Actor":"markusweimer","Number":"485","RawContent":null,"Title":"Issue 434: Fixed imprecise `cref`s in XML Docs","State":"open","Body":"This fixes a couple of dangling `cref` in the XML Docs. This commit doesn't contain functional changes to the code.\r\n\r\nIssue:\r\n  This closes #434","Url":"https://github.com/dotnet/machinelearning/pull/485","RelatedDescription":"Open PR \"Issue 434: Fixed imprecise `cref`s in XML Docs\" (#485)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-07-10T05:30:43.7859554Z","RunDurationInMilliseconds":1112}