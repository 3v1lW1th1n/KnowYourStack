{"Data":{"GitHub":{"Issues":[{"Id":"347516565","IsPullRequest":true,"CreatedAt":"2018-08-03T20:46:18","Actor":"eerhardt","Number":"645","RawContent":null,"Title":"Bump the master branch to 0.5","State":"closed","Body":"Now that we have branched for 0.4, we need to bump the master branch to the next version.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/645","RelatedDescription":"Closed or merged PR \"Bump the master branch to 0.5\" (#645)"},{"Id":"347516249","IsPullRequest":true,"CreatedAt":"2018-08-03T20:38:05","Actor":"eerhardt","Number":"644","RawContent":null,"Title":"Merge master into release/preview for 0.4","State":"closed","Body":"This is a merge of the master branch.  It is basically a straight \"accept master\" on any conflict.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/644","RelatedDescription":"Closed or merged PR \"Merge master into release/preview for 0.4\" (#644)"},{"Id":"347432074","IsPullRequest":true,"CreatedAt":"2018-08-03T15:55:11","Actor":"eerhardt","Number":"643","RawContent":null,"Title":"Fix official build failure","State":"closed","Body":"Now that the HalLearners nuget package doesn't have a PackageReference to MlNetMklDeps, the MlNetMklDeps package is no longer getting restored during the official build. Since HalLearners needs the license file from MlNetMklDeps, it is failing to build the nuget package.\r\n\r\nThe fix is to restore all project before building the packages.","Url":"https://github.com/dotnet/machinelearning/pull/643","RelatedDescription":"Closed or merged PR \"Fix official build failure\" (#643)"},{"Id":"347138582","IsPullRequest":true,"CreatedAt":"2018-08-03T13:47:57","Actor":"eerhardt","Number":"635","RawContent":null,"Title":"Copy native assemblies for packages.config","State":"closed","Body":"Whenever we have native assemblies in our nuget packages, we need to have special build logic in order for it to work on packages.config.\r\n\r\nWe already had that logic for Microsoft.ML, but were missing it for CpuMath and HalLearners.\r\n\r\nFix #633","Url":"https://github.com/dotnet/machinelearning/pull/635","RelatedDescription":"Closed or merged PR \"Copy native assemblies for packages.config\" (#635)"},{"Id":"347096233","IsPullRequest":false,"CreatedAt":"2018-08-03T13:47:57","Actor":"eerhardt","Number":"633","RawContent":null,"Title":"CpuMath and HalLearners packages don't work with packages.config","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows.  Visual Studio 15.8\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreate a new NET Framework console app.  Ensure it uses `packages.config`.\r\nInstall the `Microsoft.ML` package.\r\nTry to run through a ML.NET scenario - https://www.microsoft.com/net/learn/machine-learning-and-ai/get-started-with-ml-dotnet-tutorial\r\n\r\n- **What happened?**\r\n```\r\nUnhandled Exception: System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.DllNotFoundException: Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Runtime.Internal.CpuMath.Thunk.SumSqU(Single* ps, Int32 c)\r\n   at Microsoft.ML.Runtime.Learners.SdcaTrainerBase`1.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Runtime.Learners.LinearTrainerBase`1.Train(TrainContext context)\r\n   at Microsoft.ML.Runtime.Training.TrainerBase`1.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context)\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, String name, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor)\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples)\r\n   at Microsoft.ML.Runtime.Learners.Sdca.TrainMultiClass(IHostEnvironment env, Arguments input)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n```\r\n\r\n- **What did you expect?**\r\nIt should work\r\n\r\n### Notes\r\n\r\nThis is because we need the same .targets files we have in the `Microsoft.ML` package:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f6934a0705b8ff2b7ad2d51c9cf4f82f7d1cbd94/pkg/Microsoft.ML/build/netstandard2.0/Microsoft.ML.props#L7-L15\r\n","Url":"https://github.com/dotnet/machinelearning/issues/633","RelatedDescription":"Closed issue \"CpuMath and HalLearners packages don't work with packages.config\" (#633)"},{"Id":"347352033","IsPullRequest":false,"CreatedAt":"2018-08-03T10:56:18","Actor":"aho81","Number":"642","RawContent":null,"Title":"How to build transform-only pipelines","State":"open","Body":"I found comments, that there should be a way to use transforms without the need of a trainer/learner (i.e., building a \"processing / transform - pipeline instead of an LearningPipeline, cp.  https://github.com/dotnet/machinelearning/issues/259#issuecomment-393362342). Unfourtunately, I could not find out, how to achieve this.\r\n\r\nIn my usecase, I want to determine similarity of documents with n-gram vectorization and cosine distance. The functionalty for featurization is given by the TextFeaturizer (https://docs.microsoft.com/de-de/dotnet/api/microsoft.ml.transforms.textfeaturizer). In this usecase I don't want to do a training (yet), but am interessted in the output in the result of the TextFeaturizer itself.\r\n\r\nAccessing the results of partial steps could be helpful for debugging LearningPipelines too (cp. discussion here: https://github.com/dotnet/machinelearning/issues/259).\r\n@TomFinley \r\n","Url":"https://github.com/dotnet/machinelearning/issues/642","RelatedDescription":"Open issue \"How to build transform-only pipelines\" (#642)"},{"Id":"347270264","IsPullRequest":true,"CreatedAt":"2018-08-03T06:04:58","Actor":"codemzs","Number":"641","RawContent":null,"Title":"Make model path mandatory in export to ONNX.","State":"open","Body":"fixes #423 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/641","RelatedDescription":"Open PR \"Make model path mandatory in export to ONNX.\" (#641)"},{"Id":"347204945","IsPullRequest":false,"CreatedAt":"2018-08-03T02:00:39","Actor":"codemzs","Number":"638","RawContent":null,"Title":"Package mkl binaries with Hal Learners nuget.","State":"closed","Body":"Native SymSGD code depends on Mkl libraries during runtime hence both of them should be packaged together to prevent dependency not found issue on macOS and linux.","Url":"https://github.com/dotnet/machinelearning/issues/638","RelatedDescription":"Closed issue \"Package mkl binaries with Hal Learners nuget.\" (#638)"},{"Id":"347131475","IsPullRequest":true,"CreatedAt":"2018-08-03T02:00:39","Actor":"codemzs","Number":"634","RawContent":null,"Title":"package mkl lib with hal learners.","State":"closed","Body":"fixes #638 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/634","RelatedDescription":"Closed or merged PR \"package mkl lib with hal learners.\" (#634)"},{"Id":"347222797","IsPullRequest":true,"CreatedAt":"2018-08-03T00:58:01","Actor":"Ivanidzo4ka","Number":"640","RawContent":null,"Title":"WIP Sketch to support read-only properties","State":"open","Body":"something something #631 ","Url":"https://github.com/dotnet/machinelearning/pull/640","RelatedDescription":"Open PR \"WIP Sketch to support read-only properties\" (#640)"},{"Id":"347221914","IsPullRequest":true,"CreatedAt":"2018-08-03T00:51:52","Actor":"Zruty0","Number":"639","RawContent":null,"Title":"API 'getting started' examples","State":"open","Body":"These examples currently do not compile, they depend on both Estimators and static type checks, but let's at least agree that we can all stand behind them in terms of simplicity.\r\n\r\nDo not merge, this is a discussion-only PR.","Url":"https://github.com/dotnet/machinelearning/pull/639","RelatedDescription":"Open PR \"API 'getting started' examples\" (#639)"},{"Id":"346847604","IsPullRequest":true,"CreatedAt":"2018-08-02T22:33:10","Actor":"shauheen","Number":"629","RawContent":null,"Title":"Merge master into release/preview branch for v0.4","State":"closed","Body":"This PR is cumulatively merging master into release branch in preparation for v0.4 release.","Url":"https://github.com/dotnet/machinelearning/pull/629","RelatedDescription":"Closed or merged PR \"Merge master into release/preview branch for v0.4\" (#629)"},{"Id":"347141692","IsPullRequest":true,"CreatedAt":"2018-08-02T22:13:38","Actor":"eerhardt","Number":"636","RawContent":null,"Title":"Change the linux official build queue from test to production.","State":"closed","Body":"We were using a \"test\" build queue because of some limitations with the build lab.  Those limitations are now fixed, so we can start using the \"production\" build queue again.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/636","RelatedDescription":"Closed or merged PR \"Change the linux official build queue from test to production.\" (#636)"},{"Id":"346817676","IsPullRequest":true,"CreatedAt":"2018-08-02T21:36:20","Actor":"Ivanidzo4ka","Number":"628","RawContent":null,"Title":"Fixes in documentation for wordembedding","State":"closed","Body":"Better example, and replace html encoding to xml encoding\r\n","Url":"https://github.com/dotnet/machinelearning/pull/628","RelatedDescription":"Closed or merged PR \"Fixes in documentation for wordembedding\" (#628)"},{"Id":"347167178","IsPullRequest":false,"CreatedAt":"2018-08-02T20:43:10","Actor":"sfilipi","Number":"637","RawContent":null,"Title":"Per component examples in the repo,  to reference in the documentation","State":"open","Body":"Our examples in the documentation currently aren't very comprehensive, because they live in XML, and it is not easily maintainable to write longer code snippets embedded in XML. \r\n\r\nThe infrastructure for docs.microsoft.com supports cross-referencing other files within the XML. \r\nThose other files can be C# files and have more fully fledged examples, that compile. \r\n\r\nSetup another folder within Microsoft.ML.Tests, similar to scenarios, that will contain examples for each components. More than one component can be used for the scenario, but they should be kept simple. \r\nThose methods can be reused by the tests.\r\n\r\nThis issue will be considered resolved after  setting up one such example end-to-end. ","Url":"https://github.com/dotnet/machinelearning/issues/637","RelatedDescription":"Open issue \"Per component examples in the repo,  to reference in the documentation\" (#637)"},{"Id":"346669988","IsPullRequest":true,"CreatedAt":"2018-08-02T20:32:53","Actor":"sfilipi","Number":"625","RawContent":null,"Title":"Docs formatting","State":"closed","Body":"Incorporating the changes the content developing team made to the ml.net doc repo: https://github.com/dotnet/ml-api-docs\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/625","RelatedDescription":"Closed or merged PR \"Docs formatting\" (#625)"},{"Id":"346392942","IsPullRequest":true,"CreatedAt":"2018-08-02T20:01:39","Actor":"safern","Number":"621","RawContent":null,"Title":"Remove agent.os demands on windows ci","State":"closed","Body":"All the machines in this pool are guaranteed to be Windows_NT and now that the pool was made big enough not all of them define an agent.os property, so if they don't have one it will only use the machines that define that only. So in order to have more machines available and make CI faster, let's remove that statement and bump parallel to 4.\r\n\r\nThis was causing Windows builds to be slow and not ran in parallel.\r\n\r\ncc: @chcosta @eerhardt \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/621","RelatedDescription":"Closed or merged PR \"Remove agent.os demands on windows ci\" (#621)"},{"Id":"347092277","IsPullRequest":false,"CreatedAt":"2018-08-02T16:47:45","Actor":"TomFinley","Number":"632","RawContent":null,"Title":"Direct API: Static Typing of Data Pipelines","State":"open","Body":"Currently in all iterations of the pipeline concept, whether they be based on the v0.1 idiom of `LearningPipeline`, or the #371 proposal where `IDataView` is directly created, or the refinement of that in #581, or the convenience constructors, or whatever, there is always this idea of a pipeline being a runtime-checked thing, where each stage has some output schema with typed columns indexed by a string name, and all of this is known only at runtime -- at compile time, all the compiler knows is you have *some* estimator, or *some* data view, or something like that, but has no idea what is in it.\r\n\r\nThis makes sense from a practical perspective, since there are many applications where you cannot know the schema until runtime. E.g.: loading a model from a file, or loading a Parquet file, you aren't going to know anything until the code actually runs. So we want the underlying system to remain dynamically typed to serve those scenarios, and I do not propose changing that. That said, there are some definite usability costs:\r\n\r\n* Typos on those column names are found at runtime, which is unfortunate.\r\n* Application of the wrong transform or learner is found at runtime.\r\n* Discoverability is an issue. You just sort of have to know what transforms are applicable to your case, which is somewhat difficult since if we were to collect all the things you could apply to data (transform, train a learner), there are probably about 100 of these or thereabouts. Intellisense will be of no help to you here, because at compile time, the only thing the language knows is you have *some*.\r\n\r\nIt's sort of like working with `Dictionary<string, object>` as your central data structure, and an API that just takes `Dictionary<string, object>` everywhere. In a way that's arbitrarily powerful, but the language itself can give you no help at all about what you should do with it, which is kind of a pity since we have this nice statically typed language we're working in.\r\n\r\nSo: a statically typed helper API on top of this that was sufficiently powerful would help increase the confidence that if someone compiles it might run, and also give you some help in the form of proper intellisense of what you can do, while you are typing before you've run anything. Properly structured, if you had strong typing at the columnar level, nearly everything you can do can be automatically discoverable through intellisense. The documentation would correspondingly become a lot more focused.\r\n\r\nThe desire to have something like this is very old, but all prior attempts I recall ran into some serious problems sooner or later. In this issue I discuss such an API that I've been kicking around for a little bit, and at least so far it doesn't seem to have any show-stopping problems, at least so far as I've discovered in my initial implementations.\r\n\r\nThe following proposal is built on top of #581. (For those seeking actual code, the current exploratory work in progress is based out of [this branch](https://github.com/TomFinley/machinelearning/tree/tfinley/StrongPipe), which in turn is a branch based of @Zruty0's [branch here](https://github.com/Zruty0/machinelearning/tree/feature/estimators/src/Microsoft.ML.Core/Data).)\r\n\r\n# Simple Example\r\n\r\nIt may be that the easiest way to explain the proposal is to show a simple example, then explain it. This will be where we [train sentiment classification](https://github.com/dotnet/machinelearning/blob/89dfc82f5edcfe23015dc2c1291bc7a836188e80/test/Microsoft.ML.Tests/ScenariosWithDirectInstantiation/SentimentPredictionTests.cs#L24), though I've simplified the text settings to just the diacritics option\r\n\r\n```csharp\r\n// We load two columns, the boolean \"label\" and the textual \"sentimentText\".\r\nvar text = TextLoader.Create(\r\n    c => (label: c.LoadBool(0), sentimentText: c.LoadText(1)),\r\n    sep: '\\t', header: true);\r\n\r\n// We apply the text featurizer transform to \"sentimentText\" producing the column \"features\".\r\nvar transformation = text.CreateTransform(r =>\r\n    (r.label, features: r.sentimentText.TextFeaturizer(keepDiacritics: true)));\r\n\r\n// We apply a learner to learn \"label\" given \"features\", which will in turn produce\r\n// float \"score\", float \"probability\", and boolean \"predictedLabel\".\r\nvar training = transformation.CreateTransform(r =>\r\n    r.label.TrainLinearClassification(r.features))\r\n```\r\n\r\nAn alternative is we might do a continuous, non-segmented form (where they are all merged into a single thing):\r\n\r\n```csharp\r\nvar pipeline = TextLoader.Create(\r\n    c => (label: c.LoadBool(0), sentimentText: c.LoadText(1)),\r\n    sep: '\\t', header: true)\r\n    .ExtendWithTransform(r => (r.label, features: sentimentText.TextFeaturizer(keepDiacritics: true)))\r\n    .ExtendWithTransform(r => r.label.TrainLinearClassification(r.features));\r\n```\r\n\r\nor even the following:\r\n\r\n```csharp\r\nvar pipeline = TextLoader.Create(c =>\r\n    c.LoadBool(0).TrainLinearClassification(c.LoadText(1).TextFeaturizer(keepDiacritics: true)));\r\n```\r\n\r\n## Developer Story\r\n\r\nHere's how I imagine this playing out by someone maybe like me. So: first we have this `TextLoader.Create` method. (Feel free to suggest better names.)\r\n\r\n* The developer knows they have some data file, a TSV with two fields, a label, and some sentiment text. They write `TextLoader.Create`. The first argument is delegate, with a text loader context input, and is responsible for producing a tuple out of things composed out of that context. (Both the method signature, and the XML doc commentary, can explain this.) When they write `c => c.`, intellisense hits them with what they can do... `c.LoadBool`, `c.LoadDouble`, `c.LoadFloat`, etc. These methods produce things like `Scalar<bool>`, `Vector<bool>`, `Scalar<double>`, etc., depending on which is called, what overload is used, and so on. The developer ultimately creates a value-tuple out of all this stuff, with the bool and text loading values.\r\n\r\n* Then they have this object, here called `text`. So they type `text.`, and Intellisense pops up again. They know they want to do *something* with the data they've told the framework to load, and they see `CreateTransform` or `ExtendWithTransform`. Even if they haven't read a bit of documentation, that has enough of a name that they think, maybe, \"heck, maybe this is where I belong.\" So they choose that.\r\n\r\n* Again they are hit with a delegate. But this time, the input type is the value-tuple created in the loader. And they might type, `text.CreateTransform(r => r.label.TrainLinearClassification`. They try to feed in their `sentimentText`, but the compiler complains at them, saying, I want a `Vector<float>`, not a `Scalar<text>`. So maybe they now do `r.sentimentText.TextFeaturizer` as something sufficiently promising, since it has a promising sounding name and also returns the `Vector<float>` that the classifier claims to want. In VS it looks something like this (click the image to see zoomed in version, sorry that the screenshot is so wide):\r\n\r\n![image](https://user-images.githubusercontent.com/8295757/43598024-96326f6e-9638-11e8-992d-f72e882efe7d.png)\r\n\r\nGiven that setup, there is I think only one thing here that cannot be plausibly discovered via intellisense, or the XML docs that pop up with intellisense, and that is the fact that you would want to start the pipeline with something like `TextLoader.Create`. But I figure this will be so ubiquitous even in \"example 1\" that we can get away with it. There's also the detail about training happening through a \"label,\" and unless they happen to have the right type (`Scalar<bool>`) it simply won't show up for them. But someone reading documentation on the linear classifier would surely see that extension method and figure out what to do with it.\r\n\r\n# More Details\r\n\r\nNow we drill a little bit more into the shape and design of this API.\r\n\r\n## `PipelineColumn` and its subclasses\r\n\r\nAs we saw in the example, many transformations are indicated by the type of data. For this we have the abstract class `PipelineColumn`, which are manifested to the user through the following abstract subclasses.\r\n\r\n* `Scalar<>` represents a scalar-column of a particular type.\r\n* `Vector<>` represents a vector-valued column of a particular type, where the vector size will be fixed and known (though we might not know the actual size at compiled time)\r\n* `VarVector<>` is similar, but on known size.\r\n* `Key<>`, indicating a key type, which are essentially enumerations into a set.\r\n* `Key<,>`, indicating a key type with a known value, which are essentially enumerations into a set.\r\n* `VarKey<>` which is a key type of unknown cardinality. (These are fairly rare.)\r\n\r\n## `ValueTuple`s of `PipelineColumn`s\r\n\r\nThe pipeline  are the smallest granularity structures. Above that you have collections of these representing the values present at any given time, upon which you can apply more transformations. That value, as mentioned earlier, is a potentially nested value tuple. By potentially nested, what I mean is that you can have as many `ValueTuple`s as you want. So all of the following are fine, if we imagine that `a`, `b`, and `c` are each some sort of `PipelineColumn`:\r\n\r\n```csharp\r\n(a, b)\r\n(a, x: (b, c))\r\na\r\n```\r\n\r\nIn the first case the actual underlying data-view, when produced, would have two columns named `a` and `b`. In the second, there would be three columns, `a`, `x.b`, and `x.c`. In the last, since there is no way as near as I can tell to have a named `ValueTuple<>`, I just for now picked the name `Data`. (Note that in the case where value-tuples are present, the names of the items become the names of the output columns in the data-view schema.)\r\n\r\nThe reason for supporting nesting is, some estimators produce multiple columns (notably, in the example, the binary classification trainer produces three columns), and as far as I can tell there is no way to \"unpack\" a returned value-tuple into another value-tuple. Also it provides a convenient way to just bring along all the inputs, if we wanted to do so, by just assigning the input tuple itself as an item in the output tuple.\r\n\r\n## The Pipeline Components\r\n\r\nAt a higher level of the columns, and the (nested) tuples of columns, you have the objects that represent the pipeline components that describe each step of what you are actually doing with these things. That is, those objects mappings into those value tuples, or between them. To return to the example with `text` and `transformation` and `training`, these have the following types, in the sense that all the following statements in code would be true:\r\n\r\n```csharp\r\ntext is DataReaderEstimator<IMultiStreamSource,\r\n    (Scalar<bool> label, Scalar<string> sentimentText)>;\r\n\r\ntransformation is Estimator<\r\n    (Scalar<bool> label, Scalar<string> sentimentText),\r\n    (Scalar<bool> label, Scalar<float> features)>;\r\n\r\ntraining is Estimator<\r\n    (Scalar<bool> label, Scalar<float> features),\r\n    (Scalar<float> score, Scalar<float> probability, Scalar<bool> predictedLabel)>;\r\n```\r\n\r\nand also in those \"omnibus\" equivalents;\r\n\r\n```csharp\r\npipeline is DataReaderEstimator<IMultiStreamSource,\r\n    (Scalar<float> score, Scalar<float> probability, Scalar<bool> predictedLabel)>;\r\n```\r\n\r\nOne may note that the statically-typed API is strongly parallel to the structures proposed in #581. That is, for every core structure following the `IEstimator` idiom laid out in #581, I envision a strongly typed variant of each type. In the current working code, in fact, the objects actually implement those interfaces, but I might go to having them actually wrap them.\r\n\r\nLike the underlying dynamically typed objects, they can be combined in the usual way to form cohesive pipelines. So for example: one could take a `DataReaderEstimator<TIn, TA>` and an `Estimator<TA, TB>` to produce a `DataReaderEstimator<TIn, TB>`. (So for example, when I was using `ExtendWithTransform` instead of )\r\n\r\nThis duality is deliberate. While the *usage* of the static estimators will necessarily not resemble the dynamically typed estimators, based as it is on actual .NET types and identifiers, the structure that is being built up *is* an estimator based pipeline, and so will resemble it structurally. This duality enables one to use static-typing for as long as is convenient, then when done drop back down to the dynamically typed one. But you could also go in reverse, start with something dynamically typed -- perhaps a model loaded from a file -- essentially assert that this dynamically typed thing has a certain shape (which of course could only be checked at runtime), and then from then on continue with the statically-typed pipe. So as soon as the static typing stops being useful, there's no cliff -- you can just stop using it at that point, and continue dynamically.\r\n\r\nHowever if you can stay in the statically typed world, that's fine. You can fit a strongly typed `Estimator` to to get a strongly typed `Transformer`. You can then further get a strongly typed `DataView` out of a strongly typed `Transformer`. In the end this is still just a veneer, kind of like the `PredictionEngine` stuff, but it's a veneer that has a strong likelihood of working.\r\n\r\n## One or Two Implementation Details\r\n\r\nThe following is not something that most users will need to concern themselves with, and we won't go into too many details. However at least a loose idea of how the system works might help clear up some of the mystery.\r\n\r\nThe `Scalar<>`, `Vector<>`, etc. classes are abstract classes. The `PipelineColumn`s that are created from the helper extension methods have actual concrete implementations intended to be nested private classes in whatever estimator they're associated with. A user never sees those implementations. The component author is responsible for calling the `protected` constructor on those objects, so as to feed it the list of dependencies (what `PipelineColumn` it needs to exist before it would want to chain its own estimator), as well as a little factory object for now called a \"reconciler\" that the analyzer can call once it has satisfied those dependencies.\r\n\r\nThe analyzer itself takes the delegate. It constructs the input object, then pipes it thorugh the delegate. In the case of the estimator,  these are *not* the ones returned from any prior delegate (indeed we have no requirement that there *be* a prior delegate -- estimators can function as independent building blocks), but special instances made for that analysis task). The resulting output will be a value-tuple of `PipelineColumn`s, and by tracing back the dependencies, until we get the graph of dependencies.\r\n\r\nThe actual constructed inputs have no dependencies, and are assumed to just be there already. We then iteratively \"resolve\" dependencies -- we take all columns that have their dependencies resolved, and take some subset that all have the same \"reconciler.\" That reconciler is responsible for returning the actual `IEstimator`. Then anything that depends on *that* column gets resolved. And so on.\r\n\r\nIn this way these delegates are declarative structures. Each extension method provides these `PipelineColumn` implementations, which as objects, but it is the analyzer that goes ahead and figures out in what sequence those factory methods will be called, with what names, etc.\r\n\r\nIt might be more clear if we saw that actual engine.\r\n\r\nhttps://github.com/TomFinley/machinelearning/blob/8e0298f64f0a9f439bb83426b09e54967065793b/src/Microsoft.ML.Core/StrongPipe/BlockMaker.cs#L13\r\n\r\nThe system mostly has fake objects everywhere as standins right now just to validate the approach, so for example if I were to actually run the code in the first example, I get the following diagnostic output. (It should be relatively easy to trace back the diagnostic output.)\r\n\r\n```\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name sentimentText\r\nConstructing TextTransform estimator!\r\n    Will make 'features' out of 'sentimentText'\r\nExiting CreateTransform !!!\r\n\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name features\r\nConstructing LinearBinaryClassification estimator!\r\n    Will make 'score' out of 'label', 'features'\r\n    Will make 'probability' out of 'label', 'features'\r\n    Will make 'predictedLabel' out of 'label', 'features'\r\nExiting CreateTransform !!!\r\n```\r\n\r\nIf I had another example, like this:\r\n\r\n```csharp\r\nvar text = TextLoader.Create(\r\n    ctx => (\r\n    label: ctx.LoadBool(0),\r\n    text: ctx.LoadText(1),\r\n    numericFeatures: ctx.LoadFloat(2, 9)\r\n    ));\r\n\r\nvar transform = text.CreateTransform(r => (\r\n    r.label,\r\n    features: r.numericFeatures.ConcatWith(r.text.Tokenize().Dictionarize().BagVectorize())\r\n    ));\r\n\r\nvar train = transform.CreateTransform(r => (\r\n    r.label.TrainLinearClassification(r.features)\r\n```\r\n\r\nthen the output looks a little something like this:\r\n\r\n```\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name numericFeatures\r\nUsing input with name text\r\nConstructing WordTokenize estimator!\r\n    Will make '#Temp_0' out of 'text'\r\nConstructing Term estimator!\r\n    Will make '#Temp_1' out of '#Temp_0'\r\nConstructing KeyToVector estimator!\r\n    Will make '#Temp_2' out of '#Temp_1'\r\nConstructing Concat estimator!\r\n    Will make 'features' out of 'numericFeatures', '#Temp_2'\r\nExiting CreateTransform !!!\r\n\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name features\r\nConstructing LinearBinaryClassification estimator!\r\n    Will make 'score' out of 'label', 'features'\r\n    Will make 'probability' out of 'label', 'features'\r\n    Will make 'predictedLabel' out of 'label', 'features'\r\nExiting CreateTransform !!!\r\n```\r\n\r\nYou can sort of trace though what the analyzer is doing as it resolves dependencies, constructs `IEstimator`s, etc. etc. (Obviously the real version won't have all those little console writelines everywhere.)\r\n\r\n## Stuff Not Covered\r\n\r\nThere's a lot of stuff I haven't yet talked about. We create these blocks, how do we mix and match? What does the strongly typed `Transformer` or `DataView` look like? We talked about the text loader, what about sources that come from actual .NET objects? These we might cover in future editions on this, or in subsequent comments. But I think perhaps this writing has gone on long enough...\r\n\r\n/cc @Zruty0 , @ericstj , @eerhardt , @terrajobst , @motus ","Url":"https://github.com/dotnet/machinelearning/issues/632","RelatedDescription":"Open issue \"Direct API: Static Typing of Data Pipelines\" (#632)"},{"Id":"347079547","IsPullRequest":false,"CreatedAt":"2018-08-02T16:11:01","Actor":"Zruty0","Number":"631","RawContent":null,"Title":"Support read-only properties somehow","State":"open","Body":"As mentioned in #254 , now that we are supporting both fields and properties for the purposes of schema comprehension, it is possible to create properties that act like 'calculated fields':\r\n\r\n```c#\r\n        public class MyDataRow\r\n        {\r\n            private DateTime _dateTime;\r\n\r\n            public float Day { get { return _dateTime.Day; } }\r\n            public float DayOfWeek { get { return (float)_dateTime.DayOfWeek; } }\r\n            // etc\r\n        }\r\n```\r\nBut the above code is not sufficient, because currently we require both **getter and setter** to be present (and public). So you have to add the fake setters that throw.\r\n\r\nIs there a way to have it both ways somehow? We want to ensure that we'll be able to write to a property (in case when we use the underlying class as output), but we also want to allow read-only properties (in case when we use it as input).\r\n\r\n@TomFinley , do you have a recommendation? I am leaning towards allowing getter-only (or private-setter) properties to live, but only for input classes. This means that `SchemaDefinition` / `InternalSchemaDefinition` should have some `IsReadOnly` tracking, and corresponding error/warning messages in case we attempt to generate a 'poke' method for a read-only property .","Url":"https://github.com/dotnet/machinelearning/issues/631","RelatedDescription":"Open issue \"Support read-only properties somehow\" (#631)"},{"Id":"346184347","IsPullRequest":true,"CreatedAt":"2018-08-02T15:57:52","Actor":"dsyme","Number":"616","RawContent":null,"Title":"Allow use of property-based row classes in ML.NET","State":"closed","Body":"This is WIP to address \r\n* https://github.com/dotnet/machinelearning/issues/254 - \"Support ColumnAttribute on properties and not just fields\" and \r\n* https://github.com/dotnet/machinelearning/issues/180 - \"F# Records not compatible with ML .NET\"\r\n\r\nIt builds on #600 and you can see the added diff between #600 and this PR [here](https://github.com/dsyme/machinelearning/compare/fs1...dsyme:fs2?expand=1#diff-fe2d4189320f83b77c7f4f5dca8bb5d8R132)\r\n\r\nCopying comment from [here](https://github.com/dotnet/machinelearning/issues/254#issuecomment-409215137):\r\n\r\n> This would allow the use of [ColumnNameAttribute and friends](https://github.com/dsyme/machinelearning/compare/fs1...dsyme:fs2?expand=1#diff-46f68725db753df8e54db621da51265cR17) on both public fields (as today) and public properties that have getters/setters.\r\n> \r\n> I've tested that allows an F# record definition to be successfully used, e.g. [this test](https://github.com/dsyme/machinelearning/compare/fs1...dsyme:fs2?expand=1#diff-fe2d4189320f83b77c7f4f5dca8bb5d8R132) now passes in that branch.  It would also allow C# classes that just use attributed public get/set properties to be used, many tests for that pattern would need to be added (e.g. covering the vector, channel and other cases)\r\n> \r\n> It would be a change in spec because existing C# classes that use public fields _plus_ some additional get/set properties may now have their get/set properties considered part of the schema, when they weren't before.  I suppose this may mean the user has to add some NoColumn attributes on to these properties.  \r\n> \r\n> We could theoretically adjust the spec to be \"if there are non-zero public fields, then use public fields.  Otherwise, see if there are public get/set properties\", but right now I've used the rule \"combine the public fields and public get/set properties\" as that seems more natural and allows gradual transition of field-based types to property-based types.\r\n> \r\n> I believe this would address @terrajobst's concerns about the use of public fields, at least in the core schema model.  There are other uses of GetFields() and field-reflection in the component model/catalog parameterization system which I haven't attempted to address.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/616","RelatedDescription":"Closed or merged PR \"Allow use of property-based row classes in ML.NET\" (#616)"},{"Id":"346850249","IsPullRequest":false,"CreatedAt":"2018-08-02T03:57:25","Actor":"MaxAkbar","Number":"630","RawContent":null,"Title":"Named Entity Recognizer","State":"open","Body":"Hello ML.NET,\r\n\r\nIs there any way I can use ML.NET to created named entities?\r\n\r\nThanks,\r\n-Max","Url":"https://github.com/dotnet/machinelearning/issues/630","RelatedDescription":"Open issue \"Named Entity Recognizer\" (#630)"},{"Id":"346789518","IsPullRequest":true,"CreatedAt":"2018-08-01T22:33:22","Actor":"shauheen","Number":"627","RawContent":null,"Title":"Merge master into release/preview branch for v0.4","State":"closed","Body":"This PR is cumulatively merging master into release branch in preparation for v0.4 release.","Url":"https://github.com/dotnet/machinelearning/pull/627","RelatedDescription":"Closed or merged PR \"Merge master into release/preview branch for v0.4\" (#627)"},{"Id":"346746546","IsPullRequest":true,"CreatedAt":"2018-08-01T20:52:54","Actor":"eerhardt","Number":"626","RawContent":null,"Title":"Fix official build","State":"closed","Body":"Our official build is broken because we introduced a new dependency when building native code.\r\n\r\nPreviously, when we built native code, we didn't need to restore NuGet packages. But with #624 we now have a dependency from our native C++ code to the MklImports NuGet package. And our build fails if the package hasn't been restored.\r\n\r\nThe fix is to make `BuildNative` dependent on `RestorePackages`.","Url":"https://github.com/dotnet/machinelearning/pull/626","RelatedDescription":"Closed or merged PR \"Fix official build\" (#626)"},{"Id":"346571686","IsPullRequest":true,"CreatedAt":"2018-08-01T18:16:24","Actor":"codemzs","Number":"624","RawContent":null,"Title":"Port SymSGD trainer","State":"closed","Body":"This change adds parallel SGD trainer but disables its multi-threading capabilities because of the lack of OpenMP support by the Clang compiler on linux and macOS build systems and MKL library. It also Supersedes PR #556 by squashing all the commits in one and rebasing with master.\r\n\r\nfixes #623 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/624","RelatedDescription":"Closed or merged PR \"Port SymSGD trainer\" (#624)"},{"Id":"346548268","IsPullRequest":false,"CreatedAt":"2018-08-01T18:16:24","Actor":"codemzs","Number":"623","RawContent":null,"Title":"Port SymSGD","State":"closed","Body":"This changes adds parallel Stochastic gradient descent trainer know as SymSGD(https://arxiv.org/abs/1705.08030)","Url":"https://github.com/dotnet/machinelearning/issues/623","RelatedDescription":"Closed issue \"Port SymSGD\" (#623)"},{"Id":"346314170","IsPullRequest":false,"CreatedAt":"2018-08-01T17:22:27","Actor":"sfilipi","Number":"619","RawContent":null,"Title":"Make tests baseline comparison more lenient ","State":"closed","Body":"There are a few tests that are disabled because the baseline comparisons fail on the 5th decimal for some of the numbers generated, on some OS. \r\n\r\nAs an example, the RegressorOlsTest() in PredictorTests fails just on the Mac debug version, because only one out of the generated 4896 predictions   doesn't match:\r\n\r\nbaseline:\r\n`2625\t5\t5.09176636\t0.091766357421875\t0.0084210643544793129`\r\n\r\nMac debug run predictions:\r\n`2625\t5\t5.091751\t0.0917510986328125\t0.0084182641003280878`\r\n\r\nI think we should make the tests more lenient to failures like this, modifying the comparison with the baseline to:\r\n1- Have a sensitivity threeshold. Compare up to the 4th, or 6th decimal digit. \r\n2- Count the failures, and declare the test as failed if 3% o the predictions/lines differ?\r\n\r\n@justinormont @TomFinley  @Zruty0  @zeahmed are those acceptable ranges?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/619","RelatedDescription":"Closed issue \"Make tests baseline comparison more lenient \" (#619)"},{"Id":"346427167","IsPullRequest":true,"CreatedAt":"2018-08-01T02:42:32","Actor":"eerhardt","Number":"622","RawContent":null,"Title":"Initial replacement of SubComponent with IComponentFactory","State":"open","Body":"This is the first round of code changes necessary in order to remove SubComponent and instead use IComponentFactory.\r\n\r\nThis change removes SubComponent from the following public APIs:\r\n\r\n* `CompositeDataLoader`\r\n    * In order to completely remove it here, I needed to also remove it in some of the DataCommand classes as well - since they were calling methods on CompositeDataLoader that used SubComponent.\r\n* `Ova` and `Pkpd`\r\n* `TermTransform`\r\n\r\nWorking towards #585 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/622","RelatedDescription":"Open PR \"Initial replacement of SubComponent with IComponentFactory\" (#622)"},{"Id":"346356802","IsPullRequest":true,"CreatedAt":"2018-07-31T21:02:04","Actor":"ganik","Number":"620","RawContent":null,"Title":"Overrides forObject.Equals(Object o), GetHashCode() for ... ","State":"open","Body":"Closes #547\r\nAdded overrides for Object.Equals(Object o), GetHashCode() for VectorType, KeyType and ImageType\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/620","RelatedDescription":"Open PR \"Overrides forObject.Equals(Object o), GetHashCode() for ... \" (#620)"},{"Id":"346299942","IsPullRequest":false,"CreatedAt":"2018-07-31T18:08:29","Actor":"sfilipi","Number":"618","RawContent":null,"Title":"System.InvalidOperationException: Entry point 'Trainers.OrdinaryLeastSquaresRegressor' not found","State":"open","Body":"If you add the ML.Net package version 0.0.0.4 to the project, trainers Like `OrdinaryLeastSquaresRegressor`, and `LightGbmRegressor` will be visible, and you can add them to the pipeline. \r\nIf you run a  pipeline with those trainers, and just the ML.Net package on the project, you'll get a runtime exception, with message like: \r\n\r\n`System.InvalidOperationException: Entry point 'Trainers.OrdinaryLeastSquaresRegressor' not found   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode`\r\n\r\nThis is because the actual implementation for those learners lives in additional packages, like Microsoft.ML.LightGBM, or Microsoft.ML.HadLearners. \r\n\r\nTo get those trainers to work with the pipeline, one needs to: \r\n1- Add the respective package to the project\r\n2- Add the following like to their   <PropertyGroup> section in the .csproj file\r\n`<CopyLocalLockFileAssemblies>true</CopyLocalLockFileAssemblies>`\r\n\r\nThis will gather all the dlls in the bin folder, and everything should work correctly. \r\n","Url":"https://github.com/dotnet/machinelearning/issues/618","RelatedDescription":"Open issue \"System.InvalidOperationException: Entry point 'Trainers.OrdinaryLeastSquaresRegressor' not found\" (#618)"},{"Id":"346250613","IsPullRequest":false,"CreatedAt":"2018-07-31T15:53:29","Actor":"WladdGorshenin","Number":"617","RawContent":null,"Title":"How to dump intermediate data in pipeline?","State":"open","Body":"Hi,\r\n\r\nWhat would be the best way to get intermediate data in a pipeline? I'd like to debug data transformation steps.\r\n\r\nLooking forward for reply\r\n","Url":"https://github.com/dotnet/machinelearning/issues/617","RelatedDescription":"Open issue \"How to dump intermediate data in pipeline?\" (#617)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-08-03T21:05:39.8240885Z","RunDurationInMilliseconds":1105}