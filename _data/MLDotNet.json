{"Data":{"GitHub":{"Issues":[{"Id":"457778085","IsPullRequest":true,"CreatedAt":"2019-06-19T02:37:40","Actor":"Dmitry-A","Number":"3882","RawContent":null,"Title":"[AutoML] bring AutoML API library to master","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3882","RelatedDescription":"Open PR \"[AutoML] bring AutoML API library to master\" (#3882)"},{"Id":"457749970","IsPullRequest":true,"CreatedAt":"2019-06-19T00:15:53","Actor":"wschin","Number":"3881","RawContent":null,"Title":"[WIP] ONNXTransform Upgrade to Enable Non-tensor Types","State":"open","Body":"The current ONNXTransform only operates on tensor types. As many ONNX models (especially classifiers) produce Seq<Map<T, float>> where T can be either int or string, we should remove that limitation.","Url":"https://github.com/dotnet/machinelearning/pull/3881","RelatedDescription":"Open PR \"[WIP] ONNXTransform Upgrade to Enable Non-tensor Types\" (#3881)"},{"Id":"457740736","IsPullRequest":true,"CreatedAt":"2019-06-18T23:33:26","Actor":"justinormont","Number":"3880","RawContent":null,"Title":"Improve column purpose detection for sparse text datasets","State":"open","Body":"Fixes #3879 by not counting empty text values when calculating the column statistics.\r\n\r\nBackground from #3879:\r\n> AutoML does poorly on a few text datasets. For example, a text dataset we benchmark on has an accuracy of 0.60 vs. an expected accuracy of 0.85. \r\n> \r\n> This is caused by us detecting the text columns columns as **categorical** instead of **free text**. For the this dataset, this is due to the text column being 84% blank (a sparsely filled out column). \r\n> \r\n> **To fix:** \r\n> We need to detect the column purpose only on the set (non-blank) values.\r\n> \r\n> Recommend subtracting the blank values from `data.Count`:\r\n> https://github.com/dotnet/machinelearning/blob/227da9d7db2ce80b073cc64bfd067b04e6189de1/src/Microsoft.ML.AutoML/ColumnInference/PurposeInference.cs#L148-L158\r\n> \r\n> Currently `avgLength`, `cardinalityRatio`, `avgSpaces` are artificially lower due to the missing values.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3880","RelatedDescription":"Open PR \"Improve column purpose detection for sparse text datasets\" (#3880)"},{"Id":"457736707","IsPullRequest":false,"CreatedAt":"2019-06-18T23:17:45","Actor":"justinormont","Number":"3879","RawContent":null,"Title":"Improving column purpose detection for sparse datasets","State":"open","Body":"AutoML does poorly on a few text datasets. For example, a text dataset we benchmark on has an accuracy of 0.60 vs. an expected accuracy of 0.85. \r\n\r\nThis is caused by us detecting the text columns columns as **categorical** instead of **free text**. For the this dataset, this is due to the text column being 84% blank (a sparsely filled out column). \r\n\r\n**To fix:** \r\nWe need to detect the column purpose only on the set (non-blank) values.\r\n\r\nRecommend subtracting the blank values from `data.Count`:\r\nhttps://github.com/dotnet/machinelearning/blob/227da9d7db2ce80b073cc64bfd067b04e6189de1/src/Microsoft.ML.AutoML/ColumnInference/PurposeInference.cs#L148-L158\r\n\r\nCurrently `avgLength`, `cardinalityRatio`, `avgSpaces` are artificially lower due to the missing values.","Url":"https://github.com/dotnet/machinelearning/issues/3879","RelatedDescription":"Open issue \"Improving column purpose detection for sparse datasets\" (#3879)"},{"Id":"457135941","IsPullRequest":true,"CreatedAt":"2019-06-18T21:18:15","Actor":"ganik","Number":"3873","RawContent":null,"Title":"[WIP] Repro for Timeseries  engine exception","State":"closed","Body":"Repro for Timeseries  engine exception.\r\n@codemzs  pls take a look\r\n\r\nthx","Url":"https://github.com/dotnet/machinelearning/pull/3873","RelatedDescription":"Closed or merged PR \"[WIP] Repro for Timeseries  engine exception\" (#3873)"},{"Id":"457658265","IsPullRequest":false,"CreatedAt":"2019-06-18T19:34:03","Actor":"yaeldekel","Number":"3878","RawContent":null,"Title":"Multiclass LightGBM bug","State":"open","Body":"LightGBM trainer has two non-readonly fields called `_numClass` and `_tlcNumClass`. The second one is used to determine the number of predictors in the OVA predictor. However, the value of `_tlcNumClass` is only updated once, so if `Fit` is called again on the same estimator, it might give the wrong number of classes.","Url":"https://github.com/dotnet/machinelearning/issues/3878","RelatedDescription":"Open issue \"Multiclass LightGBM bug\" (#3878)"},{"Id":"457223476","IsPullRequest":true,"CreatedAt":"2019-06-18T17:24:26","Actor":"codemzs","Number":"3875","RawContent":null,"Title":"Add bindings for RowImpl in time series SequentialTransformerBase","State":"closed","Body":"fixes #3874\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3875","RelatedDescription":"Closed or merged PR \"Add bindings for RowImpl in time series SequentialTransformerBase\" (#3875)"},{"Id":"457221787","IsPullRequest":false,"CreatedAt":"2019-06-18T17:24:26","Actor":"codemzs","Number":"3874","RawContent":null,"Title":"Time series Sequential Transform RowImpl needs to have a binding mechanism","State":"closed","Body":"We need to keep track of bindings when GetGetter is called in the case of DataTransformer, these bindings will be used to map column id to relative column id of the transformer.","Url":"https://github.com/dotnet/machinelearning/issues/3874","RelatedDescription":"Closed issue \"Time series Sequential Transform RowImpl needs to have a binding mechanism\" (#3874)"},{"Id":"457603180","IsPullRequest":false,"CreatedAt":"2019-06-18T17:20:40","Actor":"JomanjiPT","Number":"3877","RawContent":null,"Title":"DLL not found","State":"open","Body":"I have this problem : https://stackoverflow.com/questions/56654046/system-dllnotfoundexception-unable-to-load-dll-the-specified-module-could-not\r\n\r\nAnd I think that can be something related with a problem on this web API, or else I woudn't post here.","Url":"https://github.com/dotnet/machinelearning/issues/3877","RelatedDescription":"Open issue \"DLL not found\" (#3877)"},{"Id":"457564793","IsPullRequest":false,"CreatedAt":"2019-06-18T15:56:16","Actor":"konabuta","Number":"3876","RawContent":null,"Title":"Object reference not set to an instance of an object.","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 1903\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRun the following Examples with ONNX model from Azure Custom Vision service.\r\n\r\nhttps://docs.microsoft.com/ja-jp/dotnet/api/microsoft.ml.onnxcatalog.applyonnxmodel?view=ml-dotnet-preview#Microsoft_ML_OnnxCatalog_ApplyOnnxModel_Microsoft_ML_TransformsCatalog_System_String_System_Nullable_System_Int32__System_Boolean_\r\n\r\n- **What happened?**\r\nFailed in ApplyOnnxModel with the following message.\r\nObject reference not set to an instance of an object.\r\n\r\n\r\n### Source code / logs\r\n```cs\r\nusing System;\r\nusing System.Linq;\r\nusing System.IO;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\n\r\nnamespace Samples.Dynamic\r\n{\r\n    public static class ApplyOnnxModel\r\n    {\r\n        public static void Main()\r\n        {\r\n            string strCurDir = System.Environment.CurrentDirectory;\r\n            Console.WriteLine(strCurDir);\r\n            // Download the squeeznet image model from ONNX model zoo, version 1.2\r\n            // https://github.com/onnx/models/tree/master/squeezenet or use\r\n            // Microsoft.ML.Onnx.TestModels nuget.\r\n            var assetsRelativePath = @\"../../../squeezenet\";\r\n            string assetsPath = GetAbsolutePath(assetsRelativePath);\r\n\r\n            var modelPath = Path.Combine(assetsPath, \"catdog.onnx\");\r\n\r\n            // Create ML pipeline to score the data using OnnxScoringEstimator\r\n            var mlContext = new MLContext();\r\n\r\n            // Generate sample test data.\r\n            var samples = GetTensorData();\r\n            // Convert training data to IDataView, the general data type used in ML.NET.\r\n            var data = mlContext.Data.LoadFromEnumerable(samples);\r\n            // Create the pipeline to score using provided onnx model.\r\n            //var pipeline = mlContext.Transforms.ApplyOnnxModel(modelPath);\r\n            var pipeline = mlContext.Transforms.ApplyOnnxModel(\"classLabel\",\"data\", modelPath);\r\n            // Fit the pipeline and get the transformed values\r\n            var transformedValues = pipeline.Fit(data).Transform(data);\r\n            // Retrieve model scores into Prediction class\r\n            var predictions = mlContext.Data.CreateEnumerable<Prediction>(transformedValues, reuseRowObject: false);\r\n\r\n            // Iterate rows\r\n            foreach (var prediction in predictions)\r\n            {\r\n                int numClasses = 0;\r\n                foreach (var classScore in prediction.classLabel.Take(5))\r\n                {\r\n                    Console.WriteLine($\"Class #{numClasses++} score = {classScore}\");\r\n                }\r\n                Console.WriteLine(new string('-', 10));\r\n            }\r\n\r\n            // Results look like below...\r\n            // Class #0 score = 4.544065E-05\r\n            // Class #1 score = 0.003845858\r\n            // Class #2 score = 0.0001249467\r\n            // ----------\r\n            // Class #0 score = 4.491953E-05\r\n            // Class #1 score = 0.003848222\r\n            // Class #2 score = 0.0001245592\r\n            // ----------\r\n        }\r\n\r\n        // inputSize is the overall dimensions of the model input tensor.\r\n        private const int inputSize = 224 * 224 * 3;\r\n\r\n        // A class to hold sample tensor data. Member name should match  \r\n        // the inputs that the model expects (in this case, data_0)\r\n        public class TensorData\r\n        {\r\n            [VectorType(inputSize)]\r\n            public float[] data_0 { get; set; }\r\n        }\r\n\r\n        // Method to generate sample test data. Returns 2 sample rows.\r\n        public static TensorData[] GetTensorData()\r\n        {\r\n            // This can be any numerical data. Assume image pixel values.\r\n            var image1 = Enumerable.Range(0, inputSize).Select(x => (float)x / inputSize).ToArray();\r\n            var image2 = Enumerable.Range(0, inputSize).Select(x => (float)(x + 10000) / inputSize).ToArray();\r\n            return new TensorData[] { new TensorData() { data_0 = image1 }, new TensorData() { data_0 = image2 } };\r\n        }\r\n        public static string GetAbsolutePath(string relativePath)\r\n        {\r\n            FileInfo _dataRoot = new FileInfo(typeof(ApplyOnnxModel).Assembly.Location);\r\n            string assemblyFolderPath = _dataRoot.Directory.FullName;\r\n\r\n            string fullPath = Path.Combine(assemblyFolderPath, relativePath);\r\n\r\n            return fullPath;\r\n        }\r\n\r\n        // Class to contain the output values from the transformation.\r\n        // This model generates a vector of 1000 floats.\r\n        class Prediction\r\n        {\r\n            [VectorType(1000)]\r\n            //public float[] softmaxout_1 { get; set; }\r\n            public float[] classLabel { get; set; }\r\n\r\n        }\r\n    }\r\n}\r\n```\r\n[catdog.zip](https://github.com/dotnet/machinelearning/files/3302363/catdog.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3876","RelatedDescription":"Open issue \"Object reference not set to an instance of an object.\" (#3876)"},{"Id":"457098169","IsPullRequest":false,"CreatedAt":"2019-06-17T18:58:04","Actor":"prathyusha12345","Number":"3872","RawContent":null,"Title":"Got \"Bad allocation\" exception when training 10gb data on database using Light GBM trainer","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI am trying to create a sample on using large datasets on database. The dataset I have used is criteo dataset for URL click prediction. I have imported the file into local SQL database and the size of local database is around 10GB. \r\n\r\nI am using LightGBM to do Binary classification. While training the model I got the below exception. Is there any issue with LightGBM to train Large datasets?\r\n\r\n```\r\n[LightGBM] [Warning] bad allocation\r\n\r\nC:\\Program Files\\dotnet\\dotnet.exe (process 2692) exited with code -1073740791.\r\nPress any key to close this window . . .\r\n```\r\n![image](https://user-images.githubusercontent.com/22335043/59629020-c8feb100-90f6-11e9-8f75-04b204d75ac7.png)\r\n\r\n\r\n### Source code / logs\r\n\r\nThe dataset file is taken from here \\\\ct01\\data\\Criteo\\Spark\\day_0-23_withHeader.tsv\r\n\r\nThe source code is available here  https://github.com/prathyusha12345/machinelearning-samples/tree/SQLDbSample/samples/csharp/getting-started/LargeDatasetsInSqlServer\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3872","RelatedDescription":"Open issue \"Got \"Bad allocation\" exception when training 10gb data on database using Light GBM trainer\" (#3872)"},{"Id":"456834266","IsPullRequest":false,"CreatedAt":"2019-06-17T09:31:37","Actor":"LDWDev","Number":"3871","RawContent":null,"Title":"Randomised PCA anomaly detection not detecting anomalies","State":"open","Body":"### System information\r\n\r\nWindows 10, .NET Core 2.2 console app, VS2019\r\n\r\n### Issue\r\n\r\n# SETUP\r\n\r\nGood morning. I am encountering some issues with the RPCA trainer and was hoping someone could help me out here. I'm not really sure what I'm doing wrong but I am not getting the results I would expect.\r\n\r\nI've made a toy model to test out the ML.NET anomaly detection funtionality. I manufacture two random numbers for each data point, and call them gene one and gene two. They are constrained to lie in a particular range: gene one lies between .8 and .9, and gene two lies between .1 and .5. \r\n\r\nUsing a sample from this data (with the same seed each time),  I apply an RPCA pipeline. then I call fit, then transform the training data. \r\n\r\nI then make a gene entry with a ludicrous score (10000, 25000), and transform that to see where it lies. ML.Net claims this is not an anomaly.\r\n\r\n# PROBLEM\r\n\r\nI expect to see an anomaly. I've tried this with less silly values, more silly values, with or without all the available kinds of normalisation, and reducing the rank of the PCA trainer.\r\n\r\n# LOGS\r\n\r\nHere's the output of the program. It shows the score, whether data is an inlier, and the transform of the data points.\r\n\r\nHere's the pipeline:\r\n\r\n```\r\nvar rpcaProjection = ct.Transforms.Concatenate(\"Features\", \"GeneOneScore\", \"GeneTwoScore\")\r\n                  .Append(ct.Transforms.NormalizeMeanVariance(\"NormalisedFeatures\", \"Features\"))\r\n.Append(ct.AnomalyDetection.Trainers.RandomizedPca(featureColumnName: \"NormalisedFeatures\", rank: 2));\r\n```\r\n\r\nResults from transforming first 20 training data: Predicted, score, PCA co-ordinates\r\n\r\nTrue, 0.005851699, 0.7284454, 0.6617603\r\nTrue, 0.002783414, 1.028686, 0.7808771\r\nTrue, 0.004348077, 0.9824907, 1.543225\r\nTrue, 0.004398529, 1.021341, 0.510879\r\nTrue, 0.003683135, 1.005801, 1.091905\r\nFalse, NaN, 0.9997306, 1.01117\r\nTrue, 0.003618588, 1.004708, 0.8854353\r\nTrue, 0.004349507, 0.9971809, 1.588225\r\nTrue, 0.004412429, 1.018427, 0.4791145\r\nTrue, 0.003997049, 1.008593, 1.246756\r\nTrue, 0.004217377, 1.00574, 1.322197\r\nTrue, 0.004192073, 0.9794555, 1.412197\r\nTrue, 0.004289094, 1.019702, 1.569695\r\nTrue, 0.005468629, 1.021341, 1.083963\r\nTrue, 0.003488006, 1.007865, 0.7861712\r\nFalse, NaN, 1.025348, 0.9171998\r\nTrue, 0.004403637, 1.020734, 1.508814\r\nFalse, NaN, 0.9888039, 0.9224939\r\nTrue, 0.004757768, 1.009807, 0.8113181\r\nTrue, 0.004348857, 1.011143, 0.4394088\r\n\r\nResults from transforming the \"anomaly\": Predicted, score, PCA co-ordinates\r\nTrue, 0.006252703, **121407.6, 82720.04**\r\n\r\nI've put this repo on github here:\r\n\r\nhttps://github.com/LDWDev/MLWoes/blob/master/MLtestapp/Program.cs\r\n\r\nCould anyone point out what is going on here? I would not expect the score to be the value it is.\r\n\r\nDo I need to give the trainer anomalous data? Why does the scorer think such distant values should be considered 'normal'? I have had trouble finding useful documentation/tutorials on this.","Url":"https://github.com/dotnet/machinelearning/issues/3871","RelatedDescription":"Open issue \"Randomised PCA anomaly detection not detecting anomalies\" (#3871)"},{"Id":"455987251","IsPullRequest":false,"CreatedAt":"2019-06-13T22:54:47","Actor":"marcmm","Number":"3870","RawContent":null,"Title":"Need a way to predict a batch of examples in one call to Tensorflow","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .Net Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Using Tensorflow extension, there's no support to predict a batch of examples in one call to Tensorflow.\r\n- **What happened?** This functionality is not supported at this time.\r\n- **What did you expect?** It would be good to support this functionality to improve efficiency in model prediction.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3870","RelatedDescription":"Open issue \"Need a way to predict a batch of examples in one call to Tensorflow\" (#3870)"},{"Id":"455973386","IsPullRequest":false,"CreatedAt":"2019-06-13T22:06:36","Actor":"prathyusha12345","Number":"3869","RawContent":null,"Title":"Getting OutOfMemory exception while training model on large datasets in file","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI am trying to create a sample  https://github.com/dotnet/machinelearning-samples/pull/520 to train a model on large datasets that are stored in a **file**. I am using BinaryClassification trainer. While training the model I am getting the OutOfMemory exception at the Fit() method as shown below.\r\n\r\n var model = trainingPipeLine.Fit(trainTestData.TrainSet);           \r\n\r\n![image](https://user-images.githubusercontent.com/22335043/59470767-99496380-8ded-11e9-9adb-3eb9d1d3ea43.png)\r\n\r\ncomplete details of error \r\n\r\n```\r\nSystem.FormatException\r\n  HResult=0x80131537\r\n  Message=Parsing failed with an exception: Stream reading encountered exception\r\n  Source=Microsoft.ML.Data\r\n  StackTrace:\r\n   at Microsoft.ML.Data.TextLoader.Cursor.<ParseParallel>d__33.MoveNext()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.LinkedRowFilterCursorBase.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingTransformer.Train(IHostEnvironment env, IChannel ch, ColInfo[] infos, IDataView keyData, ColumnOptionsBase[] columns, IDataView trainingData, Boolean autoConvert)\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingTransformer..ctor(IHostEnvironment env, IDataView input, ColumnOptionsBase[] columns, IDataView keyData, Boolean autoConvert)\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Transforms.OneHotEncodingTransformer..ctor(ValueToKeyMappingEstimator term, IEstimator`1 toVector, IDataView input)\r\n   at Microsoft.ML.Transforms.OneHotEncodingEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at LargeDatasetsInSqlServer.Program.Main() in C:\\GitRepos\\Fork\\ML-samples\\ML-samples-LargeDataInFile\\samples\\csharp\\getting-started\\LargeDatasetsInFile\\LargeDatasetsInFile\\Program.cs:line 107\r\n\r\nInner Exception 1:\r\nFormatException: Stream reading encountered exception\r\n\r\nInner Exception 2:\r\nOutOfMemoryException: Insufficient memory to continue the execution of the program.\r\n\r\n\r\n```\r\nThe data set is copied from shared folder **\\\\ct01\\data\\Criteo\\Spark\\day_0_withHeader.tsv**.\r\n\r\n### Source code / logs\r\n\r\nPlease find the entire source code from the  https://github.com/prathyusha12345/machinelearning-samples/tree/LargeDatasetsInFile/samples/csharp/getting-started/LargeDatasetsInFile\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3869","RelatedDescription":"Open issue \"Getting OutOfMemory exception while training model on large datasets in file\" (#3869)"},{"Id":"455967713","IsPullRequest":false,"CreatedAt":"2019-06-13T21:54:59","Actor":"prathyusha12345","Number":"3868","RawContent":null,"Title":"Training 10gb of data in local SQL database is taking more than 14 hours","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI tried to create  a sample  https://github.com/dotnet/machinelearning-samples/pull/498 to train data stored in local sql database. I tried to execute the sample . The training is not at all completing. I have started executing the sample since **14 hours** back. The model sis till showing as training.\r\n\r\nI wonder how long this training takes to execute 10gb of data. The data base contains 32 millions of records.\r\n\r\nI have copied the file from shared location \\\\ct01\\data\\Criteo\\Spark\\day_0_withHeader.tsv. The actual file size is of **42 gb**. I imported the file manually into local SQL database which can have around **10gb** of data.\r\n\r\nCould anyone please let me know how long do I/user need to wait to train 10gb of data? I wanted to see when it will complete training.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3868","RelatedDescription":"Closed issue \"Training 10gb of data in local SQL database is taking more than 14 hours\" (#3868)"},{"Id":"455945890","IsPullRequest":false,"CreatedAt":"2019-06-13T20:48:27","Actor":"benavidezb","Number":"3867","RawContent":null,"Title":"Nonlinear Regression with Custom Target Function","State":"open","Body":"Is there a nonlinear regression or curve fitting class that supports custom functions of at least two independent variables and at least 5 parameters?\r\n\r\nI have a nonlinear regression problem that I need to solve using C#. I have a transfer function defined as:\r\n\r\nZ = A+1/(1/(X/256*B+3*C)+1/(Y/1024*D+2*E))\r\n\r\nWhere X and Y are my independent variables, Z is the output data I have to train from, and A-E are the parameters I need to the regression technique to solve. I have initial guesses for these parameters:\r\n\r\nA = 20\r\n\r\nB = 10000\r\n\r\nC = 50\r\n\r\nD = 50000\r\n\r\nE = 60\r\n\r\nI don't want to use generic regression models to estimate Z as I am specifically using the estimated parameters later on in the program. Any help would be greatly appreciated.","Url":"https://github.com/dotnet/machinelearning/issues/3867","RelatedDescription":"Open issue \"Nonlinear Regression with Custom Target Function\" (#3867)"},{"Id":"455509069","IsPullRequest":true,"CreatedAt":"2019-06-13T20:40:27","Actor":"Dmitry-A","Number":"3860","RawContent":null,"Title":"[AutoML] add task agnostic wrappers for autofit calls","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3860","RelatedDescription":"Closed or merged PR \"[AutoML] add task agnostic wrappers for autofit calls\" (#3860)"},{"Id":"455876099","IsPullRequest":false,"CreatedAt":"2019-06-13T17:55:55","Actor":"CESARDELATORRE","Number":"3866","RawContent":null,"Title":"Document what's supported in \"ONNX-ML.NET\"","State":"open","Body":"@wschin, @codemzs \r\nRelated to ONNX. Can we have documented what is supported when using ONNX from ML.NET? - Either for both scenarios: 1. Export/convert model scenario and 2. Load ONNX model scenario.\r\n\r\nFor instance:\r\n\r\n- 1. When exporting ML.NET models to ONNX with [ConvertToOnnx()](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.onnxexportextensions.converttoonnx?view=ml-dotnet-preview), will any type of ML.NET model work as ONNX model executed later on by the ONNX runtime from any other framework? **In ML.NET preview versions only certain ML.NET models could be exported to the ONNX-ML format. Is that still the case?** \r\n\r\n- 2. Can any type of loaded ONNX model run on ML.NET?\r\n\r\nFor instance, in the reference for [ConvertToOnnx()](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.onnxexportextensions.converttoonnx?view=ml-dotnet-preview) it doesn't say what's supported and what's not.\r\n\r\n**Do we have any documentation stating what's supported and what's not supported in \"ONNX-ML.NET\"?**\r\n\r\nIn addition to that, performance/accuracy comparison should also be covered due to issues like this:\r\n[ONNX Exports are Lossy](https://github.com/dotnet/machinelearning/issues/3206)","Url":"https://github.com/dotnet/machinelearning/issues/3866","RelatedDescription":"Open issue \"Document what's supported in \"ONNX-ML.NET\"\" (#3866)"},{"Id":"455846204","IsPullRequest":false,"CreatedAt":"2019-06-13T16:47:08","Actor":"codemzs","Number":"3865","RawContent":null,"Title":"Sanity check APIs from Microsoft.ML.OnnxTransfomer nuget","State":"open","Body":"We plan to GA Microsoft.ML.OnnxTransfomer nuget in 1.2 release. We must do a final pass over the public API surface and ensure we only exposing relevant APIs.","Url":"https://github.com/dotnet/machinelearning/issues/3865","RelatedDescription":"Open issue \"Sanity check APIs from Microsoft.ML.OnnxTransfomer nuget\" (#3865)"},{"Id":"455844908","IsPullRequest":false,"CreatedAt":"2019-06-13T16:43:58","Actor":"codemzs","Number":"3864","RawContent":null,"Title":"Sanity check APIs from Microsoft.ML.TimeSeries nuget","State":"open","Body":"We plan to GA Microsoft.ML.TimeSeries nuget in 1.2 release. We must do a final pass over the public API surface and ensure we only exposing relevant APIs.","Url":"https://github.com/dotnet/machinelearning/issues/3864","RelatedDescription":"Open issue \"Sanity check APIs from Microsoft.ML.TimeSeries nuget\" (#3864)"},{"Id":"455843842","IsPullRequest":false,"CreatedAt":"2019-06-13T16:41:26","Actor":"codemzs","Number":"3863","RawContent":null,"Title":"Sanity check APIs from Microsoft.ML.Tensorflow nuget","State":"open","Body":"We plan to GA Microsoft.ML.Tensorflow nuget in 1.2 release. Lets do a final pass on the binary and make sure we are only exposing relevant API.","Url":"https://github.com/dotnet/machinelearning/issues/3863","RelatedDescription":"Open issue \"Sanity check APIs from Microsoft.ML.Tensorflow nuget\" (#3863)"},{"Id":"455842337","IsPullRequest":false,"CreatedAt":"2019-06-13T16:38:02","Actor":"codemzs","Number":"3862","RawContent":null,"Title":"Conform time series forecasting API to estimator standards","State":"open","Body":"Currently time series forecasting framework and API is a standalone entity. We must change that to be an estimator so that it fit seamlessly into the training pipeline. Do the following:\r\n\r\n1) Make SSA forecasting an estimator API.\r\n2) Create a fit(Idataview) that is used for training the forecasting model.\r\n3) Create a fit(IDataView, SSAModel) that is used for updating the forecasting model from a column in the IDataView\r\n4) Create a Transform(IDataView) that forecasts values up a horizon that is read from a column-row in the IDataView. Here forecasted values are represented as a variable sized vector in the column.\r\n5) Create a Transform() that forecasts values as a new IDataView where each forecasted value is its own row.\r\n\r\nCC: @ganik @artidoro @yaeldekel @CESARDELATORRE @eerhardt ","Url":"https://github.com/dotnet/machinelearning/issues/3862","RelatedDescription":"Open issue \"Conform time series forecasting API to estimator standards\" (#3862)"},{"Id":"454789414","IsPullRequest":true,"CreatedAt":"2019-06-13T16:29:00","Actor":"codemzs","Number":"3853","RawContent":null,"Title":"Update roadmap.","State":"closed","Body":"fixes #2074\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3853","RelatedDescription":"Closed or merged PR \"Update roadmap.\" (#3853)"},{"Id":"455830927","IsPullRequest":false,"CreatedAt":"2019-06-13T16:12:13","Actor":"ebizupnorth","Number":"3861","RawContent":null,"Title":"Feature: A dropdown list to choose what OptimizingMetric to use in AutoML GUI","State":"open","Body":"It would be better if there is an option to choose what OptimizingMetric to use when using the AutoML GUI during training.\r\n\r\nThanks for this amazing AutoML.","Url":"https://github.com/dotnet/machinelearning/issues/3861","RelatedDescription":"Open issue \"Feature: A dropdown list to choose what OptimizingMetric to use in AutoML GUI\" (#3861)"},{"Id":"455446582","IsPullRequest":false,"CreatedAt":"2019-06-13T09:48:42","Actor":"ebizupnorth","Number":"3858","RawContent":null,"Title":"AutoML 0.3.0 does not generate namespace properly when solution name contains space","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: \r\nOS Name:     Windows\r\n OS Version:  10.0.17134\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n- **.NET Version (eg., dotnet --info)**: \r\n Version:   3.0.100-preview5-011568\r\n Commit:    b487ff10aa\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nFollowed the tutorial on using AutoML from https://dotnet.microsoft.com/learn/machinelearning-ai/ml-dotnet-get-started-tutorial/scenario but used a project name as \"AutoML Sentiment\". Note: It contains a space.\r\n- **What happened?**\r\nAutoML did not consider the space in the project name. Generated code below gives a compile error.\r\n```\r\n//*****************************************************************************************\r\n//*                                                                                       *\r\n//* This is an auto-generated file by Microsoft ML.NET CLI (Command-Line Interface) tool. *\r\n//*                                                                                       *\r\n//*****************************************************************************************\r\n\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing AutoML SentimentML.Model.DataModels;\r\nusing Microsoft.ML.Trainers;\r\n\r\nnamespace AutoML SentimentML.ConsoleApp\r\n{\r\n    public static class ModelBuilder\r\n    {\r\n............\r\n    }\r\n}\r\n```\r\n- **What did you expect?**\r\nI expected that AutoML should replace the space with \"_\" in order to compile as shown below:\r\n\r\n```\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing AutoML_SentimentML.Model.DataModels;\r\nusing Microsoft.ML.Trainers;\r\n\r\nnamespace AutoML_SentimentML.ConsoleApp\r\n{\r\n    public static class ModelBuilder\r\n    {\r\n............\r\n    }\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3858","RelatedDescription":"Closed issue \"AutoML 0.3.0 does not generate namespace properly when solution name contains space\" (#3858)"},{"Id":"455483823","IsPullRequest":true,"CreatedAt":"2019-06-13T00:38:42","Actor":"najeeb-kazmi","Number":"3859","RawContent":null,"Title":"Change default EvaluationMetric for LightGbm trainers to conform to d…","State":"open","Body":"…efault metric in standalone LightGbm\r\n\r\nFixes #3822 \r\n\r\nIn ML.NET, the default `EvaluationMetric` for LightGbm is set to `EvaluateMetricType.Error` for multiclass, `EvaluationMetricType.LogLoss` for binary, and so on. This leads to inconsistent behavior from the user's perspective: If a user specified `EvaluationMetric = EvaluateMetricType.Default`, the parameter passed to LightGbm would be the empty string \"\", which is the LightGbm default and means that the metric is selected based on the objective. However, if they do not specify `EvaluationMetric` at all, the parameter passed to LightGbm would be Error for multiclass, LogLoss for binary, and so on. \r\n\r\nWe should make the experience for LightGbm in ML.NET consistent with what a user of standalone LightGbm experiences, and not expect them to dig through LightGbm docs and ML.NET docs to find this out.\r\n\r\nThis PR makes the user experience consistent with standalone LightGbm by by changing the default `EvaluationMetric` in ML.NET to `EvaluationMetricType.Default`.\r\n\r\n[LightGbm metric parameters docs](https://lightgbm.readthedocs.io/en/latest/Parameters.html#metric-parameters)","Url":"https://github.com/dotnet/machinelearning/pull/3859","RelatedDescription":"Open PR \"Change default EvaluationMetric for LightGbm trainers to conform to d…\" (#3859)"},{"Id":"455380977","IsPullRequest":true,"CreatedAt":"2019-06-12T19:17:58","Actor":"CESARDELATORRE","Number":"3857","RawContent":null,"Title":"Early Draft specs doc for DatabaseLoader in ML.NET","State":"open","Body":"Early Draft specs doc for a `DatabaseLoader` component in ML.NET. \r\nFeel free to provide feedback. This specs document will be evolving significantly since it is in a very early draft state.\r\n\r\nMain objective is to load data into an IDataView from relational databases (such as SQL Server, Azure SQL Database, PostgreSQL, MySQL, Oracle, etc.) in a very easy way, one line of code in most cases by simply specifying the connection string, the database `table/view/sql-sentence` and what database provider/connection type it is using.\r\n\r\nCurrently in ML.NET 1.0 or 1.1 we can only do the following:\r\n\r\n- Load data from files by using `MLContext.Data.LoadFromTextFile()`, etc.\r\n- Load data from an IEnumerable collection with `MLContext.Data.LoadFromEnumerable()`, usually coming from a database, but the developer/user is responsible for how to load/query the database. It is not straightforward such as when reading from a file.\r\n\r\n**High level design goal:**\r\nThe intention of the new component is to make a lot easier to implement _'model training scenarios  pulling/streaming data from large database tables'_ while transparently solving complicated cases such as 'transient errors' in the cloud (database connections broken as a result) when using Azure SQL Database.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3857","RelatedDescription":"Open PR \"Early Draft specs doc for DatabaseLoader in ML.NET\" (#3857)"},{"Id":"455352795","IsPullRequest":false,"CreatedAt":"2019-06-12T18:09:13","Actor":"yaeldekel","Number":"3856","RawContent":null,"Title":"Multi class LR behaves differently on .NetCore 3.0","State":"open","Body":"Four tests are failing on the .NetCore 3.0 builds:\r\n`EnsemblesMultiAveragerTest`\r\n`EnsemblesMultiClassBootstrapSelectorTest`\r\n`EnsemblesMultiVotingCombinerTest`\r\n`EnsemblesMultiStackCombinerTest`\r\n\r\nThe difference in the baselines is something like this:\r\n`L1 regularization selected 13 of 15 weights.` vs.\r\n`L1 regularization selected 11 of 15 weights.`\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3856","RelatedDescription":"Open issue \"Multi class LR behaves differently on .NetCore 3.0\" (#3856)"},{"Id":"455317777","IsPullRequest":false,"CreatedAt":"2019-06-12T16:43:13","Actor":"mungojam","Number":"3855","RawContent":null,"Title":"ARIMA with linear regressors time series modelling","State":"open","Body":"This was mentioned in some other issues that have now been closed following the first release of time series functionality.\r\n\r\nWe currently use ARIMA with linear regressors. There may be better algorithms but it works well for us and is fairly simple to understand and implement.\r\n\r\nIf you can add basic models like this and somebody produces a C#/F# equivalent of the [Forecasting Principles and Practices e-book](https://otexts.com/fpp2/intro.html) then you might be able to support quite a few people who are just getting started with time series forecasting.","Url":"https://github.com/dotnet/machinelearning/issues/3855","RelatedDescription":"Open issue \"ARIMA with linear regressors time series modelling\" (#3855)"},{"Id":"454791564","IsPullRequest":true,"CreatedAt":"2019-06-12T15:58:32","Actor":"codemzs","Number":"3854","RawContent":null,"Title":"CustomGains should allow multiple values in argument attribute.","State":"closed","Body":"fixes #3710\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3854","RelatedDescription":"Closed or merged PR \"CustomGains should allow multiple values in argument attribute.\" (#3854)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-06-19T05:30:41.5323077Z","RunDurationInMilliseconds":898}