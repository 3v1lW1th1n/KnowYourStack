{"Data":{"GitHub":{"Issues":[{"Id":"499922532","IsPullRequest":false,"CreatedAt":"2019-09-29T14:05:33","Actor":"nighotatul","Number":"4264","RawContent":null,"Title":"how we plot decision tree using LbfgsLogisticRegression Trainer?","State":"open","Body":"@eerhardt -  we got score and metrics but how we plot decision tree using trainer.","Url":"https://github.com/dotnet/machinelearning/issues/4264","RelatedDescription":"Open issue \"how we plot decision tree using LbfgsLogisticRegression Trainer?\" (#4264)"},{"Id":"499746780","IsPullRequest":false,"CreatedAt":"2019-09-28T09:06:28","Actor":"wpadron","Number":"4263","RawContent":null,"Title":"Duplicate column name exception when adding an Ignored column to AutoML framework","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10.0.18362\r\n- **.NET Version (eg., dotnet --info)**: core 3.0.100\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAdd a column that AutoML should ignore.\r\n\r\n- **What happened?**\r\nGet an exception that the column name is duplicated.\r\n\r\n- **What did you expect?**\r\nWhen you add a column to the ignored collection you don't have to remove it from another collection (there are more than one) because the columns are inferred from the dataset at runtime.\r\n\r\n### Source code / logs\r\nColumnInformation columnInformation = columnInference.ColumnInformation;\r\ncolumnInformation.NumericColumnNames.Remove(\"payment_type\"); \r\ncolumnInformation.IgnoredColumnNames.Add(\"payment_type\");\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4263","RelatedDescription":"Open issue \"Duplicate column name exception when adding an Ignored column to AutoML framework\" (#4263)"},{"Id":"499687474","IsPullRequest":true,"CreatedAt":"2019-09-28T02:51:21","Actor":"codemzs","Number":"4261","RawContent":null,"Title":"Fix code coverage yaml file.","State":"closed","Body":"Code coverage is broke due to an update that is needed in the yml file.","Url":"https://github.com/dotnet/machinelearning/pull/4261","RelatedDescription":"Closed or merged PR \"Fix code coverage yaml file.\" (#4261)"},{"Id":"499710603","IsPullRequest":true,"CreatedAt":"2019-09-28T01:36:56","Actor":"antoniovs1029","Number":"4262","RawContent":null,"Title":"Addresses #3976 about using PFI with a model loaded from disk","State":"open","Body":"With this pull request it is now possible to use PFI with some models loaded from disk. **This is not yet a final solution to the problem**, as described in the last section below.\r\n\r\n### The Problem\r\nAs explained in [this comment](https://github.com/dotnet/machinelearning/issues/3976#issuecomment-517862076) of issue #3976 it was not possible to use PFI with a model loaded from disk, because the last transformer of the loaded model was not of the appropriate type to use it with the `PermutationFeatureImportance `method.\r\n\r\nSpecifically the problem occurred because when loading the last transformer, a 'create' method would be called and it would assign an inappropriate type to the last transformer, making it unusable for PFI. For example, if a model had `RegressionPredictionTransformer<OlsModelParameters>` as last transformer, and it was saved to disk, later on when loading it from disk the last transformer would be of type `RegressionPredictionTransformer<IPredictorProducing<float>>.` This would have happened because the [Create method ](https://github.com/dotnet/machinelearning/blob/bb00e07b30e9626b3578ff1934b86dad0d1d1ce9/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L615) that is called when loading a `RegressionPredictionTransformer ` would always return a `RegressionPredictionTransformer<IPredictorProducing<float>>` regardless of the actual `TModel `that should be loaded. In this case, it would be necessary to load the last transformer as `RegressionPredictionTransformer<OlsModelParameters>` in order to use it with PFI.\r\n\r\nThis was a problem also in the BinaryClassification, MulticlassClassification and Ranking prediction transformers which implemented a similar Create method. All of these classes are used with PFI.\r\n\r\n### The approach of the solution\r\nThe main obstacle was that the appropriate type `TModel` to be used when loading the last transformer couldn't be known at compile time, only at runtime once the last transformer was being loaded.\r\n\r\nSo to solve the problem, it was necessary to load first the internal model (e.g. the `OlsModelParameters `object) in the Create method of the prediction transformer, get its type to be used as `TModel`, make a generic type at runtime for the prediction transformer using the actual `TModel`, and instantiate that type with a constructor that would receive the internal model (previously loaded) to add it to the last transformer; this constructor would then continue to load the prediction transformer.\r\n\r\n### Changes implemented\r\n\r\n- The create method of the prediction transformers (binary, multiclass, ranking and regression) was modified to solve the problem. Different overloads of constructors were created to receive the internal model once it was loaded and then continue loading the prediction transformer.\r\n\r\n- **Samples were added based on the original PFI samples**, but now using a model that is saved and loaded from disk directly in the sample. This is provided for the multiclass, ranking and regression, but NOT for the binary classification case (see the final section below).\r\n\r\n- **Test cases based on the original PFI test cases are also provided**, but now using a model that is saved and loaded from disk directly in the test case. Again, this was done for multiclass, ranking and regression, but not for binary classification.\r\n\r\n- **Changes were made to 2 tests in the `LbfgsTests.cs`** file where PFI is not used, but prediction transformers are loaded from disk. The changes regard casts that were used in the tests, but can no longer be used. For example, `as MulticlassPredictionTransformer<IPredictorProducing<VBuffer<float>>>` was replaced for `as MulticlassPredictionTransformer<MaximumEntropyModelParameters>` in one test. This is done because now the create method returns the appropriate TModel type instead of the `IPredictorProducing<>` type. Notice that it is invalid to cast from `MulticlassPredictionTransformer<MaximumEntropyModelParameters>` to `MulticlassPredictionTransformer<IPredictorProducing<VBuffer<float>>>`... so those tests fail without the changes I made to the tests. Also notice that since `IPredictorProducing<>` is internal, a regular user using a nugget wouldn't be able to do the casts that were done in those tests.\r\n\r\n### Further problems\r\nIn this pull request I provide working samples and tests for regression, multiclass and ranking. Still, I've been unable to provide them for binary classification.\r\n\r\nThe [existing sample for PFI with binary classification](https://github.com/dotnet/machinelearning/blob/2942ca4e02d354b48767a1b01017f57cdc3fe44c/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/PermutationFeatureImportance.cs#L27) uses a last transformer of type `BinaryPredictionTransformer<CalibratedModelParameterBase<LinearBinaryModelParameters,PlattCalibrator>>` which is the type necessary to use it in the PFI method. When saving and then loading that model from disk, the last transformer was of type `BinaryPredictionTransformer<IPredictorProducing<float>>`; with the changes I made to the binary transformer, it now loads a last transformer of type `BinaryPredictionTransformer<ParameterMixingCalibratorModelParameters<IPredictorProducing<float>, ICalibrator>>`, which is still not the type necessary to use PFI.\r\n\r\nThe problem is that the [Create method of ParameterMixingCalibratorModelParameters](https://github.com/dotnet/machinelearning/blob/2942ca4e02d354b48767a1b01017f57cdc3fe44c/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L564) returns a `CalibratedModelParameterBase` object. This is similar to the problem that the prediction transformers had, but there's a key difference in that `ParameterMixingCalibratorModelParameters ` is internal, and its create method returns an object of its public superclass `CalibratedModelParameterBase`. This key difference has stopped me from solving the problem using the same approach used to fix the prediction transformers. Once this pull request is accepted, I will open another issue with this specific use case, explaining it in more detail.\r\n\r\nNonetheless, notice that the problem is not in the `BinaryPredictionTransformer<TModel>` but rather in its `TModel` for this specific case. Having changed the `BinaryPredictionTransformer<TModel>` actually works as expected, in that it no longer returns a fixed `<IPredictorProducing<float>>` as TModel, and so the problem is actually in the `ParameterMixingCalibratorModelParameters `class.\r\n\r\nAlso notice that this is a signal that there might be other generic classes where the Create method returns an object with fixed type parameters that aren't the ones actually being used. This might become a problem for users trying to use PFI with a model that uses one of such classes.","Url":"https://github.com/dotnet/machinelearning/pull/4262","RelatedDescription":"Open PR \"Addresses #3976 about using PFI with a model loaded from disk\" (#4262)"},{"Id":"499573005","IsPullRequest":true,"CreatedAt":"2019-09-27T17:56:25","Actor":"KsenijaS","Number":"4260","RawContent":null,"Title":"Tensor extensions","State":"open","Body":"Output tensors from graph are being copied from unamanaged to managed memory and every time a new buffer is created. Performance will be better if we reuse buffer when it's possible.\r\nImprove performance by replacing ToArray method in Tensor class with extension methods: ToScalar, ToSpan and ToArray\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4260","RelatedDescription":"Open PR \"Tensor extensions\" (#4260)"},{"Id":"499233840","IsPullRequest":true,"CreatedAt":"2019-09-27T17:10:49","Actor":"Youssef1313","Number":"4255","RawContent":null,"Title":"Typo: Retreive -> Retrieve","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4255","RelatedDescription":"Closed or merged PR \"Typo: Retreive -> Retrieve\" (#4255)"},{"Id":"499094871","IsPullRequest":false,"CreatedAt":"2019-09-27T16:57:55","Actor":"aslotte","Number":"4252","RawContent":null,"Title":"Jupyter + ML.NET | DataFrame vs Dataview","State":"closed","Body":"While working with ML.NET in Jupyter, it can sometimes feel like double work to have to load the data first in to a DataFrame, and then also in to a IDataView to be able to use it in e.g. a training pipeline.\r\n\r\nIt would be ideal if the `.Fit` and/or `TrainTestSplit` methods could take a DataFrame as a parameter, or if there was other interoperability methods to leverage, so that the data wouldn't need to be loaded in two places.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4252","RelatedDescription":"Closed issue \"Jupyter + ML.NET | DataFrame vs Dataview\" (#4252)"},{"Id":"499523755","IsPullRequest":false,"CreatedAt":"2019-09-27T15:55:15","Actor":"luisquintanilla","Number":"4259","RawContent":null,"Title":"[Image Classification API] metricsCallback NullReferenceException when using custom function","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2\r\n- **ML.NET Version**: 1.4.0-preview\r\n\r\n### Issue\r\n\r\nTried to provide a custom function for the `metricsCallback` parameter. The documentation in IntelliSense says this method is only called during the *Training* phase. However, it does not appear to be the case. If the *Bottleneck* phase has to happen (training for first time or not using cached bottleneck values), a `System.NullReferenceException` is raised.\r\n\r\n```text\r\nSystem.NullReferenceException: 'Object reference not set to an instance of an object.'\r\n\r\ntrainMetrics was null.\r\n```\r\n\r\nI suspect this is because the same callback is used for both the Bottleneck / Training phases. It would be good to either:\r\n\r\na) Have separate callbacks depending on whether it's Bottleneck / Training phase.\r\nb) Allow the user to check which phase is currently taking place so they can display the results accordingly in their `metricsCallback` method.\r\n\r\nNote that once a model is trained and the *Bottleneck* phase no longer needs to happen since the cached values are being used, no Exceptions are raised and the application works as expected. \r\n\r\n### Source code / logs\r\n\r\nPipeline:\r\n\r\n```csharp\r\nvar trainingPipeline =\r\n    mapLabelTransform\r\n   .Append(mlContext.Model.ImageClassification(\r\n       \"ImagePath\",\r\n       \"LabelAsKey\",\r\n       arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n       epoch: 100,\r\n       batchSize: 20,\r\n       metricsCallback: DisplayMetrics,\r\n       validationSet: transformedTestData\r\n       //reuseTrainSetBottleneckCachedValues: true,\r\n       /*reuseValidationSetBottleneckCachedValues: true*/));\r\n```\r\n\r\nMetrics Callback Method:\r\n\r\n```csharp\r\npublic static void DisplayMetrics(ImageClassificationMetrics metrics)\r\n{\r\n    TrainMetrics trainMetrics = metrics.Train;\r\n    Console.WriteLine($\"Epoch: {trainMetrics.Epoch} | Accuracy {trainMetrics.Accuracy} | Loss: {trainMetrics.CrossEntropy}\");\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4259","RelatedDescription":"Open issue \"[Image Classification API] metricsCallback NullReferenceException when using custom function\" (#4259)"},{"Id":"499484953","IsPullRequest":false,"CreatedAt":"2019-09-27T14:39:31","Actor":"Genysis78","Number":"4258","RawContent":null,"Title":"Model Builder reference error","State":"open","Body":"On the CLI my regression model trains without issue, and the FastTreeTweedie is automatically selected as the best performing. In the resulting files produced by the model, in the Model.cs, I am getting an error: \"The type or namespace name 'FastTreeTweedieTrainer' could not be found (are you missing a using directive or an assembly reference?) (CS0246) [VesselAnalytics]\". This seems to be linked to the ML.FastTree but if you know of a workaround then that would be great, i.e. is there an obscure using reference that isn't automatically inserted by the model I need to insert.\n\n\n---\n#### Document Details\n\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\n\n* ID: 1b723be0-9b74-15da-b850-2b420c4a31b6\n* Version Independent ID: 557580d1-4af7-2fb7-9e48-643bcb14c11d\n* Content: [TreeExtensions.FastTreeTweedie Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.treeextensions.fasttreetweedie?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/TreeExtensions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/TreeExtensions.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/4258","RelatedDescription":"Open issue \"Model Builder reference error\" (#4258)"},{"Id":"499450711","IsPullRequest":false,"CreatedAt":"2019-09-27T13:35:46","Actor":"fwaris","Number":"4257","RawContent":null,"Title":"What is the input format required by the LDA transform?","State":"open","Body":"Ideally I would like the output of ApplyWordEmbedding transform as input to LDA for topic modeling but apparently that is not the case.\r\n\r\nSo I am not sure how to format the input to LDA.\r\n\r\nDocumentation says it should be a vector of single - which it is with after applying the embedding transform but then I see an error message when running LDA:\r\n\r\nThe specified documents are all empty in column 'Features'.\r\n\r\nWhere \"Features\" is the output of the embedding.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4257","RelatedDescription":"Open issue \"What is the input format required by the LDA transform?\" (#4257)"},{"Id":"499357959","IsPullRequest":false,"CreatedAt":"2019-09-27T10:08:43","Actor":"IgnasZ","Number":"4256","RawContent":null,"Title":"Incorrect constructor parameter type specified","State":"open","Body":"Constructor parameter 'columns' should be of type IEnumerable&lt;SchemaShape.Column&gt; instead of IEnumerable&lt;SchemaShape&gt;\n\n---\n#### Document Details\n\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\n\n* ID: 52902231-74e7-53a0-1974-ab96d7963da1\n* Version Independent ID: ebf148b4-3861-d68a-33ca-f12d59e6e3ee\n* Content: [SchemaShape Class (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.schemashape?view=ml-dotnet#feedback)\n* Content Source: [dotnet/xml/Microsoft.ML/SchemaShape.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/SchemaShape.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/4256","RelatedDescription":"Open issue \"Incorrect constructor parameter type specified\" (#4256)"},{"Id":"499166449","IsPullRequest":false,"CreatedAt":"2019-09-26T23:52:40","Actor":"gkapellmann","Number":"4254","RawContent":null,"Title":"An Autoencoder Sample","State":"open","Body":"This might not be an issue but more like a request.\r\n\r\nIs there a way to do an autoencoder? If so, can there be an example to achieve this?","Url":"https://github.com/dotnet/machinelearning/issues/4254","RelatedDescription":"Open issue \"An Autoencoder Sample\" (#4254)"},{"Id":"499119961","IsPullRequest":true,"CreatedAt":"2019-09-26T21:15:00","Actor":"LittleLittleCloud","Number":"4253","RawContent":null,"Title":"Image featurization","State":"open","Body":"It's just the same PR of the one on Justin's [repo](https://github.com/justinormont/machinelearning/pull/4)\r\n- [x] Pass image path\r\n- [x] Seperate ImageFeaturizing into four parts\r\n- [x] CodeGen","Url":"https://github.com/dotnet/machinelearning/pull/4253","RelatedDescription":"Open PR \"Image featurization\" (#4253)"},{"Id":"496657603","IsPullRequest":false,"CreatedAt":"2019-09-26T19:26:04","Actor":"nighotatul","Number":"4238","RawContent":null,"Title":"How to Draw Auto ML Statisctics Graph using XPlot.Plotly library in c#","State":"closed","Body":"Hi \r\n\r\nWe are using AutoML tool\r\n\r\nAs we got statistics of binary classification of\r\n\r\nAUC\r\nConfusion Matrix\r\nRoc\r\n\r\nHow we can draw the graph based on Matrix by using XPlot.plotly library in C#\r\n\r\nwe are not found any example in github in ML.net repository\r\n\r\nPlease provide sample\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4238","RelatedDescription":"Closed issue \"How to Draw Auto ML Statisctics Graph using XPlot.Plotly library in c#\" (#4238)"},{"Id":"497255848","IsPullRequest":false,"CreatedAt":"2019-09-26T17:51:51","Actor":"aslotte","Number":"4243","RawContent":null,"Title":"ML.NET support in Azure Machine Learning Service","State":"closed","Body":"First of all, big thanks for the initial support of ML.NET in Jupyter Notebooks. It's a fantastic addition.\r\n\r\nBased on this, I'm wondering if, when and how it will be possible to install the .NET kernel in Azure Machine Learning Service to be able to take full advantage of the cloud?","Url":"https://github.com/dotnet/machinelearning/issues/4243","RelatedDescription":"Closed issue \"ML.NET support in Azure Machine Learning Service\" (#4243)"},{"Id":"499028344","IsPullRequest":false,"CreatedAt":"2019-09-26T17:49:41","Actor":"aslotte","Number":"4251","RawContent":null,"Title":"Jupyter + ML.NET | Plotly","State":"open","Body":"This may not be the correct forum for this question, and if not, I'm happy to close it.\r\n\r\nPlotly created very large graphs, greatly slowing down the browser, especially compared to it's Python counterparts. I created a simple Scatter plot based on a dataset of 30 Mb, and Google Chrome almost completely came to a halt. I've created similar plots in Python equivalents for 500+ Mb of data with the browser running smoothly. \r\n\r\nThis means that XPlot.Plotly will not be a feasible option for any real-life datasets. Are there any other alternatives for the .NET community that we can recommend? Or should I reach out to Plotly to see if this is just a bug?","Url":"https://github.com/dotnet/machinelearning/issues/4251","RelatedDescription":"Open issue \"Jupyter + ML.NET | Plotly\" (#4251)"},{"Id":"499021022","IsPullRequest":false,"CreatedAt":"2019-09-26T17:32:48","Actor":"aslotte","Number":"4250","RawContent":null,"Title":"Jupyter + ML.NET | DataFrame | Identical to Pandas or more C# like?","State":"open","Body":"The DataFrame class currently bears a lot of resembles with the Python equivalent of Pandas. \r\n\r\nAs I don't have any API documentation in front of me, it's difficult to know the answer to this, so I thought I would ask, are there any efforts to make it more \"C# like\"?\r\n\r\nE.g., I would like to do the following for example:\r\n```\r\nvar allFraudulentRowsByTransactionDate = dataFrame.Where(x => x.IsFraud).OrderBy(y => y.TransactionDate);\r\n```\r\n\r\n**or** \r\n```\r\nvar first10Rows = dataFrame.Take(10);\r\nvar first10Percent = dataFrame.Take(dataFrame.Count() * 0.1);\r\n```\r\n**or** \r\n\r\n```\r\nvar amountColumnForOnlyFraudulentCases = dataFrame.Where(y => y.IsFraud).Select(x => x.Amount);\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4250","RelatedDescription":"Open issue \"Jupyter + ML.NET | DataFrame | Identical to Pandas or more C# like?\" (#4250)"},{"Id":"498994622","IsPullRequest":false,"CreatedAt":"2019-09-26T17:25:15","Actor":"aslotte","Number":"4249","RawContent":null,"Title":"Jupyter + ML.NET | DataFrame | Create a ToOutputFormat() function to output HTML table","State":"closed","Body":"Registering the format of a DataFrame is currently a large code block that takes away from the ML problem we're trying to solve in the Notebook. \r\n\r\nWhat about creating a ToString() or ToOutputFormat() method that outputs the default table format which I believe most people would like to have from start. ","Url":"https://github.com/dotnet/machinelearning/issues/4249","RelatedDescription":"Closed issue \"Jupyter + ML.NET | DataFrame | Create a ToOutputFormat() function to output HTML table\" (#4249)"},{"Id":"498574293","IsPullRequest":true,"CreatedAt":"2019-09-26T14:28:34","Actor":"eerhardt","Number":"4247","RawContent":null,"Title":"Fix NgramExtractingTransformer GetSlotNames to not allocate a new delegate on every invoke.","State":"closed","Body":"This was showing up as allocating a huge number of delegates for no reason.\r\n\r\nI removed the delegate all together and just pass the VBuffer in.","Url":"https://github.com/dotnet/machinelearning/pull/4247","RelatedDescription":"Closed or merged PR \"Fix NgramExtractingTransformer GetSlotNames to not allocate a new delegate on every invoke.\" (#4247)"},{"Id":"498520195","IsPullRequest":true,"CreatedAt":"2019-09-25T20:57:50","Actor":"LittleLittleCloud","Number":"4246","RawContent":null,"Title":"WIP - AutoML Add Recommendation Task","State":"open","Body":"What's already be done in this PR\r\n- [x] added `Recommendation` task and experiment in `AutoML`\r\n- [x] added `MatrixFactorization` as `MatrixFactorizationExtension`\r\n- [x] added a new Column Purpose (`LabelFeature`) and it's corresponding TransformerExtension (`LabelCategorical`) so that `AutoML` can construct the pre-process pipeline for `MatrixFactorizationExtension` correctly\r\n- [x] added a new recommendation example (with rating only) in `AutoML.Example`, and you can play with that!\r\n\r\nWhat's need to be done (Feel Free to CRUD)\r\n- [ ] figuring out how to accelerate and properly presenting the training process. Seems that `MatrixFactorization` requires more time to train a round, and the algorithm for sweeping params requires to train many rounds to find out the best parameter. It's time costy and customers might not like that.\r\n- [ ] Corresponding `CodeGen` part\r\n- [ ] Test case!\r\n- [ ] Better Naming and code style\r\n- [ ] Enable support for multiple feature trainers in `AutoML` (it requires some refactor works and shouldn't be done in this PR. But it's important)","Url":"https://github.com/dotnet/machinelearning/pull/4246","RelatedDescription":"Open PR \"WIP - AutoML Add Recommendation Task\" (#4246)"},{"Id":"497293022","IsPullRequest":true,"CreatedAt":"2019-09-23T19:48:34","Actor":"jamessantiago","Number":"4245","RawContent":null,"Title":"[Example Only] Anomaly detection example for extending AutoML features to non-experiment types","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nThis is for issue #4244 as an example.  Not sure the proper way to go about achieving the same result so this is just for discussion.","Url":"https://github.com/dotnet/machinelearning/pull/4245","RelatedDescription":"Open PR \"[Example Only] Anomaly detection example for extending AutoML features to non-experiment types\" (#4245)"},{"Id":"497291598","IsPullRequest":false,"CreatedAt":"2019-09-23T19:45:31","Actor":"jamessantiago","Number":"4244","RawContent":null,"Title":"[AutoML] Extend use of AutoML inferrence workflow for non-experiment types","State":"open","Body":"I've got a desire here to use some of the transformer inference and other cool things from AutoML but obviously doesn't fit as an experiment without a proper estimator.  I've mocked up adding anomaly detection as an experiment base by faking the estimator.  Looks like too much of AutoML is internal for me to extend it like this.  Any thoughts on how I should go about achieving the same results?  Maybe I should setup a pull request to change the appropriate protection levels for the items needed to implement the experimentbase class?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4244","RelatedDescription":"Open issue \"[AutoML] Extend use of AutoML inferrence workflow for non-experiment types\" (#4244)"},{"Id":"497235087","IsPullRequest":true,"CreatedAt":"2019-09-23T17:41:14","Actor":"harshithapv","Number":"4242","RawContent":null,"Title":"Changed Image classification API to accept Image as VBuffer<byte>","State":"open","Body":"Changed Image classification API to accept Image as V Buffer<byte>. Also, added a few optimizations to re-use the buffer for performance gains.\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4242","RelatedDescription":"Open PR \"Changed Image classification API to accept Image as VBuffer<byte>\" (#4242)"},{"Id":"497032201","IsPullRequest":false,"CreatedAt":"2019-09-23T11:08:17","Actor":"bjoped","Number":"4241","RawContent":null,"Title":"Exception in AutoML regression experiment","State":"open","Body":"Windows 10 v. 1809\r\n\r\nUpgraded From v.0.14 v. 0.15 and got ArgumentOutOfRangeException in CrossValSummaryRunner.suggestedPipelineRunDetail.\r\nBestResultUtil.GetIndexOfBestScore returns -1. \r\n\r\nCode works as expected in v.0.14. tried to upgrade to v.0.15 and v0.16 preview and both fail with the Exception.\r\n\r\n> System.ArgumentOutOfRangeException\r\n  HResult=0x80131502\r\n  Message=Index was out of range. Must be non-negative and less than the size of the collection.\r\nParameter name: index\r\n  Source=mscorlib\r\n  StackTrace:\r\n   at System.ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument argument, ExceptionResource resource)\r\n   at System.Collections.Generic.List`1.get_Item(Int32 index)\r\n   at System.Linq.Enumerable.ElementAt[TSource](IEnumerable`1 source, Int32 index)\r\n   at Microsoft.ML.AutoML.CrossValSummaryRunner`1.Run(SuggestedPipeline pipeline, DirectoryInfo modelDirectory, Int32 iterationNum) in C:\\Data\\Dev\\machinelearning\\src\\Microsoft.ML.AutoML\\Experiment\\Runners\\CrossValSummaryRunner.cs:line 74","Url":"https://github.com/dotnet/machinelearning/issues/4241","RelatedDescription":"Open issue \"Exception in AutoML regression experiment\" (#4241)"},{"Id":"496816763","IsPullRequest":false,"CreatedAt":"2019-09-22T18:41:35","Actor":"RicardoGonzagaBR","Number":"4240","RawContent":null,"Title":"[AutoML] Not Really a Issue | Any plans to include on AUTO a way to insert/change initial weights or retrain a model?using a experiment?","State":"open","Body":"Auto dont have a way to retrain a existing model or use a pre existing set of weights as starting point.  Its a suggestion, not really a issue. I think this is a wanted feature not only by me :-)","Url":"https://github.com/dotnet/machinelearning/issues/4240","RelatedDescription":"Open issue \"[AutoML] Not Really a Issue | Any plans to include on AUTO a way to insert/change initial weights or retrain a model?using a experiment?\" (#4240)"},{"Id":"496801320","IsPullRequest":false,"CreatedAt":"2019-09-22T16:26:49","Actor":"oliverw","Number":"4239","RawContent":null,"Title":"Consuming a simple ONNX model for text classification","State":"open","Body":"I'm trying to consume a trained scikit learn model that was converted to ONNX. Attempting to load the model with:\r\n\r\n```c#\r\nvar pipeline = ctx.Transforms.ApplyOnnxModel(\r\n    new[] { \"label\", \"probabilities\" }, new[] { \"input\" }, \"test.onnx\");\r\n```\r\n\r\nResults in the following exception:\r\n\r\n> System.ArgumentOutOfRangeException: 'dim (Parameter 'Dimension { } in ONNX tensor cannot exceed the maximum of 32-bit signed integer.')\r\n> Actual value was 0.'\r\n> \r\n\r\n**Update:**\r\n\r\nSaving the model with `target_opset = 9` results in:\r\n\r\n> [ErrorCode:Fail] Load model from ..\\..\\..\\..\\..\\Data\\MLModel\\test.onnx failed:Fatal error: StringNormalizer is not a registered function/op\r\n\r\n\r\n**Model creation in python:**\r\n\r\n```python\r\nimport os\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\nfrom sklearn.svm import LinearSVC\r\nfrom skl2onnx import convert_sklearn\r\nfrom skl2onnx.common.data_types import StringTensorType\r\nimport pandas as pd\r\nfrom onnxmltools import save_model\r\n\r\ndata = pd.read_csv('training_data.csv', sep='\\t')\r\n\r\npipeline = Pipeline([\r\n  ('tfidf', TfidfVectorizer()),\r\n  ('clf', LinearSVC()),\r\n])\r\n\r\npipeline.fit(data[\"Keywords\"], data[\"Label\"])\r\n\r\nonnx = convert_sklearn(pipeline, name='test_predictor',\r\n  initial_types=[('input', StringTensorType([1, 1]))])\r\n\r\nsave_model(onnx, \"test.onnx\")\r\n\r\n```\r\n\r\n**Netron:**\r\n\r\n![image](https://user-images.githubusercontent.com/51688/65391096-6fe19180-dd65-11e9-965a-3eab334533a6.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4239","RelatedDescription":"Open issue \"Consuming a simple ONNX model for text classification\" (#4239)"},{"Id":"496578497","IsPullRequest":true,"CreatedAt":"2019-09-20T23:06:26","Actor":"ashbhandare","Number":"4237","RawContent":null,"Title":"Adding Early stopping feature in ImageClassification (WIP)","State":"open","Body":"Fixes #4236\r\n\r\nModeled after https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4237","RelatedDescription":"Open PR \"Adding Early stopping feature in ImageClassification (WIP)\" (#4237)"},{"Id":"496561537","IsPullRequest":false,"CreatedAt":"2019-09-20T21:54:28","Actor":"ashbhandare","Number":"4236","RawContent":null,"Title":"Need Early Stopping feature in Image Classification ","State":"open","Body":"### Issue\r\nNeed the Early stopping feature in ML .NET so that number of epochs do not need to be set/predefined for Image Classification training.\r\nSaid feature available as a Keras callback: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4236","RelatedDescription":"Open issue \"Need Early Stopping feature in Image Classification \" (#4236)"},{"Id":"496504070","IsPullRequest":false,"CreatedAt":"2019-09-20T19:07:33","Actor":"Kavignon","Number":"4235","RawContent":null,"Title":"Support for OpenAI Gym?","State":"open","Body":"I'm wondering if it'll be possible to have native support for OpenAI gym directly from ML.NET?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4235","RelatedDescription":"Open issue \"Support for OpenAI Gym?\" (#4235)"},{"Id":"496483608","IsPullRequest":false,"CreatedAt":"2019-09-20T18:13:45","Actor":"luisquintanilla","Number":"4234","RawContent":null,"Title":"[Image Classification API] TensorFlow exception triggered: input ended unexpectedly in the middle of a field","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nTried to train an image classification DNN model using the Image Classification API on the [Intel Image Classification](https://www.kaggle.com/puneet6060/intel-image-classification) dataset.\r\n\r\n- **What happened?**\r\n\r\nThe following exception was raised\r\n\r\n```text\r\nWhile parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.\r\n```\r\n\r\n- **What did you expect?**\r\n\r\nThe model to train.\r\n\r\n### Source code / logs\r\n\r\n#### Source Code\r\n\r\n```csharp\r\npublic static IEnumerable<ImageInput> LoadImagesFromDirectory(string folder, bool useFolderNameasLabel = true)\r\n{\r\n    var files = Directory.GetFiles(folder, \"*\",\r\n        searchOption: SearchOption.AllDirectories);\r\n\r\n    foreach (var file in files)\r\n    {\r\n        if ((Path.GetExtension(file) != \".jpg\") && (Path.GetExtension(file) != \".png\"))\r\n            continue;\r\n\r\n        var label = Path.GetFileName(file);\r\n        if (useFolderNameasLabel)\r\n            label = Directory.GetParent(file).Name;\r\n        else\r\n        {\r\n            for (int index = 0; index < label.Length; index++)\r\n            {\r\n                if (!char.IsLetter(label[index]))\r\n                {\r\n                    label = label.Substring(0, index);\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n\r\n        yield return new ImageInput()\r\n        {\r\n            ImagePath = file,\r\n            Label = label\r\n        };\r\n\r\n    }\r\n}\r\n```\r\n\r\n```csharp\r\nMLContext mlContext = new MLContext();\r\n\r\nIEnumerable<ImageInput> train = LoadImagesFromDirectory(trainRelativePath, true).Take(10).ToArray();\r\nIEnumerable<ImageInput> test = LoadImagesFromDirectory(testRelativePath, true).Take(10).ToArray();\r\n\r\nIDataView trainSet = mlContext.Data.LoadFromEnumerable(train);\r\nIDataView testSet = mlContext.Data.LoadFromEnumerable(test);\r\n\r\nvar mapLabelTransform = mlContext.Transforms.Conversion.MapValueToKey\r\n  (outputColumnName: \"LabelAsKey\",\r\n   inputColumnName: \"Label\",\r\n   keyOrdinality: ValueToKeyMappingEstimator.KeyOrdinality.ByValue);\r\n\r\nvar trainingPipeline = \r\n    mapLabelTransform\r\n   .Append(mlContext.Model.ImageClassification(\r\n       \"ImagePath\",\r\n       \"LabelAsKey\",\r\n       arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n       epoch: 100,\r\n       batchSize: 150,\r\n       metricsCallback: (metrics) => Console.WriteLine(metrics)));\r\n\r\nITransformer trainedModel = trainingPipeline.Fit(trainSet);\r\n```\r\n\r\n#### Logs\r\n\r\n```text\r\nSystem.FormatException\r\n  HResult=0x80131537\r\n  Message=Tensorflow exception triggered while loading model.\r\n  Source=Microsoft.ML.Dnn\r\n  StackTrace:\r\n   at Microsoft.ML.Transforms.Dnn.DnnUtils.LoadTFSessionByModelFilePath(IExceptionContext ectx, String modelFile, Boolean metaGraph)\r\n   at Microsoft.ML.DnnCatalog.ImageClassification(ModelOperationsCatalog catalog, String featuresColumnName, String labelColumnName, String scoreColumnName, String predictedLabelColumnName, Architecture arch, Int32 epoch, Int32 batchSize, Single learningRate, ImageClassificationMetricsCallback metricsCallback, Int32 statisticFrequency, DnnFramework framework, String modelSavePath, String finalModelPrefix, IDataView validationSet, Boolean testOnTrainSet, Boolean reuseTrainSetBottleneckCachedValues, Boolean reuseValidationSetBottleneckCachedValues, String trainSetBottleneckCachedValuesFilePath, String validationSetBottleneckCachedValuesFilePath)\r\n   at ImageClassificationAPIMLNETSample.Program.Main(String[] args) in C:\\Users\\luquinta.REDMOND\\source\\repos\\ImageClassificationAPIMLNETSample\\ImageClassificationAPIMLNETSample\\Program.cs:line 59\r\n\r\nInner Exception 1:\r\nInvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.\r\n```\r\n\r\nAdditional output to the console:\r\n\r\n```text\r\nGoogle.Protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.\r\n   at Google.Protobuf.CodedInputStream.RefillBuffer(Boolean mustSucceed)\r\n   at Google.Protobuf.CodedInputStream.ReadRawBytes(Int32 size)\r\n   at Google.Protobuf.CodedInputStream.ReadBytes()\r\n   at Tensorflow.TensorProto.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Tensorflow.AttrValue.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Google.Protobuf.FieldCodec.<>c__DisplayClass16_0`1.<ForMessage>b__0(CodedInputStream input)\r\n   at Google.Protobuf.Collections.MapField`2.Codec.MessageAdapter.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Google.Protobuf.Collections.MapField`2.AddEntriesFrom(CodedInputStream input, Codec codec)\r\n   at Tensorflow.NodeDef.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Google.Protobuf.FieldCodec.<>c__DisplayClass16_0`1.<ForMessage>b__0(CodedInputStream input)\r\n   at Google.Protobuf.Collections.RepeatedField`1.AddEntriesFrom(CodedInputStream input, FieldCodec`1 codec)\r\n   at Tensorflow.GraphDef.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\n   at Tensorflow.MetaGraphDef.MergeFrom(CodedInputStream input)\r\n   at Google.Protobuf.MessageExtensions.MergeFrom(IMessage message, Byte[] data)\r\n   at Google.Protobuf.MessageParser`1.ParseFrom(Byte[] data)\r\n   at Tensorflow.saver._import_meta_graph_with_return_elements(String meta_graph_or_file, Boolean clear_devices, String import_scope, String[] return_elements)\r\n   at Microsoft.ML.Transforms.Dnn.DnnUtils.<>c__DisplayClass5_0.<LoadMetaGraph>b__0(Graph graph)\r\n   at Tensorflow.Python.tf_with[TIn,TOut](TIn py, Func`2 action)\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4234","RelatedDescription":"Open issue \"[Image Classification API] TensorFlow exception triggered: input ended unexpectedly in the middle of a field\" (#4234)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-09-30T05:30:43.5238256Z","RunDurationInMilliseconds":943}