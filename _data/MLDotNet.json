{"Data":{"GitHub":{"Issues":[{"Id":"389546906","IsPullRequest":false,"CreatedAt":"2018-12-11T00:34:01","Actor":"wschin","Number":"1857","RawContent":null,"Title":"Schema Equtable","State":"open","Body":"Sometime, we have code like\r\n```csharp\r\n            public Cursor(IChannelProvider provider, RowToRowScorerBase parent, RowCursor input, bool[] active, Func<int, bool> predicateMapper)\r\n                : base(provider, input)\r\n            {\r\n                Ch.AssertValue(parent);\r\n                Ch.AssertValue(active);\r\n                Ch.AssertValue(predicateMapper);\r\n\r\n                _bindings = parent.GetBindings();\r\n                Schema = parent.OutputSchema;\r\n                Ch.Assert(active.Length == _bindings.ColumnCount);\r\n                _active = active;\r\n\r\n                _output = _bindings.RowMapper.GetRow(input, predicateMapper);\r\n                try\r\n                {\r\n                    Ch.Assert(_output.Schema == _bindings.RowMapper.OutputSchema);\r\n                    _getters = parent.GetGetters(_output, iinfo => active[_bindings.MapIinfoToCol(iinfo)]);\r\n                }\r\n                catch (Exception)\r\n                {\r\n                    _output.Dispose();\r\n                    throw;\r\n                }\r\n            }\r\n```\r\nwhere the equivalence between two `Schema` objects is enforced by using things like\r\n```\r\n_output.Schema == _bindings.RowMapper.OutputSchema\r\n```\r\n. This implies that we need to implement proper comparison function for `Schema`.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1857","RelatedDescription":"Open issue \"Schema Equtable\" (#1857)"},{"Id":"388445125","IsPullRequest":true,"CreatedAt":"2018-12-10T23:22:56","Actor":"Anipik","Number":"1845","RawContent":null,"Title":"Reverting dead unallignedCode paths","State":"closed","Body":"Reverting unaligned CodePaths were added in https://github.com/dotnet/machinelearning/pull/1218 and https://github.com/dotnet/machinelearning/pull/1274\r\n\r\nRelated to https://github.com/dotnet/machinelearning/pull/1838\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1845","RelatedDescription":"Closed or merged PR \"Reverting dead unallignedCode paths\" (#1845)"},{"Id":"389521715","IsPullRequest":true,"CreatedAt":"2018-12-10T22:51:11","Actor":"shmoradims","Number":"1856","RawContent":null,"Title":"Enabled feature contributions for GAM trainers","State":"open","Body":"* Implemented IFeatureContributionMapper interface for GamPredictorBase to enable FCC for GAM trainers\r\n* Added test","Url":"https://github.com/dotnet/machinelearning/pull/1856","RelatedDescription":"Open PR \"Enabled feature contributions for GAM trainers\" (#1856)"},{"Id":"389517417","IsPullRequest":true,"CreatedAt":"2018-12-10T22:36:26","Actor":"Anipik","Number":"1855","RawContent":null,"Title":"Added RffBenchmark","State":"open","Body":"Adding an end to end to Benchmark for rffTransform and cpumathutils functions like matmul and matmiltran\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1855","RelatedDescription":"Open PR \"Added RffBenchmark\" (#1855)"},{"Id":"389517133","IsPullRequest":false,"CreatedAt":"2018-12-10T22:35:36","Actor":"JRAlexander","Number":"1854","RawContent":null,"Title":"ColumnAttribute and TextLoader.Column and TextLoader.Arguments has header property","State":"open","Body":"From @PeterPann23:\r\n\r\n\"To me, this seems to all address the same problem on several different steps of designing the data, perhaps make ordinal an integer and not a string and define the data kind all on-top of the class and have the text loader override it when needed if needed. Most likely one would create a model class as in MVC that consumes a given \"view\" on the world. Perhaps my MVC experience has made me bias but this in my opinion overly complicated as is.\"\r\n\r\nFixes https://github.com/dotnet/docs/issues/9470\r\n\r\nOpened an issue for this  as it's product feedback, and not a docs issue. ","Url":"https://github.com/dotnet/machinelearning/issues/1854","RelatedDescription":"Open issue \"ColumnAttribute and TextLoader.Column and TextLoader.Arguments has header property\" (#1854)"},{"Id":"388843490","IsPullRequest":false,"CreatedAt":"2018-12-07T22:57:49","Actor":"montebhoover","Number":"1853","RawContent":null,"Title":"Add components to EntryPoint catalog that are missing.","State":"open","Body":"There are several new components in ML.NET that were not added to the EntryPoint catalog:\r\n\r\n- MatrixFactorizationTrainer\r\n- PermutationFeatureImportance\r\n- GeneralizedAdditiveModels\r\n- SsaSpikeDetector\r\n- SsaChangePointDetector\r\n- IidSpikeDetector\r\n- IidChangePointDetector\r\n\r\n\r\nTo add these to the EntryPoint catalog, simply:\r\n\r\n1. Add the `SignatureEntryPointModule` signature to the `LoadableClass` assembly attribute.\r\n2. Create a public static method, that: \r\n    1. Takes as input, among others, an object representing the arguments of the component you want to expose. \r\n    2. Initializes and run the components, returning one of the nested classes of `Microsoft.ML.Runtime.EntryPoints.CommonOutputs`\r\n    3. Is annotated with the `TlcModule.EntryPoint` attribute","Url":"https://github.com/dotnet/machinelearning/issues/1853","RelatedDescription":"Open issue \"Add components to EntryPoint catalog that are missing.\" (#1853)"},{"Id":"388832123","IsPullRequest":false,"CreatedAt":"2018-12-07T22:10:51","Actor":"sfilipi","Number":"1852","RawContent":null,"Title":"No way to set the log verbosity in the MLContext","State":"open","Body":"There is currently ways to set a Logging verbosity in the MLContex. \r\nThe users need to be able to tweak logging verbosity. \r\n","Url":"https://github.com/dotnet/machinelearning/issues/1852","RelatedDescription":"Open issue \"No way to set the log verbosity in the MLContext\" (#1852)"},{"Id":"388365337","IsPullRequest":true,"CreatedAt":"2018-12-07T21:33:04","Actor":"vaeksare","Number":"1842","RawContent":null,"Title":"Prevent DNNImageModels from being downloaded on all machines","State":"closed","Body":"Moves the check location to prevent download from happening on unnecessary machines during the official build. Fixes #1841 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/1842","RelatedDescription":"Closed or merged PR \"Prevent DNNImageModels from being downloaded on all machines\" (#1842)"},{"Id":"388364996","IsPullRequest":false,"CreatedAt":"2018-12-07T21:33:04","Actor":"vaeksare","Number":"1841","RawContent":null,"Title":"DNNImageModels are downloaded on all machines during official builds","State":"closed","Body":"The models only need to be downloaded on one machine during official builds, not all of them.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1841","RelatedDescription":"Closed issue \"DNNImageModels are downloaded on all machines during official builds\" (#1841)"},{"Id":"388820432","IsPullRequest":false,"CreatedAt":"2018-12-07T21:28:48","Actor":"eerhardt","Number":"1851","RawContent":null,"Title":"Native assemblies from NuGet aren't copied correctly for packages.config","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: .NET Framework 4.7.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreate an \"old style\" .csproj using packages.config and added Microsoft.ML nuget package and built.\r\n\r\nWhen creating the project, if you uncheck the \"Create directory for solution\" checkbox, then the .sln and .csproj are in the same folder. When you restore NuGet packages, the nuget files get put in a `packages` folder in the same folder as the .csproj.\r\n\r\n- **What happened?**\r\nThe native assemblies (CpuMathNative, FastTreeNative, LdaNative, etc) were all copied into subdirectories of my output path instead of directly in my output path.\r\n\r\nFrom looking at a binlog of the build, it appears that the `AssignTargetPath` is getting confused at our `Content` items since they appear to be part of the project (since they are under the same folder as the .csproj).\r\n\r\n- **What did you expect?**\r\nThe native assemblies should be copied directly to the output folder.\r\n\r\n### Note\r\n\r\nTo fix this, we should put the `<Link>` metadata on our content items:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/14c7a472579afa3ce98bad2e3495e4c0524471b9/pkg/common/CommonPackage.props#L10-L20\r\n\r\nSee\r\n* https://github.com/dotnet/roslyn/issues/15137#issuecomment-260470890\r\n* https://github.com/Microsoft/onnxruntime/pull/127#discussion_r239845745\r\n\r\nFor other places that had this same bug.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1851","RelatedDescription":"Open issue \"Native assemblies from NuGet aren't copied correctly for packages.config\" (#1851)"},{"Id":"388786512","IsPullRequest":false,"CreatedAt":"2018-12-07T19:36:26","Actor":"rogancarr","Number":"1850","RawContent":null,"Title":"OLS FeatureWeights are not the model weights","State":"open","Body":"For the `LinearPredictor`, the `GetFeatureWeights` returns the model weights, as expected:\r\n\r\n```\r\npublic virtual void GetFeatureWeights(ref VBuffer<Float> weights)\r\n{\r\n    Weight.CopyTo(ref weights);\r\n}\r\n```\r\n\r\nThe `OlsLinearRegressionPredictor` has the same method, but it does not return the model weights. It returns the [`-log(p-value)` for each feature](https://github.com/dotnet/machinelearning/blob/14c7a472579afa3ce98bad2e3495e4c0524471b9/src/Microsoft.ML.HalLearners/OlsLinearRegression.cs#L782). This is weird because it overrides the `LinearRegressionPredictor`'s GetFeatureWeights method but returns a different kind of value, essentially the magnitudes of the p-values.\r\n\r\nNow, this goes back to the meaning of `feature weight`. Many predictors that are not linear models implement `GetFeatureWeight`, and it looks like it's a measure of importance. What's the right thing here? Do we want to return a measure of relative importance or do we want to return the model weights?\r\n\r\nCurrently, I find this API to be super confusing because there is no docstring to explain what you are getting back, and I would expect the \"Feature Weights\" of a linear model to the model weight parameters.\r\n\r\nAlso, this is a nit, but if we really want to return the magnitude of the p-values, doesn't `-log10(p-value)` make more sense? The base e log puts these onto a weird scale.","Url":"https://github.com/dotnet/machinelearning/issues/1850","RelatedDescription":"Open issue \"OLS FeatureWeights are not the model weights\" (#1850)"},{"Id":"388018148","IsPullRequest":true,"CreatedAt":"2018-12-07T19:02:33","Actor":"Ivanidzo4ka","Number":"1833","RawContent":null,"Title":"Provide proper calling conversion for x86 framework","State":"closed","Body":"Fixes #1721 \r\nRight now if we call our nuget from .net framework 4.6 x86, we get ugly PInvokeStackImbalance exception.\r\n\r\nI've check and it looks like we build our native libraries in __csdecl conversion which is standard for C and we have \r\n`#define EXPORT_API(ret) extern \"C\" __declspec(dllexport) ret` in our stdafx.h file.\r\nby default PInvoke use WinApi convention which falls down to _stdcall.\r\n\r\nOn x64 platforms and .net core everything works fine, I assume as part of implementation.\r\nFor .net framework 4.6 with x86, it throws exception.\r\n\r\nSo I put implicit calling conversion in all our PInvoke calls, and also made sure we use our stdafx.h in all our native libraries.\r\n\r\nHave no idea how to write test for this tho.","Url":"https://github.com/dotnet/machinelearning/pull/1833","RelatedDescription":"Closed or merged PR \"Provide proper calling conversion for x86 framework\" (#1833)"},{"Id":"388752316","IsPullRequest":true,"CreatedAt":"2018-12-07T17:47:39","Actor":"sfilipi","Number":"1849","RawContent":null,"Title":"Add a test for 1259","State":"open","Body":"Closes #1259 by adding the test described in the bug. \r\nThis is no longer an issue. ","Url":"https://github.com/dotnet/machinelearning/pull/1849","RelatedDescription":"Open PR \"Add a test for 1259\" (#1849)"},{"Id":"388538366","IsPullRequest":true,"CreatedAt":"2018-12-07T07:35:18","Actor":"sfilipi","Number":"1848","RawContent":null,"Title":"Disintegrating Microsoft.ML.Api dispersing its content.","State":"open","Body":"Fixes #1707  by moving most of the classes on it to Microsoft.ML.Data or Microsoft.ML.Core. \r\n\r\nLet me know if there is a better place for particular files. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1848","RelatedDescription":"Open PR \"Disintegrating Microsoft.ML.Api dispersing its content.\" (#1848)"},{"Id":"388530007","IsPullRequest":true,"CreatedAt":"2018-12-07T07:00:51","Actor":"artidoro","Number":"1847","RawContent":null,"Title":"WIP: Update of FeatureContributionCalculation to new API","State":"open","Body":"Fixes #1791.\r\n\r\nAs this is a WIP PR, I am still completing the work, but I would really appreciate your feedback on what I have done so far.\r\n\r\nIn this PR:\r\n- [x]  I created a new ITransformer for FeatureContributionCalculation (previously known as WhatTheFeature) by converting previous ISchemaBoundRowMapper to two separate classes: a IRowMapper and a ISchemaBoundMapper.\r\n- [x] I created a new IEstimator that produces the transformer.\r\n- [ ] I added tests for the Transformer and Estimator. (Need to add a few more)\r\n- [x] I added MlContext extensions.\r\n- [x] I added documentation, and checks for arguments and types.\r\n\r\nWill do in a separate PR:\r\n- Add static extensions for the estimators.\r\n- I allowed pipelines, and not just IPredictor, to be passed to the IEstimator. \r\n","Url":"https://github.com/dotnet/machinelearning/pull/1847","RelatedDescription":"Open PR \"WIP: Update of FeatureContributionCalculation to new API\" (#1847)"},{"Id":"388463357","IsPullRequest":true,"CreatedAt":"2018-12-07T01:06:12","Actor":"wschin","Number":"1846","RawContent":null,"Title":"[WIP] Remove ISchema","State":"open","Body":"Fixes #1501.\r\n\r\n- [x] Replace `ISchema` with `Schema` in all cases without writing extra code\r\n- [ ] Remove `ITransposeSchema` because it's a `ISchema`\r\n- [x] Remove the uses of `ISchema` in ColumnBindingsBase\r\n- [ ] Remove the uses of `ISchema` in `internal sealed class CompositeSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\DataView\\CompositeSchema.cs`\r\n- [ ] Remove the uses of `ISchema` in `internal sealed class FakeSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\FakeSchema.cs`\r\n- [ ] Remove the uses of `ISchema` in `private abstract class NoMetadataSchema : ISchema` in \t`machinelearning\\src\\Microsoft.ML.Data\\DataView\\Transposer.cs`\r\n- [ ] Remove the uses of `ISchema` in `private sealed class Bindings : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Dirty\\ChooseColumnsByIndexTransform.cs`\r\n- [ ] Remove the uses of `ISchema` in `private sealed class Bindings : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoader.cs`\r\n- [ ] Remove the uses of `ISchema` in `private sealed class FeatureContributionSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Scorers\\FeatureContributionCalculationTransform.cs`\r\n- [ ] Remove the uses of `ISchema` in `private sealed class FeatureNameCollectionSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Depricated\\Instances\\HeaderSchema.cs`\r\n- [ ] Remove the uses of `ISchema` in `private sealed class SchemaImpl : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Scorers\\MultiClassClassifierScorer.cs`\r\n- [ ] Remove the uses of `ISchema` in `private sealed class SchemaImpl : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\DataLoadSave\\Binary\\BinaryLoader.cs`\r\n- [x] Remove the uses of `ISchema` in `public abstract class ScoreMapperSchemaBase : ISchema` in `machinelearning\\src\\Microsoft.ML.Data\\Scorers\\ScoreMapperSchema.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class GroupSchema : ISchema` in `machinelearning\\src\\Microsoft.ML.Transforms\\GroupTransform.cs`\r\n- [x] Remove the uses of `ISchema` in `private sealed class SchemaImpl : ISchema` in \t`machinelearning\\src\\Microsoft.ML.Transforms\\UngroupTransform.cs`\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1846","RelatedDescription":"Open PR \"[WIP] Remove ISchema\" (#1846)"},{"Id":"387917242","IsPullRequest":true,"CreatedAt":"2018-12-06T23:43:21","Actor":"Anipik","Number":"1829","RawContent":null,"Title":"Tolerance added for rff tests","State":"closed","Body":"Fixes #1825\r\n\r\nRff is using the new cpumathalgorithm for matrix multiplication\r\nSo sometimes there is difference in last few decimal places(due to different number of multiplications) from the original baseline so adding tolerance corrects the error.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1829","RelatedDescription":"Closed or merged PR \"Tolerance added for rff tests\" (#1829)"},{"Id":"388338539","IsPullRequest":false,"CreatedAt":"2018-12-06T22:37:34","Actor":"leblancdavid","Number":"1839","RawContent":null,"Title":"FastTree cannot solve a simple toy problem when using feature arrays","State":"closed","Body":"I'm having a hard time understanding the API for doing basic machine learning. In our application, our feature vectors come in as basic arrays of floating point values. I create a simple toy problem to try to understand how the API works (using the samples as a guide) which uses the `FastTree` binary classifier. The training data is just 2 vectors <0, 0>:0, <1, 1>:1, which should be easily be able to fit a model to. However, when I run the evaluation I get 50% accuracy. Here is my sample code:\r\n\r\n```\r\n class Program\r\n    {\r\n        public class FeatureData\r\n        {\r\n            [ColumnName(\"Label\")]\r\n            public bool Label { get; set; }\r\n\r\n            [ColumnName(\"Features\")]\r\n            public float[] Features { get; set; }\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n\r\n            var featuresTrainingData = new List<FeatureData>()\r\n            {\r\n                new FeatureData() { Features = new float[]{0.0f, 0.0f}, Label = false},\r\n                new FeatureData() { Features = new float[]{1.0f, 1.0f}, Label = true}\r\n            };\r\n\r\n            var schemaDef = SchemaDefinition.Create(typeof(FeatureData));\r\n            schemaDef[\"Features\"].ColumnType = new VectorType(NumberType.R4, 2);\r\n\r\n            var dataView = mlContext.CreateDataView(featuresTrainingData, schemaDef);\r\n\r\n            //Train the model\r\n            var pipeline = mlContext.BinaryClassification.Trainers.FastTree(featureColumn:\"Features\", labelColumn:\"Label\");\r\n            var model = pipeline.Fit(dataView);\r\n\r\n            //Evaluate\r\n            var predictions = model.Transform(dataView);\r\n            var metrics = mlContext.BinaryClassification.Evaluate(predictions, \"Label\");\r\n\r\n            Console.WriteLine();\r\n            Console.WriteLine(\"Model quality metrics evaluation\");\r\n            Console.WriteLine(\"--------------------------------\");\r\n            Console.WriteLine($\"Accuracy: {metrics.Accuracy:P2}\");\r\n            Console.WriteLine($\"Auc: {metrics.Auc:P2}\");\r\n            Console.WriteLine($\"F1Score: {metrics.F1Score:P2}\");\r\n            Console.WriteLine(\"=============== End of model evaluation ===============\");\r\n\r\n        }\r\n    }\r\n```\r\n\r\nWhat am I doing wrong here?\r\n\r\nThank you!","Url":"https://github.com/dotnet/machinelearning/issues/1839","RelatedDescription":"Closed issue \"FastTree cannot solve a simple toy problem when using feature arrays\" (#1839)"},{"Id":"388417893","IsPullRequest":true,"CreatedAt":"2018-12-06T22:04:31","Actor":"rogancarr","Number":"1844","RawContent":null,"Title":"Confidence Intervals for Permutation Feature Importance","State":"open","Body":"**Work in Progress** to start conversations. Do not review.\r\n\r\nThis PR adds an optional confidence interval calculation to the `Permutation Feature Importance` evaluator. If the users specifies the number of permutations > 1, then the resulting evaluating metrics will contain the mean and standard deviation.\r\n\r\nFixes #1840\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1844","RelatedDescription":"Open PR \"Confidence Intervals for Permutation Feature Importance\" (#1844)"},{"Id":"388021569","IsPullRequest":true,"CreatedAt":"2018-12-06T20:34:49","Actor":"TomFinley","Number":"1835","RawContent":null,"Title":"Row now disposable","State":"closed","Body":"Fixes #1824 .\r\n\r\nNote that some internal things that instead operate on top of delegates will still have `Action` disposer delegates, but my expectation is that most of those things are (or should be) disposable.\r\n\r\nThe usual advice about the commits being a useful way to review still apply, though less so than in prior PRs since there are fewer bulk renamings than elsewhere.","Url":"https://github.com/dotnet/machinelearning/pull/1835","RelatedDescription":"Closed or merged PR \"Row now disposable\" (#1835)"},{"Id":"388365719","IsPullRequest":false,"CreatedAt":"2018-12-06T19:36:59","Actor":"TomFinley","Number":"1843","RawContent":null,"Title":"Schema.Metadata needs a better name","State":"open","Body":"\"Metadata\" is perhaps not the best name for what we currently call metadata.\r\n\r\nFirst, what is it: what we call Metadata is meant to suggest not just any metadata, but that data that we consider auxiliary, or at *most* ancillary. (So for example, slot names are in metadata, because not everything will have names for each slot. But sometimes they will, and we need a place to keep that.)\r\n\r\nThe trouble with the name \"metadata\" is that it means literally everything but the data. But this is inaccurate: there are lots of things that are data about the data (e.g., the types, the vector sizes, the names of columns) that we definitely do not want to keep in the metadata structure (since they're absolutely required information), but that is \"metadata\" in the strict linguistic sense of the word.\r\n\r\nThe only name suggested as an alternative that I am aware of is \"annotations.\" I am fine with the name annotations. Perhaps we could come up with a better name. I'll leave this open for a bit, and unless people object we can rename metadata annotations.","Url":"https://github.com/dotnet/machinelearning/issues/1843","RelatedDescription":"Open issue \"Schema.Metadata needs a better name\" (#1843)"},{"Id":"388362048","IsPullRequest":false,"CreatedAt":"2018-12-06T19:27:03","Actor":"rogancarr","Number":"1840","RawContent":null,"Title":"Add confidence intervals to permutation feature importance","State":"open","Body":"`Permutation Feature Importance` (aka `PFI`) computes the importance of a feature to a model by permuting values for that feature, scoring it with the model, and comparing the new evaluation metrics to the original evaluation metrics. For speed, `PFI` uses only one permutation, and this leads to a bit of randomness in the predicted importances. For example, based on the random seed features can change orderings of importance and permutations can even end up showing to improve the model performance. These issues can be fixed by allowing the calculation of confidence intervals around the feature importance values.","Url":"https://github.com/dotnet/machinelearning/issues/1840","RelatedDescription":"Open issue \"Add confidence intervals to permutation feature importance\" (#1840)"},{"Id":"388109478","IsPullRequest":true,"CreatedAt":"2018-12-06T18:08:53","Actor":"TomFinley","Number":"1838","RawContent":null,"Title":"Revert \"Removed AlignedArray  (#1657)\"","State":"closed","Body":"This reverts commit 72ec121afe1a889218c750f7bda7ee5093c140b7.\r\nA bug was detected that resulted in non-deterministic calculation, since the\r\nunderlying C++ code was written in a way apparently that required alignment\r\nto produce consistent results, so of course just removing the alignment and\r\ncalling an only slightly modified algorithm compromised determinism, resulting\r\nin test failure for RFF in particular.\r\n\r\nIf we can fix that bug by other means that would be preferable, since removing `AlignedArray` is a desirable outcome. Not if it means nondeterminism though, obviously. 😉 ","Url":"https://github.com/dotnet/machinelearning/pull/1838","RelatedDescription":"Closed or merged PR \"Revert \"Removed AlignedArray  (#1657)\"\" (#1838)"},{"Id":"388026559","IsPullRequest":true,"CreatedAt":"2018-12-06T02:12:52","Actor":"najeeb-kazmi","Number":"1837","RawContent":null,"Title":"Public API for Tree predictors","State":"open","Body":"Fix #1701 \r\n\r\nInternalized and explicitly implemented the following interfaces implemented by `FastTreePredictionWrapper`:\r\n- `ICanSaveInIniFormat`\r\n- `ICanSaveInSourceCode`\r\n- `ICanSaveSummary`\r\n- `ICanSaveSummaryInKeyValuePairs`\r\n- `ICanGetSummaryAsIRow`\r\n- `IFeatureContributionMapper`\r\n- `IQuantileValueMapper`\r\n- `IQuantileRegressionPredictor`\r\n- `IValueMapperDist`\r\n\r\nRenamed `FastTreePredictionWrapper` to `TreeEnsembleModelParameters` and descendants to `XYZModelParameters`. Reduced public surface of `TreeEnsembleModelParameters` and descendants.\r\n\r\nAdded public constructors for `TreeEnsembleModelParameters` and descendants.\r\n\r\nAdded a sample showing `FastTreeRegressionModelParameters` operations.","Url":"https://github.com/dotnet/machinelearning/pull/1837","RelatedDescription":"Open PR \"Public API for Tree predictors\" (#1837)"},{"Id":"388023995","IsPullRequest":true,"CreatedAt":"2018-12-06T02:00:03","Actor":"abgoswam","Number":"1836","RawContent":null,"Title":"Test for Metadata Support In DataView Construction","State":"open","Body":"Fixes #1633 \r\n\r\n- Inside the `GetGetterDelegate` we were invoking MarshalInvoke with `GetGetter<int>` .  This does not take into consideration  the generic return type `ValueGetter<TDst>`. Subsequently, the validation inside `MarshalInvokeCheckAndCreate` fails.\r\n\r\n- As part of the fix, we use reflection to invoke the generic `GetGetter<TDst>` with the appropriate type.","Url":"https://github.com/dotnet/machinelearning/pull/1836","RelatedDescription":"Open PR \"Test for Metadata Support In DataView Construction\" (#1836)"},{"Id":"388020090","IsPullRequest":false,"CreatedAt":"2018-12-06T01:40:16","Actor":"jignparm","Number":"1834","RawContent":null,"Title":"OnnxTransform -- upgrade to support Linux, Mac and CUDA GPU","State":"open","Body":"Add support for Linux X64\r\nAdd support for Mac X64\r\nAdd support for CUDA GPU for Windows and Linux (no Mac yet)","Url":"https://github.com/dotnet/machinelearning/issues/1834","RelatedDescription":"Open issue \"OnnxTransform -- upgrade to support Linux, Mac and CUDA GPU\" (#1834)"},{"Id":"387975746","IsPullRequest":true,"CreatedAt":"2018-12-05T22:34:13","Actor":"rogancarr","Number":"1832","RawContent":null,"Title":"Adding support for most learning tasks to PFI","State":"open","Body":"This PR adds support to `Permutation Feature Importance` for `Multiclass Classification`, `Ranking`, and `Clustering`.\r\n\r\nFixes #1771\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1832","RelatedDescription":"Open PR \"Adding support for most learning tasks to PFI\" (#1832)"},{"Id":"387971885","IsPullRequest":false,"CreatedAt":"2018-12-05T22:21:54","Actor":"JRAlexander","Number":"1831","RawContent":null,"Title":" Deprecate documentation topics migrated to docs.microsoft.com","State":"open","Body":"The ML.NET Cookbook and ML.NET High-Level Concepts documents have been migrated to docs.microsoft.com as agreed upon. The current documents need to be updated to point to the migrated ones.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1831","RelatedDescription":"Open issue \" Deprecate documentation topics migrated to docs.microsoft.com\" (#1831)"},{"Id":"387954020","IsPullRequest":true,"CreatedAt":"2018-12-05T22:15:59","Actor":"JRAlexander","Number":"1830","RawContent":null,"Title":"Deprecate documentation topics migrated to docs.microsoft.com","State":"closed","Body":"Deprecate migrated ML.NET Cookbook and ML.NET High-Level topics. These topics will now point to the migrated topics:\r\n* ML.NET Cookbook has been split out and migrated to [the docs.microsoft.com ML.NET How to section](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/).\r\n* ML.NET High-Level topics has been split out and migrated to the [\"Basic concepts for model training in ML.NET\" topic at docs.microsoft.com](https://docs.microsoft.com/en-us/dotnet/machine-learning/basic-concepts-model-training-in-mldotnet).\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/1831 ","Url":"https://github.com/dotnet/machinelearning/pull/1830","RelatedDescription":"Closed or merged PR \"Deprecate documentation topics migrated to docs.microsoft.com\" (#1830)"},{"Id":"387841330","IsPullRequest":true,"CreatedAt":"2018-12-05T18:48:58","Actor":"eerhardt","Number":"1828","RawContent":null,"Title":"Allow ML.NET native binaries to work on Windows machines that don't have the VC runtime installed.","State":"closed","Body":"This allows ML.NET to run on Windows Nano containers.\r\n\r\nI also ported 2 Unix compile options we are using in core-setup and corefx that were missed when originally creating the ML.NET native build infrastructure.\r\n\r\nFix #1823\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1828","RelatedDescription":"Closed or merged PR \"Allow ML.NET native binaries to work on Windows machines that don't have the VC runtime installed.\" (#1828)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-12-11T05:30:49.3853906Z","RunDurationInMilliseconds":1355}