{"Data":{"GitHub":{"Issues":[{"Id":"367039789","IsPullRequest":true,"CreatedAt":"2018-10-05T02:42:01","Actor":"Ivanidzo4ka","Number":"1160","RawContent":null,"Title":"Provide action to set Arguments class in SDCA pigstensions","State":"open","Body":"fixes https://github.com/dotnet/machinelearning/issues/1121","Url":"https://github.com/dotnet/machinelearning/pull/1160","RelatedDescription":"Open PR \"Provide action to set Arguments class in SDCA pigstensions\" (#1160)"},{"Id":"367021142","IsPullRequest":true,"CreatedAt":"2018-10-05T02:38:42","Actor":"Ivanidzo4ka","Number":"1158","RawContent":null,"Title":"WIP enable MTA","State":"closed","Body":"I'm just curious what would happen if I turn on AppartmentState in our tests.","Url":"https://github.com/dotnet/machinelearning/pull/1158","RelatedDescription":"Closed or merged PR \"WIP enable MTA\" (#1158)"},{"Id":"367026855","IsPullRequest":false,"CreatedAt":"2018-10-05T01:28:08","Actor":"Ivanidzo4ka","Number":"1159","RawContent":null,"Title":"OVA and PKPD don't have pigsty extensions.","State":"open","Body":"Not sure was it intentional, or we just forgot to add them\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1159","RelatedDescription":"Open issue \"OVA and PKPD don't have pigsty extensions.\" (#1159)"},{"Id":"367016237","IsPullRequest":false,"CreatedAt":"2018-10-05T00:20:31","Actor":"zeahmed","Number":"1157","RawContent":null,"Title":"Manage TensorFlow model loading so that it is not loaded twice; first for schema then for use in TFTransform.","State":"open","Body":"TFSession/TFGraph is loaded twice if user is interested in query the model schema first and then creating TensorFlowTransform. \r\n\r\nCurrently, there is no way to pass existing TFSession information which was loaded during schema probing to TensorFlowTransform. Furthermore, TFSession is internal to the assembly and there is no plan to expose this object.\r\n\r\nThe solution would be to create a `TensorFlowModelContext` wrapper class as follows that will carry the TFSession as internal object. A convenience constructor will created in TensorFlowTransform that will accept this object as input instead of model location.\r\n\r\n``` C#\r\npublic class TensorFlowModelContext\r\n{\r\n    internal TFSession TFSession { get; private set; }\r\n    public string ModelPath { get; private set; }\r\n    public ISchema Schema { get; private set; }\r\n\r\n    internal TensorFlowModelContext(TFSession tFSession, string modelLocation, ISchema schema)\r\n    {\r\n        TFSession = tFSession;\r\n        ModelPath = modelLocation;\r\n        Schema = schema;\r\n    }\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/1157","RelatedDescription":"Open issue \"Manage TensorFlow model loading so that it is not loaded twice; first for schema then for use in TFTransform.\" (#1157)"},{"Id":"367001971","IsPullRequest":false,"CreatedAt":"2018-10-04T23:03:22","Actor":"danmosemsft","Number":"1156","RawContent":null,"Title":"Do we have a complete testing strategy for the math code","State":"open","Body":"Seems we have 4 possible code paths in cpumath:\r\n\r\n1) sse.cpp  -- used when not on .NET Core 3.0\r\n2) avxintrinsics.cs  -- on .NET Core 3.0 with AVX available\r\n3) sseintrinsics.cs\t -- on .NET Core 3.0 with SSE but not AVX\r\n4) software fallback in cpumathutils.netcoreapp.cs -- on .NET Core 3.0 with no SIMD (eg., on ARM). There seems to be no software fallback when not on .NET Core 3.0.\r\n\r\nFor tests we have\r\nA) CpuMath.UnitTests.netcoreapp. Executes whichever of (2), (3), (4) applies at run time. Which will almost surely be (2) in all cases.\r\nB) CpuMath.UnitTests.netstandard. Same tests as above, but against (1).\r\nC) Microsoft.ML.CpuMath.PerformanceTests. Perf, not functional, tests for about 20 entry points in (1), (2), and (3) explicitly.\r\n\r\nWe need to have tests for anything we ship and support, which I think means we have a gap for (3) and (4) ie on older x86 machines and on non x86 machines.\r\n\r\n@tannergooding how commonly would the non AVX path (3) be encountered on typical customer x86 machines? Am I correct that (4) is not relevant to x86?\r\n\r\ncc @Anipik \t \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1156","RelatedDescription":"Open issue \"Do we have a complete testing strategy for the math code\" (#1156)"},{"Id":"366197302","IsPullRequest":false,"CreatedAt":"2018-10-04T22:41:48","Actor":"sfilipi","Number":"1133","RawContent":null,"Title":"docs.microsoft.com don't display all the extension methods for trainers","State":"closed","Body":"The training methods are extensions of the TrainingContext object, organized in partial classes (ex. RegressionTrainers), that are part of the same namespace (Microsoft.ML.StaticPipe), but packaged in different dlls . \r\nSo across the dlls there are several RegressionTrainers.xml (for the partial classes)\r\n\r\nOn the documents repo, there is only one RegressionTrainers.xml file (maybe the first encountered)\r\nhttps://github.com/dotnet/ml-api-docs/tree/smoke-test/dotnet/xml/Microsoft.ML.StaticPipe\r\n\r\nIf the docs CI cannot gather all those .xml in one. \r\nWe might have to keep the extension methods  within the namespaces  of the trainers, and rely on search for discoverability.\r\nIntellisense  might suffer, as the users would have to add all namespaces to get all trainers in the suggestions. \r\n\r\nWe can keep the extensions, on classes with the same names in those namespaces. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1133","RelatedDescription":"Closed issue \"docs.microsoft.com don't display all the extension methods for trainers\" (#1133)"},{"Id":"366966946","IsPullRequest":true,"CreatedAt":"2018-10-04T22:04:43","Actor":"singlis","Number":"1155","RawContent":null,"Title":"TrainUtils.Train does not have consistent API usage","State":"closed","Body":"TrainUtils.Train does not have consistent API usage for the calibrator argument (#1023)\r\n\r\nUpdates the API signature for TrainUtils.Train to take in an IComponentFactory<ICalibratorTrainer>.\r\n\r\nFixes #1023","Url":"https://github.com/dotnet/machinelearning/pull/1155","RelatedDescription":"Closed or merged PR \"TrainUtils.Train does not have consistent API usage\" (#1155)"},{"Id":"366529435","IsPullRequest":true,"CreatedAt":"2018-10-04T21:48:29","Actor":"singlis","Number":"1141","RawContent":null,"Title":"Updating the CopyColumnsEstimator and Transform to use common code (#706)","State":"closed","Body":"This builds on the Estimator conversion for the CopyColumnsTransform.\r\nThis change is mainly refactoring as common code has moved to base level classes.\r\n\r\nThis change is the following:\r\n       - CopyColumnTransform now derives from OneToOneTransformerBase\r\n       - CopyColumnEstimator now derives from TrivialEstimator\r\n       - CopyColumnTransform::Mapper now derives from MapperBase\r\n       - Removed code that was no longer needed due to these changes\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1141","RelatedDescription":"Closed or merged PR \"Updating the CopyColumnsEstimator and Transform to use common code (#706)\" (#1141)"},{"Id":"366679303","IsPullRequest":true,"CreatedAt":"2018-10-04T21:40:07","Actor":"beneyal","Number":"1147","RawContent":null,"Title":"Remove explicit ComponentCatalog parameter","State":"closed","Body":"ValidateNodes and EntryPointNode now use the ComponentCatalog\r\nproperty of IHostEnvironment.\r\n\r\nFollowing the conversation with @Ivanidzo4ka at #1135 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1147","RelatedDescription":"Closed or merged PR \"Remove explicit ComponentCatalog parameter\" (#1147)"},{"Id":"366908826","IsPullRequest":false,"CreatedAt":"2018-10-04T18:11:45","Actor":"CESARDELATORRE","Number":"1154","RawContent":null,"Title":"How to create an Estimator without using a DataReader?","State":"open","Body":"### System information\r\nUsing the new API (PiGSTy/Typed) API.\r\n\r\n### Context\r\nThis is confirmed by Tom that the needed API is still not surfacing in the new PiGSTy/Typed API for this scenario. Will come soon, I'm just opening the issue to track it down.\r\n\r\n### Problem \r\nLet’s say I’m not reading/loading data from a text file (using a DataReader) but from a Database or any other channel, like the following code:\r\n \r\n```\r\nvar env = new LocalEnvironment();\r\nIEnumerable<Orders> myData = GetDataFromDatabase();\r\nvar trainData = env.CreateStreamingDataView(myData);\r\n```\r\n \r\n….\r\n \r\nFor the whole training process, I could do something like the following, with the new API:\r\n \r\n```\r\nvar dataReader = TextLoader.CreateReader(env,\r\n                c => (\r\n                    CustomerId: c.LoadText(0),\r\n                    ProductId: c.LoadText(1),\r\n                    Quantity: c.LoadFloat(2),\r\n                    Label: c.LoadBool(3)),\r\n                    separator: ',', hasHeader: true);\r\n \r\nFieldAwareFactorizationMachinePredictor pred = null;\r\nvar ctx = new BinaryClassificationContext(env);\r\n \r\nvar est = dataReader.MakeNewEstimator()\r\n    .Append(row => (CustomerId_OHE: row.CustomerId.OneHotEncoding(), ProductId_OHE: row.ProductId.OneHotEncoding(), row.Label))\r\n    .Append(row => (Features: row.CustomerId_OHE.ConcatWith(row.ProductId_OHE), row.Label))\r\n    .Append(row => (row.Label,\r\n    preds: ctx.Trainers.FieldAwareFactorizationMachine(\r\n        row.Label,\r\n        new[] { row.Features },\r\n        advancedSettings: ffmArguments => ffmArguments.Shuffle = false,\r\n        onFit: p => pred = p)));\r\n \r\n// NO NEED FOR THIS SINCE I’M NOT READING FROM A FILE\r\n//var dataSource = reader.Read(new MultiFileSource(orderItemsLocation));\r\n \r\n// Load data in IDataView from a Database\r\nIEnumerable<Orders> myData = GetDataFromDatabase();\r\nvar trainData = env.CreateStreamingDataView(myData);\r\n \r\nvar model = est.Fit(trainData);\r\n \r\n```\r\n \r\nHowever, since we’re not reading/loading from a file, I should be able to create an Estimator by using a different way instead of a “dataReader”, since in the code above that dataReader is *not* reading anything and is just being used to create the estimator.\r\n\r\nI’d like to create the “schema” provided to the DataReader and create the Estimator without anything related to a DataReader, because I’m not reading anything with it in the code above.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1154","RelatedDescription":"Open issue \"How to create an Estimator without using a DataReader?\" (#1154)"},{"Id":"366833725","IsPullRequest":true,"CreatedAt":"2018-10-04T17:32:02","Actor":"DAXaholic","Number":"1149","RawContent":null,"Title":"Create links to detail sections","State":"closed","Body":"\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1149","RelatedDescription":"Closed or merged PR \"Create links to detail sections\" (#1149)"},{"Id":"366537606","IsPullRequest":true,"CreatedAt":"2018-10-04T17:26:44","Actor":"adamsitnik","Number":"1142","RawContent":null,"Title":"add .NET Core 3.0 support for the benchmarks","State":"closed","Body":"@Anipik works on making the 3.0 test pass, the Benchmark test was failing so here is the fix for it","Url":"https://github.com/dotnet/machinelearning/pull/1142","RelatedDescription":"Closed or merged PR \"add .NET Core 3.0 support for the benchmarks\" (#1142)"},{"Id":"366879987","IsPullRequest":false,"CreatedAt":"2018-10-04T16:50:26","Actor":"eerhardt","Number":"1153","RawContent":null,"Title":"Rename Microsoft.ML.StaticPipe.Vector<T> type","State":"open","Body":"We currently have:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/161b450a68a3f47eaf8abd4ce4778e417814b20f/src/Microsoft.ML.Data/StaticPipe/PipelineColumn.cs#L48-L52\r\n\r\nWhich is more of a schema type that says \"the column I represent is a vector type\". Which means this type isn't actually a \"vector\", but more of a \"vector column\".\r\n\r\nWe should rename this type (and the other XXColumn types), so we can \"make room\" for an actual `Vector<T>` type, which really does represent a \"vector\" object.\r\n\r\n/cc @TomFinley ","Url":"https://github.com/dotnet/machinelearning/issues/1153","RelatedDescription":"Open issue \"Rename Microsoft.ML.StaticPipe.Vector<T> type\" (#1153)"},{"Id":"366875198","IsPullRequest":true,"CreatedAt":"2018-10-04T16:37:17","Actor":"artidoro","Number":"1152","RawContent":null,"Title":"WIP: Conversion of ensemble trainers to estimators","State":"open","Body":"Ongoing work on converting the trainers to estimators (#754). This PR converts ensemble trainers (RegressionEnsembleTrainer, EnsembleTrainer, and MulticlassDataPartitionEnsembleTrainer).\r\n\r\nStill requires more work on determining the right API for the ensemble trainers. ","Url":"https://github.com/dotnet/machinelearning/pull/1152","RelatedDescription":"Open PR \"WIP: Conversion of ensemble trainers to estimators\" (#1152)"},{"Id":"366871698","IsPullRequest":true,"CreatedAt":"2018-10-04T16:27:44","Actor":"Racing5372","Number":"1151","RawContent":null,"Title":"Update README.md","State":"open","Body":"Minor addition to README","Url":"https://github.com/dotnet/machinelearning/pull/1151","RelatedDescription":"Open PR \"Update README.md\" (#1151)"},{"Id":"366846455","IsPullRequest":false,"CreatedAt":"2018-10-04T15:28:36","Actor":"HowardvanRooijen","Number":"1150","RawContent":null,"Title":"Model Backwards Compatability ","State":"open","Body":"Hi\r\n\r\nFollowing up from issue #569 - when using the latest nightly builds `0.7.0-preview-27004-1` models trained using the previous ML.NET release (0.5) fail to load, with the following exception:\r\n\r\n``` csharp\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Runtime.Model.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Runtime.Data.CompositeDataLoader.LoadSelectedTransforms(ModelLoadContext ctx, IDataView srcView, IHostEnvironment env, Func`2 isTransformTagAccepted)\r\n   at Microsoft.ML.Runtime.Model.ModelFileUtils.LoadTransforms(IHostEnvironment env, IDataView data, RepositoryReader rep)\r\n   at Microsoft.ML.Runtime.Model.ModelFileUtils.LoadTransforms(IHostEnvironment env, IDataView data, Stream modelStream)\r\n   at Microsoft.ML.Runtime.Api.ComponentCreation.LoadTransforms(IHostEnvironment env, Stream modelStream, IDataView data)\r\n   at Microsoft.ML.Runtime.Api.DataViewConstructionUtils.LoadPipeWithPredictor(IHostEnvironment env, Stream modelStream, IDataView view)\r\n   at Microsoft.ML.Runtime.Api.BatchPredictionEngine`2..ctor(IHostEnvironment env, Stream modelStream, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Runtime.Api.ComponentCreation.CreateBatchPredictionEngine[TSrc,TDst](IHostEnvironment env, Stream modelStream, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n   at Microsoft.ML.Legacy.PredictionModel.ReadAsync[TInput,TOutput](Stream stream)\r\n   at Demo.Program.<Main>d__0.MoveNext() in C:\\_Projects\\OSS\\MLNETPreviousModelLoadingError\\Demo\\Program.cs:line 25\r\n```\r\n\r\nI've attached a small demo that reproduces the above. The zip also contains a model trained on ML.NET 0.5 using the following code:\r\n\r\n``` csharp\r\nnamespace Endjin.Expenses.Demo\r\n{\r\n    #region Using Directives\r\n\r\n    using System.Collections.Generic;\r\n\r\n    using Endjin.FreeAgent.Expenses.MachineLearning.Domain;\r\n\r\n    using Microsoft.ML.Legacy;\r\n    using Microsoft.ML.Legacy.Data;\r\n    using Microsoft.ML.Legacy.Trainers;\r\n    using Microsoft.ML.Legacy.Transforms;\r\n\r\n    #endregion \r\n\r\n    public class ExpenseModelTrainer\r\n    {\r\n        public PredictionModel<TransactionModel, Prediction> Train(IEnumerable<TransactionModel> input)\r\n        {\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                CollectionDataSource.Create(input),\r\n                new TextFeaturizer(\"Features\", nameof(TransactionModel.Description), nameof(TransactionModel.Reference), nameof(TransactionModel.Amount)),\r\n                new Dictionarizer(nameof(TransactionModel.Label)),\r\n                new StochasticDualCoordinateAscentClassifier(),\r\n                new PredictedLabelColumnOriginalValueConverter { PredictedLabelColumn = nameof(Prediction.PredictedLabel) }\r\n            };\r\n\r\n            return pipeline.Train<TransactionModel, Prediction>();\r\n        }\r\n    }\r\n}\r\n```\r\n(The \"legacy\" namespaces changed in the latest version, but if you change them back to the 0.5 version namespaces - nothing else changed)\r\n\r\n[MLNETPreviousModelLoadingError.zip](https://github.com/dotnet/machinelearning/files/2446874/MLNETPreviousModelLoadingError.zip)\r\n\r\nMany thanks,\r\n\r\nHoward\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1150","RelatedDescription":"Open issue \"Model Backwards Compatability \" (#1150)"},{"Id":"366772332","IsPullRequest":false,"CreatedAt":"2018-10-04T12:46:01","Actor":"ArieJones","Number":"1148","RawContent":null,"Title":"Saving of Prediction Function","State":"open","Body":"We are currently working with the 0.50 release and looking to move to the new API. One of the questions that has surfaced is in regards to the new PredictionFunction \r\n\r\n`// Use the model for one-time prediction.\r\n// Make the prediction function object. Note that, on average, this call takes around 200x longer\r\n// than one prediction, so you might want to cache and reuse the prediction function, instead of\r\n// creating one per prediction.\r\nvar predictionFunc = model.MakePredictionFunction<IrisInput, IrisPrediction>(env);`\r\n\r\nWe are currently working with a set of models that we are saving/restoring from in order to get predictions. Sometimes these models are taking up a large amount of memory … on the order of ~8GB for some of the more complicated ones that are using various ngram lengths. \r\n\r\nSo the question would be … Would there be any reason we could not save off the PredictionFunction in addition to the model in order to possibly shave off memory consumption or should we expect that the PredictionFunction created by a model with a given memory footprint will be relatively the same size? \r\n\r\nThanks!\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1148","RelatedDescription":"Open issue \"Saving of Prediction Function\" (#1148)"},{"Id":"366636399","IsPullRequest":false,"CreatedAt":"2018-10-04T06:12:16","Actor":"dotChris90","Number":"1146","RawContent":null,"Title":"Regression learning with constrains ","State":"open","Body":"Hello Team, \r\n\r\nI just was thinking about the follow scenario and questions:\r\n\r\n- you have a normal regression Problem with n features \r\n- you build a Model based on this known features \r\n- **how does ML.NET handle constrains like \"feature 1 and 2 always must satisfy a equation\"?**  \r\n- **Is there an easy way to fit non-linear function based models without feature transform?** (something like f(x) = sin(p_1*x_1) * p_2 * exp(P_3 * x_2) * x_3, here are my data and what are the parameters?) \r\n\r\nI am from automotive engineering area and unfortunately we always facing this issues and unfortunately again most here are old school and MATLAB users. \r\n\r\nSo most engineers expect something MATLAB like, e.g. Regression.Fit(sin(p_1*x_1) * p_2 * exp(P_3 * x_2) * x_3, x_vector, y_vector) . \r\n\r\nSo this ML.NET have already something like this? I could image a model class could have something like constrains fields ... :D \r\n","Url":"https://github.com/dotnet/machinelearning/issues/1146","RelatedDescription":"Open issue \"Regression learning with constrains \" (#1146)"},{"Id":"366491704","IsPullRequest":true,"CreatedAt":"2018-10-04T03:56:15","Actor":"pkulikov","Number":"1139","RawContent":null,"Title":"New API overview: added AsDynamic call","State":"closed","Body":"The example at the end of the [overview of new ML.NET API](https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetHighLevelConcepts.md#prediction-function) doesn't use `AsDynamic`:\r\n```csharp\r\nvar inputData = env.CreateDataView(new InputExample[] { example });\r\nvar outputData = model.Transform(inputData);\r\nvar output = outputData.AsEnumerable<OutputPrediction>(env, reuseRowObject: false).Single();\r\n```\r\n\r\nSo, it looks that the `AsDynamic` call in the cookbook example is not necessary.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1139","RelatedDescription":"Closed or merged PR \"New API overview: added AsDynamic call\" (#1139)"},{"Id":"366602653","IsPullRequest":true,"CreatedAt":"2018-10-04T02:53:44","Actor":"tannergooding","Number":"1145","RawContent":null,"Title":" Fix MatchNumberWithTolerance to better compare floating-point values","State":"open","Body":"This updates `MatchNumberWithTolerance` to better compare floating-point values and enables it on Windows.\r\n\r\nThe previous algorithm was not properly accounting for the distribution of binary floating-point values and would not allow a match for numbers that could have been reasonably considered as equivalent.","Url":"https://github.com/dotnet/machinelearning/pull/1145","RelatedDescription":"Open PR \" Fix MatchNumberWithTolerance to better compare floating-point values\" (#1145)"},{"Id":"366580982","IsPullRequest":false,"CreatedAt":"2018-10-04T00:42:31","Actor":"ArieJones","Number":"1144","RawContent":null,"Title":"Inconsistancy in Training With Multiple Threads ","State":"open","Body":"We are currently using version 0.50 in creating some classifier models but are seeing some strange behavior. We are currently setting the number of threads in our classifiers due to #217 and wanting to be able to control the CPU usage on the server. \r\nSo when using a classifier like so .. \r\n`var algo = new StochasticDualCoordinateAscentClassifier()\r\n                    {\r\n                        Caching = CachingOptions.Disk,\r\n                        MaxIterations = 100,\r\n                        LossFunction = new SmoothedHingeLossSDCAClassificationLossFunction(),\r\n                        Shuffle = false,\r\n                        NumThreads = System.Environment.ProcessorCount - 1 //We use one less than the number of processors available,\r\n                    };`\r\n\r\nWhat we are noticing is that if we run this from a box with 4 cores on it then we get a decent model where the microaccuracy is above 90%. However, when we move this same code over to a larger server with 8 cores we are getting wildly different results. The microaccuracy drops down to around <60%. \r\nYikes! \r\n\r\nIs there possibly something we are missing in the documentation that would address this? ","Url":"https://github.com/dotnet/machinelearning/issues/1144","RelatedDescription":"Open issue \"Inconsistancy in Training With Multiple Threads \" (#1144)"},{"Id":"366224070","IsPullRequest":true,"CreatedAt":"2018-10-03T22:42:19","Actor":"beneyal","Number":"1135","RawContent":null,"Title":"Remove ComponentCatalog from EntryPointGraph's and GraphRunner's constructors","State":"closed","Body":"Fixes #1113 .\r\n\r\nThe constructors now use env.ComponentCatalog as their catalog, instead of a catalog being passed as an argument. All call sites were changed accordingly.","Url":"https://github.com/dotnet/machinelearning/pull/1135","RelatedDescription":"Closed or merged PR \"Remove ComponentCatalog from EntryPointGraph's and GraphRunner's constructors\" (#1135)"},{"Id":"366500309","IsPullRequest":true,"CreatedAt":"2018-10-03T22:41:43","Actor":"dzban2137","Number":"1140","RawContent":null,"Title":"General grammar and punctuation fixes in README.md","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1140","RelatedDescription":"Closed or merged PR \"General grammar and punctuation fixes in README.md\" (#1140)"},{"Id":"366549418","IsPullRequest":true,"CreatedAt":"2018-10-03T22:09:38","Actor":"Anipik","Number":"1143","RawContent":null,"Title":"Improvements to the \"Scale\" SIMD algorithm","State":"open","Body":"For inputs with fewer elements than can fit in the Vector type, it falls back to scalar code.\r\nFor inputs that are not naturally aligned (the alignment is not a multiple of 4), it does exclusively unaligned loads\r\nFor all other inputs, it will do at most two unaligned loads (one each for any leading/trailing unaligned elements) and all other loads will be aligned.\r\n\r\ncc @eerhardt @tannergooding @danmosemsft ","Url":"https://github.com/dotnet/machinelearning/pull/1143","RelatedDescription":"Open PR \"Improvements to the \"Scale\" SIMD algorithm\" (#1143)"},{"Id":"366481392","IsPullRequest":false,"CreatedAt":"2018-10-03T18:59:55","Actor":"CESARDELATORRE","Number":"1138","RawContent":null,"Title":"Possible bug/issue with TensorFlow featurizer for SDCA when using PiGSTy/Static API in a migrated sample from LearningPipeline API","State":"open","Body":"### System information\r\n- Using ML.NET v0.6 and PiGSTy/Static API\r\n\r\n### Issue\r\nWe have migrated the sample using **TensorFlow as featurizer** and using the **pre-trained Inception v3 TF model**, then using an ML.NET SDCA learner for the classification.\r\n\r\nThis is the original LearningPipeline API-based sample that was working ok:\r\nhttps://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/examples/DeepLearning_TensorFlowMLNETInceptionv3ModelScoring\r\n\r\nThe new code you can test is here:\r\nrepo: https://github.com/franperezlopez/machinelearning-samples\r\nbranch: features/samples-new-api\r\n\r\nHere’s an screenshot showing the execution:\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/46432381-fccdae00-c702-11e8-84ed-794cde3d6398.png)\r\n\r\n•\tFirst, basically, the variables temp1 and temp2 and really the same object in memory (in Watcher, after \"make object ID\", you can see that both are pointing to the same position in memory. These variables come  from the object returned by **predictor.Predict()**. See the code in order to understand the code flow.\r\n\r\nIf `model.AsDynamic.MakePredictionFunction<ImageNetData, ImageNetStaticPrediction>(env).Predict(testData)` is meant to always return the same object in memory, it would be advisable to show that explicitly in the API, doing something like:\r\n\r\n`model.AsDynamic.MakePredictionFunction<ImageNetData, ImageNetStaticPrediction>(env, testData).Predict()`\r\n\r\nThat way, testData is provided through the constructor instead as parameter for the function/method, so it is clearer that you can only use it “once”. But I'm not sure if the behavior is a bug, though...\r\n\r\nCan you confirm if we need to “copy by value” the PredictionFunction to a new object whenever we want to do a different prediction with new test/sample data? For example, in a loop with multiple predictions, etc.\r\n\r\n•\tSecond. The predictions we are getting are much worse in quality/probability than when using the LearningPipeline API. In the Watcher, looking at the metrics, you can see what’s going on. Basically, we’re exploring the preds.score returned by the SDCA, but it looks weird we’re getting numbers like **0.2** …?  --> When we were using the LearningPipeline for this same example we were getting probabilities around 0.999 or 0.0001.\r\no\tYou can also see in the screenshot the value for “**softmax2_pre_activation**”, which is the features vector coming from the neural network. \r\n\r\n![image](https://user-images.githubusercontent.com/1712635/46432660-a3b24a00-c703-11e8-85bd-93db619c348b.png)\r\n\r\nLooks like the SDCA is not learning anything, it is always classifying as “broccoli”. So, we don’t know what’s going on here.\r\nWe might be doing something wrong or it might be a bug?\r\n\r\n![image](https://user-images.githubusercontent.com/1712635/46432696-b7f64700-c703-11e8-8354-3c03a4448b80.png)\r\n\r\n\r\nBottom line, we’re blocked with this sample. It is not working properly with the new Static API after migrating a working sample with the LearningPipeline. \r\nEither we’re doing something wrong or there’s an issue/bug here?\r\n\r\nThanks,\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1138","RelatedDescription":"Open issue \"Possible bug/issue with TensorFlow featurizer for SDCA when using PiGSTy/Static API in a migrated sample from LearningPipeline API\" (#1138)"},{"Id":"366464164","IsPullRequest":false,"CreatedAt":"2018-10-03T18:15:27","Actor":"sfilipi","Number":"1137","RawContent":null,"Title":"Package the datasets needed for the samples in a nuget","State":"open","Body":"The samples in docs.microsoft.com need to be fully self-contained like other MSDN code samples, so the users can copy-paste and run them. \r\n\r\nFor this we could either package the datasets needed for the samples in a NuGet, or download them from this repo, via aka.ms links. \r\nI prefer the NuGet option, since the package creation and its updates are on the repository, and we can track history. We can't do the same for the links, afaik, and it is a separate system. \r\n\r\nThis issue will be considered complete when we publish the NuGet containing one dataset that we can reference from the samples. ","Url":"https://github.com/dotnet/machinelearning/issues/1137","RelatedDescription":"Open issue \"Package the datasets needed for the samples in a nuget\" (#1137)"},{"Id":"366461191","IsPullRequest":false,"CreatedAt":"2018-10-03T18:07:27","Actor":"zyw400","Number":"1136","RawContent":null,"Title":"Better error message for non-existing columns when executing graph","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: Latest master branch \r\n\r\n### Issue\r\n\r\nExecuting a graph with wrong LabelColumn name, the error messages is not very clear:\r\n\r\nMessage: System.ArgumentOutOfRangeException : Specified argument was out of the range of valid values.\r\nParameter name: Column\r\n\r\nIf the FeatureColumn name is wrong, the error message indicates Column not found, which is better.\r\n[infert.txt](https://github.com/dotnet/machinelearning/files/2443223/infert.txt)\r\n[graph_1.txt](https://github.com/dotnet/machinelearning/files/2443224/graph_1.txt)\r\n\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/1136","RelatedDescription":"Open issue \"Better error message for non-existing columns when executing graph\" (#1136)"},{"Id":"366197167","IsPullRequest":true,"CreatedAt":"2018-10-03T14:10:35","Actor":"xxdr4gon","Number":"1132","RawContent":null,"Title":"Release/preview","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1132","RelatedDescription":"Closed or merged PR \"Release/preview\" (#1132)"},{"Id":"366201200","IsPullRequest":true,"CreatedAt":"2018-10-03T07:04:33","Actor":"artidoro","Number":"1134","RawContent":null,"Title":"Conversion of Hogwild SGD to estimator","State":"open","Body":"Ongoing work on converting the trainers to estimators (#754). This PR converts Hogwild SGD  (StochasticGradientDescentClassificationTrainer binary classification trainer). \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/1134","RelatedDescription":"Open PR \"Conversion of Hogwild SGD to estimator\" (#1134)"},{"Id":"366167777","IsPullRequest":false,"CreatedAt":"2018-10-03T04:09:05","Actor":"Zruty0","Number":"1131","RawContent":null,"Title":"Investigate and fix test failures","State":"open","Body":"Our commit success rate is below 50% at this point. \r\n\r\nWe no longer have the annoying deadlock plaguing the builds, but somehow the builds are still failing quite often. Let's spend some time and improve that story.\r\n\r\nFrom casual look, there is no single culprit: we seem to randomly fail to initialize build environment, and random tests seem to fail in random places. I guess this may have to do with resource-constrained runs: maybe we should actually try running xUnit tests sequentially and see if the sporadic failures go away?","Url":"https://github.com/dotnet/machinelearning/issues/1131","RelatedDescription":"Open issue \"Investigate and fix test failures\" (#1131)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-10-05T05:30:35.8873165Z","RunDurationInMilliseconds":1062}