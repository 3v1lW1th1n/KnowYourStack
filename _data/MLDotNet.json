{"Data":{"GitHub":{"Issues":[{"Id":"502370834","IsPullRequest":false,"CreatedAt":"2019-10-04T01:00:15","Actor":"frank-dong-ms","Number":"4294","RawContent":null,"Title":"Remove default constructor of OnnxSequenceType attribute on next major release","State":"open","Body":"Related to issue #4120 , the temp fix to add obsolete attribute on default constructor but the ideal fix should be remove the default constructor.\r\n\r\nAs this is break Public API change, we will do it on next major release.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4294","RelatedDescription":"Open issue \"Remove default constructor of OnnxSequenceType attribute on next major release\" (#4294)"},{"Id":"501177421","IsPullRequest":true,"CreatedAt":"2019-10-04T00:23:50","Actor":"frank-dong-ms","Number":"4272","RawContent":null,"Title":"Issue 4120, add reasonable exception when user try to use OnnxSequenceType attribute without specify sequence type","State":"closed","Body":"Fixes #4120 \r\n\r\nThe issue is: when user use OnnxSequenceType attribute directly without specify sequence type like [OnnxSequenceType], user will hit run time exception when try to use it.\r\n\r\nThe ideal way to fix this issue is to remove the default constructor of OnnxSequenceTypeAttribute and user will get compiler error when he/she try to use [OnnxSequenceType]. \r\nBut this can be a break change in Public API. After discuss with @eerhardt and @ericstj , we decide to obsolete the default constructor for now. Then we will remove the default constructor in next major release.\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4272","RelatedDescription":"Closed or merged PR \"Issue 4120, add reasonable exception when user try to use OnnxSequenceType attribute without specify sequence type\" (#4272)"},{"Id":"502348385","IsPullRequest":true,"CreatedAt":"2019-10-03T23:31:47","Actor":"harshithapv","Number":"4293","RawContent":null,"Title":"Buffer re-use using ArrayPool and a few more checks","State":"open","Body":"Added ArrayPool for buffer re-use while reading images in ImageLoader.cs. A few commits for safety checks. \r\nContinuation to my previous commit #4242 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/4293","RelatedDescription":"Open PR \"Buffer re-use using ArrayPool and a few more checks\" (#4293)"},{"Id":"502329197","IsPullRequest":false,"CreatedAt":"2019-10-03T22:26:11","Actor":"antoniovs1029","Number":"4292","RawContent":null,"Title":"Use PFI with Binary Prediction Transformer and CalibratedModelParametersBase loaded from disk","State":"open","Body":"In my last accepted pull request (#4262 ) I addressed issue #3976 and was able to provide working samples and tests for using PFI with models loaded from disk except for the case of Binary Prediction Transformer. Here I open this issue about that specific problem.\r\n\r\n### Problem\r\nIn the [sample using PFI with binary classification](https://github.com/dotnet/machinelearning/blob/e19369b407e8630cfaa82b07f81f0576c9bbd145/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/PermutationFeatureImportance.cs#L40) the last transformer of the model (i.e. the linearPredictor) is of type `BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>`.\r\n\r\nProblem is that when saving and then loading that model from disk, a null reference is returned when trying to access the last transformer by casting it to the original type.\r\n```\r\n// linearPredictor is null:\r\nvar linearPredictor = (loadedmodel as TransformerChain<ITransformer>).LastTransformer as BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>; \r\n```\r\n\r\nHaving a null linearPredictor makes it unusable with PFI.\r\n\r\nIn version 1.3 of ML.Net the last transformer of the loaded model would actually be of type `BinaryPredictionTransformer<IPredictorProducing<float>>`\r\n\r\nWith the changes I made in my last PR (which will be available in version 1.4.0 preview 2) the loaded model's last transformer would be of type `BinaryPredictionTransformer<ParameterMixingCalibratedModelParameters<IPredictorProducing<float>, ICalibrator>>` which is a step forward in solving the problem, but is not yet enough.\r\n\r\nAs stated, in both cases, a cast to the original type would return null. In general, it would be expected that the user tries to make that cast in order to use PFI, failing to accomplish it.\r\n\r\nThis problem would be solved if the loaded model actually had a lastTransformer of the original type, or something castable to it.\r\n\r\n### Workaround\r\nBased on [this comment](https://github.com/dotnet/machinelearning/pull/4262#discussion_r330175774) made by @yaeldekel I've just made [this working sample of using PFI with a binary prediction transformer loaded from disk](https://gist.github.com/antoniovs1029/e5fdd86d5b7c8b6adf34cb5481ee20dd). It is pretty much the same as the original sample, only that it works with a model loaded from disk.\r\n\r\nThe key of the workaround is that the user should cast the lastTransformer not into a binary prediction transformer but rather into a `ISingleFeaturePredictionTransformer<object>`, and then do a series of casts to get whatever other object s/he may want to get from inside the lastTransformer.\r\n\r\nIn the sample I've just provided it works pretty much in this way:\r\n```\r\nvar linearPredictor = (loadedmodel as TransformerChain<ITransformer>).LastTransformer as ISingleFeaturePredictionTransformer<object>;\r\nvar predictorModel = linearPredictor.Model as CalibratedModelParametersBase;\r\nvar predictorSubModel = predictorModel.SubModel as LinearBinaryModelParameters;\r\n```\r\n\r\nNotice that this workaround worked even in ML.Net 1.3, and also works with the changes that I introduced in 1.4.0 preview 2.\r\n\r\nNotice that a similar workaround might help a user that tries to use PFI with any kind of prediction transformer loaded from disk. This would come useful if the user, for whatever reason, can not extract the linearPredictor by casting to the same type used in the original model.\r\n\r\n### Cause of the Problem\r\nThere are 3 main points that are related to the cause of this problem, all of which pertain the `Calibrator.cs ` file and aren't related to the binary prediction transformer itself:\r\n1. Unexpectedly, when loading a `ParameterMixingCalibratedModelParameters<>` its [Create method](https://github.com/dotnet/machinelearning/blob/e19369b407e8630cfaa82b07f81f0576c9bbd145/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L564) isn't called. I discovered this while debugging, and what actually happens is that, during loading, inside the [CreateInstanceCore method](https://github.com/dotnet/machinelearning/blob/7c067854b564275b0d6387ca59c0ec83e8fc91b9/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs#L197), it first looks for a constructor, and so it calls the constructor of `ParameterMixingCalibratedModelParameters<>` instead of the Create method.\r\n2. Currently, when loading a `ParameterMixingCalibratedModelParameters<>` model, a `ParameterMixingCalibratedModelParameters<IPredictorProducing<float>, ICalibrator>` is always loaded, no matter what the actual submodel and calibrator are. This doesn't change by fixing point 1). This point is similar to the [original problem found on the prediction transformers](https://github.com/dotnet/machinelearning/issues/3976#issuecomment-517862076), which I fixed in [my last pull request](https://github.com/dotnet/machinelearning/pull/4262); using a similar approach in this case would fix this point... that is, loading first the submodel and calibrator to then create a generic type at runtime with the correct parameter types.\r\n3. When fiting the model (i.e. before even saving it or loading it) the [SdcaLogisticRegressionBinaryTrainer ](https://github.com/dotnet/machinelearning/blob/46ede664e8cff585c450a7005c7069b64df5a6f1/src/Microsoft.ML.StandardTrainers/Standard/SdcaBinary.cs#L1606)creates a predictor of type `ParameterMixingCalibratedModelParameters<LinearBinaryModelParameters, PlattCalibrator>` (which I will now refer to as \"PMCMP\") but returns it as a `CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>` (let's call it \"CMPB\") this then is what makes the last transformer of the model to be a `BinaryPredictionTransformer<CMPB>` whereas the internal model of the last transformer is actually a PMCMP. When saving it to disk, it's saved as a PMCMP (i.e. it's saved using a LoaderSignature of \"PMixCaliPredExec\"), so when loading occurs, it calls the constructor of PMCMP but it doesn't cast it to a CMPB. This is different from the problem fixed in my last pull request; there, if a Regression prediction transformer was saved, then we expected to load a regression prediction transformer... whereas in here if a PMCMP is saved we actually want to load a CMPB with the correct type parameters.\r\n\r\n\r\n### Trying to solve the problem\r\nSo far I've been able to solve problems 1) and 2) described above, but after trying out different approaches I haven't been able to solve problem 3). To solve those problems I've changed different things in the `Calibrator.cs` file. My attempt to solve this problem can be found in [here ](https://github.com/antoniovs1029/machinelearning/blob/f81ae76065f12b04d101d9e63e7397f968dd1f77/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L524) (although it is somewhat messy right now)... if requested I can clean that up and open a PR for further review.\r\n\r\nWith those changes (along with the ones of my last PR), the loaded model's last transformer becomes a `BinaryPredictionTransformer<ParameterMixingCalibratedModelParameters<LinearBinaryModelParameters, PlattCalibrator>>`. Notice that even here a cast to `BPT<CMPB>` would be null, so it doesn't solve the problem. Also notice that since PMCMP is an internal class the user wouldn't be able to cast the last transformer to `BPT<PMCMP>` either, since s/he wouldn't have access to that class.\r\n\r\n### Further problems\r\nHere I've explained the specific case of loading a `BPT<CMPB>` with the specific problems that arise in CMPB and PMCMP classes because that is what is used in the sample of PFI with BPT, and in the tests of PFI with BPT. It could be possible that the problems here described are also present in other classes (for example in the other classes of [Calibrator.cs](https://github.com/dotnet/machinelearning/blob/18394c4f9e45b9c5ff41dfbabd30e31132ae4cdc/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1)) but they might not become a problem unless the user tries to access the last transformer of a model loaded from disk. In such a case the described workaround might help.","Url":"https://github.com/dotnet/machinelearning/issues/4292","RelatedDescription":"Open issue \"Use PFI with Binary Prediction Transformer and CalibratedModelParametersBase loaded from disk\" (#4292)"},{"Id":"502293780","IsPullRequest":true,"CreatedAt":"2019-10-03T22:09:47","Actor":"codemzs","Number":"4291","RawContent":null,"Title":"Update CodeCov uploader version.","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4291","RelatedDescription":"Closed or merged PR \"Update CodeCov uploader version.\" (#4291)"},{"Id":"502274691","IsPullRequest":true,"CreatedAt":"2019-10-03T20:14:53","Actor":"Nucs","Number":"4290","RawContent":null,"Title":"TensorTypeExtensions: Added conversion between Tensor to primitive C# types instead of throwing NotSupportedException","State":"open","Body":"- Added conversion between Tensor to native C# types instead of throwing NotSupportedException\r\n- Fixed proper reading of TF_STRING\r\n- Added overloads that support TF_STRING (string does not meet T generic constraint `unmanaged`","Url":"https://github.com/dotnet/machinelearning/pull/4290","RelatedDescription":"Open PR \"TensorTypeExtensions: Added conversion between Tensor to primitive C# types instead of throwing NotSupportedException\" (#4290)"},{"Id":"502267843","IsPullRequest":true,"CreatedAt":"2019-10-03T19:59:58","Actor":"ashbhandare","Number":"4289","RawContent":null,"Title":"(WIP) Image Classification API: Fix processing incomplete batch(<batchSize), images processed per epoch , enable EarlyStopping without Validation Set. Fixes #4274 and #4286    ","State":"open","Body":"1)Previously, if the images left were not enough to for a batch of batchSize, the batch would not be processed. Fixed to process incomplete batch in training and validation.\r\n2)There was a bug where the batchIndex was not getting reset when the last batch was incomplete(< batchSize). Fixed to reset batchIndex.\r\n3)EarlyStopping was not triggering when validation set is not provided. Fixed.\r\n\r\nfixes #4274 #4286","Url":"https://github.com/dotnet/machinelearning/pull/4289","RelatedDescription":"Open PR \"(WIP) Image Classification API: Fix processing incomplete batch(<batchSize), images processed per epoch , enable EarlyStopping without Validation Set. Fixes #4274 and #4286    \" (#4289)"},{"Id":"502260817","IsPullRequest":false,"CreatedAt":"2019-10-03T19:44:45","Actor":"meesoft","Number":"4288","RawContent":null,"Title":"ScoreTensorFlowModel fails with null reference exception","State":"open","Body":"### System information\r\n\r\n- Win10 64bit\r\n- .net 4.6.1\r\n- Microsoft.ML.TensorFlow 1.3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nUsed LoadTensorFlowModel and ScoreTensorFlowModel on a pretrained model\r\n- **What happened?**\r\nScoreTensorFlowModel fails with null reference exception\r\n- **What did you expect?**\r\npipeline object\r\n\r\n### Source code / logs\r\n```\r\nvar estimator = mlContext.Model.LoadTensorFlowModel(\"saved_model.pb\");\r\nConsole.WriteLine(\"Inputs: \" + string.Join(\";\", estimator.GetInputSchema().Select(c => c.Name)));\r\nvar pipeline = estimator.ScoreTensorFlowModel(\r\n    new[] { \"denoised\" },\r\n    new[] { \"is_training\", \"noisy\" }, addBatchDimensionInput: true);\r\n```\r\n\r\n[saved_model.zip](https://github.com/dotnet/machinelearning/files/3687784/saved_model.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4288","RelatedDescription":"Open issue \"ScoreTensorFlowModel fails with null reference exception\" (#4288)"},{"Id":"502232611","IsPullRequest":false,"CreatedAt":"2019-10-03T18:43:26","Actor":"aslotte","Number":"4287","RawContent":null,"Title":"Model Builder | Selecting a file without file type crashes Visual Studio","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** I downloaded the data for spam detection (ML samples)\r\n- **What happened?** When I opened the Model Builder in Visual studio and selected the training file, Visual Studio hangs and eventually crashes. Setting the file type to .tsv makes it work.\r\n- **What did you expect?** A reasonable error message would be useful, e.g. \"Please indicate if this file is tab- or comma-separated\"\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4287","RelatedDescription":"Open issue \"Model Builder | Selecting a file without file type crashes Visual Studio\" (#4287)"},{"Id":"502230174","IsPullRequest":false,"CreatedAt":"2019-10-03T18:38:01","Actor":"ashbhandare","Number":"4286","RawContent":null,"Title":"[Image Classification API] Wrong number of images processed in training. ","State":"open","Body":"- **What did you do?**\r\nRun the sample \"ResnetV2101TransferLearningTrainTestSplit\" with different batch sizes(10, 100, 300). Added logging in the training loop just before batch is processed.\r\n- **What happened?**\r\nFrom second epoch onwards, number of images processed is more than total number of images in dataset.\r\n- **What did you expect?**\r\nNumber of images processed per epoch should be same.\r\n\r\n### Source code / logs\r\n[master_10.txt](https://github.com/dotnet/machinelearning/files/3687548/master_10.txt)\r\n[master_100.txt](https://github.com/dotnet/machinelearning/files/3687549/master_100.txt)\r\n[master_300.txt](https://github.com/dotnet/machinelearning/files/3687550/master_300.txt)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4286","RelatedDescription":"Open issue \"[Image Classification API] Wrong number of images processed in training. \" (#4286)"},{"Id":"502229981","IsPullRequest":false,"CreatedAt":"2019-10-03T18:37:36","Actor":"CESARDELATORRE","Number":"4285","RawContent":null,"Title":"[Model management] Save/Load Model into a Relational Database (SQL Server)","State":"open","Body":"From feedback from a customer using SQL Server Functions and Stored Procedures implemented in C#:\r\n\r\nBasically, would be good to have an API like the following:\r\n\r\n.SaveModelToDb()\r\n.LoadModelFromDb()\r\n\r\nThe reasons and scenarios are because you run C# code only as code running within SQL Server such as a C# SQL Server Function or a Stored Procedure that is scoring an ML.NET model while doing a query or transactions.\r\n\r\nAnd not just for scoring but also for saving the model after training close to the database.. and since it is a table you could also have multiple model versions..\r\n\r\nAnother scenario would be for traditional client/server apps with the client apps directly accessing a database...\r\n\r\nDoing it that way everything would be held, and more importantly, **secured** in the database server without external dependencies.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4285","RelatedDescription":"Open issue \"[Model management] Save/Load Model into a Relational Database (SQL Server)\" (#4285)"},{"Id":"501989702","IsPullRequest":true,"CreatedAt":"2019-10-03T16:43:07","Actor":"codemzs","Number":"4279","RawContent":null,"Title":"Increment build version for 1.4.0-preview-2 and 0.16.0-preview-2 release","State":"closed","Body":"\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4279","RelatedDescription":"Closed or merged PR \"Increment build version for 1.4.0-preview-2 and 0.16.0-preview-2 release\" (#4279)"},{"Id":"502053943","IsPullRequest":false,"CreatedAt":"2019-10-03T13:04:31","Actor":"nighotatul","Number":"4281","RawContent":null,"Title":"after every execution recommendation result is continuously changes?","State":"open","Body":"@eerhardt - after every execution of following code for Periodofstay-\"Mar-May\" and\r\ntraveler_type-\"Families\",recommendation result i.e. Score continuously changes.we need constant result not every time change score.\r\n\r\n var options = new Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer.Options\r\n                        {\r\n                            // MatrixColumnIndexColumnName = \"userIdEncoded\",\r\n                            // MatrixRowIndexColumnName = \"movieIdEncoded\",\r\n                            FeatureColumnName = \"Features\",\r\n\r\n                            NormalizeFeatures = false,\r\n                            LabelColumnName =\"Label\",// labelColumnName,\r\n                            LambdaLatent = 0.01f,\r\n                            LambdaLinear = 0.001f,\r\n                            LatentDimension = 16,\r\n                            NumberOfIterations = 20,\r\n                            LearningRate = 0.5f\r\n\r\n                            // ApproximationRank = 100\r\n                        };\r\n\r\n\r\n                        //  context.ml.Trainers.MatrixFactorization(options);\r\n\r\n\r\n                        // columnNames, columnTypes\r\n                        IEstimator<ITransformer> datapipeLine = context.Transforms.CopyColumns(\r\n                                       inputColumnName: labelColumnName,\r\n                                       outputColumnName: \"Label\");\r\n                        //                context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"TravelerType\")\r\n                        //.Append(context.Transforms.Categorical.OneHotEncoding(\"HotelOneHot\", \"Hotel\"))\r\n                        //.Append(context.Transforms.Concatenate(\"Features\", \"TravelerTypeOneHot\", \"HotelOneHot\"))\r\n                        //.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(new string[] { \"Features\" }));\r\n\r\n\r\n\r\n\r\n                        List<string> featuresColumns = new List<string>();\r\n\r\n                        for (int index = 0; index < columnNames.Count; ++index)\r\n                        {\r\n\r\n                            if (columnNames[index] == labelColumnName|| columnNames[index]==\"Time\"|| columnNames[index]==\"TimeStamp\"|| columnNames[index]== \"IdPreservationColumn\")\r\n                                continue;\r\n\r\n\r\n                            Type type = columnTypes[index];\r\n\r\n                            if (type == typeof(string) || type == typeof(char) || type == typeof(byte[]) || type == typeof(bool))\r\n                            {\r\n\r\n                                if (datapipeLine == null)\r\n                                {\r\n\r\n                                    datapipeLine = context.Transforms.Categorical.OneHotEncoding(columnNames[index] + \"OneHot\", columnNames[index]);//\"TravelerType\"\r\n\r\n\r\n                                }\r\n                                else\r\n                                {\r\n                                    datapipeLine = datapipeLine.Append(context.Transforms.Categorical.OneHotEncoding(columnNames[index] + \"OneHot\", columnNames[index]));//\"TravelerType\"\r\n\r\n                                }\r\n\r\n                                featuresColumns.Add(columnNames[index] + \"OneHot\");\r\n                            }\r\n                            else\r\n                            {\r\n                                featuresColumns.Add(columnNames[index]);\r\n\r\n                            }\r\n\r\n\r\n\r\n                        }\r\n\r\n\r\n                        datapipeLine = datapipeLine.Append(context.Transforms.Concatenate(\"Features\", featuresColumns.ToArray()));\r\n                        datapipeLine = datapipeLine.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(options));// new string[] { \"Features\" }, labelColumnName));\r\n\r\n                        //        foreach (string name in columnNames)\r\n                        //{\r\n                        //    if(columnTypes)\r\n                        //    pipeline = context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"TravelerType\")\r\n\r\n                        //}\r\n\r\n\r\n\r\n\r\n\r\n                        //var pipeline = context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(options);\r\n\r\n                        //                    var pipeline = context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"Traveler_type\")\r\n                        ////.Append(context.Transforms.Categorical.OneHotEncoding(\"SeasonOneHot\", \"Season\"))\r\n                        //.Append(context.Transforms.Categorical.OneHotEncoding(\"HotelOneHot\", \"Hotel_name\"))\r\n                        //.Append(context.Transforms.Concatenate(\"Features\", \"TravelerTypeOneHot\", \"HotelOneHot\"))\r\n                        //.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(new string[] { \"Features\" },labelColumnName));\r\n\r\n\r\n                        //                    var _model = pipeline.Fit(trainData);\r\n\r\n                        //                    var _transformedTrainingData = _model.Transform(inputtestData);\r\n\r\n\r\n                        // Train the model.\r\n                        var model = datapipeLine.Fit(trainData);\r\n\r\n\r\n\r\n                        // Run the model on training or test data set.\r\n                        var transformedTrainingData = model.Transform(trainData);\r\n\r\n\r\n                        // Measure the quality of the trained model.\r\n                        // var metrics = context.BinaryClassification.Evaluate(transformedTrainingData,);\r\n\r\n                        var metrics = context.BinaryClassification.Evaluate(transformedTrainingData,\"Label\" , \"Score\", \"Probability\", \"PredictedLabel\");//labelColumnName//Prediction Data send\r\n\r\n\r\n\r\n                        //  _predictionEngine = context.Model.pr(FfmRecommendationData, FfmRecommendationPrediction>(_model);\r\n\r\n\r\n                        var predictions2 = context.Data.CreateEnumerable<RecommendationResult>(transformedTrainingData, reuseRowObject: false).ToArray();\r\n\r\n\r\nI have attached data also.\r\n[hotelrecommandation.xlsx](https://github.com/dotnet/machinelearning/files/3686131/hotelrecommandation.xlsx)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4281","RelatedDescription":"Open issue \"after every execution recommendation result is continuously changes?\" (#4281)"},{"Id":"502045120","IsPullRequest":false,"CreatedAt":"2019-10-03T12:48:06","Actor":"nighotatul","Number":"4280","RawContent":null,"Title":"we are getting more thane one score in spam detection?","State":"open","Body":"@eerhardt - please see this code,\r\n\r\n var dataProcessPipeline = context.Transforms.Conversion.MapValueToKey(\"Label\", \"Label\")\r\n                                                  .Append(context.Transforms.Text.FeaturizeText(\"FeaturesText\", new Microsoft.ML.Transforms.Text.TextFeaturizingEstimator.Options\r\n                                                  {\r\n                                                      WordFeatureExtractor = new Microsoft.ML.Transforms.Text.WordBagEstimator.Options { NgramLength = 2, UseAllLengths = true },\r\n                                                      CharFeatureExtractor = new Microsoft.ML.Transforms.Text.WordBagEstimator.Options { NgramLength = 3, UseAllLengths = false },\r\n                                                  }, \"Message\"))\r\n                                                  .Append(context.Transforms.CopyColumns(\"Features\", \"FeaturesText\"))\r\n                                                  .Append(context.Transforms.NormalizeLpNorm(\"Features\", \"Features\"))\r\n                                                  .AppendCacheCheckpoint(context);\r\n\r\n                        // Set the training algorithm \r\n                        var trainer = context.MulticlassClassification.Trainers.OneVersusAll(context.BinaryClassification.Trainers.AveragedPerceptron(labelColumnName: \"Label\", numberOfIterations: 10, featureColumnName: \"Features\"), labelColumnName: \"Label\")\r\n                                                  .Append(context.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\", \"PredictedLabel\"));\r\n                        var trainingPipeLine = dataProcessPipeline.Append(trainer);\r\n\r\n\r\n                        //Console.WriteLine(\"=============== Cross-validating to get model's accuracy metrics ===============\");\r\n                        //var crossValidationResults = mlContext.MulticlassClassification.CrossValidate(data: data, estimator: trainingPipeLine, numberOfFolds: 5);\r\n                        //ConsoleHelper.PrintMulticlassClassificationFoldsAverageMetrics(trainer.ToString(), crossValidationResults);\r\n\r\n                        // Now let's train a model on the full dataset to help us get better results\r\n                        var model = trainingPipeLine.Fit(trainData);\r\n\r\n\r\n                        IDataView predictions = model.Transform(trainData);\r\n\r\n\r\n                        List<SpamPrediction> predictedResults = context.Data.CreateEnumerable<SpamPrediction>(predictions, reuseRowObject: false).ToList();\r\n\r\nwe attached data also. then which one score we consider?\r\n[spamdata.xlsx](https://github.com/dotnet/machinelearning/files/3686067/spamdata.xlsx)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4280","RelatedDescription":"Open issue \"we are getting more thane one score in spam detection?\" (#4280)"},{"Id":"501839858","IsPullRequest":true,"CreatedAt":"2019-10-03T05:17:27","Actor":"codemzs","Number":"4278","RawContent":null,"Title":"Fix build breaks.","State":"closed","Body":"Build first broke with #4237 and remained broken until this change.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4278","RelatedDescription":"Closed or merged PR \"Fix build breaks.\" (#4278)"},{"Id":"501709698","IsPullRequest":true,"CreatedAt":"2019-10-03T01:10:55","Actor":"bpstark","Number":"4277","RawContent":null,"Title":"Added support for running TF based models on GPU in Linux","State":"closed","Body":"Modified the GPU samples to take a dependency on both the linux and\r\nwindows TF GPU redist.\r\n\r\nModified the readme content to explain how to use on linux.\r\n\r\nTested on Ubuntu 18.04 with GTX1070, was able to run on the GPU without any issue.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4277","RelatedDescription":"Closed or merged PR \"Added support for running TF based models on GPU in Linux\" (#4277)"},{"Id":"501195820","IsPullRequest":true,"CreatedAt":"2019-10-02T17:51:36","Actor":"pieths","Number":"4273","RawContent":null,"Title":"Add DateTime to DateTime standard conversion.","State":"closed","Body":"This fixes an error which is caused by a missing DateTime to DateTime conversion when outputting DateTime columns in NimbusML. NimbusML calls in to `RowCursorUtils.GetGetterAsCore` (indirectly) which tries to find a conversion from DateTime to DateTime and fails with the following error:\r\n\r\n```console\r\nError: *** System.InvalidOperationException: 'No standard conversion from 'DateTime' to 'DateTime'\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4273","RelatedDescription":"Closed or merged PR \"Add DateTime to DateTime standard conversion.\" (#4273)"},{"Id":"499922532","IsPullRequest":false,"CreatedAt":"2019-10-02T14:59:50","Actor":"nighotatul","Number":"4264","RawContent":null,"Title":"how we plot decision tree using fast tree Trainer?","State":"closed","Body":"@eerhardt -  we got score and metrics but how we plot decision tree using trainer.","Url":"https://github.com/dotnet/machinelearning/issues/4264","RelatedDescription":"Closed issue \"how we plot decision tree using fast tree Trainer?\" (#4264)"},{"Id":"501375399","IsPullRequest":false,"CreatedAt":"2019-10-02T09:24:07","Actor":"yaeldekel","Number":"4276","RawContent":null,"Title":"Issues with ImageClassificationTransformer","State":"open","Body":"- The Options class contains two string array fields: one for input column names and one for output column names. However, it always uses exactly two input columns: a label column and a features column, and it always outputs exactly two output columns: score and predicted label. This discrepancy should be addressed.\r\n- The transformer has a field called `_labelColumnName` that is serialized and deserialized and otherwise does nothing. Since after deserialization we cannot rely on having data that has a label column anyway, this field should be removed.\r\n- `GetOutputSchema()` in the estimator does not check that the type of the label column is correct (what other types, if any, should be allowed other than key type?), and neither does the constructor (it doesn't check the type of the features column either).\r\n- I think the constructor of the transformer should not have a boolean flag to indicate whether the transformer is being instantiated from file or from the estimator. Instead, the estimator should do the required training (including figuring out the class count), and there should be one constructor for the transformer, that is called both from the estimator's `Fit()` method, and from the transformer's `Create(ModelLoadContext)` method.\r\n- The estimator has a `_transformer` field that is not needed.\r\n- The transformer ctor has an unused argument: `batchSize` - don't know if the error is in not using it or in not needing it.","Url":"https://github.com/dotnet/machinelearning/issues/4276","RelatedDescription":"Open issue \"Issues with ImageClassificationTransformer\" (#4276)"},{"Id":"501263651","IsPullRequest":false,"CreatedAt":"2019-10-02T04:08:51","Actor":"nighotatul","Number":"4275","RawContent":null,"Title":"how we draw tree using fast tree algorithm?","State":"open","Body":"as per suggestion given by @eerhardt, following link to @ganik @codemzs or @yaeldekel \r\nhttps://github.com/dotnet/machinelearning/issues/4264\r\n@ganik -  i have prepared sample on this below link.\r\nthis is Visualize sickit-learn decision trees with d3.js\r\nhttp://bl.ocks.org/fractalytics/raw/495b63cf671b4c487bc40801366384e0/\r\n\r\nwe do not know python script but we know C#. so that please helps us to draw above tree using fasttree ml.net using score,weights,bias.\r\nif any sample is their please share with us.","Url":"https://github.com/dotnet/machinelearning/issues/4275","RelatedDescription":"Open issue \"how we draw tree using fast tree algorithm?\" (#4275)"},{"Id":"499710603","IsPullRequest":true,"CreatedAt":"2019-10-02T03:58:43","Actor":"antoniovs1029","Number":"4262","RawContent":null,"Title":"Addresses #3976 about using PFI with a model loaded from disk","State":"closed","Body":"With this pull request it is now possible to use PFI with some models loaded from disk. **This is not yet a final solution to the problem**, as described in the last section below.\r\n\r\n### The Problem\r\nAs explained in [this comment](https://github.com/dotnet/machinelearning/issues/3976#issuecomment-517862076) of issue #3976 it was not possible to use PFI with a model loaded from disk, because the last transformer of the loaded model was not of the appropriate type to use it with the `PermutationFeatureImportance `method.\r\n\r\nSpecifically the problem occurred because when loading the last transformer, a 'create' method would be called and it would assign an inappropriate type to the last transformer, making it unusable for PFI. For example, if a model had `RegressionPredictionTransformer<OlsModelParameters>` as last transformer, and it was saved to disk, later on when loading it from disk the last transformer would be of type `RegressionPredictionTransformer<IPredictorProducing<float>>.` This would have happened because the [Create method ](https://github.com/dotnet/machinelearning/blob/bb00e07b30e9626b3578ff1934b86dad0d1d1ce9/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L615) that is called when loading a `RegressionPredictionTransformer ` would always return a `RegressionPredictionTransformer<IPredictorProducing<float>>` regardless of the actual `TModel `that should be loaded. In this case, it would be necessary to load the last transformer as `RegressionPredictionTransformer<OlsModelParameters>` in order to use it with PFI.\r\n\r\nThis was a problem also in the BinaryClassification, MulticlassClassification and Ranking prediction transformers which implemented a similar Create method. All of these classes are used with PFI.\r\n\r\n### The approach of the solution\r\nThe main obstacle was that the appropriate type `TModel` to be used when loading the last transformer couldn't be known at compile time, only at runtime once the last transformer was being loaded.\r\n\r\nSo to solve the problem, it was necessary to load first the internal model (e.g. the `OlsModelParameters `object) in the Create method of the prediction transformer, get its type to be used as `TModel`, make a generic type at runtime for the prediction transformer using the actual `TModel`, and instantiate that type with a constructor that would receive the internal model (previously loaded) to add it to the last transformer; this constructor would then continue to load the prediction transformer.\r\n\r\n### Changes implemented\r\n\r\n- The create method of the prediction transformers (binary, multiclass, ranking and regression) was modified to solve the problem. Different overloads of constructors were created to receive the internal model once it was loaded and then continue loading the prediction transformer.\r\n\r\n- **Samples were added based on the original PFI samples**, but now using a model that is saved and loaded from disk directly in the sample. This is provided for the multiclass, ranking and regression, but NOT for the binary classification case (see the final section below).\r\n\r\n- **Test cases based on the original PFI test cases are also provided**, but now using a model that is saved and loaded from disk directly in the test case. Again, this was done for multiclass, ranking and regression, but not for binary classification.\r\n\r\n- **Changes were made to 2 tests in the `LbfgsTests.cs`** file where PFI is not used, but prediction transformers are loaded from disk. The changes regard casts that were used in the tests, but can no longer be used. For example, `as MulticlassPredictionTransformer<IPredictorProducing<VBuffer<float>>>` was replaced for `as MulticlassPredictionTransformer<MaximumEntropyModelParameters>` in one test. This is done because now the create method returns the appropriate TModel type instead of the `IPredictorProducing<>` type. Notice that it is invalid to cast from `MulticlassPredictionTransformer<MaximumEntropyModelParameters>` to `MulticlassPredictionTransformer<IPredictorProducing<VBuffer<float>>>`... so those tests fail without the changes I made to the tests. Also notice that since `IPredictorProducing<>` is internal, a regular user using a nugget wouldn't be able to do the casts that were done in those tests.\r\n\r\n### Further problems\r\nIn this pull request I provide working samples and tests for regression, multiclass and ranking. Still, I've been unable to provide them for binary classification.\r\n\r\nThe [existing sample for PFI with binary classification](https://github.com/dotnet/machinelearning/blob/2942ca4e02d354b48767a1b01017f57cdc3fe44c/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/PermutationFeatureImportance.cs#L27) uses a last transformer of type `BinaryPredictionTransformer<CalibratedModelParameterBase<LinearBinaryModelParameters,PlattCalibrator>>` which is the type necessary to use it in the PFI method. When saving and then loading that model from disk, the last transformer was of type `BinaryPredictionTransformer<IPredictorProducing<float>>`; with the changes I made to the binary transformer, it now loads a last transformer of type `BinaryPredictionTransformer<ParameterMixingCalibratorModelParameters<IPredictorProducing<float>, ICalibrator>>`, which is still not the type necessary to use PFI.\r\n\r\nThe problem is that the [Create method of ParameterMixingCalibratorModelParameters](https://github.com/dotnet/machinelearning/blob/2942ca4e02d354b48767a1b01017f57cdc3fe44c/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L564) returns a `CalibratedModelParameterBase` object. This is similar to the problem that the prediction transformers had, but there's a key difference in that `ParameterMixingCalibratorModelParameters ` is internal, and its create method returns an object of its public superclass `CalibratedModelParameterBase`. This key difference has stopped me from solving the problem using the same approach used to fix the prediction transformers. Once this pull request is accepted, I will open another issue with this specific use case, explaining it in more detail.\r\n\r\nNonetheless, notice that the problem is not in the `BinaryPredictionTransformer<TModel>` but rather in its `TModel` for this specific case. Having changed the `BinaryPredictionTransformer<TModel>` actually works as expected, in that it no longer returns a fixed `<IPredictorProducing<float>>` as TModel, and so the problem is actually in the `ParameterMixingCalibratorModelParameters `class.\r\n\r\nAlso notice that this is a signal that there might be other generic classes where the Create method returns an object with fixed type parameters that aren't the ones actually being used. This might become a problem for users trying to use PFI with a model that uses one of such classes.","Url":"https://github.com/dotnet/machinelearning/pull/4262","RelatedDescription":"Closed or merged PR \"Addresses #3976 about using PFI with a model loaded from disk\" (#4262)"},{"Id":"501037711","IsPullRequest":true,"CreatedAt":"2019-10-02T01:40:45","Actor":"bpstark","Number":"4270","RawContent":null,"Title":"Modified the project to support running of TensorFlow on GPU on Windows.","State":"closed","Body":"Removed all dependencies of TensorFlow redist from the source projects,\r\nand instead added the dependency to the Sample project.\r\nCreated separate sample project for GPU examples since gpu tensorflow requires cuda,\r\nwhich may not be available on all machines, so it needs to be a separate\r\nproject.\r\nAdded documentation for setup as there is now some setup requirements to use this API.\r\n\r\nIn testing on the large flowers data set I was able to see a large improvement in speed, from taking ~720 seconds to train to taking ~156 seconds. \r\n\r\nFixes #4269\r\n\r\nAddresses part of the issue in #86 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4270","RelatedDescription":"Closed or merged PR \"Modified the project to support running of TensorFlow on GPU on Windows.\" (#4270)"},{"Id":"501034241","IsPullRequest":false,"CreatedAt":"2019-10-02T01:40:45","Actor":"bpstark","Number":"4269","RawContent":null,"Title":"TensorFlow based DNN models do not support the GPU on windows.","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n### Issue\r\n\r\nCurrently the DNN TensorFlow based models do not support GPU training/inferencing. \r\n\r\nDNNs should be able to support the GPU.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4269","RelatedDescription":"Closed issue \"TensorFlow based DNN models do not support the GPU on windows.\" (#4269)"},{"Id":"501207590","IsPullRequest":false,"CreatedAt":"2019-10-02T00:14:38","Actor":"luisquintanilla","Number":"4274","RawContent":null,"Title":"[Image Classification API] No evaluation when batchSize parameter > # of instances in dataset","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2\r\n- **ML.NET Version**: 1.4.0-preview\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nTried to train an image classification model using the Image Classification API. The value set for `batchSize` parameter is 300. Meanwhile then number of data instances in the test set is 182.\r\n\r\n- **What happened?**\r\n\r\nNo evaluation takes place. 0 batches are processed. \r\n\r\n- **What did you expect?**\r\n\r\nThe model to train and for it to evaluate the number of instances provided. In this case since the number of data instances is less than the amount set for the `batchSize` parameter, it would process 1 batch instead of 0.\r\n\r\nThe model to evaluate\r\n\r\n### Source code / logs\r\n\r\nPipeline:\r\n\r\n```csharp\r\nvar trainingPipeline =\r\n                mapLabelTransform\r\n               .Append(mlContext.Model.ImageClassification(\r\n                   featuresColumnName: \"ImagePath\",\r\n                   labelColumnName: \"LabelAsKey\",\r\n                   arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n                   epoch: 100,\r\n                   batchSize: 300,\r\n                   testOnTrainSet: false,\r\n                   metricsCallback: (metrics) => Console.WriteLine(metrics),\r\n                   validationSet: transformedTestData,\r\n                   reuseTrainSetBottleneckCachedValues: true,\r\n                   reuseValidationSetBottleneckCachedValues: true));\r\n```\r\n\r\nOutput:\r\n\r\n```text\r\nNumber of rows 182\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  93, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  94, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  95, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  96, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  97, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  98, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  99, Accuracy:        NaN\r\n```\r\n\r\nWhen the `batchSize` is set equal to the number of rows (in this case 182), this is the output:\r\n\r\n```text\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  95, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  96, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  97, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  98, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  99, Accuracy:          1\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4274","RelatedDescription":"Open issue \"[Image Classification API] No evaluation when batchSize parameter > # of instances in dataset\" (#4274)"},{"Id":"500440844","IsPullRequest":true,"CreatedAt":"2019-10-01T23:16:16","Actor":"najeeb-kazmi","Number":"4265","RawContent":null,"Title":"PFI entrypoint - Add checks for null Label, Feature, and GroupId columns","State":"closed","Body":"Related #4231 #4232 \r\n\r\nCheck whether Label, Feature, and GroupId columns are null.","Url":"https://github.com/dotnet/machinelearning/pull/4265","RelatedDescription":"Closed or merged PR \"PFI entrypoint - Add checks for null Label, Feature, and GroupId columns\" (#4265)"},{"Id":"501176332","IsPullRequest":false,"CreatedAt":"2019-10-01T22:23:05","Actor":"sergioprates","Number":"4271","RawContent":null,"Title":"How to process image with 1 channel?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**:\r\n.NET Core 3.0 \r\n\r\n### Issue\r\nI have a model that is trained in keras that accept a input shape of 64x64x1, in this case an image in gray scale. But I don't found a way of pre-process image to send only one channel to model, in ML.NET only have a method that extract one channel, R, G, B or Alpha.\r\n- **What did you do?**\r\n`var pipeline = mlContext.Transforms.ResizeImages(resizing: ImageResizingEstimator.ResizingKind.Fill, outputColumnName: onnxModel.ModelInput, imageWidth: ImageSettings.imageWidth,\r\n                imageHeight: ImageSettings.imageHeight, inputColumnName: nameof(ImageInputData.Image))\r\n                .Append(mlContext.Transforms.ConvertToGrayscale(outputColumnName: onnxModel.ModelInput, inputColumnName: onnxModel.ModelInput))\r\n                .Append(mlContext.Transforms.ExtractPixels(outputColumnName: onnxModel.ModelInput, inputColumnName: onnxModel.ModelInput, interleavePixelColors: true, \r\n                orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ARGB, colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Red))\r\n                .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: onnxModel.ModelPath, outputColumnName: onnxModel.ModelOutput, inputColumnName: onnxModel.ModelInput));`\r\n\r\nMy image come from a input form, like onnx examples in samples repository\r\n- **What happened?**\r\nI'm getting incorrect prediction, because I don't know how to reshape image to 64x64x1, in case that I send 64x64x3 format, I'm getting the error \"Length of memory (12288) must match product of dimensions (4096).\"\r\n- **What did you expect?**\r\nI expect that ML.NET provide a way to reshape my image to one channel image to get correct predictions\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4271","RelatedDescription":"Open issue \"How to process image with 1 channel?\" (#4271)"},{"Id":"500531241","IsPullRequest":true,"CreatedAt":"2019-10-01T00:18:26","Actor":"frank-dong-ms","Number":"4267","RawContent":null,"Title":"Fix the build badge link","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4267","RelatedDescription":"Closed or merged PR \"Fix the build badge link\" (#4267)"},{"Id":"500564972","IsPullRequest":false,"CreatedAt":"2019-09-30T22:46:48","Actor":"bsambrone","Number":"4268","RawContent":null,"Title":"Feature request: add \"optimize for\" in the AutoML CLI","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 (but applies to any)\r\n- **.NET Version (eg., dotnet --info)**: netcoreapp2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** Ran the AutoML CLI from powershell\r\n- **What happened?** It auto-trained as expected, but seemed to optimize just for accuracy. This isn't helpful when the data is highly skewed and I want to optimize for high precision or F1 score.\r\n- **What did you expect?** I was hoping to be able to specify what to optimize for just like I do when using this from C# and not the CLI.\r\n\r\nThe feature request is to add a command line flag to specify what to optimize for when running the AutoML CLI utility.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4268","RelatedDescription":"Open issue \"Feature request: add \"optimize for\" in the AutoML CLI\" (#4268)"},{"Id":"500451878","IsPullRequest":false,"CreatedAt":"2019-09-30T18:43:56","Actor":"najeeb-kazmi","Number":"4266","RawContent":null,"Title":"Evaluate PFI on raw features","State":"open","Body":"Right now, the [PFI implementation](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Transforms/PermutationFeatureImportance.cs), permutes and evaluates feature importances on the slots of the feature vector. However, I may want to evaluate PFI on the raw features (instead of or in addition to) the slots of the feature vector.\r\n\r\nConsider this scenario: PCA transform or a \"hash\" transform e.g. Text Transform with NGram Hash or Categorical Hash has been applied to raw features and the corresponding slots have no name or are unintelligible names. PFI on these slots isn't very \"explainable\" for these slots. Some sense of \"importance\" can still be had if the initial column could be permuted.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4266","RelatedDescription":"Open issue \"Evaluate PFI on raw features\" (#4266)"},{"Id":"499746780","IsPullRequest":false,"CreatedAt":"2019-09-28T09:06:28","Actor":"wpadron","Number":"4263","RawContent":null,"Title":"Duplicate column name exception when adding an Ignored column to AutoML framework","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10.0.18362\r\n- **.NET Version (eg., dotnet --info)**: core 3.0.100\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nAdd a column that AutoML should ignore.\r\n\r\n- **What happened?**\r\nGet an exception that the column name is duplicated.\r\n\r\n- **What did you expect?**\r\nWhen you add a column to the ignored collection you don't have to remove it from another collection (there are more than one) because the columns are inferred from the dataset at runtime.\r\n\r\n### Source code / logs\r\nColumnInformation columnInformation = columnInference.ColumnInformation;\r\ncolumnInformation.NumericColumnNames.Remove(\"payment_type\"); \r\ncolumnInformation.IgnoredColumnNames.Add(\"payment_type\");\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4263","RelatedDescription":"Open issue \"Duplicate column name exception when adding an Ignored column to AutoML framework\" (#4263)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-10-04T05:30:41.2532652Z","RunDurationInMilliseconds":1013}