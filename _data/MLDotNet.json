{"Data":{"GitHub":{"Issues":[{"Id":"419659231","IsPullRequest":true,"CreatedAt":"2019-03-13T00:08:37","Actor":"zeahmed","Number":"2911","RawContent":null,"Title":"Exposed ngram extraction options in TextFeaturizer","State":"closed","Body":"This PR fixes #2802, fixes #2838 and partially addresses #838,.\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2911","RelatedDescription":"Closed or merged PR \"Exposed ngram extraction options in TextFeaturizer\" (#2911)"},{"Id":"420249334","IsPullRequest":true,"CreatedAt":"2019-03-12T23:25:13","Actor":"rogancarr","Number":"2937","RawContent":null,"Title":"Adding Debugging Scenario tests for V1 APIs","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Debugging functionality we want fully supported in V1.\r\n\r\nScenarios\r\n- I can see how my data was read in to verify that I specified the schema correctly\r\n- I can see the output at the end of my pipeline to see which columns are available (score, probability, predicted label)\r\n- I can look at intermediate steps of the pipeline to debug my model.   Example: > I were to have the text \"Help I'm a bug!\" I should be able to see the steps where it is normalized to \"help i'm a bug\" then tokenized into [\"help\", \"i'm\", \"a\", \"bug\"] then mapped into term numbers [203, 25, 3, 511] then projected into the sparse float vector {3:1, 25:1, 203:1, 511:1}, etc. etc.\r\n- (P1) I can access the information needed for understanding the progress of my training (e.g. number of trees trained so far out of how many)\r\n\r\nFixes #2932 ","Url":"https://github.com/dotnet/machinelearning/pull/2937","RelatedDescription":"Open PR \"Adding Debugging Scenario tests for V1 APIs\" (#2937)"},{"Id":"420248988","IsPullRequest":true,"CreatedAt":"2019-03-12T23:23:52","Actor":"Ivanidzo4ka","Number":"2936","RawContent":null,"Title":"Hide more things in Data assembly","State":"open","Body":"fixes https://github.com/dotnet/machinelearning/issues/2926","Url":"https://github.com/dotnet/machinelearning/pull/2936","RelatedDescription":"Open PR \"Hide more things in Data assembly\" (#2936)"},{"Id":"420248728","IsPullRequest":true,"CreatedAt":"2019-03-12T23:22:49","Actor":"zeahmed","Number":"2935","RawContent":null,"Title":"Added support for inserting batch dimension in inputs in TensorFlow.","State":"open","Body":"This PR fixes #2778.\r\n\r\nIt is difficult to induce shape of the inputs from the data or model when the model accepts input of any shape but internal operators requires the input in particular shape. This is the problem with the inception model available at the following location.\r\n\r\nhttps://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\r\n\r\nThe model takes input data of any shape. There is a convolution layer just after the input which requires 4-D input. The first dimension for Conv2D operation in TensorFlow is the batch dimension. That's causing failure of samples in #2778. The ML.NET input is [224, 244, 3] while convolution layer in the above model requires [-1, 224, 224, 3]. The ultimate solution to this problem is to have reshape transform #765.\r\n\r\nHowever, it will take time implement. To unblock #2778, the temporary solution implemented here is to add a parameter in options class or other public interfaces called “AddBatchDimensionInput”. When user set it to true, batch dimension would be added to the inputs otherwise not. \r\n","Url":"https://github.com/dotnet/machinelearning/pull/2935","RelatedDescription":"Open PR \"Added support for inserting batch dimension in inputs in TensorFlow.\" (#2935)"},{"Id":"420247676","IsPullRequest":false,"CreatedAt":"2019-03-12T23:18:19","Actor":"rogancarr","Number":"2934","RawContent":null,"Title":"Logs are inscrutable","State":"open","Body":"There is a `Log` on `MLContext` objects, but it is very hard to read. It would be nice to add a `Level` to the log and some better organization than brackets.\r\n\r\nFor example,  SDCA returns lines like:\r\n```cs\r\n\"[Source=SdcaTrainerBase; Training, Kind = Info] Auto - tuning parameters: L2 = 0.001.\",\r\n\"[Source = SdcaTrainerBase; Training, Kind = Info] Auto - tuning parameters: L1Threshold(L1 / L2) = 0.\",\r\n\"[Source = SdcaTrainerBase; Training, Kind = Info] Using best model from iteration 7.\"};\r\n```\r\nBut to find these, you have to search a huge stream of information.","Url":"https://github.com/dotnet/machinelearning/issues/2934","RelatedDescription":"Open issue \"Logs are inscrutable\" (#2934)"},{"Id":"420237013","IsPullRequest":false,"CreatedAt":"2019-03-12T22:38:38","Actor":"sfilipi","Number":"2933","RawContent":null,"Title":"Knowing what to cast the model to is hard","State":"open","Body":"I have been writing a few tests about saving the model and reloading the models, and casting the model members to the right types, so I can get to something nested. \r\n\r\nExample  \r\n\r\n    `(IEstimator<ITransformer> pipe, IDataView dataView) = GetBinaryClassificationPipeline();\r\n\r\n     pipe = pipe.Append(ML.BinaryClassification.Trainers.LogisticRegression(\r\n     new LogisticRegression.Options\r\n     {\r\n         ShowTrainingStatistics = true,\r\n         ComputeStandardDeviation = new ComputeLRTrainingStdThroughMkl(),\r\n     }));\r\n\r\n     // SEE THE CASTS\r\n      var transformer = pipe.Fit(dataView) as TransformerChain<BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>>;\r\n\r\n      var linearModel = transformer.LastTransformer.Model.SubModel as LinearBinaryModelParameters;\r\n      var stats = linearModel.Statistics;\r\n\r\n     var modelPath = GetOutputPath(\"temp.zip\");\r\n     // Save model. \r\n     using (var file = File.Create(modelPath))\r\n     transformer.SaveTo(ML, file);\r\n\r\n     // Load model.\r\n     TransformerChain<ITransformer> transformerChain;\r\n     using (var file = File.OpenRead(modelPath))\r\n     transformerChain = TransformerChain.LoadFrom(ML, file);\r\n\r\n     // SEE THE CASTS\r\n     var lastTransformer = transformerChain.LastTransformer as BinaryPredictionTransformer<IPredictorProducing<float>>;\r\n      var model = lastTransformer.Model as ParameterMixingCalibratedModelParameters<IPredictorWithFeatureWeights<float>, ICalibrator>;\r\n      linearModel = model.SubModel as LinearBinaryModelParameters;\r\n      var stats = linearModel.Statistics;\r\n`\r\n\r\nNotice the casts \r\nThe only way to get to the Statistics (or weights, bias etc) is by casting to the right type. \r\nIt takes living in the Visual Studio debugger to figure out the right types.. \r\n","Url":"https://github.com/dotnet/machinelearning/issues/2933","RelatedDescription":"Open issue \"Knowing what to cast the model to is hard\" (#2933)"},{"Id":"420201052","IsPullRequest":false,"CreatedAt":"2019-03-12T20:54:39","Actor":"rogancarr","Number":"2932","RawContent":null,"Title":"Create functional tests for all Debugging scenarios","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Debugging functionality we want fully supported in V1.\r\n\r\nScenarios\r\n- I can see how my data was read in to verify that I specified the schema correctly\r\n- I can see the output at the end of my pipeline to see which columns are available (score, probability, predicted label)\r\n- I can look at intermediate steps of the pipeline to debug my model.   Example: > I were to have the text \"Help I'm a bug!\" I should be able to see the steps where it is normalized to \"help i'm a bug\" then tokenized into [\"help\", \"i'm\", \"a\", \"bug\"] then mapped into term numbers [203, 25, 3, 511] then projected into the sparse float vector {3:1, 25:1, 203:1, 511:1}, etc. etc.\r\n- (P1) I can access the information needed for understanding the progress of my training (e.g. number of trees trained so far out of how many)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2932","RelatedDescription":"Open issue \"Create functional tests for all Debugging scenarios\" (#2932)"},{"Id":"420199102","IsPullRequest":true,"CreatedAt":"2019-03-12T20:49:30","Actor":"rogancarr","Number":"2931","RawContent":null,"Title":"Train FieldAwareFactorizationMachines without providing arguments","State":"open","Body":"This PR adds an extension method for `FieldAwareFactorizationMachines` to allow it to be called without providing any arguments by using the default `Feature` column name as the only `Features` column.\r\n\r\nFixes #2927 ","Url":"https://github.com/dotnet/machinelearning/pull/2931","RelatedDescription":"Open PR \"Train FieldAwareFactorizationMachines without providing arguments\" (#2931)"},{"Id":"420160170","IsPullRequest":true,"CreatedAt":"2019-03-12T20:05:17","Actor":"shauheen","Number":"2930","RawContent":null,"Title":"Fix readme sample","State":"closed","Body":"revert changes done for #2565 in #2887 . The code snippet is working in 0.11. But this is just a snippet and users should check the samples repo for complete samples.","Url":"https://github.com/dotnet/machinelearning/pull/2930","RelatedDescription":"Closed or merged PR \"Fix readme sample\" (#2930)"},{"Id":"420141184","IsPullRequest":true,"CreatedAt":"2019-03-12T18:27:18","Actor":"codemzs","Number":"2929","RawContent":null,"Title":"Move ONNX Transformer into Microsoft.ML.Transforms.Onnx namespace.","State":"open","Body":"towards #2751\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2929","RelatedDescription":"Open PR \"Move ONNX Transformer into Microsoft.ML.Transforms.Onnx namespace.\" (#2929)"},{"Id":"419793212","IsPullRequest":true,"CreatedAt":"2019-03-12T18:21:24","Actor":"rogancarr","Number":"2923","RawContent":null,"Title":"Logistic Regression NumberOfIterations to MaximumNumberOfIterations","State":"closed","Body":"This PR updates `Logistic Regression` (multiclass, regression aka poisson, and multiclass) to specify the `MaximumNumberOfIterations` instead of `NumberOfIterations` as it's a stopping criterion and not necessarily a tuning parameter.\r\n\r\nI also took a look around the codebase, and this is the last change of this sort that will be needed.\r\n\r\nFixes #2922 ","Url":"https://github.com/dotnet/machinelearning/pull/2923","RelatedDescription":"Closed or merged PR \"Logistic Regression NumberOfIterations to MaximumNumberOfIterations\" (#2923)"},{"Id":"419792652","IsPullRequest":false,"CreatedAt":"2019-03-12T18:21:23","Actor":"rogancarr","Number":"2922","RawContent":null,"Title":"Logistic Regression: NumberOfIterations should be MaximumNumberOfIterations","State":"closed","Body":"Similar to `SDCA` and `K-Means`, `Logistic Regression` has a `NumberOfIterations` option that stands for the maximum number of iterations.\r\n\r\nI propose changing it to `MaximumNumberOfIterations`.\r\n\r\n** I searched through all the learners, and this is the last learner that needs this change.","Url":"https://github.com/dotnet/machinelearning/issues/2922","RelatedDescription":"Closed issue \"Logistic Regression: NumberOfIterations should be MaximumNumberOfIterations\" (#2922)"},{"Id":"419748347","IsPullRequest":true,"CreatedAt":"2019-03-12T18:14:00","Actor":"wschin","Number":"2918","RawContent":null,"Title":"Scrub text normalizer","State":"closed","Body":"Another step toward #2832. This PR is all about renaming with an internalization of `IReadOnlyCollection`,\r\n```\r\n-        public IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n+        internal IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2918","RelatedDescription":"Closed or merged PR \"Scrub text normalizer\" (#2918)"},{"Id":"420128782","IsPullRequest":false,"CreatedAt":"2019-03-12T17:59:39","Actor":"Ivanidzo4ka","Number":"2928","RawContent":null,"Title":"Scrubbing normalization transforms","State":"open","Body":"Sub task of #2827 \r\n`LpNormalize`\r\n`GlobalContrastNormalize`\r\n(since `LpNormColumnOptions` and `GcnColumnOptions` are nested classes we can just call them `ColumnOptions`)\r\n`Normalize `\r\nstuff like: `public TData Stddev`\r\nor  `public readonly ImmutableArray<NormalizingTransformer.ColumnOptions> Columns;`\r\nor `public readonly int NumBins;`\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2928","RelatedDescription":"Open issue \"Scrubbing normalization transforms\" (#2928)"},{"Id":"420126813","IsPullRequest":false,"CreatedAt":"2019-03-12T17:55:20","Actor":"rogancarr","Number":"2927","RawContent":null,"Title":"FieldAwareFactorizationMachines trainer can't have any empty arguments list","State":"open","Body":"The `FieldAwareFactorizationMachines` trainer cannot be given an empty arguments list.\r\n\r\n```cs\r\nvar ffmTrainer = mlContext.BinaryClassification.Trainers.FieldAwareFactorizationMachine(\r\n    new FieldAwareFactorizationMachineBinaryClassificationTrainer.Options { });\r\n```\r\nor\r\n```cs\r\nvar ffmTrainer = mlContext.BinaryClassification.Trainers.FieldAwareFactorizationMachine(\r\n    new string[] {\"Features\"});\r\n```\r\nI suggest allowing an empty arguments list by default. cc @sfilipi ","Url":"https://github.com/dotnet/machinelearning/issues/2927","RelatedDescription":"Open issue \"FieldAwareFactorizationMachines trainer can't have any empty arguments list\" (#2927)"},{"Id":"420121979","IsPullRequest":false,"CreatedAt":"2019-03-12T17:44:44","Actor":"Ivanidzo4ka","Number":"2926","RawContent":null,"Title":"More hiding of unnecessary public classes","State":"open","Body":"https://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.Data/Commands/EvaluateCommand.cs#L30\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.Data/Commands/TrainCommand.cs#L28\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.Data/DataLoadSave/TrivialLoaderEstimator.cs#L10\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.StandardTrainers/Standard/MultiClass/OneVersusAllTrainer.cs#L244 Would ask @sfilipi  since she is mentioned she works on OVA output columns, maybe this enum would proof useful.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/40abffc4eb98990c86804a05ca707a467edbe3d6/src/Microsoft.ML.Data/Transforms/SlotsDroppingTransformer.cs#L38 Would double check with @TomFinley  right now, all we have is public class, and everything inside it is hidden, so it's useless for user. We don't have `IEstimator` for it, so I'm not sure how valuable it's to have it. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2926","RelatedDescription":"Open issue \"More hiding of unnecessary public classes\" (#2926)"},{"Id":"420073506","IsPullRequest":true,"CreatedAt":"2019-03-12T16:09:11","Actor":"andrewkittredge","Number":"2925","RawContent":null,"Title":"handle space in the directory path.","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n\r\nfixes https://github.com/dotnet/machinelearning/issues/191","Url":"https://github.com/dotnet/machinelearning/pull/2925","RelatedDescription":"Open PR \"handle space in the directory path.\" (#2925)"},{"Id":"419868211","IsPullRequest":true,"CreatedAt":"2019-03-12T08:56:26","Actor":"llRandom","Number":"2924","RawContent":null,"Title":"Added an extension method for saving statically typed model (#1286)","State":"open","Body":"Added an extension method for saving statically typed model\r\nFixes #1286","Url":"https://github.com/dotnet/machinelearning/pull/2924","RelatedDescription":"Open PR \"Added an extension method for saving statically typed model (#1286)\" (#2924)"},{"Id":"419766655","IsPullRequest":true,"CreatedAt":"2019-03-12T02:07:56","Actor":"rogancarr","Number":"2921","RawContent":null,"Title":"Adding functional tests for all training scenarios","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Training functionality we want fully supported in V1.\r\n\r\nScenarios\r\n\r\n- I can provide multiple learners and easily compare evaluation metrics between them.\r\n- I can use an initial predictor to update/train the model for some trainers (e.g. linear learners like averaged perceptron). Specifically, start the weights for the model from the existing weights.  \r\n- Metacomponents smartly restrict their use to compatible components.   Example: \"When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.\"\r\n- I can use OVA and easily add any binary classifier to it\r\n\r\nFixes #2906 ","Url":"https://github.com/dotnet/machinelearning/pull/2921","RelatedDescription":"Open PR \"Adding functional tests for all training scenarios\" (#2921)"},{"Id":"419766088","IsPullRequest":false,"CreatedAt":"2019-03-12T02:05:16","Actor":"rogancarr","Number":"2920","RawContent":null,"Title":"OVA Multiclass Classification can be instantiated for variety of sub-trainer training tasks","State":"open","Body":"In writing a test for #2859, I have found that it is possible to create an `OVA` (aka \"One-Versus-All\") multiclass classification trainer learners other than a binary classifier as an input.\r\n\r\nOne of our V1 Goals is:\r\n- Metacomponents smartly restrict their use to compatible components.   Example: \"When specifying what trainer OVA should use, a user will be able to specify any binary classifier. If they specify a regression or multi-class classifier ideally that should be a compile error.\"\r\n\r\nFor all types\r\n- **Anomaly Detection** throws on `Fit()` due to data mismatch. Suggests that this could work under ideal conditions.\r\n- **Binary classification** works, as expected.\r\n- **Clustering** is a runtime error upon pipeline construction (OVA checks the model type produced).\r\n- **Multiclass classification** is a runtime error upon pipeline construction (OVA checks the model type produced).\r\n- **Ranking** pipeline can be instantiated, but `Fit()` fails on \"mismatch for label column\".\r\n- **Regression** pipeline can be instantiated, but `Fit()` fails on \"mismatch for label column\".\r\n\r\n(Note that I didn't run a recommender check because this needs to be coded x64-only at this point.)\r\n\r\n**Updated**: With the recent change to one-label-type-per task, Ranking and Regression now fail on the `Fit()`. I've updated the title to reflect that we can no longer train working models, but we can instantiate the pipeline.","Url":"https://github.com/dotnet/machinelearning/issues/2920","RelatedDescription":"Open issue \"OVA Multiclass Classification can be instantiated for variety of sub-trainer training tasks\" (#2920)"},{"Id":"419764027","IsPullRequest":true,"CreatedAt":"2019-03-12T01:56:00","Actor":"artidoro","Number":"2919","RawContent":null,"Title":"One name for MulticlassClassification","State":"open","Body":"Fixes #2623.\r\n\r\nIn this PR I make sure that the case of `Multiclass` is consistent and rename:\r\n- `MultiClass[...]` to `Multiclass[...]`\r\n\r\nWith PR #2903 this solves #2623.","Url":"https://github.com/dotnet/machinelearning/pull/2919","RelatedDescription":"Open PR \"One name for MulticlassClassification\" (#2919)"},{"Id":"419738674","IsPullRequest":false,"CreatedAt":"2019-03-11T23:58:22","Actor":"Ivanidzo4ka","Number":"2917","RawContent":null,"Title":"Unify way of setting random seed","State":"open","Body":"I can understand why we use nullable seed in one place and defaults in another, but why it's uint in one places and int in others is beyond my understanding.\r\n\r\n**UInt:**\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/Transforms/Hashing.cs#L1164\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L892\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L377\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/Text/WrappedTextTransformers.cs#L184\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/OneHotHashEncoding.cs#L241\r\n\r\n**Int:**\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L135\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/24f782d306f58d31778eddde181c16939be17292/src/Microsoft.ML.Data/DataLoadSave/DataOperationsCatalog.cs#L293\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Transforms/RandomFourierFeaturizing.cs#L659\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.PCA/PCACatalog.cs#L31\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/MLContext.cs#L79\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2917","RelatedDescription":"Open issue \"Unify way of setting random seed\" (#2917)"},{"Id":"419727543","IsPullRequest":true,"CreatedAt":"2019-03-11T23:13:50","Actor":"wschin","Number":"2916","RawContent":null,"Title":"Polish char- and word-level tokenizers & stopword removers","State":"open","Body":"Another sub-task of #2832.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2916","RelatedDescription":"Open PR \"Polish char- and word-level tokenizers & stopword removers\" (#2916)"},{"Id":"419699070","IsPullRequest":true,"CreatedAt":"2019-03-11T22:43:50","Actor":"ganik","Number":"2915","RawContent":null,"Title":"Fixing inconsistency in usage of LossFunction","State":"closed","Body":"fixes #2174\r\nfixes #2594 \r\nI had to re-do the PR due to messed up forked branch. This is a duplicate of #2856","Url":"https://github.com/dotnet/machinelearning/pull/2915","RelatedDescription":"Closed or merged PR \"Fixing inconsistency in usage of LossFunction\" (#2915)"},{"Id":"419685093","IsPullRequest":true,"CreatedAt":"2019-03-11T21:45:37","Actor":"ganik","Number":"2913","RawContent":null,"Title":"Fixing inconsistency in usage of LossFunction","State":"closed","Body":"fixes #2174\r\nfixes #2594 \r\n\r\nI had to re-do the PR due to messed up forked branch. This is a duplicate of #2856 ","Url":"https://github.com/dotnet/machinelearning/pull/2913","RelatedDescription":"Closed or merged PR \"Fixing inconsistency in usage of LossFunction\" (#2913)"},{"Id":"419692418","IsPullRequest":true,"CreatedAt":"2019-03-11T21:29:18","Actor":"sfilipi","Number":"2914","RawContent":null,"Title":"updating namespaces ","State":"open","Body":"Towards #2751\r\n\r\nMicrosoft.ML.LightGBM -> changes to Microsoft.ML.Trainers.LightGBM\r\nMicrosoft.ML.Transforms.FeatureSelection -> moves to Microsoft.ML.Transforms","Url":"https://github.com/dotnet/machinelearning/pull/2914","RelatedDescription":"Open PR \"updating namespaces \" (#2914)"},{"Id":"419649999","IsPullRequest":true,"CreatedAt":"2019-03-11T21:02:19","Actor":"codemzs","Number":"2908","RawContent":null,"Title":"Fix links in Entrypoints.md after StandardLearners rename.","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/2908","RelatedDescription":"Closed or merged PR \"Fix links in Entrypoints.md after StandardLearners rename.\" (#2908)"},{"Id":"419653161","IsPullRequest":true,"CreatedAt":"2019-03-11T20:43:56","Actor":"ganik","Number":"2909","RawContent":null,"Title":"Make IServerFactory internal","State":"closed","Body":"fixes #1973\r\nThis concludes the issue 1973. The only remaining issue of same kind is making ISupportBoosterParameterFactory internal and its addressed by #2559","Url":"https://github.com/dotnet/machinelearning/pull/2909","RelatedDescription":"Closed or merged PR \"Make IServerFactory internal\" (#2909)"},{"Id":"419668176","IsPullRequest":false,"CreatedAt":"2019-03-11T20:28:01","Actor":"eerhardt","Number":"2912","RawContent":null,"Title":"Consider making DataView and IEstimator Preview methods return DataTable","State":"open","Body":"Visual Studio has the ability to visualize a data set if the object is a `System.Data.DataTable`.\r\n\r\nWe currently have some debugger extension methods:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b861b5d64841cbe0f2c866ee7586872aac450a51/src/Microsoft.ML.Data/DebuggerExtensions.cs#L15-L62\r\n\r\nWe should consider making these return `DataTable`, so VS can visualize them. Or potentially we could add ancillary methods that return `DataTable`, and keep the current methods returning `DataDebuggerPreview`, if we think the current experience has value over the visualization in VS.","Url":"https://github.com/dotnet/machinelearning/issues/2912","RelatedDescription":"Open issue \"Consider making DataView and IEstimator Preview methods return DataTable\" (#2912)"},{"Id":"419655669","IsPullRequest":false,"CreatedAt":"2019-03-11T19:58:19","Actor":"gilnahmias","Number":"2910","RawContent":null,"Title":"Support encrypted models","State":"open","Body":"We want the ability to publish trained models that people can use to predict on their own devices, but not to reverse engineer the algorithms used to train them. That, in order to protect IP while allowing sensitive data to be predicted on customer machines.\r\nCan you support that?","Url":"https://github.com/dotnet/machinelearning/issues/2910","RelatedDescription":"Open issue \"Support encrypted models\" (#2910)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-03-13T05:30:33.6166646Z","RunDurationInMilliseconds":521}