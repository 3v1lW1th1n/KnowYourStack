{"Data":{"GitHub":{"Issues":[{"Id":"341354477","IsPullRequest":false,"CreatedAt":"2018-07-15T21:38:28","Actor":"galvesribeiro","Number":"536","RawContent":null,"Title":"WASM support","State":"open","Body":"Hello folks!\r\n\r\nTrying to make ML.Net to work on mono-wasm but I just figured out the hard way that it only works on x64:\r\n\r\n![image](https://user-images.githubusercontent.com/4714040/42738687-1104bf6e-885e-11e8-813b-e55a91976ccc.png)\r\n\r\nIs there any chance to get the native part built to wasm?\r\n\r\nThanks!","Url":"https://github.com/dotnet/machinelearning/issues/536","RelatedDescription":"Open issue \"WASM support\" (#536)"},{"Id":"341193133","IsPullRequest":false,"CreatedAt":"2018-07-14T00:27:17","Actor":"dan-drews","Number":"535","RawContent":null,"Title":"How would I concatenate columns of different types?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**:  .NET Framework 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Combined numeric columns with FeaturizedText Columns\r\n- **What happened?** I received an exception about mismatched column Types\r\n- **What did you expect?** I'm not 100% sure. I am hoping to find a way to combine a text featurizer with numeric values into the \"Features\" column to take multiple data types into account. I saw that we have the categorical vectorizers and Hash Transform Columns available, but I from what i understand, that is for a distinct number of categories.\r\n\r\nWhat I am trying to accomplish is utilizing numeric and text values in the prediction. Maybe this is just a lack of understanding on my part for this and it is not possible, but I'm kind of hoping to post the pieces of my business object that that I think could impact the result, and I cannot figure out how to do that effectively.\r\n\r\nNote: I am using a FastTreeRegressor predicting a float value.","Url":"https://github.com/dotnet/machinelearning/issues/535","RelatedDescription":"Open issue \"How would I concatenate columns of different types?\" (#535)"},{"Id":"341175974","IsPullRequest":false,"CreatedAt":"2018-07-13T22:22:13","Actor":"eerhardt","Number":"534","RawContent":null,"Title":"Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core","State":"open","Body":".NET Core 2.1 [introduced hardware intrinsics APIs](https://github.com/dotnet/designs/blob/master/accepted/platform-intrinsics.md) that allow C# code to take full advantage of the CPU. For example, you can now write algorithms using SSE or AVX instructions purely from C# code.\r\n\r\nThe CpuMathNative assembly exists solely so ML.NET can take advantage of SSE and AVX instructions in its algorithms. When running on .NET Core 2.1+, we can remove our dependency on this native assembly, and instead port the C++ SIMD code to using the new C# intrinsics APIs.\r\n\r\nHowever, to do this (and still support the full .NET Framework), we need to do some refactoring to our assemblies and NuGet packages.\r\n\r\nThe first thing we need to do is allow `Microsoft.ML.CpuMath` to be multi-targeted for `netstandard2.0;netcoreapp2.1`. This will allow us to compile against the netcoreapp2.1 specific SSE APIs.\r\n\r\nHowever, doing that affects our `Microsoft.ML` nuget package. This is because when you make a nuget package, you put your assemblies into TFM specific folders `lib\\netstandard2.0`, `lib\\netcoreapp2.1`, etc. And the way asset picking works is that once it finds assets for a specific TFM, it stops looking.  (The reasoning is typically there is a single assembly per nuget package.) So if we have a single assembly, CpuMath, that needs to go into both `lib\\netstandard2.0` and `lib\\netcoreapp2.1`, we have a problem. It means ALL our assemblies need to go into BOTH folders, which is unnecessary duplication.\r\n\r\nTo solve this duplication, I propose to split CpuMath into its own nuget package.  So we will have this structure:\r\n\r\n* `Microsoft.ML.CpuMath`\r\n    - Contains the CpuMath managed assemblies (one for each TFM) and the CpuMathNative assemblies.\r\n* `Microsoft.ML`\r\n    - Has a dependency on `Microsoft.ML.CpuMath`.\r\n\r\nIn order to do this correctly, we need to remove the assembly reference from `Microsoft.ML.CpuMath.dll` on `Microsoft.ML.Core.dll`. This is because the nuget dependency goes the other way.  The only reason `Microsoft.ML.CpuMath.dll` depends on `Microsoft.ML.Core.dll` is so it can use the `Contracts` class.  We can break this dependency by using the `PRIVATE_CONTRACTS` define constant, and source linking the `Contracts.cs` file into CpuMath.\r\n\r\n/cc @TomFinley @ericstj @briancylui @tannergooding ","Url":"https://github.com/dotnet/machinelearning/issues/534","RelatedDescription":"Open issue \"Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core\" (#534)"},{"Id":"341148843","IsPullRequest":false,"CreatedAt":"2018-07-13T20:24:29","Actor":"bsexton","Number":"533","RawContent":null,"Title":"Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.","State":"open","Body":"### System information\r\nIssue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**:  4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I started with the TaxiFare Example and that works. But then I changed the model and added my own values and my data. I got the error about the \"Features\" above. I played with it for a while and tried limiting my data. Even tried predicting the Fare Amount again.\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/533","RelatedDescription":"Open issue \"Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.\" (#533)"},{"Id":"341147669","IsPullRequest":false,"CreatedAt":"2018-07-13T20:19:49","Actor":"vivekpradhan","Number":"532","RawContent":null,"Title":"LightGBM on ML.NET trains slower than LightGBM command line","State":"open","Body":"### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.301\r\n Commit:    59524873d6\r\n\r\nRuntime Environment:\r\n OS Name:     ubuntu\r\n OS Version:  16.04\r\n\r\nHardware:\r\nGoogle Cloud default 64 core machine.\r\n\r\n### Issue\r\n\r\nRan training on same dataset with same params.\r\nDataset: 25k features x 140k rows (balanced binary classes)\r\nParams: \r\nCommand Line: \r\n```\r\n./lightgbm metric=binary_logloss min_data_in_leaf=500 bagging_fraction=0.8 boosting_type=gbdt bagging_freq=5 max_bin=255 objective=binary valid_data=../../../pedata/test.csv max_depth=10 feature_fraction=0.8 num_leaves=70 output_result=prediction.txt num_machines=1 learning_rate=0.1 output_model=LightGBM_model.txt data=../../../pedata/train.csv num_threads=64 task=train is_training_metric=true num_iterations=500 metric_freq=1 tree_learner=serial\r\n```\r\nML.NET\r\n```\r\nvar lclassifier = new LightGbmBinaryClassifier() { UseCat=false, MaxBin= 255, EvalMetric= LightGbmArgumentsEvalMetricType.Logloss , NumLeaves= 70, NThread= 64,LearningRate= 0.1, NumBoostRound= 500, MinDataPerLeaf= 500};\r\n            lclassifier.Booster = new GbdtBoosterParameterFunction() { \r\n                MaxDepth = 10,\r\n                FeatureFraction=0.8,\r\n                SubsampleFreq=5 };\r\n            pipeline.Add(lclassifier);\r\n```\r\n- **What happened?**\r\n\r\nBoth use all the 64 cores (As seen on htop).\r\nData Loading + Training Time: Command Line: 10mins, ML.NET: 17mins\r\n\r\n- **What did you expect?**\r\nSince both were build on my machine from source, I expected that the training time would be comparable.  \r\n\r\nWhy is the ML.NET implementation slower? Is there something I can do to speed it up?\r\n\r\n```\r\nStopwatch stopwatch = new Stopwatch();\r\nstopwatch.Start();\r\n// STEP 5: Train your model based on the data set\r\nvar model = pipeline.Train<IrisData, IrisPrediction>();\r\nstopwatch.Stop();\r\n```\r\nThe above stopwatch gives me time taken for Loading+Training. Is there a way to check the time taken only for the training step. Right now I am not sure if the data loading is slow or the training is slow.\r\n\r\n-----------------\r\nEdit: I got approximate training time by assuming that when CPU usage spikes, thats when training starts.\r\nTraining Time: Command Line: 335s, ML.NET:680s (approx)\r\nData Loading: Command Line: 265s, ML.NET: 340s (approx)","Url":"https://github.com/dotnet/machinelearning/issues/532","RelatedDescription":"Open issue \"LightGBM on ML.NET trains slower than LightGBM command line\" (#532)"},{"Id":"341144408","IsPullRequest":false,"CreatedAt":"2018-07-13T20:07:40","Actor":"mgolois","Number":"531","RawContent":null,"Title":"How to get the accuracy when using a FastTreeRegressor?","State":"open","Body":"When predicting a flight delay, I would like to let the user know how accurate is the prediction. I was not able to find a way to ouput that information with a regression algorithm:\r\n\r\n```\r\n         static void Main(string[] args)\r\n        {\r\n\r\n            string trainDataPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Flight Delay Prediction-TrainData.csv\");\r\n            string testDataPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Flight Delay Prediction-TestData.csv\");\r\n            string modelPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Model.zip\");\r\n            Console.WriteLine(Environment.CurrentDirectory);\r\n\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                new TextLoader(trainDataPath).CreateFrom<FlightInfo>(useHeader: true, separator: ','),\r\n                new ColumnCopier((\"ArrivalDelay\", \"Label\")),\r\n                new CategoricalOneHotVectorizer(\"Airline\", \"OriginAirport\"),\r\n                new ColumnConcatenator(\"Features\", \"Airline\", \"OriginAirport\"),\r\n                new FastTreeRegressor()\r\n            };\r\n\r\n            var model = pipeline.Train<FlightInfo, FlightDelayPrediction>();\r\n\r\n            model.WriteAsync(modelPath).Wait();\r\n\r\n\r\n            var testData = new TextLoader(testDataPath).CreateFrom<FlightInfo>(useHeader: true, separator: ',');\r\n\r\n            var evaluator = new RegressionEvaluator();\r\n\r\n            var metrics = evaluator.Evaluate(model, testData);\r\n\r\n            Console.WriteLine($\"Rms = {metrics.Rms}\");\r\n            Console.WriteLine($\"RSquared = {metrics.RSquared}\");\r\n\r\n            var predictDelay = new FlightInfo();\r\n\r\n            Console.WriteLine(\"Let's try to predict an airline and departing city delay:\");\r\n            Console.Write(\"Airline: \");\r\n            predictDelay.Airline = Console.ReadLine();\r\n            Console.Write(\"Departing City: \");\r\n            predictDelay.OriginAirport = Console.ReadLine();\r\n\r\n            var prediction = model.Predict(predictDelay);\r\n            Console.WriteLine($\"Predicted Arrival Delay: {prediction.ArrivalDelay}\");\r\n            Console.ReadKey();\r\n        }\r\n    }\r\n    public class FlightInfo\r\n    {\r\n        [Column(\"0\")]\r\n        public string Airline;\r\n        [Column(\"1\")]\r\n        public float ArrivalDelay;\r\n        [Column(\"2\")]\r\n        public string OriginAirport;\r\n\r\n    }\r\n\r\n    public class FlightDelayPrediction\r\n    {\r\n        [ColumnName(\"Score\")]\r\n        public float ArrivalDelay;\r\n    }\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/531","RelatedDescription":"Open issue \"How to get the accuracy when using a FastTreeRegressor?\" (#531)"},{"Id":"341133131","IsPullRequest":false,"CreatedAt":"2018-07-13T19:24:58","Actor":"zeahmed","Number":"530","RawContent":null,"Title":"[TextTransform] Char n-grams are different when using with/without word n-grams.","State":"open","Body":"### System information\r\n\r\n`Not relevant`\r\n\r\n### Issue\r\nWhen using TextTransform to compute n-grams, it has been observed that character n-grams produced are not consistent when computing it with/without word n-grams option. For example, for the following sentence \r\n```\r\nThis is a cat\r\n```\r\nThe character n-grams produced are as follows. where `<STX>`, `<ETX>` and `<SP>` are start of sentence, end of sentence and space control characters respectively.\r\n\r\n| Char 3-gram | Char 3-gram + Word 3-gram|\r\n|-|-|\r\n|\\<STX\\>\\|t\\|h | \\<STX\\>\\|t\\|h\r\n| t\\|h\\|i | t\\|h\\|i\r\n| h\\|i\\|s | h\\|i\\|s\r\n| i\\|s\\|\\<SP\\> | i\\|s\\|\\<ETX\\>\r\n| s\\|\\<SP\\>\\|i | s\\|\\<ETX\\>\\|\\<STX\\>\r\n| \\<SP\\>\\|i\\|s | \\<ETX\\>\\|\\<STX\\>\\|i\r\n| s\\|\\<SP\\>\\|a | \\<STX\\>\\|i\\|s\r\n| \\<SP\\>\\|a\\|\\<SP\\> | \\<ETX\\>\\|\\<STX\\>\\|a\r\n| a\\|\\<SP\\>\\|c | \\<STX\\>\\|a\\|\\<ETX\\>\r\n| \\<SP\\>\\|c\\|a | a\\|\\<ETX\\>\\|\\<STX\\>\r\n| c\\|a\\|t | \\<ETX\\>\\|\\<STX\\>\\|c\r\n| a\\|t\\|\\<ETX\\> | \\<STX\\>\\|c\\|a\r\n|-| c\\|a\\|t\r\n|-| a\\|t\\|\\<ETX\\>\r\n\r\n### Source code / logs\r\nThe cause of the problem is word tokenizer which is applied at the following location in the code.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/669f4fad33184c9c558314f8bc758f7928ad62bf/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L266\r\n\r\nThe `NeedsWordTokenizationTransform` property is set according to following criteria\r\nhttps://github.com/dotnet/machinelearning/blob/669f4fad33184c9c558314f8bc758f7928ad62bf/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L169\r\n\r\nThis means whenever word n-grams are being computed the tokenization is performed first and character n-gram extractor computes n-grams on words instead of sentences i.e. \r\n\r\ninstead of computing char n-grams on \r\n```\r\n<STX>This<SP>is<SP>a<SP>cat<ETX>\r\n```\r\nit computes char n-grams on\r\n```\r\n<STX>This<ETX>\r\n<STX>is<ETX>\r\n<STX>a<ETX>\r\n<STX>cat<ETX>\r\n```\r\nFirst of all, is the expected behavior?\r\nI my point of view `NOT` because in this way character n-gram is adding noise and losing important information regarding the sentence which in some cases may give superior performance.\r\n\r\n### Solution\r\nApply char n-gram extractor on `IDataView` that was not used for word processing in the code.","Url":"https://github.com/dotnet/machinelearning/issues/530","RelatedDescription":"Open issue \"[TextTransform] Char n-grams are different when using with/without word n-grams.\" (#530)"},{"Id":"339677302","IsPullRequest":true,"CreatedAt":"2018-07-13T18:38:33","Actor":"dan-drews","Number":"514","RawContent":null,"Title":"Remove Extra Code Comments and unused InternalStreams project","State":"closed","Body":"Fixes #513\r\n\r\nThis is the first go-around at finding extra commented code sitting around. I'll circle back on more when I have a chance.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/514","RelatedDescription":"Closed or merged PR \"Remove Extra Code Comments and unused InternalStreams project\" (#514)"},{"Id":"339673667","IsPullRequest":false,"CreatedAt":"2018-07-13T18:38:33","Actor":"dan-drews","Number":"513","RawContent":null,"Title":"Remove commented code","State":"closed","Body":"While digging into the source code, I discovered a large amount of commented out code throughout the solution.\r\n\r\nUnless there is a reason behind this that I am not aware of, I think it is best to remove this. In a worst-case scenario, we have the git history to take care of this.\r\n\r\nOne example is in UnbufferedStream.cs, the following code is all commented out:\r\n\r\n    //}\r\n    //if (checkStream == null)\r\n    //{\r\n    //    checkStream = new FileStream(fileName, FileMode.Open, FileAccess.Read, FileShare.Read);\r\n    //}\r\n    //byte[] cbuf = new byte[count];\r\n    //int checkRead = checkStream.Read(cbuf, 0, cbuf.Length);\r\n    //if (checkRead != read)\r\n    //{\r\n    //    Console.WriteLine(\"!!! bytes read mismatch at \" + fileName + \": \"  + checkStream.Position + \" / \" + Position + \": \" +\r\n    //        \"read = \" + read + \"; checkRead = \" + checkRead);\r\n    //}\r\n    //else\r\n    //{\r\n    //    Console.WriteLine(\">>> bytes read match at \" + fileName + \": \" + checkStream.Position + \" / \" + Position + \": \" +\r\n    //        \"read = \" + read + \"; checkRead = \" + checkRead);\r\n    //}\r\n\r\nI haven't yet discovered the extent of this, but I think some work should be done on this.","Url":"https://github.com/dotnet/machinelearning/issues/513","RelatedDescription":"Closed issue \"Remove commented code\" (#513)"},{"Id":"341087165","IsPullRequest":true,"CreatedAt":"2018-07-13T16:44:39","Actor":"sfilipi","Number":"529","RawContent":null,"Title":"WIP - Adding documentation about the rest of the classes involved on generating the CSharpAPI","State":"open","Body":"Resolves #389 \r\nAdded more documentation and examples about mostly transforms components. (A few learners as well.)\r\n\r\nThe documentation for the classes involved in generating the entry points lives in the doc.xml documents, since it needs to be referenced from two locations, for the most part, and since the CSharpApi is auto-generated. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/529","RelatedDescription":"Open PR \"WIP - Adding documentation about the rest of the classes involved on generating the CSharpAPI\" (#529)"},{"Id":"341032515","IsPullRequest":true,"CreatedAt":"2018-07-13T16:32:56","Actor":"TomFinley","Number":"527","RawContent":null,"Title":"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest","State":"closed","Body":"Fixes #526 .\r\n\r\nThe test `TrainAndPredictIrisModelUsingDirectInstantiationTest` now has analogous changes to the `TrainAndPredictIrisModelTest` test.","Url":"https://github.com/dotnet/machinelearning/pull/527","RelatedDescription":"Closed or merged PR \"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest\" (#527)"},{"Id":"341030146","IsPullRequest":false,"CreatedAt":"2018-07-13T16:32:56","Actor":"TomFinley","Number":"526","RawContent":null,"Title":"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest test from commit #428","State":"closed","Body":"PR #428 was merged July 12, many days after PR #468 which added a new test on the Iris dataset July 2. The changes in #428 were not applied to that new test, and with the merge that test is failing.","Url":"https://github.com/dotnet/machinelearning/issues/526","RelatedDescription":"Closed issue \"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest test from commit #428\" (#526)"},{"Id":"341041086","IsPullRequest":true,"CreatedAt":"2018-07-13T14:30:02","Actor":"Ivanidzo4ka","Number":"528","RawContent":null,"Title":"WIP Image support","State":"open","Body":"address #489 \r\nneed update for nuget story.\r\nneed create issue about IDataView datatype extensibility.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/528","RelatedDescription":"Open PR \"WIP Image support\" (#528)"},{"Id":"340825260","IsPullRequest":false,"CreatedAt":"2018-07-12T22:52:36","Actor":"sfilipi","Number":"525","RawContent":null,"Title":"Rename the NGramNgramExtractor class to a better name. ","State":"open","Body":"I think the NGramNgramExtractor class in the CSharpApi.cs should have a better name. \r\n\r\nCirca line 17990: \r\n`public sealed class NGramNgramExtractor : NgramExtractor` ","Url":"https://github.com/dotnet/machinelearning/issues/525","RelatedDescription":"Open issue \"Rename the NGramNgramExtractor class to a better name. \" (#525)"},{"Id":"340727915","IsPullRequest":false,"CreatedAt":"2018-07-12T18:10:32","Actor":"CESARDELATORRE","Number":"523","RawContent":null,"Title":"ML.NET exports to ONNX v1.2.2 file which is not supported in current released Windows 10 RS4 but only in RS5","State":"closed","Body":"### System information\r\n- **Windows RS4 vs. RS5**\r\n- **ML.NET 0.3**\r\n\r\n### Issue\r\nThe current released Windows (RS4) with WinML, supports only ONNX v1.0 models while Windows RS5 WinML supports only ONNX v1.2.2 models.\r\n\r\nThis is an issue since ML.NET exports ONNX 1.2.2 files which therefore don't work on current released Windows (RS4) with WinML, but only on the next version of Windows (RS5), which is still not publicly available.\r\n\r\nSince this issue might be happening depending on the target platforms, it would be advisable to parametrize the ONNX version of the model to export/generate (ONNX v1.0, v1.2.2, etc.), so it can work on multiple target platforms depending on the version. \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/523","RelatedDescription":"Closed issue \"ML.NET exports to ONNX v1.2.2 file which is not supported in current released Windows 10 RS4 but only in RS5\" (#523)"},{"Id":"340734090","IsPullRequest":false,"CreatedAt":"2018-07-12T17:42:32","Actor":"zeahmed","Number":"524","RawContent":null,"Title":"Add description to convenience constructors.","State":"open","Body":"Recently, convenience constructors were added to different components to help easily create these components in the pipeline (cf. #380 #487 and #520).\r\n\r\nIt is also desirable to add helpful comments/description to these constructor to help user understand the components purpose and possible usage.\r\n\r\nTo be more precise, here is list of transforms that needs description for convenience constructors.\r\n\r\n- BootstrapSampleTransform\r\n- CategoricalHashTransform\r\n- CategoricalTransform\r\n- ConcatTransform\r\n- CopyColumnsTransform\r\n- CountFeatureSelection\r\n- DropColumnsTransform\r\n- LpNormNormalizerTransform\r\n- NAFilter\r\n- NormalizeTransform\r\n- ChooseColumnsTransform.cs\r\n- ConvertTransform.cs\r\n- DropSlotsTransform.cs\r\n- GenerateNumberTransform.cs\r\n- HashTransform.cs\r\n- KeyToValueTransform.cs\r\n- KeyToVectorTransform.cs\r\n- LabelConvertTransform.cs\r\n- LabelIndicatorTransform.cs\r\n- RangeFilter.cs\r\n- ShuffleTransform.cs\r\n- SkipTakeFilter.cs\r\n- TermTransform.cs\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs","Url":"https://github.com/dotnet/machinelearning/issues/524","RelatedDescription":"Open issue \"Add description to convenience constructors.\" (#524)"},{"Id":"340486297","IsPullRequest":true,"CreatedAt":"2018-07-12T04:35:43","Actor":"TomFinley","Number":"522","RawContent":null,"Title":"Conversion of ITrainer.Train returns predictor, accepts +TrainContext","State":"open","Body":"Fixes #509.\r\n\r\n* `ITrainer.Train` returns a predictor. There is no `CreatePredictor` method on the interface.\r\n\r\n* `ITrainer.Train` always accepts a `TrainContext`. Dataset type is no longer a generic parameter. This context object replaces the functionality previously offered by the combination of `ITrainer`, `IValidatingTrainer`, `IIncrementalTrainer`, and `IIncrementalValidatingTrainer`, which is now captured in one `ITrainer.Train` method with differently configured contexts.\r\n\r\n* All trainers updated to these two new idioms. Many trainers correspondingly improved to no longer be stateful objects. (The exceptions are those that are just too far gone to be done with less than herculean effort at refactoring them to no longer use instance fields for their computation, most notably, LBFGS and FastTree based trainers.)\r\n\r\n* Utility code meant to deal with the complexity of the aforementioned `IT/IVT/IIT/IIVT` idiom reduced considerably.\r\n\r\n* Opportunistic improvements to `ITrainer` implementors where observed.","Url":"https://github.com/dotnet/machinelearning/pull/522","RelatedDescription":"Open PR \"Conversion of ITrainer.Train returns predictor, accepts +TrainContext\" (#522)"},{"Id":"339547248","IsPullRequest":true,"CreatedAt":"2018-07-11T23:20:39","Actor":"sfilipi","Number":"510","RawContent":null,"Title":"XML strings for the documentation should live outside of the src code, in xml files. ","State":"closed","Body":"Resolves #477  by moving the strings with the XML remarks, examples etc into a separate XML file. \r\nNow the actual classes and their C# Api counterparts share the path to the XML node that contains the documentation and the respective example. \r\n\r\nOn this PR, there are only two examples that are separate from the rest of the descriptive xml: the LogisticRegressionBinaryClassifier and LogisticRegressionClassifier, to give an idea of the infrastructure. \r\n\r\nThe rest of the examples are coming in the next PR, together with the rest of the documentation. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/510","RelatedDescription":"Closed or merged PR \"XML strings for the documentation should live outside of the src code, in xml files. \" (#510)"},{"Id":"340248576","IsPullRequest":false,"CreatedAt":"2018-07-11T13:44:19","Actor":"hrkrx","Number":"521","RawContent":null,"Title":"Structure of a regression tree","State":"open","Body":"I want to visualize a regression tree.\r\nSo i got one form my trained model.\r\n\r\nBut now i am wondering how the object (RegressionTree from Microsoft.ML.Runtime.FastTree.Internal) is structured and how i can obtain a connected tree from that object.\r\n\r\nOnly for display purposes i have a class like this:\r\n\r\n```\r\npublic class TreeNode\r\n{\r\n     public List<TreeNode> Children;\r\n     public TreeNode Parent;\r\n     public string Content;\r\n     [...]\r\n}\r\n```\r\n\r\nand i am struggling to connect the values of the arrays in RegressionTree to a TreeNode based tree.\r\n\r\nThank you for your time!","Url":"https://github.com/dotnet/machinelearning/issues/521","RelatedDescription":"Open issue \"Structure of a regression tree\" (#521)"},{"Id":"339336146","IsPullRequest":false,"CreatedAt":"2018-07-10T22:49:12","Actor":"justinormont","Number":"507","RawContent":null,"Title":"PipelineInference creates invalid JSON","State":"closed","Body":"Currently, PipelineInference creates an EntryPoint JSON graph beginning with:\r\n```json\r\n{'Nodes' : [{\r\n  \"Name\": \"TextAnalytics.TextTransform\",\r\n  \"Inputs\": {\r\n    \"Column\": {\r\n      \"Name\": \"text_tf\",\r\n      \"Source\": [\r\n        \"text\"\r\n      ]\r\n    },\r\n    \r\n}}]}\r\n```\r\n\r\nThe initial `'Nodes'` should have double-quotes like `\"Nodes\"`. JSON spec requires double quotes on keys. \r\n\r\nAs is, this fails a JSON.parse(), which makes the created JSON difficult to work with in NodeJS.\r\n\r\nSource of the issue:\r\nhttps://github.com/dotnet/machinelearning/blob/9d19d0e7058e328ead93f549205e5c329324ec05/src/Microsoft.ML.PipelineInference/PipelinePattern.cs#L276\r\n","Url":"https://github.com/dotnet/machinelearning/issues/507","RelatedDescription":"Closed issue \"PipelineInference creates invalid JSON\" (#507)"},{"Id":"339877803","IsPullRequest":true,"CreatedAt":"2018-07-10T22:47:43","Actor":"jwood803","Number":"516","RawContent":null,"Title":"Fix quotes on json","State":"closed","Body":"Fixes issue #507.\r\n\r\nDidn't see any impacted tests for this, but going to see about adding one.","Url":"https://github.com/dotnet/machinelearning/pull/516","RelatedDescription":"Closed or merged PR \"Fix quotes on json\" (#516)"},{"Id":"339993621","IsPullRequest":true,"CreatedAt":"2018-07-10T20:24:59","Actor":"zeahmed","Number":"520","RawContent":null,"Title":"[Part 3] Added convenience constructors for set of transforms.","State":"open","Body":"This PR fixes #518. The convenience constructors were added for following transforms.\r\n\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs","Url":"https://github.com/dotnet/machinelearning/pull/520","RelatedDescription":"Open PR \"[Part 3] Added convenience constructors for set of transforms.\" (#520)"},{"Id":"339990673","IsPullRequest":false,"CreatedAt":"2018-07-10T20:15:43","Actor":"dotChris90","Number":"519","RawContent":null,"Title":"Is a simulation model not also a kind of machine learning model?","State":"open","Body":"Hello ML.NET Team, \r\n\r\nthis week I was talking with some guys from simulation and a question come up into my mind. **It is more a general question about machine learning**. Why simulation models are not part of models for machine learning? A simulation model like from MATLAB/Simulink, Amesim, Modellica, .... are basically a text based description (XML or sth else) in form of mathematical formulas for prediction. \r\n\r\nYou see - yeah maybe they look different but they are not too different from each others. A simulation model also has a signal flow / topology and parameters which need to be \"trained\" just like a neuronal network. This \"training\" is mostly done by measurement signals and by finding the parameter which produce the smallest error (like traditional regression problem). As you can see - like neuronal network. Actual in last years I often saw some articles which suggested neuronal networks for simulation - okay nice idea but .... if you think about car or airplane simulation .... such measurements are extrem expensive and most articles I saw did not connect physical laws with the network (which is a pity).\r\n\r\nI just ask myself - is such a model + parameter finding algorithm not also a kind of \"Learner\"? And if so - why most frameworks like Spark, Scikit etc. ignore them? If it is because there are too many model formats (file formats) - then just let you know : there is \"Functional Mockup Interface (FMI)\" --> a model format to rule all other formats. .NET brings different programming languages together, FMI brings different models. \r\n\r\nDo not see it as task or critical wish. I just want to discuss with others and see their opinion. :D\r\n\r\n  \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/519","RelatedDescription":"Open issue \"Is a simulation model not also a kind of machine learning model?\" (#519)"},{"Id":"339961735","IsPullRequest":false,"CreatedAt":"2018-07-10T18:40:19","Actor":"zeahmed","Number":"518","RawContent":null,"Title":"[Part 3] Create convenience constructor for the listed Transforms.","State":"open","Body":"This work item is related to #371 and is the 3rd work item in series of creating convenience constructor (cf. #380 and #487). In this work item, convenience constructors will be created following set of transforms. \r\n\r\n- GroupTransform.cs\r\n- HashJoinTransform.cs\r\n- KeyToBinaryVectorTransform.cs\r\n- LoadTransform.cs\r\n- MissingValueIndicatorTransform.cs\r\n- MutualInformationFeatureSelectionTransform.cs\r\n- NADropTransform.cs\r\n- NAHandleTransform.cs\r\n- NAIndicatorTransform.cs\r\n- NAReplaceTransform.cs\r\n- OptionalColumnTransform.cs\r\n- RffTransform.cs\r\n- UngroupTransform.cs\r\n- WhiteningTransform.cs\r\n","Url":"https://github.com/dotnet/machinelearning/issues/518","RelatedDescription":"Open issue \"[Part 3] Create convenience constructor for the listed Transforms.\" (#518)"},{"Id":"339919247","IsPullRequest":false,"CreatedAt":"2018-07-10T16:32:01","Actor":"22140505","Number":"517","RawContent":null,"Title":"How to continue training based on the existing model?","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/issues/517","RelatedDescription":"Open issue \"How to continue training based on the existing model?\" (#517)"},{"Id":"339802189","IsPullRequest":false,"CreatedAt":"2018-07-10T11:29:44","Actor":"satish860","Number":"515","RawContent":null,"Title":"NA Handling ","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows \r\n- **.NET Version (eg., dotnet --info)**:  2.1.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI was trying to work on Titanic kaggle problem and trying to train and I am looking for an example of how to handle Null values. \r\nI have seen handling option but not able to find how to use it in Pipeline.\r\n\r\nBetween one difference I have seen between Python interfaces and .net is the ability to experiment easily and I am finding it bit harder to do here. If you have any practices it will be helpful if we can discuss here. \r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/515","RelatedDescription":"Open issue \"NA Handling \" (#515)"},{"Id":"339640745","IsPullRequest":false,"CreatedAt":"2018-07-09T23:24:12","Actor":"mjmckp","Number":"512","RawContent":null,"Title":"Make grid search of parameter space more efficient","State":"open","Body":"The ML.Net library suffers from a lack of decoupling between data preparation and model training, required to do an efficient grid search over training parameters.\r\n\r\nThat is, ideally the API should be structured in such a way that it is possible to do the following:\r\n\r\n1. Prepare the data set once, so that it can be **re-used multiple times**.  As much as possible, any pre-training calculations should be done up front (or perhaps cached to be re-used).  For large data sets, the overhead of repeating this step each time is significant, taking as long or longer than the training itself.\r\n2. For algorithms with multiple training iterations, it should be straightforward to **retain the intermediate trained models** at each iteration (or at a specified set of iterations).  This way, it is then easy to compute metrics for the intermediate models on training and validation data sets, and ultimately select one of the intermediate models for use in production without having to re-run the training.\r\n\r\nFor example, consider training a LightGBM model.  This is the training method in `LightGbmTrainerBase.cs`:\r\n```\r\n        public void Train(RoleMappedData data)\r\n        {\r\n            Dataset dtrain;\r\n            CategoricalMetaData catMetaData;\r\n            using (var ch = Host.Start(\"Loading data for LightGBM\"))\r\n            {\r\n                using (var pch = Host.StartProgressChannel(\"Loading data for LightGBM\"))\r\n                    dtrain = LoadTrainingData(ch, data, out catMetaData);\r\n                ch.Done();\r\n            }\r\n            using (var ch = Host.Start(\"Training with LightGBM\"))\r\n            {\r\n                using (var pch = Host.StartProgressChannel(\"Training with LightGBM\"))\r\n                    TrainCore(ch, pch, dtrain, catMetaData);\r\n                ch.Done();\r\n            }\r\n            dtrain.Dispose();\r\n            DisposeParallelTraining();\r\n        }\r\n```\r\n\r\nIn order to address point 1) above, the `dtrain` object returned by `LoadTrainingData` should be available to be re-used.  This would require that the configuration parameters for data preparation are specified separately to those for training, instead of all thrown in together into the `LightGbmArguments` type.\r\n\r\nNow, in regards to point 2) above, note that the `TrainCore` method calls `WrappedLightGBMTraining.Train`, which has the following structure:\r\n```\r\n        public static Booster Train(IChannel ch, IProgressChannel pch,\r\n            Dictionary<string, object> parameters, Dataset dtrain, Dataset dvalid = null, int numIteration = 100,\r\n            bool verboseEval = true, int earlyStoppingRound = 0)\r\n        {\r\n            // create Booster.\r\n            Booster bst = new Booster(parameters, dtrain, dvalid);\r\n\r\n            for (int iter = 0; iter < numIteration; ++iter)\r\n            {\r\n                // training logic\r\n            }\r\n            return bst;\r\n        }\r\n```\r\nIn order to get the intermediate models, this method should return `Booster []` instead of just the final `Booster` (or perhaps instead in this case, the `Booster` object should support extraction of a prediction model which only contains the first `N` trees of the ensemble).\r\n\r\nPerhaps there is already the facility to do this in ML.Net, but I'm unable to find anything from my reading of the source or any of the examples.\r\n\r\nI think 99.9% of all machine learning research requires doing a parameter grid search at some stage, and hence this is essential functionality that should be as efficient as possible.","Url":"https://github.com/dotnet/machinelearning/issues/512","RelatedDescription":"Open issue \"Make grid search of parameter space more efficient\" (#512)"},{"Id":"339553215","IsPullRequest":false,"CreatedAt":"2018-07-09T18:09:58","Actor":"tauheedul","Number":"511","RawContent":null,"Title":"Suggestion - Make Machine Learning Models explainable by design with ML.NET","State":"open","Body":"It's often difficult to understand how Machine Learning applications come to a decision. Some Developers reuse model samples without knowing how it works and is considered a black box to many.\r\n\r\nThis is an opportunity for ML.NET to stand out and automatically make models explainable. \r\n- ML.NET framework could keep a stack trace of some kind that keeps an audit of decisions\r\n- Including how confident it was in that decision (a rating or percentage)\r\n- With a fairness rating, evaluating the bias contained in the data supplied to the model\r\n- This could be output to the application upon request. Much like you can output a trace of an Exception.\r\n- Extend these peek abilities in Visual Studio so you can inspect what 3rd party models are doing (just like Resharpers decompile capabilities with libraries)\r\n\r\nA framework that automatically keeps a self-audit of decisions would be way ahead of the rest and could help developers understand what the model is doing under the hood. Especially if they are relying on models supplied by third parties.\r\n\r\nThis could boost the development of ML using ML.NET and is exactly the kind of thing that made .NET such an easy framework to work with.","Url":"https://github.com/dotnet/machinelearning/issues/511","RelatedDescription":"Open issue \"Suggestion - Make Machine Learning Models explainable by design with ML.NET\" (#511)"},{"Id":"339537461","IsPullRequest":false,"CreatedAt":"2018-07-09T17:19:14","Actor":"TomFinley","Number":"509","RawContent":null,"Title":"Direct API discussion: ITrainer proposed changes","State":"open","Body":"There are two changes proposed here for `ITrainer`. Due to the nature of the changes, assuming we agree they are good ideas, it really makes sense that they ought to happen in one go, since they involve changes to the same core functionality.\r\n\r\nI am quite certain the first thing is a good idea, but the second thing I am less certain about. (Of course my confidence could be misplaced. :smile:) People that occur to me as potentially being good contributors to the discussion would be @eerhardt , @zeahmed , @shauheen , @ericstj , @glebuk . (To be clear, this is not exclusionary. Anyone can and should feel free to comment. I just want these people to get flagged is all. :smile: )\r\n\r\n## `ITrainer<TData, TPred>.Train` ought to return the predictor\r\n\r\nCurrently in order to train a predictor, there is a two step process. You call `ITrainer.Train` then call `ITrainer.GetPredictor`. As near as I can tell this arrangement was meant as some scheme to support [online training](https://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L164), but of course that vision never came to pass, and if we were to actually support online training I have to imagine it would be through some separate interface anyway.\r\n\r\nThis arrangement seems unambiguously bad. It necessitates making `ITrainer` objects stateful for no particularly good reason. This complicates both the implementation and usage of the class, since (1) the caller can't do things like call `Train` multiple times even though a developer, seeing this interface, might reasonably suppose such a thing were possible and (2) the author of the `ITrainer` component has to protect against that misuse.\r\n\r\n## Get rid of `IValidatingTrainer`, `IIncrementalTrainer`, `IValidatingIncrementalTrainer`\r\n\r\n### The problem\r\n\r\nFirst let's talk about the problem...\r\n\r\nMost (all?) trainers implement `ITrainer<RoleMappedData>`, based on this interface here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L105\r\n\r\nWe have historically followed adding more inputs to the training process by declaring specialized interfaces that represent the Cartesian product of all possible permutations of inputs, as we see:\r\n\r\n* There was a discussion about adding a validation set. So we *doubled* the number of interfaces to two, `ITrainer`, and `IValidatingTrainer`.\r\n\r\n* Later on there was a discussion about adding continued training based on an initialization. So we again doubled the number of interfaces, introducing `IIncrementalTrainer` and `IValidatingIncrementalTrainer`.\r\n\r\n* There have been discussions of adding a test set to allow computing metrics as training progresses. Following the same strategy we would of course again double the number of interfaces (the full set being represented, perhaps, by `IValidatingIncrementalTestingTrainer`), for a total of eight.\r\n\r\n* If hypothetically we were to somehow allow for one more input beyond that, we'd have a total of sixteen interfaces.\r\n\r\nEtc. etc. That there is this exponential cost makes clear something is misdesigned. This has cost not only here and in the implementations of `ITrainer`, but in the usage as well. [Here we see a method that explores the cartesian product of possible interfaces so it can call the right one.](https://github.com/dotnet/machinelearning/blob/828dc227f4d7346e11094479c7a2e443addc8102/src/Microsoft.ML.Data/Commands/TrainCommand.cs#L287) It seems to me something is wrong here when just calling \"train\" requires a fairly non-obvious utility method to make sure we call the \"right\" train.\r\n\r\nThis issue incidentally is the primary reason why we haven't done anything like add support for test set metrics during training (despite the many requests). That is, it is not any technical difficulty with the idea itself, it's just that writing such a thing would make the code unmaintainable.\r\n\r\n### The possible solution(s)\r\n\r\n***So***: instead we might just have one interface, with one required input (the training dataset), and all these other things are optional.\r\n\r\nThere are two obvious ways I could imagine doing this, first explicitly as part of the method signature on `ITrainer<...>`:\r\n\r\n```csharp\r\npublic interface ITrainer<TDataset, TPredictor> {\r\n    TPredictor Train(TDataset train, TDataset validation = null, TDataset testSet = null, IPredictor initPredictor = null); }\r\n```\r\n\r\nOr else have some sort of context object. (I'm not married to any of these names, to be clear. :smile: )\r\n\r\n```csharp\r\npublic sealed class TrainContext {\r\n    public RoleMappedData Train { get; }\r\n    public RoleMappedData Validation { get; }\r\n    public RoleMappedData Test { get; }\r\n    public IPredictor InitPredictor { get; }\r\n}\r\n```\r\n\r\nand all trainers implement `ITrainer<TrainContext>` instead of `ITrainer<RoleMappedData>`.\r\n\r\nThe latter is perhaps a bit more awkward since it involves the addition of a new abstraction (the hypothetical `TrainContext`), but it is more flexible in a forward-looking sense, since if we add more \"stuff\" to how we initialize trainers, we won't break all existing `ITrainer` implementations. (My expectation is that trainers that can't support something would simply ignore.)","Url":"https://github.com/dotnet/machinelearning/issues/509","RelatedDescription":"Open issue \"Direct API discussion: ITrainer proposed changes\" (#509)"},{"Id":"339362364","IsPullRequest":false,"CreatedAt":"2018-07-09T08:59:52","Actor":"petterton","Number":"508","RawContent":null,"Title":"How to mix categorical and numerical features in LightGbm?","State":"open","Body":"I am implementing a LightGBM example where I have a mix of categorical and numerical features, and can't figure how this should be done in ML.NET.\r\n\r\nIn Python, LightGBM accepts a 'categorical_feature' parameter, giving the possibility to specify if a feature should be handled as categorical or numerical/ordinal. I can not find that this parameter is available in the ML.NET version. Could this be added?","Url":"https://github.com/dotnet/machinelearning/issues/508","RelatedDescription":"Open issue \"How to mix categorical and numerical features in LightGbm?\" (#508)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-07-16T05:30:37.8428705Z","RunDurationInMilliseconds":1219}