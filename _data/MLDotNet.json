{"Data":{"GitHub":{"Issues":[{"Id":"503034214","IsPullRequest":true,"CreatedAt":"2019-10-06T00:36:44","Actor":"codemzs","Number":"4301","RawContent":null,"Title":"[DO NOT REVIEW][TEMPORARY]","State":"open","Body":"DO NOT REVIEW, JUST A PR TO CREATE ANOTHER PR. WILL CLOSE SOON.","Url":"https://github.com/dotnet/machinelearning/pull/4301","RelatedDescription":"Open PR \"[DO NOT REVIEW][TEMPORARY]\" (#4301)"},{"Id":"502053943","IsPullRequest":false,"CreatedAt":"2019-10-05T13:54:04","Actor":"nighotatul","Number":"4281","RawContent":null,"Title":"after every execution recommendation result is continuously changes?","State":"closed","Body":"@eerhardt - after every execution of following code for Periodofstay-\"Mar-May\" and\r\ntraveler_type-\"Families\",recommendation result i.e. Score continuously changes.we need constant result not every time change score.\r\n\r\n var options = new Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer.Options\r\n                        {\r\n                            // MatrixColumnIndexColumnName = \"userIdEncoded\",\r\n                            // MatrixRowIndexColumnName = \"movieIdEncoded\",\r\n                            FeatureColumnName = \"Features\",\r\n\r\n                            NormalizeFeatures = false,\r\n                            LabelColumnName =\"Label\",// labelColumnName,\r\n                            LambdaLatent = 0.01f,\r\n                            LambdaLinear = 0.001f,\r\n                            LatentDimension = 16,\r\n                            NumberOfIterations = 20,\r\n                            LearningRate = 0.5f\r\n\r\n                            // ApproximationRank = 100\r\n                        };\r\n\r\n\r\n                        //  context.ml.Trainers.MatrixFactorization(options);\r\n\r\n\r\n                        // columnNames, columnTypes\r\n                        IEstimator<ITransformer> datapipeLine = context.Transforms.CopyColumns(\r\n                                       inputColumnName: labelColumnName,\r\n                                       outputColumnName: \"Label\");\r\n                        //                context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"TravelerType\")\r\n                        //.Append(context.Transforms.Categorical.OneHotEncoding(\"HotelOneHot\", \"Hotel\"))\r\n                        //.Append(context.Transforms.Concatenate(\"Features\", \"TravelerTypeOneHot\", \"HotelOneHot\"))\r\n                        //.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(new string[] { \"Features\" }));\r\n\r\n\r\n\r\n\r\n                        List<string> featuresColumns = new List<string>();\r\n\r\n                        for (int index = 0; index < columnNames.Count; ++index)\r\n                        {\r\n\r\n                            if (columnNames[index] == labelColumnName|| columnNames[index]==\"Time\"|| columnNames[index]==\"TimeStamp\"|| columnNames[index]== \"IdPreservationColumn\")\r\n                                continue;\r\n\r\n\r\n                            Type type = columnTypes[index];\r\n\r\n                            if (type == typeof(string) || type == typeof(char) || type == typeof(byte[]) || type == typeof(bool))\r\n                            {\r\n\r\n                                if (datapipeLine == null)\r\n                                {\r\n\r\n                                    datapipeLine = context.Transforms.Categorical.OneHotEncoding(columnNames[index] + \"OneHot\", columnNames[index]);//\"TravelerType\"\r\n\r\n\r\n                                }\r\n                                else\r\n                                {\r\n                                    datapipeLine = datapipeLine.Append(context.Transforms.Categorical.OneHotEncoding(columnNames[index] + \"OneHot\", columnNames[index]));//\"TravelerType\"\r\n\r\n                                }\r\n\r\n                                featuresColumns.Add(columnNames[index] + \"OneHot\");\r\n                            }\r\n                            else\r\n                            {\r\n                                featuresColumns.Add(columnNames[index]);\r\n\r\n                            }\r\n\r\n\r\n\r\n                        }\r\n\r\n\r\n                        datapipeLine = datapipeLine.Append(context.Transforms.Concatenate(\"Features\", featuresColumns.ToArray()));\r\n                        datapipeLine = datapipeLine.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(options));// new string[] { \"Features\" }, labelColumnName));\r\n\r\n                        //        foreach (string name in columnNames)\r\n                        //{\r\n                        //    if(columnTypes)\r\n                        //    pipeline = context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"TravelerType\")\r\n\r\n                        //}\r\n\r\n\r\n\r\n\r\n\r\n                        //var pipeline = context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(options);\r\n\r\n                        //                    var pipeline = context.Transforms.Categorical.OneHotEncoding(\"TravelerTypeOneHot\", \"Traveler_type\")\r\n                        ////.Append(context.Transforms.Categorical.OneHotEncoding(\"SeasonOneHot\", \"Season\"))\r\n                        //.Append(context.Transforms.Categorical.OneHotEncoding(\"HotelOneHot\", \"Hotel_name\"))\r\n                        //.Append(context.Transforms.Concatenate(\"Features\", \"TravelerTypeOneHot\", \"HotelOneHot\"))\r\n                        //.Append(context.BinaryClassification.Trainers.FieldAwareFactorizationMachine(new string[] { \"Features\" },labelColumnName));\r\n\r\n\r\n                        //                    var _model = pipeline.Fit(trainData);\r\n\r\n                        //                    var _transformedTrainingData = _model.Transform(inputtestData);\r\n\r\n\r\n                        // Train the model.\r\n                        var model = datapipeLine.Fit(trainData);\r\n\r\n\r\n\r\n                        // Run the model on training or test data set.\r\n                        var transformedTrainingData = model.Transform(trainData);\r\n\r\n\r\n                        // Measure the quality of the trained model.\r\n                        // var metrics = context.BinaryClassification.Evaluate(transformedTrainingData,);\r\n\r\n                        var metrics = context.BinaryClassification.Evaluate(transformedTrainingData,\"Label\" , \"Score\", \"Probability\", \"PredictedLabel\");//labelColumnName//Prediction Data send\r\n\r\n\r\n\r\n                        //  _predictionEngine = context.Model.pr(FfmRecommendationData, FfmRecommendationPrediction>(_model);\r\n\r\n\r\n                        var predictions2 = context.Data.CreateEnumerable<RecommendationResult>(transformedTrainingData, reuseRowObject: false).ToArray();\r\n\r\n\r\nI have attached data also.\r\n[hotelrecommandation.xlsx](https://github.com/dotnet/machinelearning/files/3686131/hotelrecommandation.xlsx)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4281","RelatedDescription":"Closed issue \"after every execution recommendation result is continuously changes?\" (#4281)"},{"Id":"502871807","IsPullRequest":true,"CreatedAt":"2019-10-05T00:57:05","Actor":"harshithapv","Number":"4298","RawContent":null,"Title":"Fixed documentation for ImageClassificationMetricsCallback to resolve the confusion in issue #4259","State":"closed","Body":"Fixed documentation for ImageClassificationMetricsCallback function to resolve the confusion in issue #4259\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4298","RelatedDescription":"Closed or merged PR \"Fixed documentation for ImageClassificationMetricsCallback to resolve the confusion in issue #4259\" (#4298)"},{"Id":"502863179","IsPullRequest":true,"CreatedAt":"2019-10-04T23:40:12","Actor":"frank-dong-ms","Number":"4297","RawContent":null,"Title":"Issue 4120","State":"closed","Body":"Follow up on Issue #4120 \r\n\r\n1. Use EditorBrowsable attribute to hide the default constructor from intellisense.\r\n2. Use Obsolete(\"XX\", false) instead of Obsolete(\"XX\", true) to be safe.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4297","RelatedDescription":"Closed or merged PR \"Issue 4120\" (#4297)"},{"Id":"502230174","IsPullRequest":false,"CreatedAt":"2019-10-04T23:19:42","Actor":"ashbhandare","Number":"4286","RawContent":null,"Title":"[Image Classification API] Wrong number of images processed in training. ","State":"closed","Body":"- **What did you do?**\r\nRun the sample \"ResnetV2101TransferLearningTrainTestSplit\" with different batch sizes(10, 100, 300). Added logging in the training loop just before batch is processed.\r\n- **What happened?**\r\nFrom second epoch onwards, number of images processed is more than total number of images in dataset.\r\n- **What did you expect?**\r\nNumber of images processed per epoch should be same.\r\n\r\n### Source code / logs\r\n[master_10.txt](https://github.com/dotnet/machinelearning/files/3687548/master_10.txt)\r\n[master_100.txt](https://github.com/dotnet/machinelearning/files/3687549/master_100.txt)\r\n[master_300.txt](https://github.com/dotnet/machinelearning/files/3687550/master_300.txt)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4286","RelatedDescription":"Closed issue \"[Image Classification API] Wrong number of images processed in training. \" (#4286)"},{"Id":"502267843","IsPullRequest":true,"CreatedAt":"2019-10-04T23:16:37","Actor":"ashbhandare","Number":"4289","RawContent":null,"Title":"Image Classification API: Fix processing incomplete batch(<batchSize), images processed per epoch , enable EarlyStopping without Validation Set. Fixes #4274 and #4286    ","State":"closed","Body":"1)Previously, if the images left were not enough to for a batch of batchSize, the batch would not be processed. Fixed to process incomplete batch in training and validation.\r\n2)There was a bug where the batchIndex was not getting reset when the last batch was incomplete(< batchSize). Fixed to reset batchIndex.\r\n3)EarlyStopping was not triggering when validation set is not provided. Fixed.\r\n\r\nfixes #4274 #4286","Url":"https://github.com/dotnet/machinelearning/pull/4289","RelatedDescription":"Closed or merged PR \"Image Classification API: Fix processing incomplete batch(<batchSize), images processed per epoch , enable EarlyStopping without Validation Set. Fixes #4274 and #4286    \" (#4289)"},{"Id":"501207590","IsPullRequest":false,"CreatedAt":"2019-10-04T23:16:37","Actor":"luisquintanilla","Number":"4274","RawContent":null,"Title":"[Image Classification API] No evaluation when batchSize parameter > # of instances in dataset","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2\r\n- **ML.NET Version**: 1.4.0-preview\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nTried to train an image classification model using the Image Classification API. The value set for `batchSize` parameter is 300. Meanwhile then number of data instances in the test set is 182.\r\n\r\n- **What happened?**\r\n\r\nNo evaluation takes place. 0 batches are processed. \r\n\r\n- **What did you expect?**\r\n\r\nThe model to train and for it to evaluate the number of instances provided. In this case since the number of data instances is less than the amount set for the `batchSize` parameter, it would process 1 batch instead of 0.\r\n\r\nThe model to evaluate\r\n\r\n### Source code / logs\r\n\r\nPipeline:\r\n\r\n```csharp\r\nvar trainingPipeline =\r\n                mapLabelTransform\r\n               .Append(mlContext.Model.ImageClassification(\r\n                   featuresColumnName: \"ImagePath\",\r\n                   labelColumnName: \"LabelAsKey\",\r\n                   arch: ImageClassificationEstimator.Architecture.ResnetV2101,\r\n                   epoch: 100,\r\n                   batchSize: 300,\r\n                   testOnTrainSet: false,\r\n                   metricsCallback: (metrics) => Console.WriteLine(metrics),\r\n                   validationSet: transformedTestData,\r\n                   reuseTrainSetBottleneckCachedValues: true,\r\n                   reuseValidationSetBottleneckCachedValues: true));\r\n```\r\n\r\nOutput:\r\n\r\n```text\r\nNumber of rows 182\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  93, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  94, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  95, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  96, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  97, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  98, Accuracy:        NaN\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   0, Epoch:  99, Accuracy:        NaN\r\n```\r\n\r\nWhen the `batchSize` is set equal to the number of rows (in this case 182), this is the output:\r\n\r\n```text\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  95, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  96, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  97, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  98, Accuracy:          1\r\nPhase: Training, Dataset used: Validation, Batch Processed Count:   1, Epoch:  99, Accuracy:          1\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/4274","RelatedDescription":"Closed issue \"[Image Classification API] No evaluation when batchSize parameter > # of instances in dataset\" (#4274)"},{"Id":"502878212","IsPullRequest":true,"CreatedAt":"2019-10-04T23:06:34","Actor":"antoniovs1029","Number":"4300","RawContent":null,"Title":"Fixes #4299 related to ML.Samples and ML.Samples.GPU sharing the same Program.cs file","State":"open","Body":"A simple change to fix #4299 . Simply added a new Program.cs file to the ML.Samples.GPU, independent of the one in ML.Samples.","Url":"https://github.com/dotnet/machinelearning/pull/4300","RelatedDescription":"Open PR \"Fixes #4299 related to ML.Samples and ML.Samples.GPU sharing the same Program.cs file\" (#4300)"},{"Id":"502875147","IsPullRequest":false,"CreatedAt":"2019-10-04T22:52:37","Actor":"antoniovs1029","Number":"4299","RawContent":null,"Title":"Problems caused by ML.Samples and ML.Samples.GPU sharing the same Program.cs file","State":"open","Body":"### Issue\r\n\r\n**What did you do?**: I modified the Program.cs file in the ML.Samples project to run a sample that exists in the Samples.Dynamic.Trainers.Regression namespace.\r\n\r\n**What happened?**:\r\nSince ML.Samples and ML.Samples.GPU share the same Program.cs file, my changes in the Program.cs under ML.Samples had effects on the ML.Samples.GPU project.\r\n\r\nAn error appeared in the Program.cs file inside the ML.Samples.GPU project saying that the namespace Samples.Dynamic didn't have a name 'Trainers' and that I might have been missing an assembly reference. Also, while editing the Program.cs inside ML.Samples I received warning tooltips making reference to the errors in ML.Samples.GPU's Program.cs.\r\n\r\nAlthough this didn't prevent me to run the sample, it was odd to see that error messages. Also, later, when trying to run tests inside Visual Studio, I got a compiler errors because of this, and I couldn't run tests. I didn't use to have these compiler errors before, because ML.Samples.GPU was introduced in a recent commit to the master branch.\r\n\r\n**How to solve the problem?**\r\nEventhough ML.Samples has the correct settings to access the sample I was trying to run, ML.Samples.GPU doesn't. This problem might happen with other samples as well.\r\n\r\nSo to simply solve this problem, a new Program.cs file needs to be added to the ML.Samples.GPU project, that is independent to the one in ML.Samples.","Url":"https://github.com/dotnet/machinelearning/issues/4299","RelatedDescription":"Open issue \"Problems caused by ML.Samples and ML.Samples.GPU sharing the same Program.cs file\" (#4299)"},{"Id":"502348385","IsPullRequest":true,"CreatedAt":"2019-10-04T17:03:37","Actor":"harshithapv","Number":"4293","RawContent":null,"Title":"Buffer re-use using ArrayPool and a few more checks","State":"closed","Body":"Added ArrayPool for buffer re-use while reading images in ImageLoader.cs. A few commits for safety checks. \r\nContinuation to my previous commit #4242 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/4293","RelatedDescription":"Closed or merged PR \"Buffer re-use using ArrayPool and a few more checks\" (#4293)"},{"Id":"502698674","IsPullRequest":false,"CreatedAt":"2019-10-04T15:22:00","Actor":"HamzahIqbal765","Number":"4296","RawContent":null,"Title":"Far more weights than features when obtaining PFI Metrics for Binary Classification","State":"open","Body":"Windows 10 v. 1809\r\n- NET Core SDK (3.0.100): \r\n\r\n\r\nI have used trainined thje model with numerical features, and this has successfully returned PFI metrics, whereby the number of weights is equivalent to the number of features.\r\nHowever, the issue arises when  I pass a dataset without numerical features. When the features are categorical and strings, I use one hot encoding to convert the features into the appropriate vectors. \r\nIn both the former and present case, I use a FastForest trainer. \r\nWhen I follow the documentation for PFI, the model is trained fine, but when I run the code:\r\n\r\n` VBuffer<float> weights = default;\r\nlinearPredictor.Model.SubModel.GetFeatureWeights(ref weights);`\r\n\r\nI get over 80 weights when I only have 12 features in my data. And I cannot continue following the documentation since it matches the index of the weights against the index of the feature.\r\n\r\nIs there a way to get the PFI when using OneHotEncoding?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4296","RelatedDescription":"Open issue \"Far more weights than features when obtaining PFI Metrics for Binary Classification\" (#4296)"},{"Id":"502657868","IsPullRequest":false,"CreatedAt":"2019-10-04T14:06:54","Actor":"nighotatul","Number":"4295","RawContent":null,"Title":"How to Convert Transform Result into DataTable by dynamically ?","State":"open","Body":"@eerhardt - \r\n\r\nIDataView multiclassTransformer = model.Transform(trainTestData.TestSet);\r\n\r\nDataViewSchema columns = multiclassTransformer.Schema;\r\n\r\nDataViewSchema.Column? columnOrNull = multiclassTransformer.Schema.GetColumnOrNull(\"Features\");\r\n                            VBuffer<ReadOnlyMemory<char>> slotNames = new VBuffer<ReadOnlyMemory<char>>();\r\n                            if (columnOrNull.HasValue)\r\n                                columnOrNull.GetValueOrDefault().GetSlotNames(ref slotNames);\r\n\r\n                            IList<string> featurenameCollection= (IList<string>)slotNames.Items(false).Select<KeyValuePair<int, ReadOnlyMemory<char>>, string>((Func<KeyValuePair<int, ReadOnlyMemory<char>>, string>)(kv => kv.Value.ToString())).ToList<string>();\r\n\r\n\r\nHow i can convert the output result into DataTable\r\n\r\nAs Many of example uses Hardcoded class like below example\r\n\r\npublic class MultiClassResultPrediction\r\n        {\r\n            // public uint GroupId { get; set; }\r\n\r\n            // public uint Label { get; set; }\r\n\r\n            // Prediction made by the model that is used to indicate the relative ranking of the candidate search results.\r\n            public float Score { get; set; }\r\n\r\n            // Values that are influential in determining the relevance of a data instance. This is a vector that contains concatenated columns from the underlying dataset.\r\n            // public float[] Features { get; set; }\r\n        }\r\n\r\n\r\nList<MultiClassResultPrediction> predictedResult = context.Data.CreateEnumerable<MultiClassResultPrediction>(predictions, reuseRowObject: false).ToList();\r\n\r\nor \r\n\r\nelse dynamic class where we can access featurevalues,label values and output result schema\r\nlike PredictedLabel,Score\r\nlike below example :\r\n\r\nwhere we can return output in web.\r\n\r\n       IDictionary<string, object> flexibleJson = new ExpandoObject();\r\n        for (int i = 0; i < length; i++)\r\n        {\r\n           \r\n            flexibleJson.Add(colName, colValue);\r\n        }\r\n\r\n        var serialized = JsonConvert.SerializeObject(flexibleJson);\r\n\r\nSo my concern is how we can convert result into DataTable\r\n\r\nis there any way we can achieve the desired result by dynamically into DataTabel?","Url":"https://github.com/dotnet/machinelearning/issues/4295","RelatedDescription":"Open issue \"How to Convert Transform Result into DataTable by dynamically ?\" (#4295)"},{"Id":"502370834","IsPullRequest":false,"CreatedAt":"2019-10-04T01:00:15","Actor":"frank-dong-ms","Number":"4294","RawContent":null,"Title":"Remove default constructor of OnnxSequenceType attribute on next major release","State":"open","Body":"Related to issue #4120 , the temp fix to add obsolete attribute on default constructor but the ideal fix should be remove the default constructor.\r\n\r\nAs this is break Public API change, we will do it on next major release.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4294","RelatedDescription":"Open issue \"Remove default constructor of OnnxSequenceType attribute on next major release\" (#4294)"},{"Id":"501177421","IsPullRequest":true,"CreatedAt":"2019-10-04T00:23:50","Actor":"frank-dong-ms","Number":"4272","RawContent":null,"Title":"Issue 4120, add reasonable exception when user try to use OnnxSequenceType attribute without specify sequence type","State":"closed","Body":"Fixes #4120 \r\n\r\nThe issue is: when user use OnnxSequenceType attribute directly without specify sequence type like [OnnxSequenceType], user will hit run time exception when try to use it.\r\n\r\nThe ideal way to fix this issue is to remove the default constructor of OnnxSequenceTypeAttribute and user will get compiler error when he/she try to use [OnnxSequenceType]. \r\nBut this can be a break change in Public API. After discuss with @eerhardt and @ericstj , we decide to obsolete the default constructor for now. Then we will remove the default constructor in next major release.\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4272","RelatedDescription":"Closed or merged PR \"Issue 4120, add reasonable exception when user try to use OnnxSequenceType attribute without specify sequence type\" (#4272)"},{"Id":"502329197","IsPullRequest":false,"CreatedAt":"2019-10-03T22:26:11","Actor":"antoniovs1029","Number":"4292","RawContent":null,"Title":"Use PFI with Binary Prediction Transformer and CalibratedModelParametersBase loaded from disk","State":"open","Body":"In my last accepted pull request (#4262 ) I addressed issue #3976 and was able to provide working samples and tests for using PFI with models loaded from disk except for the case of Binary Prediction Transformer. Here I open this issue about that specific problem.\r\n\r\n### Problem\r\nIn the [sample using PFI with binary classification](https://github.com/dotnet/machinelearning/blob/e19369b407e8630cfaa82b07f81f0576c9bbd145/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/BinaryClassification/PermutationFeatureImportance.cs#L40) the last transformer of the model (i.e. the linearPredictor) is of type `BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>`.\r\n\r\nProblem is that when saving and then loading that model from disk, a null reference is returned when trying to access the last transformer by casting it to the original type.\r\n```\r\n// linearPredictor is null:\r\nvar linearPredictor = (loadedmodel as TransformerChain<ITransformer>).LastTransformer as BinaryPredictionTransformer<CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>>; \r\n```\r\n\r\nHaving a null linearPredictor makes it unusable with PFI.\r\n\r\nIn version 1.3 of ML.Net the last transformer of the loaded model would actually be of type `BinaryPredictionTransformer<IPredictorProducing<float>>`\r\n\r\nWith the changes I made in my last PR (which will be available in version 1.4.0 preview 2) the loaded model's last transformer would be of type `BinaryPredictionTransformer<ParameterMixingCalibratedModelParameters<IPredictorProducing<float>, ICalibrator>>` which is a step forward in solving the problem, but is not yet enough.\r\n\r\nAs stated, in both cases, a cast to the original type would return null. In general, it would be expected that the user tries to make that cast in order to use PFI, failing to accomplish it.\r\n\r\nThis problem would be solved if the loaded model actually had a lastTransformer of the original type, or something castable to it.\r\n\r\n### Workaround\r\nBased on [this comment](https://github.com/dotnet/machinelearning/pull/4262#discussion_r330175774) made by @yaeldekel I've just made [this working sample of using PFI with a binary prediction transformer loaded from disk](https://gist.github.com/antoniovs1029/e5fdd86d5b7c8b6adf34cb5481ee20dd). It is pretty much the same as the original sample, only that it works with a model loaded from disk.\r\n\r\nThe key of the workaround is that the user should cast the lastTransformer not into a binary prediction transformer but rather into a `ISingleFeaturePredictionTransformer<object>`, and then do a series of casts to get whatever other object s/he may want to get from inside the lastTransformer.\r\n\r\nIn the sample I've just provided it works pretty much in this way:\r\n```\r\nvar linearPredictor = (loadedmodel as TransformerChain<ITransformer>).LastTransformer as ISingleFeaturePredictionTransformer<object>;\r\nvar predictorModel = linearPredictor.Model as CalibratedModelParametersBase;\r\nvar predictorSubModel = predictorModel.SubModel as LinearBinaryModelParameters;\r\n```\r\n\r\nNotice that this workaround worked even in ML.Net 1.3, and also works with the changes that I introduced in 1.4.0 preview 2.\r\n\r\nNotice that a similar workaround might help a user that tries to use PFI with any kind of prediction transformer loaded from disk. This would come useful if the user, for whatever reason, can not extract the linearPredictor by casting to the same type used in the original model.\r\n\r\n### Cause of the Problem\r\nThere are 3 main points that are related to the cause of this problem, all of which pertain the `Calibrator.cs ` file and aren't related to the binary prediction transformer itself:\r\n1. Unexpectedly, when loading a `ParameterMixingCalibratedModelParameters<>` its [Create method](https://github.com/dotnet/machinelearning/blob/e19369b407e8630cfaa82b07f81f0576c9bbd145/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L564) isn't called. I discovered this while debugging, and what actually happens is that, during loading, inside the [CreateInstanceCore method](https://github.com/dotnet/machinelearning/blob/7c067854b564275b0d6387ca59c0ec83e8fc91b9/src/Microsoft.ML.Core/ComponentModel/ComponentCatalog.cs#L197), it first looks for a constructor, and so it calls the constructor of `ParameterMixingCalibratedModelParameters<>` instead of the Create method.\r\n2. Currently, when loading a `ParameterMixingCalibratedModelParameters<>` model, a `ParameterMixingCalibratedModelParameters<IPredictorProducing<float>, ICalibrator>` is always loaded, no matter what the actual submodel and calibrator are. This doesn't change by fixing point 1). This point is similar to the [original problem found on the prediction transformers](https://github.com/dotnet/machinelearning/issues/3976#issuecomment-517862076), which I fixed in [my last pull request](https://github.com/dotnet/machinelearning/pull/4262); using a similar approach in this case would fix this point... that is, loading first the submodel and calibrator to then create a generic type at runtime with the correct parameter types.\r\n3. When fiting the model (i.e. before even saving it or loading it) the [SdcaLogisticRegressionBinaryTrainer ](https://github.com/dotnet/machinelearning/blob/46ede664e8cff585c450a7005c7069b64df5a6f1/src/Microsoft.ML.StandardTrainers/Standard/SdcaBinary.cs#L1606)creates a predictor of type `ParameterMixingCalibratedModelParameters<LinearBinaryModelParameters, PlattCalibrator>` (which I will now refer to as \"PMCMP\") but returns it as a `CalibratedModelParametersBase<LinearBinaryModelParameters, PlattCalibrator>` (let's call it \"CMPB\") this then is what makes the last transformer of the model to be a `BinaryPredictionTransformer<CMPB>` whereas the internal model of the last transformer is actually a PMCMP. When saving it to disk, it's saved as a PMCMP (i.e. it's saved using a LoaderSignature of \"PMixCaliPredExec\"), so when loading occurs, it calls the constructor of PMCMP but it doesn't cast it to a CMPB. This is different from the problem fixed in my last pull request; there, if a Regression prediction transformer was saved, then we expected to load a regression prediction transformer... whereas in here if a PMCMP is saved we actually want to load a CMPB with the correct type parameters.\r\n\r\n\r\n### Trying to solve the problem\r\nSo far I've been able to solve problems 1) and 2) described above, but after trying out different approaches I haven't been able to solve problem 3). To solve those problems I've changed different things in the `Calibrator.cs` file. My attempt to solve this problem can be found in [here ](https://github.com/antoniovs1029/machinelearning/blob/f81ae76065f12b04d101d9e63e7397f968dd1f77/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L524) (although it is somewhat messy right now)... if requested I can clean that up and open a PR for further review.\r\n\r\nWith those changes (along with the ones of my last PR), the loaded model's last transformer becomes a `BinaryPredictionTransformer<ParameterMixingCalibratedModelParameters<LinearBinaryModelParameters, PlattCalibrator>>`. Notice that even here a cast to `BPT<CMPB>` would be null, so it doesn't solve the problem. Also notice that since PMCMP is an internal class the user wouldn't be able to cast the last transformer to `BPT<PMCMP>` either, since s/he wouldn't have access to that class.\r\n\r\n### Further problems\r\nHere I've explained the specific case of loading a `BPT<CMPB>` with the specific problems that arise in CMPB and PMCMP classes because that is what is used in the sample of PFI with BPT, and in the tests of PFI with BPT. It could be possible that the problems here described are also present in other classes (for example in the other classes of [Calibrator.cs](https://github.com/dotnet/machinelearning/blob/18394c4f9e45b9c5ff41dfbabd30e31132ae4cdc/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1)) but they might not become a problem unless the user tries to access the last transformer of a model loaded from disk. In such a case the described workaround might help.","Url":"https://github.com/dotnet/machinelearning/issues/4292","RelatedDescription":"Open issue \"Use PFI with Binary Prediction Transformer and CalibratedModelParametersBase loaded from disk\" (#4292)"},{"Id":"502293780","IsPullRequest":true,"CreatedAt":"2019-10-03T22:09:47","Actor":"codemzs","Number":"4291","RawContent":null,"Title":"Update CodeCov uploader version.","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/4291","RelatedDescription":"Closed or merged PR \"Update CodeCov uploader version.\" (#4291)"},{"Id":"502274691","IsPullRequest":true,"CreatedAt":"2019-10-03T20:14:53","Actor":"Nucs","Number":"4290","RawContent":null,"Title":"TensorTypeExtensions: Added conversion between Tensor to primitive C# types instead of throwing NotSupportedException","State":"open","Body":"- Added conversion between Tensor to native C# types instead of throwing NotSupportedException\r\n- Fixed proper reading of TF_STRING\r\n- Added overloads that support TF_STRING (string does not meet T generic constraint `unmanaged`","Url":"https://github.com/dotnet/machinelearning/pull/4290","RelatedDescription":"Open PR \"TensorTypeExtensions: Added conversion between Tensor to primitive C# types instead of throwing NotSupportedException\" (#4290)"},{"Id":"502260817","IsPullRequest":false,"CreatedAt":"2019-10-03T19:44:45","Actor":"meesoft","Number":"4288","RawContent":null,"Title":"ScoreTensorFlowModel fails with null reference exception","State":"open","Body":"### System information\r\n\r\n- Win10 64bit\r\n- .net 4.6.1\r\n- Microsoft.ML.TensorFlow 1.3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nUsed LoadTensorFlowModel and ScoreTensorFlowModel on a pretrained model\r\n- **What happened?**\r\nScoreTensorFlowModel fails with null reference exception\r\n- **What did you expect?**\r\npipeline object\r\n\r\n### Source code / logs\r\n```\r\nvar estimator = mlContext.Model.LoadTensorFlowModel(\"saved_model.pb\");\r\nConsole.WriteLine(\"Inputs: \" + string.Join(\";\", estimator.GetInputSchema().Select(c => c.Name)));\r\nvar pipeline = estimator.ScoreTensorFlowModel(\r\n    new[] { \"denoised\" },\r\n    new[] { \"is_training\", \"noisy\" }, addBatchDimensionInput: true);\r\n```\r\n\r\n[saved_model.zip](https://github.com/dotnet/machinelearning/files/3687784/saved_model.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4288","RelatedDescription":"Open issue \"ScoreTensorFlowModel fails with null reference exception\" (#4288)"},{"Id":"502232611","IsPullRequest":false,"CreatedAt":"2019-10-03T18:43:26","Actor":"aslotte","Number":"4287","RawContent":null,"Title":"Model Builder | Selecting a file without file type crashes Visual Studio","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?** I downloaded the data for spam detection (ML samples)\r\n- **What happened?** When I opened the Model Builder in Visual studio and selected the training file, Visual Studio hangs and eventually crashes. Setting the file type to .tsv makes it work.\r\n- **What did you expect?** A reasonable error message would be useful, e.g. \"Please indicate if this file is tab- or comma-separated\"\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4287","RelatedDescription":"Open issue \"Model Builder | Selecting a file without file type crashes Visual Studio\" (#4287)"},{"Id":"502229981","IsPullRequest":false,"CreatedAt":"2019-10-03T18:37:36","Actor":"CESARDELATORRE","Number":"4285","RawContent":null,"Title":"[Model management] Save/Load Model into a Relational Database (SQL Server)","State":"open","Body":"From feedback from a customer using SQL Server Functions and Stored Procedures implemented in C#:\r\n\r\nBasically, would be good to have an API like the following:\r\n\r\n.SaveModelToDb()\r\n.LoadModelFromDb()\r\n\r\nThe reasons and scenarios are because you run C# code only as code running within SQL Server such as a C# SQL Server Function or a Stored Procedure that is scoring an ML.NET model while doing a query or transactions.\r\n\r\nAnd not just for scoring but also for saving the model after training close to the database.. and since it is a table you could also have multiple model versions..\r\n\r\nAnother scenario would be for traditional client/server apps with the client apps directly accessing a database...\r\n\r\nDoing it that way everything would be held, and more importantly, **secured** in the database server without external dependencies.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4285","RelatedDescription":"Open issue \"[Model management] Save/Load Model into a Relational Database (SQL Server)\" (#4285)"},{"Id":"501989702","IsPullRequest":true,"CreatedAt":"2019-10-03T16:43:07","Actor":"codemzs","Number":"4279","RawContent":null,"Title":"Increment build version for 1.4.0-preview-2 and 0.16.0-preview-2 release","State":"closed","Body":"\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4279","RelatedDescription":"Closed or merged PR \"Increment build version for 1.4.0-preview-2 and 0.16.0-preview-2 release\" (#4279)"},{"Id":"502045120","IsPullRequest":false,"CreatedAt":"2019-10-03T12:48:06","Actor":"nighotatul","Number":"4280","RawContent":null,"Title":"we are getting more thane one score in spam detection?","State":"open","Body":"@eerhardt - please see this code,\r\n\r\n var dataProcessPipeline = context.Transforms.Conversion.MapValueToKey(\"Label\", \"Label\")\r\n                                                  .Append(context.Transforms.Text.FeaturizeText(\"FeaturesText\", new Microsoft.ML.Transforms.Text.TextFeaturizingEstimator.Options\r\n                                                  {\r\n                                                      WordFeatureExtractor = new Microsoft.ML.Transforms.Text.WordBagEstimator.Options { NgramLength = 2, UseAllLengths = true },\r\n                                                      CharFeatureExtractor = new Microsoft.ML.Transforms.Text.WordBagEstimator.Options { NgramLength = 3, UseAllLengths = false },\r\n                                                  }, \"Message\"))\r\n                                                  .Append(context.Transforms.CopyColumns(\"Features\", \"FeaturesText\"))\r\n                                                  .Append(context.Transforms.NormalizeLpNorm(\"Features\", \"Features\"))\r\n                                                  .AppendCacheCheckpoint(context);\r\n\r\n                        // Set the training algorithm \r\n                        var trainer = context.MulticlassClassification.Trainers.OneVersusAll(context.BinaryClassification.Trainers.AveragedPerceptron(labelColumnName: \"Label\", numberOfIterations: 10, featureColumnName: \"Features\"), labelColumnName: \"Label\")\r\n                                                  .Append(context.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\", \"PredictedLabel\"));\r\n                        var trainingPipeLine = dataProcessPipeline.Append(trainer);\r\n\r\n\r\n                        //Console.WriteLine(\"=============== Cross-validating to get model's accuracy metrics ===============\");\r\n                        //var crossValidationResults = mlContext.MulticlassClassification.CrossValidate(data: data, estimator: trainingPipeLine, numberOfFolds: 5);\r\n                        //ConsoleHelper.PrintMulticlassClassificationFoldsAverageMetrics(trainer.ToString(), crossValidationResults);\r\n\r\n                        // Now let's train a model on the full dataset to help us get better results\r\n                        var model = trainingPipeLine.Fit(trainData);\r\n\r\n\r\n                        IDataView predictions = model.Transform(trainData);\r\n\r\n\r\n                        List<SpamPrediction> predictedResults = context.Data.CreateEnumerable<SpamPrediction>(predictions, reuseRowObject: false).ToList();\r\n\r\nwe attached data also. then which one score we consider?\r\n[spamdata.xlsx](https://github.com/dotnet/machinelearning/files/3686067/spamdata.xlsx)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4280","RelatedDescription":"Open issue \"we are getting more thane one score in spam detection?\" (#4280)"},{"Id":"501839858","IsPullRequest":true,"CreatedAt":"2019-10-03T05:17:27","Actor":"codemzs","Number":"4278","RawContent":null,"Title":"Fix build breaks.","State":"closed","Body":"Build first broke with #4237 and remained broken until this change.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4278","RelatedDescription":"Closed or merged PR \"Fix build breaks.\" (#4278)"},{"Id":"501709698","IsPullRequest":true,"CreatedAt":"2019-10-03T01:10:55","Actor":"bpstark","Number":"4277","RawContent":null,"Title":"Added support for running TF based models on GPU in Linux","State":"closed","Body":"Modified the GPU samples to take a dependency on both the linux and\r\nwindows TF GPU redist.\r\n\r\nModified the readme content to explain how to use on linux.\r\n\r\nTested on Ubuntu 18.04 with GTX1070, was able to run on the GPU without any issue.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4277","RelatedDescription":"Closed or merged PR \"Added support for running TF based models on GPU in Linux\" (#4277)"},{"Id":"501195820","IsPullRequest":true,"CreatedAt":"2019-10-02T17:51:36","Actor":"pieths","Number":"4273","RawContent":null,"Title":"Add DateTime to DateTime standard conversion.","State":"closed","Body":"This fixes an error which is caused by a missing DateTime to DateTime conversion when outputting DateTime columns in NimbusML. NimbusML calls in to `RowCursorUtils.GetGetterAsCore` (indirectly) which tries to find a conversion from DateTime to DateTime and fails with the following error:\r\n\r\n```console\r\nError: *** System.InvalidOperationException: 'No standard conversion from 'DateTime' to 'DateTime'\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4273","RelatedDescription":"Closed or merged PR \"Add DateTime to DateTime standard conversion.\" (#4273)"},{"Id":"501375399","IsPullRequest":false,"CreatedAt":"2019-10-02T09:24:07","Actor":"yaeldekel","Number":"4276","RawContent":null,"Title":"Issues with ImageClassificationTransformer","State":"open","Body":"- The Options class contains two string array fields: one for input column names and one for output column names. However, it always uses exactly two input columns: a label column and a features column, and it always outputs exactly two output columns: score and predicted label. This discrepancy should be addressed.\r\n- The transformer has a field called `_labelColumnName` that is serialized and deserialized and otherwise does nothing. Since after deserialization we cannot rely on having data that has a label column anyway, this field should be removed.\r\n- `GetOutputSchema()` in the estimator does not check that the type of the label column is correct (what other types, if any, should be allowed other than key type?), and neither does the constructor (it doesn't check the type of the features column either).\r\n- I think the constructor of the transformer should not have a boolean flag to indicate whether the transformer is being instantiated from file or from the estimator. Instead, the estimator should do the required training (including figuring out the class count), and there should be one constructor for the transformer, that is called both from the estimator's `Fit()` method, and from the transformer's `Create(ModelLoadContext)` method.\r\n- The estimator has a `_transformer` field that is not needed.\r\n- The transformer ctor has an unused argument: `batchSize` - don't know if the error is in not using it or in not needing it.","Url":"https://github.com/dotnet/machinelearning/issues/4276","RelatedDescription":"Open issue \"Issues with ImageClassificationTransformer\" (#4276)"},{"Id":"501263651","IsPullRequest":false,"CreatedAt":"2019-10-02T04:08:51","Actor":"nighotatul","Number":"4275","RawContent":null,"Title":"how we draw tree using fast tree algorithm?","State":"open","Body":"as per suggestion given by @eerhardt, following link to @ganik @codemzs or @yaeldekel \r\nhttps://github.com/dotnet/machinelearning/issues/4264\r\n@ganik -  i have prepared sample on this below link.\r\nthis is Visualize sickit-learn decision trees with d3.js\r\nhttp://bl.ocks.org/fractalytics/raw/495b63cf671b4c487bc40801366384e0/\r\n\r\nwe do not know python script but we know C#. so that please helps us to draw above tree using fasttree ml.net using score,weights,bias.\r\nif any sample is their please share with us.","Url":"https://github.com/dotnet/machinelearning/issues/4275","RelatedDescription":"Open issue \"how we draw tree using fast tree algorithm?\" (#4275)"},{"Id":"501037711","IsPullRequest":true,"CreatedAt":"2019-10-02T01:40:45","Actor":"bpstark","Number":"4270","RawContent":null,"Title":"Modified the project to support running of TensorFlow on GPU on Windows.","State":"closed","Body":"Removed all dependencies of TensorFlow redist from the source projects,\r\nand instead added the dependency to the Sample project.\r\nCreated separate sample project for GPU examples since gpu tensorflow requires cuda,\r\nwhich may not be available on all machines, so it needs to be a separate\r\nproject.\r\nAdded documentation for setup as there is now some setup requirements to use this API.\r\n\r\nIn testing on the large flowers data set I was able to see a large improvement in speed, from taking ~720 seconds to train to taking ~156 seconds. \r\n\r\nFixes #4269\r\n\r\nAddresses part of the issue in #86 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4270","RelatedDescription":"Closed or merged PR \"Modified the project to support running of TensorFlow on GPU on Windows.\" (#4270)"},{"Id":"501034241","IsPullRequest":false,"CreatedAt":"2019-10-02T01:40:45","Actor":"bpstark","Number":"4269","RawContent":null,"Title":"TensorFlow based DNN models do not support the GPU on windows.","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n### Issue\r\n\r\nCurrently the DNN TensorFlow based models do not support GPU training/inferencing. \r\n\r\nDNNs should be able to support the GPU.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4269","RelatedDescription":"Closed issue \"TensorFlow based DNN models do not support the GPU on windows.\" (#4269)"},{"Id":"501176332","IsPullRequest":false,"CreatedAt":"2019-10-01T22:23:05","Actor":"sergioprates","Number":"4271","RawContent":null,"Title":"How to process image with 1 channel?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\n- **.NET Version (eg., dotnet --info)**:\r\n.NET Core 3.0 \r\n\r\n### Issue\r\nI have a model that is trained in keras that accept a input shape of 64x64x1, in this case an image in gray scale. But I don't found a way of pre-process image to send only one channel to model, in ML.NET only have a method that extract one channel, R, G, B or Alpha.\r\n- **What did you do?**\r\n`var pipeline = mlContext.Transforms.ResizeImages(resizing: ImageResizingEstimator.ResizingKind.Fill, outputColumnName: onnxModel.ModelInput, imageWidth: ImageSettings.imageWidth,\r\n                imageHeight: ImageSettings.imageHeight, inputColumnName: nameof(ImageInputData.Image))\r\n                .Append(mlContext.Transforms.ConvertToGrayscale(outputColumnName: onnxModel.ModelInput, inputColumnName: onnxModel.ModelInput))\r\n                .Append(mlContext.Transforms.ExtractPixels(outputColumnName: onnxModel.ModelInput, inputColumnName: onnxModel.ModelInput, interleavePixelColors: true, \r\n                orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ARGB, colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Red))\r\n                .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: onnxModel.ModelPath, outputColumnName: onnxModel.ModelOutput, inputColumnName: onnxModel.ModelInput));`\r\n\r\nMy image come from a input form, like onnx examples in samples repository\r\n- **What happened?**\r\nI'm getting incorrect prediction, because I don't know how to reshape image to 64x64x1, in case that I send 64x64x3 format, I'm getting the error \"Length of memory (12288) must match product of dimensions (4096).\"\r\n- **What did you expect?**\r\nI expect that ML.NET provide a way to reshape my image to one channel image to get correct predictions\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4271","RelatedDescription":"Open issue \"How to process image with 1 channel?\" (#4271)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-10-07T05:30:43.1975293Z","RunDurationInMilliseconds":1046}