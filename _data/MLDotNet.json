{"Data":{"GitHub":{"Issues":[{"Id":"342556761","IsPullRequest":true,"CreatedAt":"2018-07-19T02:30:07","Actor":"codemzs","Number":"556","RawContent":null,"Title":"WIP Port SymSGD","State":"open","Body":"This PR depends on the MKL nuget for native code and hence it won't compile at the moment. I will be updating it with tests and documentation as MKL PR comes up. I have also upgraded SymSGD trainer to use ITrainer interface that returns a predictor.","Url":"https://github.com/dotnet/machinelearning/pull/556","RelatedDescription":"Open PR \"WIP Port SymSGD\" (#556)"},{"Id":"342549622","IsPullRequest":true,"CreatedAt":"2018-07-19T01:46:31","Actor":"Ivanidzo4ka","Number":"555","RawContent":null,"Title":"Don't fail in case of const field in Collection source and extended support for type conversion","State":"open","Body":"Fixes  #537.\r\nAdds support for multiple basic C# types to convert Dataview <-> collection.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/555","RelatedDescription":"Open PR \"Don't fail in case of const field in Collection source and extended support for type conversion\" (#555)"},{"Id":"342531912","IsPullRequest":false,"CreatedAt":"2018-07-18T23:59:17","Actor":"Zruty0","Number":"554","RawContent":null,"Title":"Need a doc on Type-to-DataView schema mapping","State":"open","Body":"We should have a doc that describes exactly how we go from \r\n```(csharp)\r\n        public class IrisData\r\n        {\r\n            [Column(\"0\")]\r\n            public float Label;\r\n\r\n            [Column(\"1\")]\r\n            public float SepalLength;\r\n\r\n            [Column(\"2\")]\r\n            public float SepalWidth;\r\n\r\n            [Column(\"3\")]\r\n            public float PetalLength;\r\n\r\n            [Column(\"4\")]\r\n            public float PetalWidth;\r\n        }\r\n```\r\nto the schema of the data view. It should cover:\r\n* Why field types are important, and how they are used\r\n* What exactly is `ColumnAttribute`, `ColumnNameAttribute`\r\n* Handling of vectors and `VectorTypeAttribute`\r\n* Handling of key types and `KeyTypeAttribute`\r\n* `SchemaDefinition` as a means of runtime schema hints.\r\n* Limitations / what can not be done.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/554","RelatedDescription":"Open issue \"Need a doc on Type-to-DataView schema mapping\" (#554)"},{"Id":"341087165","IsPullRequest":true,"CreatedAt":"2018-07-18T23:44:57","Actor":"sfilipi","Number":"529","RawContent":null,"Title":"Adding documentation about the rest of the classes involved on generating the CSharpAPI","State":"closed","Body":"Resolves #389 \r\nAdded more documentation and examples about mostly transforms components. (A few learners as well.)\r\n\r\nThe documentation for the classes involved in generating the entry points lives in the doc.xml documents, since it needs to be referenced from two locations, for the most part, and since the CSharpApi is auto-generated. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/529","RelatedDescription":"Closed or merged PR \"Adding documentation about the rest of the classes involved on generating the CSharpAPI\" (#529)"},{"Id":"342469916","IsPullRequest":false,"CreatedAt":"2018-07-18T19:57:21","Actor":"TomFinley","Number":"553","RawContent":null,"Title":"Introduce code analyzer","State":"open","Body":"Like most sufficiently large codebases the ML.NET project is guilty of having acquired a set of idioms. Internally we had a code analyzer, to help catch some of the most common issues that tended to come up in PRs, but sometimes we don't do this, and need to fix issues later (e.g., #271, #442, #478). I want to migrate that analyzer to the open source repository, to hopefully automate some of this.\r\n\r\nThere are of course other things we could do with an analyzer, once we have one.\r\n\r\n/cc @ericstj ","Url":"https://github.com/dotnet/machinelearning/issues/553","RelatedDescription":"Open issue \"Introduce code analyzer\" (#553)"},{"Id":"342443150","IsPullRequest":false,"CreatedAt":"2018-07-18T18:33:04","Actor":"briancylui","Number":"552","RawContent":null,"Title":"Port native SIMD algorithms for SSE to managed code","State":"open","Body":"### Summary (July 18)\r\n1. Prepare to check in code to ML.NET repo, with:\r\n* [C# implementations](https://github.com/briancylui/machinelearning/blob/SseKey/src/Microsoft.ML.CpuMath/CpuMathUtils.DotNetCoreApp.cs) of [SSE intrinsics](https://github.com/briancylui/machinelearning/blob/SseKey/src/Microsoft.ML.CpuMath/SseIntrinsics.cs) living in [src/Microsoft.ML.CpuMath](https://github.com/briancylui/machinelearning/tree/SseKey/src/Microsoft.ML.CpuMath)\r\n* [Unit tests](https://github.com/briancylui/machinelearning/blob/SseKey/test/Microsoft.ML.CpuMath.UnitTests/UnitTests.cs) and [performance tests](https://github.com/briancylui/machinelearning/blob/SseKey/test/Microsoft.ML.CpuMath.PerformanceTests/SsePerformanceTests.cs) living in [test/Microsoft.ML.CpuMath.[Unit/Performance]Tests](https://github.com/briancylui/machinelearning/tree/SseKey/test)\r\n2. Resolve multi-targeting issue of targeting two different frameworks: .NET Core App 3.0 and .NET Standard 2.0\r\n3. Additional rigorous unit tests and performance tests to ensure correctness and efficiency\r\n4. Link to working repo (forked): https://github.com/briancylui/machinelearning\r\n5. Link to original issue page for 12-week timeline: https://github.com/briancylui/machinelearning/issues/1\r\n\r\n### Goals\r\n1.\tPort ML.NET C++ SIMD algorithms for SSE to C#\r\n2.\tEnsure C# Hardware Intrinsics feature for SSE meets the needs of ML.NET\r\n3.\tUnit test all functions and get performance benchmark numbers for before and after changes\r\n4.\t(Stretch) Provide software fallback implementations to support more architectures\r\n\r\n[Keeping only the relevant, high-level details below from original [progress](https://github.com/briancylui/machinelearning/issues/1) page to give a general sense of progress]\r\n### Progress\r\n\r\n**Week 2 (Jun 25-29): Port SIMD operations in .NET to managed code outside of ML.NET**\r\n- [x] Implement SSE support and software fallbacks in managed code for all key intrinsics\r\n- [x] Comply with coding style standard\r\n- [x] Implement working unit tests for all key intrinsics\r\n- [x] Implement working performance tests for all key intrinsics using [BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet) ([slides](https://microsoft.sharepoint.com/:p:/r/teams/netfx/corefx/_layouts/15/Doc.aspx?sourcedoc=%7Bf4cdc660-09d2-40ae-a099-4c6bf213bec1%7D&action=default) and [recording](https://microsoft.sharepoint.com/teams/netfx/corefx/Documents/Forms/AllItems.aspx?id=%2Fteams%2Fnetfx%2Fcorefx%2FDocuments%2FModern%20BCL%2Fmodern%20BCL%20talk%20series%20%2D%20Benchmark%2ENET%204%2027%202018%2Emp4&parent=%2Fteams%2Fnetfx%2Fcorefx%2FDocuments%2FModern%20BCL&p=true&slrid=1efa769e-e056-0000-7f34-41a0941dbef8))\r\n- [x] Present performance results in a table ([SsePerf-report-github.pdf](https://github.com/briancylui/machinelearning/files/2157186/SsePerf-report-github.pdf))\r\n\r\n``` ini\r\n\r\nBenchmarkDotNet=v0.10.14, OS=Windows 10.0.15063.1155 (1703/CreatorsUpdate/Redstone2)\r\nIntel Core i7-7700 CPU 3.60GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores\r\nFrequency=3515623 Hz, Resolution=284.4446 ns, Timer=TSC\r\n.NET Core SDK=2.1.300\r\n  [Host]     : .NET Core 2.1.0 (CoreCLR 4.6.26515.07, CoreFX 4.6.26515.06), 64bit RyuJIT\r\n  DefaultJob : .NET Core 2.1.0 (CoreCLR 4.6.26515.07, CoreFX 4.6.26515.06), 64bit RyuJIT\r\n\r\n\r\n```\r\n|                    Method |       Mean |      Error |     StdDev |\r\n|-------------------------- |-----------:|-----------:|-----------:|\r\n|            NativeDotUPerf |   363.2 us |  7.7293 us | 18.8143 us |\r\n|                MyDotUPerf |   340.2 us |  6.7218 us |  8.0018 us |\r\n|           NativeDotSUPerf | 2,178.3 us | 43.4641 us | 40.6563 us |\r\n|               MyDotSUPerf | 2,144.7 us | 19.1638 us | 16.0027 us |\r\n|          NativeSumSqUPerf |   540.6 us |  3.0299 us |  2.8342 us |\r\n|              MySumSqUPerf |   538.8 us |  2.5507 us |  2.3859 us |\r\n|            NativeAddUPerf |   313.9 us |  2.5163 us |  2.3537 us |\r\n|                MyAddUPerf |   303.3 us |  4.5125 us |  4.2210 us |\r\n|           NativeAddSUPerf | 2,691.8 us | 29.4588 us | 27.5558 us |\r\n|               MyAddSUPerf | 2,658.1 us | 51.3336 us | 64.9206 us |\r\n|       NativeAddScaleUPerf |   300.0 us |  5.5529 us |  5.1941 us |\r\n|           MyAddScaleUPerf |   309.8 us |  5.3974 us |  4.7846 us |\r\n|      NativeAddScaleSUPerf | 2,550.9 us | 21.8322 us | 20.4218 us |\r\n|          MyAddScaleSUPerf | 2,805.3 us | 20.5171 us | 19.1917 us |\r\n|          NativeScaleUPerf |   131.4 us |  0.6347 us |  0.5626 us |\r\n|              MyScaleUPerf |   130.7 us |  1.2159 us |  1.1373 us |\r\n|           NativeDist2Perf |   336.4 us |  2.0555 us |  1.9227 us |\r\n|               MyDist2Perf |   335.2 us |  8.3427 us | 11.4196 us |\r\n|         NativeSumAbsUPerf |   258.0 us |  1.6470 us |  1.5406 us |\r\n|            MySumAbsqUPerf |   258.9 us |  0.9447 us |  0.7889 us |\r\n| NativeMulElementWiseUPerf |   466.4 us |  1.9625 us |  1.6388 us |\r\n|     MyMulElementWiseUPerf |   467.2 us |  4.3560 us |  4.0747 us |\r\n\r\n\r\n**Week 3-5 (Jul 2-20): Port algo to C#, write unit tests and performance tests, check in code**\r\n- [x] Apply real data to test implemented managed code using BenchmarkDotNet\r\n- [x] Integrate local code into ML.NET repo to prepare for checking in code, including:\r\n* C# implementations of intrinsics\r\n* Unit tests\r\n* Performance tests\r\n- [ ] Implement additional unit tests to test the complete code paths for two different target frameworks\r\n- [ ] Scale up implementation, unit tests, and performance tests to cover all SSE intrinsics\r\n\r\n**Week 6 (Jul 23-27)**\r\n- [ ] Write blog post on how ML.NET is taking advantage of .NET Core hardware intrinsics\r\n\r\n**Week 7-9 (Jul 30-Aug 17)**\r\n- [ ] Write AVX implementations \r\n- [ ] Performance test before and after. We should see some perf gains here.\r\n- [ ] Write blog post on AVX vs SSE comparisons (both implementation and runtime perf)\r\n- [ ] Check in code to ML.NET\r\n\r\n**Week 10-11 (Aug 20-31) (Stretch)**\r\n- [ ] Provide software fallback implementations\r\n\r\n**Week 12 (Sept 3-7)**\r\n- [ ] Clean up, presentation, close out remaining issues","Url":"https://github.com/dotnet/machinelearning/issues/552","RelatedDescription":"Open issue \"Port native SIMD algorithms for SSE to managed code\" (#552)"},{"Id":"342210925","IsPullRequest":false,"CreatedAt":"2018-07-18T07:36:13","Actor":"StanislavChankov","Number":"551","RawContent":null,"Title":"Score column is missing. Parameter name ScoreColumn.","State":"open","Body":"### Issue\r\nThrows an exception \r\n- **What did you do?**\r\n![image](https://user-images.githubusercontent.com/35253870/42866807-475cd2a8-8a76-11e8-9509-d8d147534fa7.png)\r\n\r\n- **What happened?**\r\n![image](https://user-images.githubusercontent.com/35253870/42866529-6e75a5d2-8a75-11e8-8aaf-b4a609affc96.png)\r\n\r\n- **What did you expect?**\r\nTo train without errors or warnings like I have.\r\n### Source code / logs\r\n**ML.NET Version: 0.3.0**\r\n![image](https://user-images.githubusercontent.com/35253870/42866497-59a16876-8a75-11e8-80c8-dfe0ca695d56.png)\r\n![image](https://user-images.githubusercontent.com/35253870/42866716-0f85de24-8a76-11e8-8da4-8cd233d3f7d3.png)\r\n\r\n![image](https://user-images.githubusercontent.com/35253870/42866191-96d304a8-8a74-11e8-99da-4eb762792eb0.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/551","RelatedDescription":"Open issue \"Score column is missing. Parameter name ScoreColumn.\" (#551)"},{"Id":"342139971","IsPullRequest":true,"CreatedAt":"2018-07-18T01:05:47","Actor":"codemzs","Number":"550","RawContent":null,"Title":"Ensure ONNX export is compatible with Windows RS5","State":"open","Body":"fixes #549 by testing ONNX models on Windows RS5 machine.","Url":"https://github.com/dotnet/machinelearning/pull/550","RelatedDescription":"Open PR \"Ensure ONNX export is compatible with Windows RS5\" (#550)"},{"Id":"342139834","IsPullRequest":false,"CreatedAt":"2018-07-18T01:04:56","Actor":"codemzs","Number":"549","RawContent":null,"Title":"Ensure ONNX export is Windows RS5 compatible.","State":"open","Body":"Added more tests for ONNX export and ran the model on RS5 machine to ensure model loads and evaluates.","Url":"https://github.com/dotnet/machinelearning/issues/549","RelatedDescription":"Open issue \"Ensure ONNX export is Windows RS5 compatible.\" (#549)"},{"Id":"342119690","IsPullRequest":true,"CreatedAt":"2018-07-17T23:04:51","Actor":"zeahmed","Number":"548","RawContent":null,"Title":"Fixed the TextTransform bug where chargrams where being computed differently when using with/without word tokenizer.","State":"open","Body":"This PR fixes #530. The cause of the problem was `word tokenizer` being applied before `char tokenizer` causing scalar valued text (e.g. `This is a cat`) to become vector (e.g. <This, is, a, cat>). \r\n\r\nPreviously, char tokenizer treated every vector item as separate text item (e.g. computing chargrams on each item by placing start and end markers `<STX>token<ETX>` instead of taking `This is a cat` as single text item).\r\n\r\nThe fix is in CharTokenizeTransform. The CharTokenizeTransform can take either a scalar or vector column as input. The processing of chargrams are done as follows.\r\n\r\n- If the input column is a scalar with text type then chargrams are computed by prepending `<STX>` and appending `<ETX>` characters at the start and at the end of the text respectively.  For example, if the input is `This is a cat` then chargrams will be computed on `<STX>This is a cat<ETX>`.\r\n\r\n- If the input column is a vector with text type (it could be a result of concatenation of several text columns together or application of word tokenizer before char tokenizer) then chargrams will be computed by prepending `<STX>` and appending `<ETX>` characters at start and at the end of the vector respectively. Also, spaces are inserted after every item in the vector. For example, if the input is `<This, is, a, cat>` then chargrams will be computed on `<STX>This is a cat<ETX>`.\r\n\r\nThis will ensure that whether  word tokenizer is applied or not before char tokenizer the chargrams computed are consistent.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/548","RelatedDescription":"Open PR \"Fixed the TextTransform bug where chargrams where being computed differently when using with/without word tokenizer.\" (#548)"},{"Id":"342110400","IsPullRequest":false,"CreatedAt":"2018-07-17T22:22:50","Actor":"Ivanidzo4ka","Number":"547","RawContent":null,"Title":"ColumnType not properly implements IEquatable","State":"open","Body":"https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/Data/ColumnType.cs\r\nAccording to https://msdn.microsoft.com/en-us/library/ms131190(v=vs.110).aspx (see Notes to Implementers:) we suppose to also override GetHashCode which we don't do.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/547","RelatedDescription":"Open issue \"ColumnType not properly implements IEquatable\" (#547)"},{"Id":"342077809","IsPullRequest":false,"CreatedAt":"2018-07-17T20:45:02","Actor":"Ivanidzo4ka","Number":"546","RawContent":null,"Title":"Rename tlcresources in Resource manager","State":"open","Body":"```\r\n        private const string DefaultUrl = \"https://aka.ms/tlc-resources/\";\r\n      \r\n        private static string TlcResourcesUrl\r\n```\r\nwe have this TLC mentions in https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Core/Utilities/ResourceManagerUtils.cs\r\nand it would be nice to rename them to something ml.net specific.\r\n\r\nIn same time we need to make sure default url should point to valid location (we can't just rename it in code, we also need to update aka.ms)","Url":"https://github.com/dotnet/machinelearning/issues/546","RelatedDescription":"Open issue \"Rename tlcresources in Resource manager\" (#546)"},{"Id":"342076074","IsPullRequest":true,"CreatedAt":"2018-07-17T20:39:52","Actor":"Ivanidzo4ka","Number":"545","RawContent":null,"Title":"WIP word embedding transform","State":"open","Body":"I heard word embedding can be nice thing for Text classification\r\n- [ ] Create issue\r\n- [ ] Put legal attributes for Wikipedia files\r\n- [ ] Put legal attributes for Glove files\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/545","RelatedDescription":"Open PR \"WIP word embedding transform\" (#545)"},{"Id":"342056815","IsPullRequest":false,"CreatedAt":"2018-07-17T19:40:10","Actor":"EduardoGarcias","Number":"544","RawContent":null,"Title":"CrossValidation fails with a valid pipeline","State":"open","Body":"### System information\r\n\r\n- **Windows 10 Home (1803) - 64bit**:\r\n- **.NET Version 2.1.202**: \r\n- **WPF application with includes class libraries in .net 4.7 framework version**:\r\n\r\n### Issue\r\n\r\nIt is not possible for me to perform a CrossValidation on a Pipline, which I use for training my model. The training is performed without any issues. Normal evaluation works correctly (using classes like BinaryClassificationEvaluator or RegressionEvaluator) but the CrossValidation ends with an error. The error is as follows:\r\n> InvalidOperationException: No valid training instances found, all instances have missing features.\r\n\r\n\r\n### Source code / logs\r\n\r\n- Pipeline body is like:\r\n`          \r\n     \r\n                new TextLoader(filePath).CreateFrom<ReopenedIssueData>(),\r\n                new TextFeaturizer(Columns.Environment, Columns.Environment),\r\n                new TextFeaturizer(Columns.Type, Columns.Type),\r\n                new TextFeaturizer(Columns.ProjectName, Columns.ProjectName),\r\n                new TextFeaturizer(Columns.AsigneeEmail, Columns.AsigneeEmail),\r\n                new TextFeaturizer(Columns.ReporterEmail, Columns.ReporterEmail),\r\n                new ColumnConcatenator(\r\n                    Columns.Features,\r\n                    Columns.Environment,\r\n                    Columns.Type,\r\n                    Columns.CommentsCount,\r\n                    Columns.CommentsLenght,\r\n                    Columns.ReporterCommentsCount,\r\n                    Columns.ProjectName,\r\n                    Columns.AsigneeEmail,\r\n                    Columns.ReporterEmail),\r\n                new FastTreeBinaryClassifier(),\r\n                new PredictedLabelColumnOriginalValueConverter() { PredictedLabelColumn=Columns.PredictedLabel   }\r\n                    \r\n`\r\n\r\n- And the StackTrace is as follows:\r\n\r\n>  at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointGraph.RunNode(EntryPointNode node)\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAllNonMacros()\r\n   at Microsoft.ML.Runtime.EntryPoints.JsonUtils.GraphRunner.RunAll()\r\n   at Microsoft.ML.Models.CrossValidator.CrossValidate[TInput,TOutput](LearningPipeline pipeline)\r\n   at RepositoryAnalyser.MachineLearning.Services.TrainingModelEvaluator.CrossValidate[TData,TPrediction](LearningPipeline pipeline, MachineLearningMechanism mechanism, Int32 numOfFolds)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/544","RelatedDescription":"Open issue \"CrossValidation fails with a valid pipeline\" (#544)"},{"Id":"341998856","IsPullRequest":false,"CreatedAt":"2018-07-17T16:43:38","Actor":"TomFinley","Number":"543","RawContent":null,"Title":"Rename properties of `ITrainerEx` (`TrainerInfo`)","State":"open","Body":"`ITrainerEx` (or its functional successor `TrainerInfo` from #522) contains the following properties.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ef169b2c67ef394b65d5bedbebd378913789fd9c/src/Microsoft.ML.Core/Prediction/ITrainer.cs#L35-L58\r\n\r\nAs the comment suggests, we ought to be consistent in naming. There are several things we might consider doing here.\r\n\r\nThe first thing we might consider is getting rid of `NeedCalibration` specifically. It is I believe always true when the predictor returned from this is a binary predictor, but does not itself return probabilities. This is a trait that I believe can be directly derived from the predictor object itself, so we might be able to simplify the code here. (Certainly the code to detect whether a predictor produces probabilities might potentially be somewhat involved, and the situation here may be less simple than I suspect.)\r\n\r\nThe other thing is reconciling `Need` and `Want`. The prefix `Need` is a bit odd, since certainly you don't *need* to do any of those things for things to work, it's just a suggestion that it might work better *if* you do those things.\r\n\r\nHowever rather than just reconciling the prefix, we might consider renaming them altogether. They're very oddly named in the sense that they don't describe a property of the trainer they are attached to, they describe an action we suggest a user of the trainer should do to use them (or in the case of `NeedCalibration`, an action to take on the result of training). That is, they are *prescriptive* as opposed to *descriptive*, which seems undesirable.\r\n\r\nSo take `NeedNormalization`... trainers don't just need normalization randomly for no reason, they need normalization because they have parametric assumptions about feature data -- maybe a property could be devised to explain that, with the understanding that if it's true a user may benefit from normalizing features. Similarly, caching tends to be useful if an algorithm could perform many passes over the data (therefore making it better to keep in memory).\r\n\r\nHowever maybe this is a bit too goofy... `NeedNormalization` is easy for more people to reach the desired action vs. some complicated multi-step process of reasoning (\"it has parametric assumptions about features, I think my data is not, the way people tend to fix this is apply normalizers, so I will apply a normalizer\" vs. just \"ah, needs normalization, I will normalize.\"). Despite the fact that the name is prescriptive and not descriptive, maybe that does not in itself make it inferior to the alternative?\r\n\r\nNot sure about this.\r\n\r\n/cc @eerhardt , @ericstj , @Zruty0 ","Url":"https://github.com/dotnet/machinelearning/issues/543","RelatedDescription":"Open issue \"Rename properties of `ITrainerEx` (`TrainerInfo`)\" (#543)"},{"Id":"341951176","IsPullRequest":true,"CreatedAt":"2018-07-17T14:43:30","Actor":"eerhardt","Number":"542","RawContent":null,"Title":" Allow CpuMath to reference C# Hardware Intrinsics APIs.","State":"open","Body":"Need to multi-target CpuMath for netstandard and netcoreapp3.0.  Also, since we are going to move CpuMath into its own NuGet package, remove the dependency from CpuMath to the ML.Core project.\r\n\r\nAdd a build parameter to enable building against .NET Core 3.0's Runtime Intrinsics APIs.\r\n\r\nFix #534 ","Url":"https://github.com/dotnet/machinelearning/pull/542","RelatedDescription":"Open PR \" Allow CpuMath to reference C# Hardware Intrinsics APIs.\" (#542)"},{"Id":"341657323","IsPullRequest":false,"CreatedAt":"2018-07-16T19:59:51","Actor":"eerhardt","Number":"541","RawContent":null,"Title":"Need to rename TlcEnvironment","State":"open","Body":"Our only public, concrete environment class is named \"TlcEnvironment\", which uses the internal \"TLC\" acronym/name and has no meaning anymore.\r\n\r\nWe should come up with a better name for our default environment class.\r\n\r\n/cc @ericstj @TomFinley ","Url":"https://github.com/dotnet/machinelearning/issues/541","RelatedDescription":"Open issue \"Need to rename TlcEnvironment\" (#541)"},{"Id":"341599530","IsPullRequest":false,"CreatedAt":"2018-07-16T17:01:01","Actor":"dsyme","Number":"540","RawContent":null,"Title":"Plan for F# bug and testing","State":"open","Body":"I've been asked to fix some issues related to F# in this repo, especially #180. This is a planning note regarding this work.\r\n\r\nTODO:\r\n\r\n* [ ] Add one F# scripting \"smoke test\" under `tests\\FSharpScripting\\SmokeTest` based around those done by @isaacabraham, see https://github.com/isaacabraham/ml-test-experiment.  \r\n\r\n   * This test will run under CI on Windows. It will currently require .NET Framework or Mono.  \r\n\r\n* [ ] Add one F# compiled-project \"smoke test\" under `tests\\FSharpProjects\\SmokeTest` based around those done by @isaacabraham, see https://github.com/isaacabraham/ml-test-experiment.  \r\n\r\n   * This test will run under CI on both Windows and Linux and only require .NET Core\r\n\r\nWhen futher API updates and re-designs are made it is up to the person doing the re-design to adjust these tests :) Ask for help if you need it, but the F# code will be simple and I'm sure all contributors are capable of adjusting trivial F# code, F# is dead simple to learn.\r\n\r\nThen, when [this bug](https://github.com/dotnet/machinelearning/issues/180) is fixed, a test will be added to both tests\\FSharpScripting\\SmokeTest and tests\\FSharpProjects\\SmokeTest.\r\n\r\nSeparately I will propose updates for documentation for F#, and we can later look at more comprehensive documentation, samples and testing.","Url":"https://github.com/dotnet/machinelearning/issues/540","RelatedDescription":"Open issue \"Plan for F# bug and testing\" (#540)"},{"Id":"341571989","IsPullRequest":true,"CreatedAt":"2018-07-16T15:40:33","Actor":"abgoswam","Number":"539","RawContent":null,"Title":"PipelineSweeperMacro for Multi-Class Classification","State":"open","Body":"Fixes #538\r\n\r\n- The PipelineSweeper currently only supports AUC as the optimization metric.  Trying to optimize on any other metric throws an exception.\r\n- Need to fix the way metrics are handled by the PipelineSweeper Macro.\r\n- Added a test case for MultiClass classification using the PipelineSweeper.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/539","RelatedDescription":"Open PR \"PipelineSweeperMacro for Multi-Class Classification\" (#539)"},{"Id":"341569557","IsPullRequest":false,"CreatedAt":"2018-07-16T15:34:25","Actor":"abgoswam","Number":"538","RawContent":null,"Title":"PipelineSweeping fails for MultiClass classification","State":"open","Body":"### Issue\r\n\r\n- **PipelineSweeper fails for 'TrainerKind': 'SignatureMultiClassClassifierTrainer'**\r\n- **System.InvalidOperationException : Requested value 'Accuracy(micro-avg)' is not a member of the Enum type 'Metrics'**\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/538","RelatedDescription":"Open issue \"PipelineSweeping fails for MultiClass classification\" (#538)"},{"Id":"341144408","IsPullRequest":false,"CreatedAt":"2018-07-16T14:12:15","Actor":"mgolois","Number":"531","RawContent":null,"Title":"How to get the accuracy when using a FastTreeRegressor?","State":"closed","Body":"When predicting a flight delay, I would like to let the user know how accurate is the prediction. I was not able to find a way to ouput that information with a regression algorithm:\r\n\r\n```\r\n         static void Main(string[] args)\r\n        {\r\n\r\n            string trainDataPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Flight Delay Prediction-TrainData.csv\");\r\n            string testDataPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Flight Delay Prediction-TestData.csv\");\r\n            string modelPath = Path.Combine(Environment.CurrentDirectory, \"Data\", \"Model.zip\");\r\n            Console.WriteLine(Environment.CurrentDirectory);\r\n\r\n            var pipeline = new LearningPipeline\r\n            {\r\n                new TextLoader(trainDataPath).CreateFrom<FlightInfo>(useHeader: true, separator: ','),\r\n                new ColumnCopier((\"ArrivalDelay\", \"Label\")),\r\n                new CategoricalOneHotVectorizer(\"Airline\", \"OriginAirport\"),\r\n                new ColumnConcatenator(\"Features\", \"Airline\", \"OriginAirport\"),\r\n                new FastTreeRegressor()\r\n            };\r\n\r\n            var model = pipeline.Train<FlightInfo, FlightDelayPrediction>();\r\n\r\n            model.WriteAsync(modelPath).Wait();\r\n\r\n\r\n            var testData = new TextLoader(testDataPath).CreateFrom<FlightInfo>(useHeader: true, separator: ',');\r\n\r\n            var evaluator = new RegressionEvaluator();\r\n\r\n            var metrics = evaluator.Evaluate(model, testData);\r\n\r\n            Console.WriteLine($\"Rms = {metrics.Rms}\");\r\n            Console.WriteLine($\"RSquared = {metrics.RSquared}\");\r\n\r\n            var predictDelay = new FlightInfo();\r\n\r\n            Console.WriteLine(\"Let's try to predict an airline and departing city delay:\");\r\n            Console.Write(\"Airline: \");\r\n            predictDelay.Airline = Console.ReadLine();\r\n            Console.Write(\"Departing City: \");\r\n            predictDelay.OriginAirport = Console.ReadLine();\r\n\r\n            var prediction = model.Predict(predictDelay);\r\n            Console.WriteLine($\"Predicted Arrival Delay: {prediction.ArrivalDelay}\");\r\n            Console.ReadKey();\r\n        }\r\n    }\r\n    public class FlightInfo\r\n    {\r\n        [Column(\"0\")]\r\n        public string Airline;\r\n        [Column(\"1\")]\r\n        public float ArrivalDelay;\r\n        [Column(\"2\")]\r\n        public string OriginAirport;\r\n\r\n    }\r\n\r\n    public class FlightDelayPrediction\r\n    {\r\n        [ColumnName(\"Score\")]\r\n        public float ArrivalDelay;\r\n    }\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/531","RelatedDescription":"Closed issue \"How to get the accuracy when using a FastTreeRegressor?\" (#531)"},{"Id":"341403566","IsPullRequest":false,"CreatedAt":"2018-07-16T06:32:52","Actor":"rauhs","Number":"537","RawContent":null,"Title":"`const` on the instance class will throw","State":"open","Body":"Adding a:\r\n\r\n```\r\n    public const string MagicNone = \" NONE \";\r\n```\r\n\r\nto an \"instance\" class (ie the class used to feed ML.NET the instances) will throw an ugly exception which is hard to figure out.\r\n\r\nI think there is another issue where more careful reflecting of the class is suggested. Can't find it right now though","Url":"https://github.com/dotnet/machinelearning/issues/537","RelatedDescription":"Open issue \"`const` on the instance class will throw\" (#537)"},{"Id":"341354477","IsPullRequest":false,"CreatedAt":"2018-07-15T21:38:28","Actor":"galvesribeiro","Number":"536","RawContent":null,"Title":"WASM support","State":"open","Body":"Hello folks!\r\n\r\nTrying to make ML.Net to work on mono-wasm but I just figured out the hard way that it only works on x64:\r\n\r\n![image](https://user-images.githubusercontent.com/4714040/42738687-1104bf6e-885e-11e8-813b-e55a91976ccc.png)\r\n\r\nIs there any chance to get the native part built to wasm?\r\n\r\nThanks!","Url":"https://github.com/dotnet/machinelearning/issues/536","RelatedDescription":"Open issue \"WASM support\" (#536)"},{"Id":"341193133","IsPullRequest":false,"CreatedAt":"2018-07-14T00:27:17","Actor":"dan-drews","Number":"535","RawContent":null,"Title":"How would I concatenate columns of different types?","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 x64\r\n- **.NET Version (eg., dotnet --info)**:  .NET Framework 4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Combined numeric columns with FeaturizedText Columns\r\n- **What happened?** I received an exception about mismatched column Types\r\n- **What did you expect?** I'm not 100% sure. I am hoping to find a way to combine a text featurizer with numeric values into the \"Features\" column to take multiple data types into account. I saw that we have the categorical vectorizers and Hash Transform Columns available, but I from what i understand, that is for a distinct number of categories.\r\n\r\nWhat I am trying to accomplish is utilizing numeric and text values in the prediction. Maybe this is just a lack of understanding on my part for this and it is not possible, but I'm kind of hoping to post the pieces of my business object that that I think could impact the result, and I cannot figure out how to do that effectively.\r\n\r\nNote: I am using a FastTreeRegressor predicting a float value.","Url":"https://github.com/dotnet/machinelearning/issues/535","RelatedDescription":"Open issue \"How would I concatenate columns of different types?\" (#535)"},{"Id":"341175974","IsPullRequest":false,"CreatedAt":"2018-07-13T22:22:13","Actor":"eerhardt","Number":"534","RawContent":null,"Title":"Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core","State":"open","Body":".NET Core 2.1 [introduced hardware intrinsics APIs](https://github.com/dotnet/designs/blob/master/accepted/platform-intrinsics.md) that allow C# code to take full advantage of the CPU. For example, you can now write algorithms using SSE or AVX instructions purely from C# code.\r\n\r\nThe CpuMathNative assembly exists solely so ML.NET can take advantage of SSE and AVX instructions in its algorithms. When running on .NET Core 2.1+, we can remove our dependency on this native assembly, and instead port the C++ SIMD code to using the new C# intrinsics APIs.\r\n\r\nHowever, to do this (and still support the full .NET Framework), we need to do some refactoring to our assemblies and NuGet packages.\r\n\r\nThe first thing we need to do is allow `Microsoft.ML.CpuMath` to be multi-targeted for `netstandard2.0;netcoreapp2.1`. This will allow us to compile against the netcoreapp2.1 specific SSE APIs.\r\n\r\nHowever, doing that affects our `Microsoft.ML` nuget package. This is because when you make a nuget package, you put your assemblies into TFM specific folders `lib\\netstandard2.0`, `lib\\netcoreapp2.1`, etc. And the way asset picking works is that once it finds assets for a specific TFM, it stops looking.  (The reasoning is typically there is a single assembly per nuget package.) So if we have a single assembly, CpuMath, that needs to go into both `lib\\netstandard2.0` and `lib\\netcoreapp2.1`, we have a problem. It means ALL our assemblies need to go into BOTH folders, which is unnecessary duplication.\r\n\r\nTo solve this duplication, I propose to split CpuMath into its own nuget package.  So we will have this structure:\r\n\r\n* `Microsoft.ML.CpuMath`\r\n    - Contains the CpuMath managed assemblies (one for each TFM) and the CpuMathNative assemblies.\r\n* `Microsoft.ML`\r\n    - Has a dependency on `Microsoft.ML.CpuMath`.\r\n\r\nIn order to do this correctly, we need to remove the assembly reference from `Microsoft.ML.CpuMath.dll` on `Microsoft.ML.Core.dll`. This is because the nuget dependency goes the other way.  The only reason `Microsoft.ML.CpuMath.dll` depends on `Microsoft.ML.Core.dll` is so it can use the `Contracts` class.  We can break this dependency by using the `PRIVATE_CONTRACTS` define constant, and source linking the `Contracts.cs` file into CpuMath.\r\n\r\n/cc @TomFinley @ericstj @briancylui @tannergooding ","Url":"https://github.com/dotnet/machinelearning/issues/534","RelatedDescription":"Open issue \"Need to refactor CpuMath to enable using C# intrinsics APIs on .NET Core\" (#534)"},{"Id":"341148843","IsPullRequest":false,"CreatedAt":"2018-07-13T20:24:29","Actor":"bsexton","Number":"533","RawContent":null,"Title":"Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.","State":"open","Body":"### System information\r\nIssue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**:  4.6.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** I started with the TaxiFare Example and that works. But then I changed the model and added my own values and my data. I got the error about the \"Features\" above. I played with it for a while and tried limiting my data. Even tried predicting the Fare Amount again.\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/533","RelatedDescription":"Open issue \"Issue changing model from TaxiFareExample. 'Features' must be a known-size vector of R4, but has type: Vec<I4, 2>.\" (#533)"},{"Id":"341147669","IsPullRequest":false,"CreatedAt":"2018-07-13T20:19:49","Actor":"vivekpradhan","Number":"532","RawContent":null,"Title":"LightGBM on ML.NET trains slower than LightGBM command line","State":"open","Body":"### System information\r\n\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.301\r\n Commit:    59524873d6\r\n\r\nRuntime Environment:\r\n OS Name:     ubuntu\r\n OS Version:  16.04\r\n\r\nHardware:\r\nGoogle Cloud default 64 core machine.\r\n\r\n### Issue\r\n\r\nRan training on same dataset with same params.\r\nDataset: 25k features x 140k rows (balanced binary classes)\r\nParams: \r\nCommand Line: \r\n```\r\n./lightgbm metric=binary_logloss min_data_in_leaf=500 bagging_fraction=0.8 boosting_type=gbdt bagging_freq=5 max_bin=255 objective=binary valid_data=../../../pedata/test.csv max_depth=10 feature_fraction=0.8 num_leaves=70 output_result=prediction.txt num_machines=1 learning_rate=0.1 output_model=LightGBM_model.txt data=../../../pedata/train.csv num_threads=64 task=train is_training_metric=true num_iterations=500 metric_freq=1 tree_learner=serial\r\n```\r\nML.NET\r\n```\r\nvar lclassifier = new LightGbmBinaryClassifier() { UseCat=false, MaxBin= 255, EvalMetric= LightGbmArgumentsEvalMetricType.Logloss , NumLeaves= 70, NThread= 64,LearningRate= 0.1, NumBoostRound= 500, MinDataPerLeaf= 500};\r\n            lclassifier.Booster = new GbdtBoosterParameterFunction() { \r\n                MaxDepth = 10,\r\n                FeatureFraction=0.8,\r\n                SubsampleFreq=5 };\r\n            pipeline.Add(lclassifier);\r\n```\r\n- **What happened?**\r\n\r\nBoth use all the 64 cores (As seen on htop).\r\nData Loading + Training Time: Command Line: 10mins, ML.NET: 17mins\r\n\r\n- **What did you expect?**\r\nSince both were build on my machine from source, I expected that the training time would be comparable.  \r\n\r\nWhy is the ML.NET implementation slower? Is there something I can do to speed it up?\r\n\r\n```\r\nStopwatch stopwatch = new Stopwatch();\r\nstopwatch.Start();\r\n// STEP 5: Train your model based on the data set\r\nvar model = pipeline.Train<IrisData, IrisPrediction>();\r\nstopwatch.Stop();\r\n```\r\nThe above stopwatch gives me time taken for Loading+Training. Is there a way to check the time taken only for the training step. Right now I am not sure if the data loading is slow or the training is slow.\r\n\r\n-----------------\r\nEdit: I got approximate training time by assuming that when CPU usage spikes, thats when training starts.\r\nTraining Time: Command Line: 335s, ML.NET:680s (approx)\r\nData Loading: Command Line: 265s, ML.NET: 340s (approx)","Url":"https://github.com/dotnet/machinelearning/issues/532","RelatedDescription":"Open issue \"LightGBM on ML.NET trains slower than LightGBM command line\" (#532)"},{"Id":"341133131","IsPullRequest":false,"CreatedAt":"2018-07-13T19:24:58","Actor":"zeahmed","Number":"530","RawContent":null,"Title":"[TextTransform] Char n-grams are different when using with/without word n-grams.","State":"open","Body":"### System information\r\n\r\n`Not relevant`\r\n\r\n### Issue\r\nWhen using TextTransform to compute n-grams, it has been observed that character n-grams produced are not consistent when computing it with/without word n-grams option. For example, for the following sentence \r\n```\r\nThis is a cat\r\n```\r\nThe character n-grams produced are as follows. where `<STX>`, `<ETX>` and `<SP>` are start of sentence, end of sentence and space control characters respectively.\r\n\r\n| Char 3-gram | Char 3-gram + Word 3-gram|\r\n|-|-|\r\n|\\<STX\\>\\|t\\|h | \\<STX\\>\\|t\\|h\r\n| t\\|h\\|i | t\\|h\\|i\r\n| h\\|i\\|s | h\\|i\\|s\r\n| i\\|s\\|\\<SP\\> | i\\|s\\|\\<ETX\\>\r\n| s\\|\\<SP\\>\\|i | s\\|\\<ETX\\>\\|\\<STX\\>\r\n| \\<SP\\>\\|i\\|s | \\<ETX\\>\\|\\<STX\\>\\|i\r\n| s\\|\\<SP\\>\\|a | \\<STX\\>\\|i\\|s\r\n| \\<SP\\>\\|a\\|\\<SP\\> | \\<ETX\\>\\|\\<STX\\>\\|a\r\n| a\\|\\<SP\\>\\|c | \\<STX\\>\\|a\\|\\<ETX\\>\r\n| \\<SP\\>\\|c\\|a | a\\|\\<ETX\\>\\|\\<STX\\>\r\n| c\\|a\\|t | \\<ETX\\>\\|\\<STX\\>\\|c\r\n| a\\|t\\|\\<ETX\\> | \\<STX\\>\\|c\\|a\r\n|-| c\\|a\\|t\r\n|-| a\\|t\\|\\<ETX\\>\r\n\r\n### Source code / logs\r\nThe cause of the problem is word tokenizer which is applied at the following location in the code.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/669f4fad33184c9c558314f8bc758f7928ad62bf/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L266\r\n\r\nThe `NeedsWordTokenizationTransform` property is set according to following criteria\r\nhttps://github.com/dotnet/machinelearning/blob/669f4fad33184c9c558314f8bc758f7928ad62bf/src/Microsoft.ML.Transforms/Text/TextTransform.cs#L169\r\n\r\nThis means whenever word n-grams are being computed the tokenization is performed first and character n-gram extractor computes n-grams on words instead of sentences i.e. \r\n\r\ninstead of computing char n-grams on \r\n```\r\n<STX>This<SP>is<SP>a<SP>cat<ETX>\r\n```\r\nit computes char n-grams on\r\n```\r\n<STX>This<ETX>\r\n<STX>is<ETX>\r\n<STX>a<ETX>\r\n<STX>cat<ETX>\r\n```\r\nFirst of all, is the expected behavior?\r\nI my point of view `NOT` because in this way character n-gram is adding noise and losing important information regarding the sentence which in some cases may give superior performance.\r\n\r\n### Solution\r\nApply char n-gram extractor on `IDataView` that was not used for word processing in the code.","Url":"https://github.com/dotnet/machinelearning/issues/530","RelatedDescription":"Open issue \"[TextTransform] Char n-grams are different when using with/without word n-grams.\" (#530)"},{"Id":"341032515","IsPullRequest":true,"CreatedAt":"2018-07-13T16:32:56","Actor":"TomFinley","Number":"527","RawContent":null,"Title":"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest","State":"closed","Body":"Fixes #526 .\r\n\r\nThe test `TrainAndPredictIrisModelUsingDirectInstantiationTest` now has analogous changes to the `TrainAndPredictIrisModelTest` test.","Url":"https://github.com/dotnet/machinelearning/pull/527","RelatedDescription":"Closed or merged PR \"Fix TrainAndPredictIrisModelUsingDirectInstantiationTest\" (#527)"},{"Id":"341041086","IsPullRequest":true,"CreatedAt":"2018-07-13T14:30:02","Actor":"Ivanidzo4ka","Number":"528","RawContent":null,"Title":"WIP Image support","State":"open","Body":"address #489 \r\nneed create issue about IDataView datatype extensibility.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/528","RelatedDescription":"Open PR \"WIP Image support\" (#528)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-07-19T05:30:37.4362907Z","RunDurationInMilliseconds":1102}