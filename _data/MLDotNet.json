{"Data":{"GitHub":{"Issues":[{"Id":"417581237","IsPullRequest":true,"CreatedAt":"2019-03-08T03:47:21","Actor":"wschin","Number":"2865","RawContent":null,"Title":"Scrub projection transforms","State":"closed","Body":"Fix #2831. \r\n\r\nTransforms touched:\r\nRFF, LpNorm, GcNorm, PCA, Whiten, Normalize.","Url":"https://github.com/dotnet/machinelearning/pull/2865","RelatedDescription":"Closed or merged PR \"Scrub projection transforms\" (#2865)"},{"Id":"418578227","IsPullRequest":true,"CreatedAt":"2019-03-08T00:32:08","Actor":"ganik","Number":"2887","RawContent":null,"Title":"Update Readme to fix code sample","State":"open","Body":"fixes #2565 ","Url":"https://github.com/dotnet/machinelearning/pull/2887","RelatedDescription":"Open PR \"Update Readme to fix code sample\" (#2887)"},{"Id":"418128219","IsPullRequest":true,"CreatedAt":"2019-03-08T00:03:00","Actor":"artidoro","Number":"2876","RawContent":null,"Title":"Scrubbing task: rest of transforms","State":"closed","Body":"Fixes: #2835.\r\n\r\nThis PR does the scrubbing for the following transforms:\r\n\r\n- ReplaceMissingValues\r\n- IndicateMissingValues\r\n- CustomMapping\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2876","RelatedDescription":"Closed or merged PR \"Scrubbing task: rest of transforms\" (#2876)"},{"Id":"418564732","IsPullRequest":true,"CreatedAt":"2019-03-07T23:35:52","Actor":"shmoradims","Number":"2886","RawContent":null,"Title":"Cleaned LightGBM documentation","State":"open","Body":"LightGBM API, trainers, boosters, and options documentation. Part of #2522.","Url":"https://github.com/dotnet/machinelearning/pull/2886","RelatedDescription":"Open PR \"Cleaned LightGBM documentation\" (#2886)"},{"Id":"418545439","IsPullRequest":true,"CreatedAt":"2019-03-07T22:33:32","Actor":"sfilipi","Number":"2885","RawContent":null,"Title":"Main namespace types2445","State":"open","Body":"Towards #2445. \r\n\r\nIn the first commit IHost and related moves to Microsoft.ML.Runtime\r\nIDataFile moves to Microsoft.ML.Data\r\nLoss related functionality moves to Microsoft.ML.Trainers. \r\n\r\nThird commit is making it build. \r\nProcedure:\r\nUse VisualStudio Find/Replace all to replace:\r\n1- `using System;`  -> `using System; using Microsoft.ML.Runtime;`\r\n2- `using Microsoft.Data.DataView;`  -> `using Microsoft.Data.DataView; using Microsoft.ML.Runtime;`\r\n3- `using Microsoft.ML.Data;`  -> `using Microsoft.ML.Data; using Microsoft.ML.Runtime;`\r\n\r\nThinking that the above would touch most cs files. \r\nManually spot fixed the references in the .tt files, and the references to loss related changes, and IDataFile changes. \r\n\r\nI used the [format all files](https://marketplace.visualstudio.com/items?itemName=munyabe.FormatAllFiles) vs extension to order/align/remove dead usings. \r\n\r\nthrough spot-checking I noticed that the tool had converted some variables to readonly, and has remove explicit casts in some points, so i .. reviewed all files of the src folder and reverted those two types of changes. So i kept the using changes for 95% of the files, and some white-space fixes in about 5% of the files. \r\n\r\nAll tests passed locally on windows x64","Url":"https://github.com/dotnet/machinelearning/pull/2885","RelatedDescription":"Open PR \"Main namespace types2445\" (#2885)"},{"Id":"418483397","IsPullRequest":true,"CreatedAt":"2019-03-07T21:59:11","Actor":"rogancarr","Number":"2880","RawContent":null,"Title":"Update TreeTrainersCatalog to use standard parameter names","State":"closed","Body":"This PR updates the `TreeTrainerCatalog` to use standard parameter names (e.g. `numTrees` => `numberOfTrees`).\r\n\r\nFixes #2877 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/2880","RelatedDescription":"Closed or merged PR \"Update TreeTrainersCatalog to use standard parameter names\" (#2880)"},{"Id":"418429070","IsPullRequest":false,"CreatedAt":"2019-03-07T21:59:11","Actor":"rogancarr","Number":"2877","RawContent":null,"Title":"FastForest catalog arguments haven't been scrubbed","State":"closed","Body":"The FastForest `options` has been scrubbed, but the catalog arguments still have the old names. This is a reminder issue to go back and fix that at some point.","Url":"https://github.com/dotnet/machinelearning/issues/2877","RelatedDescription":"Closed issue \"FastForest catalog arguments haven't been scrubbed\" (#2877)"},{"Id":"418522569","IsPullRequest":false,"CreatedAt":"2019-03-07T21:31:43","Actor":"TomFinley","Number":"2884","RawContent":null,"Title":"Discussion: ColumnOptions actually a good name?","State":"open","Body":"In #2878, @eerhardt had a comment that we should consider, the gist of which was, since all of our `Options` classes have mutable properties, is it appropriate for `ColumnOptions` to be called this, since they are not and often cannot be mutable? We also have issue #2854 where @rogancarr thought he couldn't get normalization information out of the structure since it was named options, so this is not actually as academic an issue than I might have thought, say, a few days ago.\r\n\r\nThe approach taken in #2709 was that these structures created for configuration of the per-column options should be called options, and that it was (apparently) assumed to be irrelevant whether those items were mutable or not. Now, I'm not saying we should revert that PR necessarily, but it is something to consider, since it seems to be confusing people.\r\n\r\nNow then, the structures themselves obviously must not be mutable, since they are often the same structures used in the associated estimators and transformers to project schema, e.g., here it is for the n-gram hashing estimator:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a5580108d6171ae8dfa5ba60210dc2d88c9dec75/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L1077\r\n\r\nHere it is in the transformer:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a5580108d6171ae8dfa5ba60210dc2d88c9dec75/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L1077\r\n\r\nSo, just something to think about, whether it was in fact a good idea for this thing to be called \"options\" really, in all the cases we named it options. Maybe we could have a refinement on the policy of naming this thing? Or maybe we decide to just live with it, because the confusion of calling all these things \"options\" vs. \"info\" vs. \"whatever\" is greater than this inconsistency in roles?\r\n\r\nI'm fine with leaving it as is, but I do see some confusion so I think we should think about it, and at least formulate a psoition.\r\n\r\n/cc @eerhardt and @rogancarr and @sfilipi and @artidoro ...","Url":"https://github.com/dotnet/machinelearning/issues/2884","RelatedDescription":"Open issue \"Discussion: ColumnOptions actually a good name?\" (#2884)"},{"Id":"418053060","IsPullRequest":true,"CreatedAt":"2019-03-07T21:28:21","Actor":"singlis","Number":"2874","RawContent":null,"Title":"mlnetmkldeps nuget package updates","State":"closed","Body":"Related to changes for updating mlnetmkldeps nuget package, issue #2211.\r\n - Updates to the nuspec file\r\n - Updates to the instructions for creating the nuget","Url":"https://github.com/dotnet/machinelearning/pull/2874","RelatedDescription":"Closed or merged PR \"mlnetmkldeps nuget package updates\" (#2874)"},{"Id":"418502584","IsPullRequest":true,"CreatedAt":"2019-03-07T20:39:28","Actor":"rogancarr","Number":"2883","RawContent":null,"Title":"Specify MaxNumberOfIterations for SDCA, K-Means","State":"open","Body":"This PR updates SDCA and K-Means to specify `MaximumNumberOfIterations` rather than `NumberOfIterations` to make the name more precise. Essentially, for these learners, the maximum number of iterations is a worst-case scenario and a last-resort stopping criteria.\r\n\r\nFixes #2871\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2883","RelatedDescription":"Open PR \"Specify MaxNumberOfIterations for SDCA, K-Means\" (#2883)"},{"Id":"418499835","IsPullRequest":false,"CreatedAt":"2019-03-07T20:31:46","Actor":"rogancarr","Number":"2882","RawContent":null,"Title":"Non-standard naming in L-BFGS Learners (LogisticRegression, PoissonRegression)","State":"open","Body":"In `LogisticRegression` and `PoissonRegression` (which use the same L-BFGS base), we have a parameter `IterationsToRemember` that refers to the number of gradients to accumulate in the history. While this terminology makes sense, it's not what we usually encounter in the field.\r\n\r\nIn the literature, we see this referred to as the \"history size\" (see e.g. [wikipedia](https://en.wikipedia.org/wiki/Limited-memory_BFGS)).\r\n\r\nIn the various toolkits that expose an L-BFGS solver, they use:\r\nScikit Learn: Doesn't expose it.\r\nSpark: [NumberOfCorrections](https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/mllib/optimization/LBFGS.html)\r\nTensorFlow: [num_correction_pairs](https://www.tensorflow.org/probability/api_docs/python/tfp/optimizer/lbfgs_minimize)\r\nPyTorch: [history_size](https://pytorch.org/docs/stable/_modules/torch/optim/lbfgs.html)\r\n\r\nI would vote for `HistorySize`, with the docs explaining what it is.\r\n\r\nWhat do you all think? Any big feelings around this?","Url":"https://github.com/dotnet/machinelearning/issues/2882","RelatedDescription":"Open issue \"Non-standard naming in L-BFGS Learners (LogisticRegression, PoissonRegression)\" (#2882)"},{"Id":"417553476","IsPullRequest":false,"CreatedAt":"2019-03-07T20:12:44","Actor":"Ivanidzo4ka","Number":"2864","RawContent":null,"Title":"Different behavior for TokenizeChar and TokenizeWords","State":"closed","Body":"TokenizeChar produce vector of keys.\r\nTokenizeWords produce vector of strings.\r\nI have to add MapValueToKey to TokenizeWords in order to apply ProduceNgrams to it.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2864","RelatedDescription":"Closed issue \"Different behavior for TokenizeChar and TokenizeWords\" (#2864)"},{"Id":"418487450","IsPullRequest":false,"CreatedAt":"2019-03-07T19:59:09","Actor":"TomFinley","Number":"2881","RawContent":null,"Title":"Value-tuple stragglers in the public API","State":"open","Body":"There was a prior PR #2581 and issue #2501 related to value-tuples and why they should not be part of our public surface. I have noticed that there are some \"stragglers\" still remaining in the public API. So, the work is perhaps not yet complete.\r\n\r\nThe following list is I *believe* complete for `Core`/`Data`/`Transforms`/`FastTree`/`ImageAnalytics`/`KMeansClustering`/`LightGBM`/`PCA`/`Tensorflow`/`StandardLearners`/`Data.DataView` assemblies.\r\n\r\nThere are three distinct categories where this flaw has remained. (Though the last \"category\" other has only one item.)\r\n\r\n# Properties on transformers\r\n\r\nSome transformers are exposing information about themselves via this mechanism.\r\n\r\n* KeyToBinaryVectorMappingTransformer.Columns\r\n* MissingValueDroppingTransformer.Columns\r\n* MissingValueIndicatorTransformer.Columns\r\n* CustomStopWordsRemovingTransformer.Columns\r\n* TextNormalizingTransformer.Columns\r\n* TokenizingByCharactersTransformer.Columns\r\n* WordEmbeddingsExtractingTransformer.Columns\r\n* ImageGrayscalingTransformer.Columns\r\n* ImageLoadingTransformer.Columns\r\n* LatentDirichletAllocationTransformer.ItemScoresPerTopic and WordScoresPerTopic\r\n\r\n# MLContext estimator creation extension methods\r\n\r\nThere are some overloads of MLContext extension methods on various catalogs that are stil using it. I view this as a *lesser* sin since this is at least something that could conceivably be fixed using an overload if we decide it is necessary, but I'd still prefer to be consistent.\r\n\r\n* ProduceHashedNgrams extension method\r\n* ProduceHashedWordBags extension method\r\n* ProduceNgrams extension method\r\n* ProduceWordBags extension method\r\n* RemoveDefaultStopWords extension method\r\n* TokenizeWords extension method\r\n\r\n# Others\r\n\r\nLastly, I see a Microsoft.ML.ColumnOptions global class with an implicit operator from value-tuples. This one is *probably* harmless, since that specific class is for representing a simple case.\r\n\r\n/cc @yaeldekel @Ivanidzo4ka ","Url":"https://github.com/dotnet/machinelearning/issues/2881","RelatedDescription":"Open issue \"Value-tuple stragglers in the public API\" (#2881)"},{"Id":"417496864","IsPullRequest":true,"CreatedAt":"2019-03-07T19:36:17","Actor":"rogancarr","Number":"2859","RawContent":null,"Title":"Add V1 Introspective Training Tests","State":"closed","Body":"This PR adds tests to cover the Introspective Training scenarios we want fully supported in V1.\r\n\r\nI can take an existing model file and inspect what transformers were included in the pipeline\t \t \r\nI can inspect the coefficients (weights and bias) of a linear model without much work. Easy to find via auto-complete.\t \t \r\nI can inspect the normalization coefficients of a normalizer in my pipeline without much work. Easy to find via auto-complete.\t \t \t \r\nI can inspect the trees of a boosted decision tree model without much work. Easy to find via auto-complete.\t \t \t \r\nI can inspect the topics after training an LDA transform. Easy to find via auto-complete.\t \t \t \r\nI can inspect a categorical transform and see which feature values map to which key values. Easy to find via auto-complete.\t \t \t \r\nP1: I can access the GAM feature histograms through APIs\r\n\r\nFixes: #2498 ","Url":"https://github.com/dotnet/machinelearning/pull/2859","RelatedDescription":"Closed or merged PR \"Add V1 Introspective Training Tests\" (#2859)"},{"Id":"418430258","IsPullRequest":true,"CreatedAt":"2019-03-07T19:10:20","Actor":"TomFinley","Number":"2878","RawContent":null,"Title":"Make array values intended to be immutable IReadOnlyList","State":"closed","Body":"Just a bit of relatively minor polish of something revealed during review of the public surface. In a handful of places we were returning arrays as values intended to be immutable. As elsewhere where perf isn't critical I've shifted to having the return value be `IReadOnlyList`. We've been doing this elsewhere but evidently missed a handful spots.\r\n\r\nIn an *ideal* world we'd make them actually immutable, as via `System.Collections.Immutable`, as I indeed did one or two places, but for the time being I think it suffices that we just make them read-only (even if the user could technically still muck with them with a cast, I'd consider fixing that problem later to be a non-breaking change in the API).\r\n\r\nI only undertook this review in the Core/Data/Transform assemblies.","Url":"https://github.com/dotnet/machinelearning/pull/2878","RelatedDescription":"Closed or merged PR \"Make array values intended to be immutable IReadOnlyList\" (#2878)"},{"Id":"418432912","IsPullRequest":false,"CreatedAt":"2019-03-07T17:39:15","Actor":"tauheedul","Number":"2879","RawContent":null,"Title":"Suggestion: Model Explainability Interpretability Visualization using Decision Tree Diagrams","State":"open","Body":"I previously logged an enhancement for #511 - \"Suggestion - Make Machine Learning Models explainable by design with ML.NET\". @rogancarr kindly broke down that request into separate new enhancements. \r\nhttps://github.com/dotnet/machinelearning/issues/511#issuecomment-448329385\r\n\r\nIn this enhancement, I am suggesting we add visualization of Machine Learning decisions using a Decision Tree within Visual Studio. Now that ML.NET supports Feature Importance (#599) this should be possible.\r\n\r\n**How it could be done.**\r\nI propose in the Visual Studio IDE Editor a new Model Visualization tab is added \r\n(Similar to the CPU Performance usage or a UML Class Diagram that shows how objects relate to each other)\r\n- The tab could show a graphical decision tree showing a path the algorithm took and why it did it\r\n- The decision tree could be derived from the feature importance metrics that are available within ML.NET\r\n- At each level of a tree, you could inspect the Data that contributed to it (an extension of IDataView?)\r\n\r\n **There have been similar issues logged, but my request is different from the following...**\r\n- Feature request: get reasons behind predictions made by Decision Trees #913\r\n- Is it possible to visualize a generated decision tree? #326\r\n- Pipeline visualization please #2478\r\n- Proof of concept for debugger visualization #847\r\n\r\n**Advanced Deep Learning Debugging / Explainability** \r\nAlso from the perspective of a Deep Learning model e.g. a TensorFlow or ONNX model, would it be possible to peek into the neural network nodes? (not only a high-level feature importance score but peek into what each node is doing e.g. you can view feature importance at each node level)\r\n\r\nIn the Visual Studio IDE we could have a Model with a tree of neurons (maybe thousands)... each neuron can be expanded and the evaluation of what each node is doing can be inspected.\r\n\r\nThis can open up the opportunity to allow developers to create custom graphing for visual feedback and monitor the progression of a decision in real-time.\r\n\r\nIt allows you to trace which neurons are fired in any given execution of the model and how a given set of data impacted the score and at what stage it changed.\r\n\r\n**Examples of how this can work**\r\n[Explaining Explanations: An Overview of Interpretability of Machine Learning](https://arxiv.org/abs/1806.00069)\r\n\r\n[Want To Simplify Neural Networks? Transform Them Into Decision Trees](https://www.analyticsindiamag.com/want-to-simplify-neural-networks-transform-them-into-decision-trees/)\r\n\r\n[\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)\r\n\r\n[A Brief History of Machine Learning Models Explainability](https://medium.com/@Zelros/a-brief-history-of-machine-learning-models-explainability-f1c3301be9dc)\r\n\r\n[Decision Trees — Understanding Explainable AI](https://towardsdatascience.com/decision-trees-understanding-explainable-ai-620fc37e598d)\r\n\r\n[How to Perform Explainable Machine Learning Classification — Without Any Trees](https://towardsdatascience.com/how-to-perform-explainable-machine-learning-classification-without-any-trees-873db4192c68)\r\n\r\n[AI for health care: tackling the issue of interpretability.](https://medium.com/@Pacmedhealth/ai-for-health-care-tackling-the-issue-of-interpretability-868be42aaf50)\r\n\r\n[What matters is what’s on the outside: model explainability using black box approaches](https://medium.com/james-blogs/what-matters-is-whats-on-the-outside-model-explainability-using-black-box-approaches-ee1c4e6d564f)\r\n\r\n[Explainable AI: P1 - The Importance of Human Interpretable Machine Learning](https://towardsdatascience.com/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476)\r\n\r\n[Explainable AI: P2 - Model Interpretation Strategies](https://towardsdatascience.com/explainable-artificial-intelligence-part-2-model-interpretation-strategies-75d4afa6b739)\r\n\r\n[Explainable AI: P3 - Hands-on Machine Learning Model Interpretation](https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608)\r\n\r\n[How to Explain the Prediction of a Machine Learning Model?](https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html)\r\n\r\n[Identifying and Correcting Label Bias in Machine Learning](https://towardsdatascience.com/identifying-and-correcting-label-bias-in-machine-learning-ed177d30349e)\r\n\r\n[Toward ethical, transparent and fair AI/ML: a critical reading list](https://medium.com/@eirinimalliaraki/toward-ethical-transparent-and-fair-ai-ml-a-critical-reading-list-d950e70a70ea)\r\n\r\nMichał Łopuszyński - Data Scientist, University of Warsaw has built up a list of excellent resources covering these topics \r\nhttps://github.com/lopusz/awesome-interpretable-machine-learning\r\n\r\nSandra Wachter discusses the benefits of offering counterfactual explanations that will be valuable to end users who are non-technical...\r\n[Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR](https://arxiv.org/abs/1711.00399)\r\n\r\ncc: @rustd @shauheen @Ivanidzo4ka","Url":"https://github.com/dotnet/machinelearning/issues/2879","RelatedDescription":"Open issue \"Suggestion: Model Explainability Interpretability Visualization using Decision Tree Diagrams\" (#2879)"},{"Id":"418034986","IsPullRequest":true,"CreatedAt":"2019-03-07T05:06:35","Actor":"Ivanidzo4ka","Number":"2872","RawContent":null,"Title":"ImageModels in tensorflow are 4 dimensional.","State":"closed","Body":"Fixes https://github.com/dotnet/machinelearning/issues/2778\r\nWell, not exactly fixes, it's more like a hack.\r\nProper solution would be to implement Reshape transform https://github.com/dotnet/machinelearning/issues/765","Url":"https://github.com/dotnet/machinelearning/pull/2872","RelatedDescription":"Closed or merged PR \"ImageModels in tensorflow are 4 dimensional.\" (#2872)"},{"Id":"418092547","IsPullRequest":true,"CreatedAt":"2019-03-07T01:57:59","Actor":"najeeb-kazmi","Number":"2875","RawContent":null,"Title":"Scrubbing image transforms","State":"open","Body":"Fixes #2833 ","Url":"https://github.com/dotnet/machinelearning/pull/2875","RelatedDescription":"Open PR \"Scrubbing image transforms\" (#2875)"},{"Id":"418035994","IsPullRequest":false,"CreatedAt":"2019-03-06T22:19:37","Actor":"wschin","Number":"2873","RawContent":null,"Title":"exampleWeightColumnName v.s. weightColumnName","State":"open","Body":"In trainers like\r\n```csharp\r\n        internal RandomizedPcaTrainer(IHostEnvironment env,\r\n            string features,\r\n            string weights = null,\r\n            string featureColumnName,\r\n            string exampleWeightColumnName = null,\r\n            int rank = Options.Defaults.NumComponents,\r\n            int oversampling = Options.Defaults.OversamplingParameters,\r\n            bool center = Options.Defaults.IsCenteredZeroMean,\r\n            bool ensureZeroMean = Options.Defaults.EnsureZeroMean,\r\n            int? seed = null)\r\n```\r\nwe have `exampleWeightColumnName` but it seems `weightColumnName` is clear enough under this context. Can we switch to `weightColumnName`?","Url":"https://github.com/dotnet/machinelearning/issues/2873","RelatedDescription":"Open issue \"exampleWeightColumnName v.s. weightColumnName\" (#2873)"},{"Id":"417946748","IsPullRequest":true,"CreatedAt":"2019-03-06T22:14:40","Actor":"TomFinley","Number":"2869","RawContent":null,"Title":"PFI statistics polish","State":"closed","Body":"Fixes 2868. Also contributes minorly towards #2445, by making the statistics classes (not the context extension methods) in the `Microsoft.ML.Data` namespace.","Url":"https://github.com/dotnet/machinelearning/pull/2869","RelatedDescription":"Closed or merged PR \"PFI statistics polish\" (#2869)"},{"Id":"417534131","IsPullRequest":true,"CreatedAt":"2019-03-06T21:10:39","Actor":"Ivanidzo4ka","Number":"2863","RawContent":null,"Title":"Scrubbing schema related transforms","State":"closed","Body":"Should fix https://github.com/dotnet/machinelearning/issues/2828","Url":"https://github.com/dotnet/machinelearning/pull/2863","RelatedDescription":"Closed or merged PR \"Scrubbing schema related transforms\" (#2863)"},{"Id":"417998372","IsPullRequest":false,"CreatedAt":"2019-03-06T20:38:28","Actor":"rogancarr","Number":"2871","RawContent":null,"Title":"NumberOfIterations vs. MaxIterations","State":"open","Body":"The recent naming changes to K-Means and SDCA (and perhaps others?) resulted in `MaxIterations` being renamed to `NumberOfIterations`. Since this parameter specifies the worst-case bound and not the actual number of iterations taken in most cases, I think we should keep it named `MaxIterations`. \r\n\r\nWhatever we call it, `NumberOfIterations` is not what this parameter specifies &mdash; this is a stopping criterion, not a guaranteed execution parameter.","Url":"https://github.com/dotnet/machinelearning/issues/2871","RelatedDescription":"Open issue \"NumberOfIterations vs. MaxIterations\" (#2871)"},{"Id":"417980422","IsPullRequest":false,"CreatedAt":"2019-03-06T19:52:36","Actor":"daholste","Number":"2870","RawContent":null,"Title":"Update default n-gram length for Text Transform to match default text recipe","State":"open","Body":"@justinormont and the text team tuned default n-gram lengths for the default text recipe in the internal repo\r\n\r\nThese defaults are:\r\nWord -- bigrams (w/ unigrams)\r\nCharacter -- trigrams (w/o unigrams and bigrams)\r\n\r\nOne chart from his findings:\r\n![image](https://user-images.githubusercontent.com/4080826/51941076-8c8d1b80-23c8-11e9-89d5-e30b42db39d0.png)\r\n\r\nThe line w/ the light blue call-out represents current ML.NET defaults (Unigram + Trichar)\r\nThe line w/ the light green call-out is the requested change (Bigram + Trichar)\r\nThe line w/ the pink call-out shows the Trigram+Trichar is better in terms of accuracy, but with a time hit, and accuracy has a cross over at NumIterations > 8 for Averaged Perceptron learner.","Url":"https://github.com/dotnet/machinelearning/issues/2870","RelatedDescription":"Open issue \"Update default n-gram length for Text Transform to match default text recipe\" (#2870)"},{"Id":"417946257","IsPullRequest":false,"CreatedAt":"2019-03-06T18:25:30","Actor":"TomFinley","Number":"2868","RawContent":null,"Title":"Further polishing of PFI statistics structures","State":"open","Body":"There are a couple problems with PFI public surface that should be resolved.\r\n\r\nThe statistics classes did not have their property names updated when the underlying metrics were themselves updated, for example, as seen here.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/adb53c41fd8c612df30f8d0213b7f459ef113724/src/Microsoft.ML.Transforms/PermutationFeatureImportanceExtensions.cs#L459-L463\r\n\r\nAlso, these statistics objects themselves exposed more of their infrastructure and workings than is necessary or helpful at this moment, for the purpose for which they are intended. (That is, exposing an abstract base class that is only necessary for internal usage, some protected members visible, being publicly instantiable, and all the usual problems.)","Url":"https://github.com/dotnet/machinelearning/issues/2868","RelatedDescription":"Open issue \"Further polishing of PFI statistics structures\" (#2868)"},{"Id":"417626434","IsPullRequest":true,"CreatedAt":"2019-03-06T05:14:21","Actor":"singlis","Number":"2867","RawContent":null,"Title":"Updating MKL","State":"open","Body":"- Updating ml.net to use mlnetDep nuget 0.0.0.9. This does a couple of things:\r\n1) Updates ML.Net to use MKL version 2008.3.10\r\n2) Enables OpenMP for MKL\r\n3) Project changes for handling the OpenMP library, note that we only copy this library on windows builds. Both Mac and Linux require this library to be installed.\r\n- Enables OpenMP for SymSGDNative\r\n- NumberOfThreads parameter now set the number of threads to use for SymSGDNative.\r\n\r\nThis related to issue #2211 ","Url":"https://github.com/dotnet/machinelearning/pull/2867","RelatedDescription":"Open PR \"Updating MKL\" (#2867)"},{"Id":"417582208","IsPullRequest":false,"CreatedAt":"2019-03-06T01:40:05","Actor":"yaeldekel","Number":"2866","RawContent":null,"Title":"Different behavior when calling Fit() on a transformer chain and on an IDataLoaderEstimator","State":"open","Body":"The following code runs without errors:\r\n\r\n```\r\n            var loader = ml.Data.CreateTextLoader<InputData>(hasHeader: true, dataSample: file);\r\n            var data = loader.Load(file);\r\n\r\n            // Pipeline.\r\n            var pipeline = ml.BinaryClassification.Trainers.GeneralizedAdditiveModels();\r\n\r\n            // Train.\r\n            var model = pipeline.Fit(data);\r\n```\r\nHowever, the following code fails with schema mismatch exception:\r\n```\r\n            var loader = ml.Data.CreateTextLoader<InputData>(hasHeader: true, dataSample: file);\r\n\r\n            // Define the same pipeline starting with the loader.\r\n            var pipeline = loader.Append(ml.BinaryClassification.Trainers.GeneralizedAdditiveModels());\r\n\r\n           // Train\r\n            var model = pipeline.Fit(file);\r\n```\r\n\r\nThis may also be related to issue #1969 .","Url":"https://github.com/dotnet/machinelearning/issues/2866","RelatedDescription":"Open issue \"Different behavior when calling Fit() on a transformer chain and on an IDataLoaderEstimator\" (#2866)"},{"Id":"417526216","IsPullRequest":true,"CreatedAt":"2019-03-05T22:45:52","Actor":"shauheen","Number":"2861","RawContent":null,"Title":"Update release for 0.11","State":"closed","Body":"Updating the 0.11 release","Url":"https://github.com/dotnet/machinelearning/pull/2861","RelatedDescription":"Closed or merged PR \"Update release for 0.11\" (#2861)"},{"Id":"417531477","IsPullRequest":true,"CreatedAt":"2019-03-05T22:28:31","Actor":"artidoro","Number":"2862","RawContent":null,"Title":"Scrubbing of the key related transforms","State":"open","Body":"Fixes #2829.\r\n\r\nRelated to the scrubbing tasks. I focus on the key related transforms in this PR.\r\n\r\nNote: in most places the following method is used by the estimator to get the the columns. I kept it but made it internal, despite Ivan suggested deleting it.\r\n\r\n```charp\r\ninternal IReadOnlyCollection<KeyToVectorMappingEstimator.ColumnOptions> Columns => _columns.AsReadOnly();\r\n```\r\n\r\nList of transforms:\r\n\r\n- MapKeyToBinaryVector\r\n- MapKeyToBinaryVector\r\n- MapKeyToVector\r\n- MapKeyToValue\r\n- MapValueToKey\r\n- ValueMap\r\n- OneHotEncoding\r\n- Hash\r\n- OneHotHash\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2862","RelatedDescription":"Open PR \"Scrubbing of the key related transforms\" (#2862)"},{"Id":"417501324","IsPullRequest":true,"CreatedAt":"2019-03-05T21:21:01","Actor":"shauheen","Number":"2860","RawContent":null,"Title":"Adding release notes for v0.11","State":"closed","Body":"Adding release notes","Url":"https://github.com/dotnet/machinelearning/pull/2860","RelatedDescription":"Closed or merged PR \"Adding release notes for v0.11\" (#2860)"},{"Id":"417488244","IsPullRequest":true,"CreatedAt":"2019-03-05T20:31:23","Actor":"yaeldekel","Number":"2858","RawContent":null,"Title":"Add save/load APIs for IDataLoader","State":"open","Body":"Fixes #2735.","Url":"https://github.com/dotnet/machinelearning/pull/2858","RelatedDescription":"Open PR \"Add save/load APIs for IDataLoader\" (#2858)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-03-08T05:30:35.3192752Z","RunDurationInMilliseconds":659}