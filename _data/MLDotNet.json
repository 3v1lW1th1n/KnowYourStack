{"Data":{"GitHub":{"Issues":[{"Id":"458305426","IsPullRequest":false,"CreatedAt":"2019-06-20T02:33:43","Actor":"magicdict","Number":"3889","RawContent":null,"Title":"How to set Chinese RemoveDefaultStopWords? ","State":"open","Body":"How to set Chinese RemoveDefaultStopWords? \r\nI Guess I can load a stop word list form a external file.","Url":"https://github.com/dotnet/machinelearning/issues/3889","RelatedDescription":"Open issue \"How to set Chinese RemoveDefaultStopWords? \" (#3889)"},{"Id":"458195107","IsPullRequest":false,"CreatedAt":"2019-06-19T19:46:46","Actor":"luisquintanilla","Number":"3888","RawContent":null,"Title":"exampleWeightColumnName parameter name and description may be confusing","State":"open","Body":"The purpose or use of this parameter may be confusing for users as to what the intent of it is based on the name and description. \r\n\r\n- It would be good to keep the name inline with the other column names (i.e. featureColumnName, labelColumnName). \r\n- Adding what type is expected by the column in the description would help as well (The column data must be Single). \r\n- Finally, it would help to describe the function of this parameter. Is this applying a weight to the individual observation, is it meant to set the initial weights of the features, or is it meant to set the importance of the features? To my knowledge this is to set the importance of the individual observation but clarification would help.\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: ca42bd00-b107-5a38-06c2-5b33e5e361fc\r\n* Version Independent ID: 9eceb504-86f7-3e71-7ddd-97e21254c026\r\n* Content: [StandardTrainersCatalog.Sdca Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.standardtrainerscatalog.sdca?view=ml-dotnet#feedback)\r\n* Content Source: [dotnet/xml/Microsoft.ML/StandardTrainersCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/StandardTrainersCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/3888","RelatedDescription":"Open issue \"exampleWeightColumnName parameter name and description may be confusing\" (#3888)"},{"Id":"458182738","IsPullRequest":false,"CreatedAt":"2019-06-19T19:15:26","Actor":"justinormont","Number":"3887","RawContent":null,"Title":"SymSGD IndexOutOfRangeException","State":"open","Body":"I get an error when using OVA-SymSGD on an internal dataset. Other learners, like SDCA and OVA-AveragedPerceptron work successfully (though LightGBM dies due to https://github.com/dotnet/machinelearning/issues/1625).\r\n\r\n## Error:\r\n```md\r\nException: System.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.Native.LearnAll(InputDataManager inputDataManager, Boolean tuneLR, Single& lr, Single l2Const, Single piw, Span`1 weightVector, Single& bias, Int32 numFeatres, Int32 numPasses, Int32 numThreads, Boolean tuneNumLocIter, Int32& numLocIter, Single tolerance, Boolean needShuffle, Boolean shouldInitialize, GCHandle stateGCHandle, ChannelCallBack info)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.OneVersusAllTrainer.TrainOne(IChannel ch, ITrainerEstimator`2 trainer, RoleMappedData data, Int32 cls)\r\n   at Microsoft.ML.Trainers.OneVersusAllTrainer.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, AutoMLLogger logger)\r\n```\r\n\r\n## Pipeline\r\nBelow is the same pipeline but using SDCA, which runs successfully.\r\n```C#\r\nvar dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(\"label_col\", \"label_col\")\r\n                  .Append(mlContext.Transforms.Categorical.OneHotEncoding(new[] { new InputOutputColumnPair(\"col1\", \"col1\"), new InputOutputColumnPair(\"col2\", \"col2\"), new InputOutputColumnPair(\"col3\", \"col3\"), new InputOutputColumnPair(\"col4\", \"col4\"), new InputOutputColumnPair(\"col5\", \"col5\") }))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(\"col6_tf\", \"col6\"))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(\"col7_tf\", \"col7\"))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(\"col8_tf\", \"col8\"))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(\"col9_tf\", \"col9\"))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(\"col10_tf\", \"col10\"))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(\"col11_tf\", \"col11\"))\r\n                  .Append(mlContext.Transforms.Text.FeaturizeText(\"col12_tf\", \"col12\"))\r\n                  .Append(mlContext.Transforms.Concatenate(\"Features\", new[] { \"col1\", \"col2\", \"col3\", \"col4\", \"col5\", \"col6_tf\", \"col7_tf\", \"col8_tf\", \"col9_tf\", \"col10_tf\", \"col11_tf\", \"col12_tf\", \"col13\", \"col14\", \"col15\", \"col16\", \"col17\", \"col18\", \"col19\", \"col20\", \"col21\" }))\r\n                  .Append(mlContext.Transforms.NormalizeMinMax(\"Features\", \"Features\"))\r\n                  .AppendCacheCheckpoint(mlContext);\r\n\r\n            // Set the training algorithm \r\n            var trainer = mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(labelColumnName: \"label_col\", featureColumnName: \"Features\")\r\n                  .Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\", \"PredictedLabel\"));\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3887","RelatedDescription":"Open issue \"SymSGD IndexOutOfRangeException\" (#3887)"},{"Id":"458151759","IsPullRequest":false,"CreatedAt":"2019-06-19T18:11:06","Actor":"CyberFranck","Number":"3886","RawContent":null,"Title":"Fit endlessly loop if code in a form","State":"open","Body":"I have create a small winform project. made a very basic SDCA regression for one property of an object. So far the code has been in the program.cs Main() method. Now i created an empty new form called Form1. There is no control yet and i just copied the code from the program.cs Main() directly into the Form1_Load().\r\n\r\nThe problem is that the code endless loop on the `IEstimator<ITransformer>.Fit(IDataView Input)`.\r\n\r\nin program.cs the code takes about 3 seconds to complete every single time and CPU reach about 75%. When it run from the form the code run indefinitely (longest i waited was 45 min while away on lunch break). Tried couple hundreds of time on 2 different PC and we both have the same issue. It never completes.\r\n\r\nI tried removing [STAThread] on the program.cs Main() just for the fun and the code still runs fine there so it's not necessary (anyway not for the Fit() method).","Url":"https://github.com/dotnet/machinelearning/issues/3886","RelatedDescription":"Open issue \"Fit endlessly loop if code in a form\" (#3886)"},{"Id":"458133705","IsPullRequest":false,"CreatedAt":"2019-06-19T17:25:44","Actor":"justinormont","Number":"3885","RawContent":null,"Title":"Rationalize Infinity handling in Normalizers","State":"open","Body":"A while back, I looked in to how can we handle values of Infinity & -Infinity in our normalizers. We should standardize the handling of +/- Infinity in our normalizers.\r\n\r\n## Background\r\nValues of Infinity are rather hard for users to handle as NAHandle ignores the Infinity & -Infinity values. I believe you would need a custom mapping transform to deal with these values.\r\n\r\nThe comes up in a dataset where I'm calculating pairwise features, eg: { x+y, x*y, x*y*y, x*e^y, ... }. I am overflowing into Infinity. This leads to FastTree ignoring rows, and SDCA dying w/ Infinite bias terms. \r\n\r\n## Summary\r\nMinMaxNormalizer+NAHandleTransform seems to be the best option to handle data values of ±Infinity. This option isn't perfect, as it is slow (causes an additional full pass of the data), and doubles your number of features.  \r\n\r\nCurrently, when a user applies normalization which replaces Infinity data values with NA we then silently skips rows. This is confusing to users and hard to debug.\r\n\r\n## Recommendation\r\nHave MinMaxNormalizer replace +/- Infinity w/ 0.00 (default on with a checkbox). \r\nThis will cause the (auto-applied) normalization to no longer replace Infinity with NA, which currently causes the learners to ignore the rows. \r\nModify the other normalization transforms to have consistent handling of Infinity data values.\r\n \r\n## Transforms' handling of Infinity\r\n\r\n**NAHandleTransform:**\r\nBad: Ignores Infinity (maps Infinity => Infinity). \r\nAll learners work, but some skip rows w/ Infinity\r\n\r\n \r\n\r\n**MinMaxNormalizer:**\r\nNot good: Replaces Infinity w/ NA. But this transform is recommended to add just before linear learners, which causes the learner to see NA, and drop the row (for either training or prediction). \r\nAll learners work, but skips rows w/ NA in it. \r\n\r\n \r\n\r\n**MeanVarNormalizer:**\r\nBad: Ignores Infinity (maps Infinity => Infinity), but normalizes the other numbers correctly. \r\nAll learners work, but some skip rows w/ Infinity in it.\r\n\r\n \r\n\r\n**LogMeanVarNormalizer:**\r\nGood: Replaces Infinity w/ 0. Could be better w/ an indicator column for the imputing. \r\nAll learners work. \r\n\r\n \r\n\r\n**BinNormalizer:**\r\nVery bad: Replaces Infinity w/ 1, but replaces all other values in the column w/ 0 also. Effectively wipes out the column. \r\n\r\nNo learners die, but the column is wiped out.\r\n\r\n \r\n\r\n**SupervisedBinNormalizer:**\r\nVery bad: Replaces Infinity w/ 0, but replaces all other values in the column w/ 0 also. Effectively wipes out the column. \r\n\r\nNo learners die, but the column is wiped out.\r\n\r\n \r\n\r\n**MinMaxNormalizer+NAHandleTransform:**\r\nVery good: Replaces Infinity w/ 0 (NA then 0), and also adds an indicator column for the imputing. Double the size of the feature column though and causes a full pass of the data (trainable transform).\r\n\r\nAll learners work great.\r\n\r\n------\r\n\r\nThe above analysis is on the internal version of ML.NET, but I don't expect there has been changes to the behavior. ","Url":"https://github.com/dotnet/machinelearning/issues/3885","RelatedDescription":"Open issue \"Rationalize Infinity handling in Normalizers\" (#3885)"},{"Id":"457887633","IsPullRequest":false,"CreatedAt":"2019-06-19T08:54:24","Actor":"magicdict","Number":"3884","RawContent":null,"Title":"How to set metric for lightgbm?","State":"open","Body":"I compare the python lightgbm and ml.net,some parm can't set.\r\n```python\r\nparams = {\r\n    \"boosting_type\": \"gbdt\",\r\n    \"objective\": \"binary\",\r\n    \"metric\": \"binary_logloss\",\r\n    \"num_leaves\": 32,\r\n    \"learning_rate\": 0.05,\r\n    \"feature_fraction\": 0.9,\r\n    \"bagging_fraction\": 0.8,\r\n    \"bagging_freq\": 5,\r\n    \"verbose\": 1,\r\n}\r\n```\r\nmetric is one of miss parm.\r\n\r\nBy the way,how to display the progress of training lightgbm at console like python?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3884","RelatedDescription":"Open issue \"How to set metric for lightgbm?\" (#3884)"},{"Id":"457885125","IsPullRequest":false,"CreatedAt":"2019-06-19T08:49:08","Actor":"siddusri1990","Number":"3883","RawContent":null,"Title":"Schema mismatch for label column '': expected Single, got Key<UInt32> Parameter name: labelCol","State":"open","Body":"I am trying to create my first ML regression model using ML.Net (.net core 2.1), getting above error message when fitting the pipeline with data view. Could you please help with correct solution. please find the code which I was trying, here I have to predict the Name result based on Name and Duplicate name values.\r\n public class FeatureData\r\n    {\r\n        [LoadColumn(3)]\r\n        public string Name;\r\n\r\n        [LoadColumn(20)]\r\n        public string DuplicateName;\r\n        [LoadColumn(31)]\r\n        public string NameResult;\r\n    }\r\n    public class LabelData\r\n    {\r\n        [ColumnName(\"Score\")]\r\n        public string NameResult;\r\n    }\r\n\r\n      IDataView dataView = mlContext.Data.LoadFromTextFile<FeatureData>(dataPath, hasHeader: true, separatorChar: ',',allowQuoting:true);\r\n   \r\n            var pipeline = mlContext.Transforms.CopyColumns(outputColumnName: \"Label\", inputColumnName: \"NameResult\")\r\n .Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"NameEncoded\", inputColumnName: \"Name\"))\r\n.Append(mlContext.Transforms.Categorical.OneHotEncoding(outputColumnName: \"DuplicateNameEncoded\", inputColumnName: \"DuplicateName\"))\r\n.Append(mlContext.Transforms.Concatenate(\"Features\", \"NameEncoded\", \"DuplicateNameEncoded\"))\r\n.Append(mlContext.Regression.Trainers.FastTree());\r\n\r\n            var model = pipeline.Fit(dataView); ///getting above error here","Url":"https://github.com/dotnet/machinelearning/issues/3883","RelatedDescription":"Open issue \"Schema mismatch for label column '': expected Single, got Key<UInt32> Parameter name: labelCol\" (#3883)"},{"Id":"457778085","IsPullRequest":true,"CreatedAt":"2019-06-19T02:37:40","Actor":"Dmitry-A","Number":"3882","RawContent":null,"Title":"[AutoML] bring AutoML API library to master","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3882","RelatedDescription":"Open PR \"[AutoML] bring AutoML API library to master\" (#3882)"},{"Id":"457749970","IsPullRequest":true,"CreatedAt":"2019-06-19T00:15:53","Actor":"wschin","Number":"3881","RawContent":null,"Title":"[WIP] ONNXTransform Upgrade to Enable Non-tensor Types","State":"open","Body":"The current ONNXTransform only operates on tensor types. As many ONNX models (especially classifiers) produce Seq<Map<T, float>> where T can be either int or string, we should remove that limitation.","Url":"https://github.com/dotnet/machinelearning/pull/3881","RelatedDescription":"Open PR \"[WIP] ONNXTransform Upgrade to Enable Non-tensor Types\" (#3881)"},{"Id":"457740736","IsPullRequest":true,"CreatedAt":"2019-06-18T23:33:26","Actor":"justinormont","Number":"3880","RawContent":null,"Title":"[WIP] Improve column purpose detection for sparse text datasets","State":"open","Body":"Fixes #3879 by not counting empty text values when calculating the column statistics.\r\n\r\nBackground from #3879:\r\n> AutoML does poorly on a few text datasets. For example, a text dataset we benchmark on has an accuracy of 0.60 vs. an expected accuracy of 0.85. \r\n> \r\n> This is caused by us detecting the text columns columns as **categorical** instead of **free text**. For the this dataset, this is due to the text column being 84% blank (a sparsely filled out column). \r\n> \r\n> **To fix:** \r\n> We need to detect the column purpose only on the set (non-blank) values.\r\n> \r\n> Recommend subtracting the blank values from `data.Count`:\r\n> https://github.com/dotnet/machinelearning/blob/227da9d7db2ce80b073cc64bfd067b04e6189de1/src/Microsoft.ML.AutoML/ColumnInference/PurposeInference.cs#L148-L158\r\n> \r\n> Currently `avgLength`, `cardinalityRatio`, `avgSpaces` are artificially lower due to the missing values.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3880","RelatedDescription":"Open PR \"[WIP] Improve column purpose detection for sparse text datasets\" (#3880)"},{"Id":"457736707","IsPullRequest":false,"CreatedAt":"2019-06-18T23:17:45","Actor":"justinormont","Number":"3879","RawContent":null,"Title":"Improving column purpose detection for sparse datasets","State":"open","Body":"AutoML does poorly on a few text datasets. For example, a text dataset we benchmark on has an accuracy of 0.60 vs. an expected accuracy of 0.85. \r\n\r\nThis is caused by us detecting the text columns columns as **categorical** instead of **free text**. For the this dataset, this is due to the text column being 84% blank (a sparsely filled out column). \r\n\r\n**To fix:** \r\nWe need to detect the column purpose only on the set (non-blank) values.\r\n\r\nRecommend subtracting the blank values from `data.Count`:\r\nhttps://github.com/dotnet/machinelearning/blob/227da9d7db2ce80b073cc64bfd067b04e6189de1/src/Microsoft.ML.AutoML/ColumnInference/PurposeInference.cs#L148-L158\r\n\r\nCurrently `avgLength`, `cardinalityRatio`, `avgSpaces` are artificially lower due to the missing values.","Url":"https://github.com/dotnet/machinelearning/issues/3879","RelatedDescription":"Open issue \"Improving column purpose detection for sparse datasets\" (#3879)"},{"Id":"457135941","IsPullRequest":true,"CreatedAt":"2019-06-18T21:18:15","Actor":"ganik","Number":"3873","RawContent":null,"Title":"[WIP] Repro for Timeseries  engine exception","State":"closed","Body":"Repro for Timeseries  engine exception.\r\n@codemzs  pls take a look\r\n\r\nthx","Url":"https://github.com/dotnet/machinelearning/pull/3873","RelatedDescription":"Closed or merged PR \"[WIP] Repro for Timeseries  engine exception\" (#3873)"},{"Id":"457658265","IsPullRequest":false,"CreatedAt":"2019-06-18T19:34:03","Actor":"yaeldekel","Number":"3878","RawContent":null,"Title":"Multiclass LightGBM bug","State":"open","Body":"LightGBM trainer has two non-readonly fields called `_numClass` and `_tlcNumClass`. The second one is used to determine the number of predictors in the OVA predictor. However, the value of `_tlcNumClass` is only updated once, so if `Fit` is called again on the same estimator, it might give the wrong number of classes.","Url":"https://github.com/dotnet/machinelearning/issues/3878","RelatedDescription":"Open issue \"Multiclass LightGBM bug\" (#3878)"},{"Id":"457223476","IsPullRequest":true,"CreatedAt":"2019-06-18T17:24:26","Actor":"codemzs","Number":"3875","RawContent":null,"Title":"Add bindings for RowImpl in time series SequentialTransformerBase","State":"closed","Body":"fixes #3874\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3875","RelatedDescription":"Closed or merged PR \"Add bindings for RowImpl in time series SequentialTransformerBase\" (#3875)"},{"Id":"457221787","IsPullRequest":false,"CreatedAt":"2019-06-18T17:24:26","Actor":"codemzs","Number":"3874","RawContent":null,"Title":"Time series Sequential Transform RowImpl needs to have a binding mechanism","State":"closed","Body":"We need to keep track of bindings when GetGetter is called in the case of DataTransformer, these bindings will be used to map column id to relative column id of the transformer.","Url":"https://github.com/dotnet/machinelearning/issues/3874","RelatedDescription":"Closed issue \"Time series Sequential Transform RowImpl needs to have a binding mechanism\" (#3874)"},{"Id":"457603180","IsPullRequest":false,"CreatedAt":"2019-06-18T17:20:40","Actor":"JomanjiPT","Number":"3877","RawContent":null,"Title":"DLL not found","State":"open","Body":"I have this problem : https://stackoverflow.com/questions/56654046/system-dllnotfoundexception-unable-to-load-dll-the-specified-module-could-not\r\n\r\nAnd I think that can be something related with a problem on this web API, or else I woudn't post here.","Url":"https://github.com/dotnet/machinelearning/issues/3877","RelatedDescription":"Open issue \"DLL not found\" (#3877)"},{"Id":"457564793","IsPullRequest":false,"CreatedAt":"2019-06-18T15:56:16","Actor":"konabuta","Number":"3876","RawContent":null,"Title":"Object reference not set to an instance of an object.","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 1903\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRun the following Examples with ONNX model from Azure Custom Vision service.\r\n\r\nhttps://docs.microsoft.com/ja-jp/dotnet/api/microsoft.ml.onnxcatalog.applyonnxmodel?view=ml-dotnet-preview#Microsoft_ML_OnnxCatalog_ApplyOnnxModel_Microsoft_ML_TransformsCatalog_System_String_System_Nullable_System_Int32__System_Boolean_\r\n\r\n- **What happened?**\r\nFailed in ApplyOnnxModel with the following message.\r\nObject reference not set to an instance of an object.\r\n\r\n\r\n### Source code / logs\r\n```cs\r\nusing System;\r\nusing System.Linq;\r\nusing System.IO;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\n\r\nnamespace Samples.Dynamic\r\n{\r\n    public static class ApplyOnnxModel\r\n    {\r\n        public static void Main()\r\n        {\r\n            string strCurDir = System.Environment.CurrentDirectory;\r\n            Console.WriteLine(strCurDir);\r\n            // Download the squeeznet image model from ONNX model zoo, version 1.2\r\n            // https://github.com/onnx/models/tree/master/squeezenet or use\r\n            // Microsoft.ML.Onnx.TestModels nuget.\r\n            var assetsRelativePath = @\"../../../squeezenet\";\r\n            string assetsPath = GetAbsolutePath(assetsRelativePath);\r\n\r\n            var modelPath = Path.Combine(assetsPath, \"catdog.onnx\");\r\n\r\n            // Create ML pipeline to score the data using OnnxScoringEstimator\r\n            var mlContext = new MLContext();\r\n\r\n            // Generate sample test data.\r\n            var samples = GetTensorData();\r\n            // Convert training data to IDataView, the general data type used in ML.NET.\r\n            var data = mlContext.Data.LoadFromEnumerable(samples);\r\n            // Create the pipeline to score using provided onnx model.\r\n            //var pipeline = mlContext.Transforms.ApplyOnnxModel(modelPath);\r\n            var pipeline = mlContext.Transforms.ApplyOnnxModel(\"classLabel\",\"data\", modelPath);\r\n            // Fit the pipeline and get the transformed values\r\n            var transformedValues = pipeline.Fit(data).Transform(data);\r\n            // Retrieve model scores into Prediction class\r\n            var predictions = mlContext.Data.CreateEnumerable<Prediction>(transformedValues, reuseRowObject: false);\r\n\r\n            // Iterate rows\r\n            foreach (var prediction in predictions)\r\n            {\r\n                int numClasses = 0;\r\n                foreach (var classScore in prediction.classLabel.Take(5))\r\n                {\r\n                    Console.WriteLine($\"Class #{numClasses++} score = {classScore}\");\r\n                }\r\n                Console.WriteLine(new string('-', 10));\r\n            }\r\n\r\n            // Results look like below...\r\n            // Class #0 score = 4.544065E-05\r\n            // Class #1 score = 0.003845858\r\n            // Class #2 score = 0.0001249467\r\n            // ----------\r\n            // Class #0 score = 4.491953E-05\r\n            // Class #1 score = 0.003848222\r\n            // Class #2 score = 0.0001245592\r\n            // ----------\r\n        }\r\n\r\n        // inputSize is the overall dimensions of the model input tensor.\r\n        private const int inputSize = 224 * 224 * 3;\r\n\r\n        // A class to hold sample tensor data. Member name should match  \r\n        // the inputs that the model expects (in this case, data_0)\r\n        public class TensorData\r\n        {\r\n            [VectorType(inputSize)]\r\n            public float[] data_0 { get; set; }\r\n        }\r\n\r\n        // Method to generate sample test data. Returns 2 sample rows.\r\n        public static TensorData[] GetTensorData()\r\n        {\r\n            // This can be any numerical data. Assume image pixel values.\r\n            var image1 = Enumerable.Range(0, inputSize).Select(x => (float)x / inputSize).ToArray();\r\n            var image2 = Enumerable.Range(0, inputSize).Select(x => (float)(x + 10000) / inputSize).ToArray();\r\n            return new TensorData[] { new TensorData() { data_0 = image1 }, new TensorData() { data_0 = image2 } };\r\n        }\r\n        public static string GetAbsolutePath(string relativePath)\r\n        {\r\n            FileInfo _dataRoot = new FileInfo(typeof(ApplyOnnxModel).Assembly.Location);\r\n            string assemblyFolderPath = _dataRoot.Directory.FullName;\r\n\r\n            string fullPath = Path.Combine(assemblyFolderPath, relativePath);\r\n\r\n            return fullPath;\r\n        }\r\n\r\n        // Class to contain the output values from the transformation.\r\n        // This model generates a vector of 1000 floats.\r\n        class Prediction\r\n        {\r\n            [VectorType(1000)]\r\n            //public float[] softmaxout_1 { get; set; }\r\n            public float[] classLabel { get; set; }\r\n\r\n        }\r\n    }\r\n}\r\n```\r\n[catdog.zip](https://github.com/dotnet/machinelearning/files/3302363/catdog.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3876","RelatedDescription":"Open issue \"Object reference not set to an instance of an object.\" (#3876)"},{"Id":"457098169","IsPullRequest":false,"CreatedAt":"2019-06-17T18:58:04","Actor":"prathyusha12345","Number":"3872","RawContent":null,"Title":"Got \"Bad allocation\" exception when training 10gb data on database using Light GBM trainer","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI am trying to create a sample on using large datasets on database. The dataset I have used is criteo dataset for URL click prediction. I have imported the file into local SQL database and the size of local database is around 10GB. \r\n\r\nI am using LightGBM to do Binary classification. While training the model I got the below exception. Is there any issue with LightGBM to train Large datasets?\r\n\r\n```\r\n[LightGBM] [Warning] bad allocation\r\n\r\nC:\\Program Files\\dotnet\\dotnet.exe (process 2692) exited with code -1073740791.\r\nPress any key to close this window . . .\r\n```\r\n![image](https://user-images.githubusercontent.com/22335043/59629020-c8feb100-90f6-11e9-8f75-04b204d75ac7.png)\r\n\r\n\r\n### Source code / logs\r\n\r\nThe dataset file is taken from here \\\\ct01\\data\\Criteo\\Spark\\day_0-23_withHeader.tsv\r\n\r\nThe source code is available here  https://github.com/prathyusha12345/machinelearning-samples/tree/SQLDbSample/samples/csharp/getting-started/LargeDatasetsInSqlServer\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3872","RelatedDescription":"Open issue \"Got \"Bad allocation\" exception when training 10gb data on database using Light GBM trainer\" (#3872)"},{"Id":"456834266","IsPullRequest":false,"CreatedAt":"2019-06-17T09:31:37","Actor":"LDWDev","Number":"3871","RawContent":null,"Title":"Randomised PCA anomaly detection not detecting anomalies","State":"open","Body":"### System information\r\n\r\nWindows 10, .NET Core 2.2 console app, VS2019\r\n\r\n### Issue\r\n\r\n# SETUP\r\n\r\nGood morning. I am encountering some issues with the RPCA trainer and was hoping someone could help me out here. I'm not really sure what I'm doing wrong but I am not getting the results I would expect.\r\n\r\nI've made a toy model to test out the ML.NET anomaly detection funtionality. I manufacture two random numbers for each data point, and call them gene one and gene two. They are constrained to lie in a particular range: gene one lies between .8 and .9, and gene two lies between .1 and .5. \r\n\r\nUsing a sample from this data (with the same seed each time),  I apply an RPCA pipeline. then I call fit, then transform the training data. \r\n\r\nI then make a gene entry with a ludicrous score (10000, 25000), and transform that to see where it lies. ML.Net claims this is not an anomaly.\r\n\r\n# PROBLEM\r\n\r\nI expect to see an anomaly. I've tried this with less silly values, more silly values, with or without all the available kinds of normalisation, and reducing the rank of the PCA trainer.\r\n\r\n# LOGS\r\n\r\nHere's the output of the program. It shows the score, whether data is an inlier, and the transform of the data points.\r\n\r\nHere's the pipeline:\r\n\r\n```\r\nvar rpcaProjection = ct.Transforms.Concatenate(\"Features\", \"GeneOneScore\", \"GeneTwoScore\")\r\n                  .Append(ct.Transforms.NormalizeMeanVariance(\"NormalisedFeatures\", \"Features\"))\r\n.Append(ct.AnomalyDetection.Trainers.RandomizedPca(featureColumnName: \"NormalisedFeatures\", rank: 2));\r\n```\r\n\r\nResults from transforming first 20 training data: Predicted, score, PCA co-ordinates\r\n\r\nTrue, 0.005851699, 0.7284454, 0.6617603\r\nTrue, 0.002783414, 1.028686, 0.7808771\r\nTrue, 0.004348077, 0.9824907, 1.543225\r\nTrue, 0.004398529, 1.021341, 0.510879\r\nTrue, 0.003683135, 1.005801, 1.091905\r\nFalse, NaN, 0.9997306, 1.01117\r\nTrue, 0.003618588, 1.004708, 0.8854353\r\nTrue, 0.004349507, 0.9971809, 1.588225\r\nTrue, 0.004412429, 1.018427, 0.4791145\r\nTrue, 0.003997049, 1.008593, 1.246756\r\nTrue, 0.004217377, 1.00574, 1.322197\r\nTrue, 0.004192073, 0.9794555, 1.412197\r\nTrue, 0.004289094, 1.019702, 1.569695\r\nTrue, 0.005468629, 1.021341, 1.083963\r\nTrue, 0.003488006, 1.007865, 0.7861712\r\nFalse, NaN, 1.025348, 0.9171998\r\nTrue, 0.004403637, 1.020734, 1.508814\r\nFalse, NaN, 0.9888039, 0.9224939\r\nTrue, 0.004757768, 1.009807, 0.8113181\r\nTrue, 0.004348857, 1.011143, 0.4394088\r\n\r\nResults from transforming the \"anomaly\": Predicted, score, PCA co-ordinates\r\nTrue, 0.006252703, **121407.6, 82720.04**\r\n\r\nI've put this repo on github here:\r\n\r\nhttps://github.com/LDWDev/MLWoes/blob/master/MLtestapp/Program.cs\r\n\r\nCould anyone point out what is going on here? I would not expect the score to be the value it is.\r\n\r\nDo I need to give the trainer anomalous data? Why does the scorer think such distant values should be considered 'normal'? I have had trouble finding useful documentation/tutorials on this.","Url":"https://github.com/dotnet/machinelearning/issues/3871","RelatedDescription":"Open issue \"Randomised PCA anomaly detection not detecting anomalies\" (#3871)"},{"Id":"455987251","IsPullRequest":false,"CreatedAt":"2019-06-13T22:54:47","Actor":"marcmm","Number":"3870","RawContent":null,"Title":"Need a way to predict a batch of examples in one call to Tensorflow","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .Net Core 2.1\r\n\r\n### Issue\r\n\r\n- **What did you do?** Using Tensorflow extension, there's no support to predict a batch of examples in one call to Tensorflow.\r\n- **What happened?** This functionality is not supported at this time.\r\n- **What did you expect?** It would be good to support this functionality to improve efficiency in model prediction.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3870","RelatedDescription":"Open issue \"Need a way to predict a batch of examples in one call to Tensorflow\" (#3870)"},{"Id":"455973386","IsPullRequest":false,"CreatedAt":"2019-06-13T22:06:36","Actor":"prathyusha12345","Number":"3869","RawContent":null,"Title":"Getting OutOfMemory exception while training model on large datasets in file","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI am trying to create a sample  https://github.com/dotnet/machinelearning-samples/pull/520 to train a model on large datasets that are stored in a **file**. I am using BinaryClassification trainer. While training the model I am getting the OutOfMemory exception at the Fit() method as shown below.\r\n\r\n var model = trainingPipeLine.Fit(trainTestData.TrainSet);           \r\n\r\n![image](https://user-images.githubusercontent.com/22335043/59470767-99496380-8ded-11e9-9adb-3eb9d1d3ea43.png)\r\n\r\ncomplete details of error \r\n\r\n```\r\nSystem.FormatException\r\n  HResult=0x80131537\r\n  Message=Parsing failed with an exception: Stream reading encountered exception\r\n  Source=Microsoft.ML.Data\r\n  StackTrace:\r\n   at Microsoft.ML.Data.TextLoader.Cursor.<ParseParallel>d__33.MoveNext()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.LinkedRowFilterCursorBase.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingTransformer.Train(IHostEnvironment env, IChannel ch, ColInfo[] infos, IDataView keyData, ColumnOptionsBase[] columns, IDataView trainingData, Boolean autoConvert)\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingTransformer..ctor(IHostEnvironment env, IDataView input, ColumnOptionsBase[] columns, IDataView keyData, Boolean autoConvert)\r\n   at Microsoft.ML.Transforms.ValueToKeyMappingEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Transforms.OneHotEncodingTransformer..ctor(ValueToKeyMappingEstimator term, IEstimator`1 toVector, IDataView input)\r\n   at Microsoft.ML.Transforms.OneHotEncodingEstimator.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at LargeDatasetsInSqlServer.Program.Main() in C:\\GitRepos\\Fork\\ML-samples\\ML-samples-LargeDataInFile\\samples\\csharp\\getting-started\\LargeDatasetsInFile\\LargeDatasetsInFile\\Program.cs:line 107\r\n\r\nInner Exception 1:\r\nFormatException: Stream reading encountered exception\r\n\r\nInner Exception 2:\r\nOutOfMemoryException: Insufficient memory to continue the execution of the program.\r\n\r\n\r\n```\r\nThe data set is copied from shared folder **\\\\ct01\\data\\Criteo\\Spark\\day_0_withHeader.tsv**.\r\n\r\n### Source code / logs\r\n\r\nPlease find the entire source code from the  https://github.com/prathyusha12345/machinelearning-samples/tree/LargeDatasetsInFile/samples/csharp/getting-started/LargeDatasetsInFile\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3869","RelatedDescription":"Open issue \"Getting OutOfMemory exception while training model on large datasets in file\" (#3869)"},{"Id":"455967713","IsPullRequest":false,"CreatedAt":"2019-06-13T21:54:59","Actor":"prathyusha12345","Number":"3868","RawContent":null,"Title":"Training 10gb of data in local SQL database is taking more than 14 hours","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n\r\n\r\n### Issue\r\n\r\nI tried to create  a sample  https://github.com/dotnet/machinelearning-samples/pull/498 to train data stored in local sql database. I tried to execute the sample . The training is not at all completing. I have started executing the sample since **14 hours** back. The model sis till showing as training.\r\n\r\nI wonder how long this training takes to execute 10gb of data. The data base contains 32 millions of records.\r\n\r\nI have copied the file from shared location \\\\ct01\\data\\Criteo\\Spark\\day_0_withHeader.tsv. The actual file size is of **42 gb**. I imported the file manually into local SQL database which can have around **10gb** of data.\r\n\r\nCould anyone please let me know how long do I/user need to wait to train 10gb of data? I wanted to see when it will complete training.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3868","RelatedDescription":"Closed issue \"Training 10gb of data in local SQL database is taking more than 14 hours\" (#3868)"},{"Id":"455945890","IsPullRequest":false,"CreatedAt":"2019-06-13T20:48:27","Actor":"benavidezb","Number":"3867","RawContent":null,"Title":"Nonlinear Regression with Custom Target Function","State":"open","Body":"Is there a nonlinear regression or curve fitting class that supports custom functions of at least two independent variables and at least 5 parameters?\r\n\r\nI have a nonlinear regression problem that I need to solve using C#. I have a transfer function defined as:\r\n\r\nZ = A+1/(1/(X/256*B+3*C)+1/(Y/1024*D+2*E))\r\n\r\nWhere X and Y are my independent variables, Z is the output data I have to train from, and A-E are the parameters I need to the regression technique to solve. I have initial guesses for these parameters:\r\n\r\nA = 20\r\n\r\nB = 10000\r\n\r\nC = 50\r\n\r\nD = 50000\r\n\r\nE = 60\r\n\r\nI don't want to use generic regression models to estimate Z as I am specifically using the estimated parameters later on in the program. Any help would be greatly appreciated.","Url":"https://github.com/dotnet/machinelearning/issues/3867","RelatedDescription":"Open issue \"Nonlinear Regression with Custom Target Function\" (#3867)"},{"Id":"455509069","IsPullRequest":true,"CreatedAt":"2019-06-13T20:40:27","Actor":"Dmitry-A","Number":"3860","RawContent":null,"Title":"[AutoML] add task agnostic wrappers for autofit calls","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3860","RelatedDescription":"Closed or merged PR \"[AutoML] add task agnostic wrappers for autofit calls\" (#3860)"},{"Id":"455876099","IsPullRequest":false,"CreatedAt":"2019-06-13T17:55:55","Actor":"CESARDELATORRE","Number":"3866","RawContent":null,"Title":"Document what's supported in \"ONNX-ML.NET\"","State":"open","Body":"@wschin, @codemzs \r\nRelated to ONNX. Can we have documented what is supported when using ONNX from ML.NET? - Either for both scenarios: 1. Export/convert model scenario and 2. Load ONNX model scenario.\r\n\r\nFor instance:\r\n\r\n- 1. When exporting ML.NET models to ONNX with [ConvertToOnnx()](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.onnxexportextensions.converttoonnx?view=ml-dotnet-preview), will any type of ML.NET model work as ONNX model executed later on by the ONNX runtime from any other framework? **In ML.NET preview versions only certain ML.NET models could be exported to the ONNX-ML format. Is that still the case?** \r\n\r\n- 2. Can any type of loaded ONNX model run on ML.NET?\r\n\r\nFor instance, in the reference for [ConvertToOnnx()](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.onnxexportextensions.converttoonnx?view=ml-dotnet-preview) it doesn't say what's supported and what's not.\r\n\r\n**Do we have any documentation stating what's supported and what's not supported in \"ONNX-ML.NET\"?**\r\n\r\nIn addition to that, performance/accuracy comparison should also be covered due to issues like this:\r\n[ONNX Exports are Lossy](https://github.com/dotnet/machinelearning/issues/3206)","Url":"https://github.com/dotnet/machinelearning/issues/3866","RelatedDescription":"Open issue \"Document what's supported in \"ONNX-ML.NET\"\" (#3866)"},{"Id":"455846204","IsPullRequest":false,"CreatedAt":"2019-06-13T16:47:08","Actor":"codemzs","Number":"3865","RawContent":null,"Title":"Sanity check APIs from Microsoft.ML.OnnxTransfomer nuget","State":"open","Body":"We plan to GA Microsoft.ML.OnnxTransfomer nuget in 1.2 release. We must do a final pass over the public API surface and ensure we only exposing relevant APIs.","Url":"https://github.com/dotnet/machinelearning/issues/3865","RelatedDescription":"Open issue \"Sanity check APIs from Microsoft.ML.OnnxTransfomer nuget\" (#3865)"},{"Id":"455844908","IsPullRequest":false,"CreatedAt":"2019-06-13T16:43:58","Actor":"codemzs","Number":"3864","RawContent":null,"Title":"Sanity check APIs from Microsoft.ML.TimeSeries nuget","State":"open","Body":"We plan to GA Microsoft.ML.TimeSeries nuget in 1.2 release. We must do a final pass over the public API surface and ensure we only exposing relevant APIs.","Url":"https://github.com/dotnet/machinelearning/issues/3864","RelatedDescription":"Open issue \"Sanity check APIs from Microsoft.ML.TimeSeries nuget\" (#3864)"},{"Id":"455843842","IsPullRequest":false,"CreatedAt":"2019-06-13T16:41:26","Actor":"codemzs","Number":"3863","RawContent":null,"Title":"Sanity check APIs from Microsoft.ML.Tensorflow nuget","State":"open","Body":"We plan to GA Microsoft.ML.Tensorflow nuget in 1.2 release. Lets do a final pass on the binary and make sure we are only exposing relevant API.","Url":"https://github.com/dotnet/machinelearning/issues/3863","RelatedDescription":"Open issue \"Sanity check APIs from Microsoft.ML.Tensorflow nuget\" (#3863)"},{"Id":"455842337","IsPullRequest":false,"CreatedAt":"2019-06-13T16:38:02","Actor":"codemzs","Number":"3862","RawContent":null,"Title":"Conform time series forecasting API to estimator standards","State":"open","Body":"Currently time series forecasting framework and API is a standalone entity. We must change that to be an estimator so that it fit seamlessly into the training pipeline. Do the following:\r\n\r\n1) Make SSA forecasting an estimator API.\r\n2) Create a fit(Idataview) that is used for training the forecasting model.\r\n3) Create a fit(IDataView, SSAModel) that is used for updating the forecasting model from a column in the IDataView\r\n4) Create a Transform(IDataView) that forecasts values up a horizon that is read from a column-row in the IDataView. Here forecasted values are represented as a variable sized vector in the column.\r\n5) Create a Transform() that forecasts values as a new IDataView where each forecasted value is its own row.\r\n\r\nCC: @ganik @artidoro @yaeldekel @CESARDELATORRE @eerhardt ","Url":"https://github.com/dotnet/machinelearning/issues/3862","RelatedDescription":"Open issue \"Conform time series forecasting API to estimator standards\" (#3862)"},{"Id":"455830927","IsPullRequest":false,"CreatedAt":"2019-06-13T16:12:13","Actor":"ebizupnorth","Number":"3861","RawContent":null,"Title":"Feature: A dropdown list to choose what OptimizingMetric to use in AutoML GUI","State":"open","Body":"It would be better if there is an option to choose what OptimizingMetric to use when using the AutoML GUI during training.\r\n\r\nThanks for this amazing AutoML.","Url":"https://github.com/dotnet/machinelearning/issues/3861","RelatedDescription":"Open issue \"Feature: A dropdown list to choose what OptimizingMetric to use in AutoML GUI\" (#3861)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-06-20T05:30:41.1512186Z","RunDurationInMilliseconds":950}