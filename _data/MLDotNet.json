{"Data":{"GitHub":{"Issues":[{"Id":"419017008","IsPullRequest":true,"CreatedAt":"2019-03-09T01:23:55","Actor":"rogancarr","Number":"2899","RawContent":null,"Title":"Create model file V1 scenario tests","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Model Files functionality we want fully supported in V1.\r\n\r\nThis PR adds tests for the following scenarios:\r\n\r\n* I can train a model and save it as a file. This model includes the learner as well as the transforms\r\n* I can use a model file in a completely different process to make predictions\r\n* I can easily figure out which NuGets (and versions) I need to score an ML.NET model\r\n* I can export ML.NET models to ONNX (limited to the existing internal functionality)\r\n\r\nFixes #2896 ","Url":"https://github.com/dotnet/machinelearning/pull/2899","RelatedDescription":"Open PR \"Create model file V1 scenario tests\" (#2899)"},{"Id":"419014212","IsPullRequest":true,"CreatedAt":"2019-03-09T01:02:21","Actor":"wschin","Number":"2898","RawContent":null,"Title":"Scrub n-gram hashing and n-gram","State":"open","Body":"One step closer to #2832. This PR only polishes NgramHashingTransform.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2898","RelatedDescription":"Open PR \"Scrub n-gram hashing and n-gram\" (#2898)"},{"Id":"418963554","IsPullRequest":true,"CreatedAt":"2019-03-09T00:59:50","Actor":"rogancarr","Number":"2894","RawContent":null,"Title":"Renaming IterationsToRemember to HistorySize for L-BFGS learners.","State":"closed","Body":"This PR renames the L-BFGS parameter `IterationsToRemember` to `HistorySize` to be more in line with the common nomenclature. (Previously it was `MemorySize`.)\r\n\r\nFixes #2882 ","Url":"https://github.com/dotnet/machinelearning/pull/2894","RelatedDescription":"Closed or merged PR \"Renaming IterationsToRemember to HistorySize for L-BFGS learners.\" (#2894)"},{"Id":"418499835","IsPullRequest":false,"CreatedAt":"2019-03-09T00:59:50","Actor":"rogancarr","Number":"2882","RawContent":null,"Title":"Non-standard naming in L-BFGS Learners (LogisticRegression, PoissonRegression)","State":"closed","Body":"In `LogisticRegression` and `PoissonRegression` (which use the same L-BFGS base), we have a parameter `IterationsToRemember` that refers to the number of gradients to accumulate in the history. While this terminology makes sense, it's not what we usually encounter in the field.\r\n\r\nIn the literature, we see this referred to as the \"history size\" (see e.g. [wikipedia](https://en.wikipedia.org/wiki/Limited-memory_BFGS)).\r\n\r\nIn the various toolkits that expose an L-BFGS solver, they use:\r\nScikit Learn: Doesn't expose it.\r\nSpark: [NumberOfCorrections](https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/mllib/optimization/LBFGS.html)\r\nTensorFlow: [num_correction_pairs](https://www.tensorflow.org/probability/api_docs/python/tfp/optimizer/lbfgs_minimize)\r\nPyTorch: [history_size](https://pytorch.org/docs/stable/_modules/torch/optim/lbfgs.html)\r\n\r\nI would vote for `HistorySize`, with the docs explaining what it is.\r\n\r\nWhat do you all think? Any big feelings around this?","Url":"https://github.com/dotnet/machinelearning/issues/2882","RelatedDescription":"Closed issue \"Non-standard naming in L-BFGS Learners (LogisticRegression, PoissonRegression)\" (#2882)"},{"Id":"419009750","IsPullRequest":false,"CreatedAt":"2019-03-09T00:34:14","Actor":"rogancarr","Number":"2897","RawContent":null,"Title":"Two Ways to Save a Model","State":"open","Body":"The current API has two ways to save a model:\r\n\r\n```cs\r\nmodel.SaveTo(MlContext, stream);\r\nmlContext.Model.Save(ITransformer, stream);\r\n```\r\n\r\nDo we just want one of these?\r\n\r\nMaybe related to #2735 ","Url":"https://github.com/dotnet/machinelearning/issues/2897","RelatedDescription":"Open issue \"Two Ways to Save a Model\" (#2897)"},{"Id":"419007474","IsPullRequest":false,"CreatedAt":"2019-03-09T00:21:45","Actor":"rogancarr","Number":"2896","RawContent":null,"Title":"Create functional tests for all Model Files scenarios","State":"open","Body":"As laid out in #2498 , we need scenarios to cover the Model Files functionality we want fully supported in V1.\r\n\r\nDefinitely need for V1\r\n- I can train a model and save it as a file. This model includes the learner as well as the transforms\r\n- I can use a model file in a completely different process to make predictions \r\n- I can easily figure out which NuGets (and versions) I need to score an ML.NET model \r\n- I can export ML.NET models to ONNX (limited to the existing internal functionality)\r\n\r\nMay not need for now:\r\n- I can save a model to text \r\n- I can use newer versions of ML.NET with ML.NET model files of previous versions (for v1.x)\r\n- I can use model files interchangeably between compatible versions of ML.NET and NimbusML\r\n- I can move data between NimbusML and ML.NET (using IDV). Prepare with NimbusML and load with ML.NET","Url":"https://github.com/dotnet/machinelearning/issues/2896","RelatedDescription":"Open issue \"Create functional tests for all Model Files scenarios\" (#2896)"},{"Id":"419005311","IsPullRequest":false,"CreatedAt":"2019-03-09T00:09:37","Actor":"zeahmed","Number":"2895","RawContent":null,"Title":"Discrepancy in NgramExtractorTrasform, NgramExtractingTransformer and NgramExtractingEstimator.","State":"open","Body":"If you search for `NgramExtract` in the solution, the following three main classes pop up.\r\n\r\n1. NgramExtractorTransform (in WordBagTransform.cs)\r\n2. NgramExtractingTransformer (in NgramTransform.cs)\r\n3. NgramExtractingEstimator (in NgramTrasnform.cs)\r\n\r\n`2` and `3` seem to be the actual classes where ngram extraction logic is written. However, `1` uses `2` and `3` with a pre-processing step where if input is text it is first converted to terms using ValueToKeyMappingTransformer.\r\n\r\nFirst, `NgramExtractorTransform` does not seem to be in correct file i.e filename and class name do not match.\r\nSecond, the `NgramExtractorTransform` is not doing ngram extraction instead composing two different estimators (NgramExtractingEstimator and ValueToKeyMappingEstimator).\r\n\r\nI think `NgramExtractorTransform` be renamed to `WordBagTransform` or something appropirate.\r\n\r\nCC: @Ivanidzo4ka, @TomFinley, @sfilipi, @rogancarr.","Url":"https://github.com/dotnet/machinelearning/issues/2895","RelatedDescription":"Open issue \"Discrepancy in NgramExtractorTrasform, NgramExtractingTransformer and NgramExtractingEstimator.\" (#2895)"},{"Id":"418952994","IsPullRequest":true,"CreatedAt":"2019-03-08T20:51:56","Actor":"artidoro","Number":"2893","RawContent":null,"Title":"WIP: Refactoring of ColumnOptions for ImagePixelExtractor","State":"open","Body":"Related to #2884.\r\n\r\nThe change does the following things:\r\n1. Internalizes the immutable class `ColumnInfos` and moves it to the transformer\r\n2. Exposes the previously named `Column` class and renames it `ColumnOptions`\r\n3. Internalizes entrypoint only fields in `ColumnOptions`, renames those that did not match the public API\r\n4. Refactored the constructor so that it takes the new `ColumnOptions` class\r\n\r\n\r\nThe overall behavior of the Estimator/Transformer API is unchanged (besides the use of the new mutable class).\r\nHowever, this change alters the entrypoints API behavior in the following way.\r\nPast behavior:\r\n- Can set column specific options.\r\n- Can set overall options for all columns\r\n- Can set overall options for some column and column specific options for others. \r\n\r\nAfter this change: \r\n- Can set column specific options.\r\n- Can set overall options for all columns\r\n\r\nI would also like to change the name of the input and output columns (in `SourceNameColumnBase`) to something more appropriate than `Name` and `Source`, but since that will touch a lot of files, I would like some feedback on the approach first. ","Url":"https://github.com/dotnet/machinelearning/pull/2893","RelatedDescription":"Open PR \"WIP: Refactoring of ColumnOptions for ImagePixelExtractor\" (#2893)"},{"Id":"418947219","IsPullRequest":true,"CreatedAt":"2019-03-08T20:33:36","Actor":"Ivanidzo4ka","Number":"2892","RawContent":null,"Title":"Scrubbing online learners","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/2892","RelatedDescription":"Open PR \"Scrubbing online learners\" (#2892)"},{"Id":"418925097","IsPullRequest":true,"CreatedAt":"2019-03-08T19:28:39","Actor":"wschin","Number":"2891","RawContent":null,"Title":"Scrub word embedding transform","State":"open","Body":"Toward #2832. This PR only contains renaming and internalizes a function,\r\n```\r\n-        public IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n+        private IReadOnlyCollection<(string outputColumnName, string inputColumnName)> Columns => ColumnPairs.AsReadOnly();\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2891","RelatedDescription":"Open PR \"Scrub word embedding transform\" (#2891)"},{"Id":"418917603","IsPullRequest":true,"CreatedAt":"2019-03-08T19:07:05","Actor":"wschin","Number":"2890","RawContent":null,"Title":"Scrub Latent Dirichlet Allocation Transform (Just Renaming)","State":"open","Body":"Toward #2832. This PR handles Latent Dirichlet Allocation.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2890","RelatedDescription":"Open PR \"Scrub Latent Dirichlet Allocation Transform (Just Renaming)\" (#2890)"},{"Id":"418889778","IsPullRequest":true,"CreatedAt":"2019-03-08T19:03:38","Actor":"shauheen","Number":"2889","RawContent":null,"Title":"Temporarily disable myget","State":"closed","Body":"fixes #2244  AGAIN!","Url":"https://github.com/dotnet/machinelearning/pull/2889","RelatedDescription":"Closed or merged PR \"Temporarily disable myget\" (#2889)"},{"Id":"418502584","IsPullRequest":true,"CreatedAt":"2019-03-08T17:23:39","Actor":"rogancarr","Number":"2883","RawContent":null,"Title":"Specify MaxNumberOfIterations for SDCA, K-Means","State":"closed","Body":"This PR updates SDCA and K-Means to specify `MaximumNumberOfIterations` rather than `NumberOfIterations` to make the name more precise. Essentially, for these learners, the maximum number of iterations is a worst-case scenario and a last-resort stopping criteria.\r\n\r\nFixes #2871\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2883","RelatedDescription":"Closed or merged PR \"Specify MaxNumberOfIterations for SDCA, K-Means\" (#2883)"},{"Id":"417998372","IsPullRequest":false,"CreatedAt":"2019-03-08T17:23:39","Actor":"rogancarr","Number":"2871","RawContent":null,"Title":"NumberOfIterations vs. MaxIterations","State":"closed","Body":"The recent naming changes to K-Means and SDCA (and perhaps others?) resulted in `MaxIterations` being renamed to `NumberOfIterations`. Since this parameter specifies the worst-case bound and not the actual number of iterations taken in most cases, I think we should keep it named `MaxIterations`. \r\n\r\nWhatever we call it, `NumberOfIterations` is not what this parameter specifies &mdash; this is a stopping criterion, not a guaranteed execution parameter.","Url":"https://github.com/dotnet/machinelearning/issues/2871","RelatedDescription":"Closed issue \"NumberOfIterations vs. MaxIterations\" (#2871)"},{"Id":"418545439","IsPullRequest":true,"CreatedAt":"2019-03-08T16:27:51","Actor":"sfilipi","Number":"2885","RawContent":null,"Title":"Main namespace types2445","State":"closed","Body":"Towards #2445. \r\n\r\nIn the first commit IHost and related moves to Microsoft.ML.Runtime\r\nIDataFile moves to Microsoft.ML.Data\r\nLoss related functionality moves to Microsoft.ML.Trainers. \r\n\r\nThird commit is making it build. \r\nProcedure:\r\nUse VisualStudio Find/Replace all to replace:\r\n1- `using System;`  -> `using System; using Microsoft.ML.Runtime;`\r\n2- `using Microsoft.Data.DataView;`  -> `using Microsoft.Data.DataView; using Microsoft.ML.Runtime;`\r\n3- `using Microsoft.ML.Data;`  -> `using Microsoft.ML.Data; using Microsoft.ML.Runtime;`\r\n\r\nThinking that the above would touch most cs files. \r\nManually spot fixed the references in the .tt files, and the references to loss related changes, and IDataFile changes. \r\n\r\nI used the [format all files](https://marketplace.visualstudio.com/items?itemName=munyabe.FormatAllFiles) vs extension to order/align/remove dead usings. \r\n\r\nthrough spot-checking I noticed that the tool had converted some variables to readonly, and has remove explicit casts in some points, so i .. reviewed all files of the src folder and reverted those two types of changes. So i kept the using changes for 95% of the files, and some white-space fixes in about 5% of the files. \r\n\r\nAll tests passed locally on windows x64","Url":"https://github.com/dotnet/machinelearning/pull/2885","RelatedDescription":"Closed or merged PR \"Main namespace types2445\" (#2885)"},{"Id":"418645228","IsPullRequest":true,"CreatedAt":"2019-03-08T06:04:54","Actor":"wschin","Number":"2888","RawContent":null,"Title":"More Normalizer Scrubbing (Just Renaming)","State":"open","Body":"Follow up of #2865. Some public APIs were missed.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2888","RelatedDescription":"Open PR \"More Normalizer Scrubbing (Just Renaming)\" (#2888)"},{"Id":"418578227","IsPullRequest":true,"CreatedAt":"2019-03-08T00:32:08","Actor":"ganik","Number":"2887","RawContent":null,"Title":"Update Readme to fix code sample","State":"open","Body":"fixes #2565 ","Url":"https://github.com/dotnet/machinelearning/pull/2887","RelatedDescription":"Open PR \"Update Readme to fix code sample\" (#2887)"},{"Id":"418128219","IsPullRequest":true,"CreatedAt":"2019-03-08T00:03:00","Actor":"artidoro","Number":"2876","RawContent":null,"Title":"Scrubbing task: rest of transforms","State":"closed","Body":"Fixes: #2835.\r\n\r\nThis PR does the scrubbing for the following transforms:\r\n\r\n- ReplaceMissingValues\r\n- IndicateMissingValues\r\n- CustomMapping\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2876","RelatedDescription":"Closed or merged PR \"Scrubbing task: rest of transforms\" (#2876)"},{"Id":"418564732","IsPullRequest":true,"CreatedAt":"2019-03-07T23:35:52","Actor":"shmoradims","Number":"2886","RawContent":null,"Title":"Cleaned LightGBM documentation","State":"open","Body":"LightGBM API, trainers, boosters, and options documentation. Part of #2522.\r\nSource of documentation are:\r\n* https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst\r\n* https://lightgbm.readthedocs.io/en/latest/Parameters.html\r\n* ML.NET source code","Url":"https://github.com/dotnet/machinelearning/pull/2886","RelatedDescription":"Open PR \"Cleaned LightGBM documentation\" (#2886)"},{"Id":"418483397","IsPullRequest":true,"CreatedAt":"2019-03-07T21:59:11","Actor":"rogancarr","Number":"2880","RawContent":null,"Title":"Update TreeTrainersCatalog to use standard parameter names","State":"closed","Body":"This PR updates the `TreeTrainerCatalog` to use standard parameter names (e.g. `numTrees` => `numberOfTrees`).\r\n\r\nFixes #2877 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/2880","RelatedDescription":"Closed or merged PR \"Update TreeTrainersCatalog to use standard parameter names\" (#2880)"},{"Id":"418429070","IsPullRequest":false,"CreatedAt":"2019-03-07T21:59:11","Actor":"rogancarr","Number":"2877","RawContent":null,"Title":"FastForest catalog arguments haven't been scrubbed","State":"closed","Body":"The FastForest `options` has been scrubbed, but the catalog arguments still have the old names. This is a reminder issue to go back and fix that at some point.","Url":"https://github.com/dotnet/machinelearning/issues/2877","RelatedDescription":"Closed issue \"FastForest catalog arguments haven't been scrubbed\" (#2877)"},{"Id":"418522569","IsPullRequest":false,"CreatedAt":"2019-03-07T21:31:43","Actor":"TomFinley","Number":"2884","RawContent":null,"Title":"Discussion: ColumnOptions actually a good name?","State":"open","Body":"In #2878, @eerhardt had a comment that we should consider, the gist of which was, since all of our `Options` classes have mutable properties, is it appropriate for `ColumnOptions` to be called this, since they are not and often cannot be mutable? We also have issue #2854 where @rogancarr thought he couldn't get normalization information out of the structure since it was named options, so this is not actually as academic an issue than I might have thought, say, a few days ago.\r\n\r\nThe approach taken in #2709 was that these structures created for configuration of the per-column options should be called options, and that it was (apparently) assumed to be irrelevant whether those items were mutable or not. Now, I'm not saying we should revert that PR necessarily, but it is something to consider, since it seems to be confusing people.\r\n\r\nNow then, the structures themselves obviously must not be mutable, since they are often the same structures used in the associated estimators and transformers to project schema, e.g., here it is for the n-gram hashing estimator:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a5580108d6171ae8dfa5ba60210dc2d88c9dec75/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L1077\r\n\r\nHere it is in the transformer:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/a5580108d6171ae8dfa5ba60210dc2d88c9dec75/src/Microsoft.ML.Transforms/Text/NgramHashingTransformer.cs#L1077\r\n\r\nSo, just something to think about, whether it was in fact a good idea for this thing to be called \"options\" really, in all the cases we named it options. Maybe we could have a refinement on the policy of naming this thing? Or maybe we decide to just live with it, because the confusion of calling all these things \"options\" vs. \"info\" vs. \"whatever\" is greater than this inconsistency in roles?\r\n\r\nI'm fine with leaving it as is, but I do see some confusion so I think we should think about it, and at least formulate a psoition.\r\n\r\n/cc @eerhardt and @rogancarr and @sfilipi and @artidoro ...","Url":"https://github.com/dotnet/machinelearning/issues/2884","RelatedDescription":"Open issue \"Discussion: ColumnOptions actually a good name?\" (#2884)"},{"Id":"418053060","IsPullRequest":true,"CreatedAt":"2019-03-07T21:28:21","Actor":"singlis","Number":"2874","RawContent":null,"Title":"mlnetmkldeps nuget package updates","State":"closed","Body":"Related to changes for updating mlnetmkldeps nuget package, issue #2211.\r\n - Updates to the nuspec file\r\n - Updates to the instructions for creating the nuget","Url":"https://github.com/dotnet/machinelearning/pull/2874","RelatedDescription":"Closed or merged PR \"mlnetmkldeps nuget package updates\" (#2874)"},{"Id":"418487450","IsPullRequest":false,"CreatedAt":"2019-03-07T19:59:09","Actor":"TomFinley","Number":"2881","RawContent":null,"Title":"Value-tuple stragglers in the public API","State":"open","Body":"There was a prior PR #2581 and issue #2501 related to value-tuples and why they should not be part of our public surface. I have noticed that there are some \"stragglers\" still remaining in the public API. So, the work is perhaps not yet complete.\r\n\r\nThe following list is I *believe* complete for `Core`/`Data`/`Transforms`/`FastTree`/`ImageAnalytics`/`KMeansClustering`/`LightGBM`/`PCA`/`Tensorflow`/`StandardLearners`/`Data.DataView` assemblies.\r\n\r\nThere are three distinct categories where this flaw has remained. (Though the last \"category\" other has only one item.)\r\n\r\n# Properties on transformers\r\n\r\nSome transformers are exposing information about themselves via this mechanism.\r\n\r\n* KeyToBinaryVectorMappingTransformer.Columns\r\n* MissingValueDroppingTransformer.Columns\r\n* MissingValueIndicatorTransformer.Columns\r\n* CustomStopWordsRemovingTransformer.Columns\r\n* TextNormalizingTransformer.Columns\r\n* TokenizingByCharactersTransformer.Columns\r\n* WordEmbeddingsExtractingTransformer.Columns\r\n* ImageGrayscalingTransformer.Columns\r\n* ImageLoadingTransformer.Columns\r\n* LatentDirichletAllocationTransformer.ItemScoresPerTopic and WordScoresPerTopic\r\n\r\n# MLContext estimator creation extension methods\r\n\r\nThere are some overloads of MLContext extension methods on various catalogs that are stil using it. I view this as a *lesser* sin since this is at least something that could conceivably be fixed using an overload if we decide it is necessary, but I'd still prefer to be consistent.\r\n\r\n* ProduceHashedNgrams extension method\r\n* ProduceHashedWordBags extension method\r\n* ProduceNgrams extension method\r\n* ProduceWordBags extension method\r\n* RemoveDefaultStopWords extension method\r\n* TokenizeWords extension method\r\n\r\n# Others\r\n\r\nLastly, I see a Microsoft.ML.ColumnOptions global class with an implicit operator from value-tuples. This one is *probably* harmless, since that specific class is for representing a simple case.\r\n\r\n/cc @yaeldekel @Ivanidzo4ka ","Url":"https://github.com/dotnet/machinelearning/issues/2881","RelatedDescription":"Open issue \"Value-tuple stragglers in the public API\" (#2881)"},{"Id":"418430258","IsPullRequest":true,"CreatedAt":"2019-03-07T19:10:20","Actor":"TomFinley","Number":"2878","RawContent":null,"Title":"Make array values intended to be immutable IReadOnlyList","State":"closed","Body":"Just a bit of relatively minor polish of something revealed during review of the public surface. In a handful of places we were returning arrays as values intended to be immutable. As elsewhere where perf isn't critical I've shifted to having the return value be `IReadOnlyList`. We've been doing this elsewhere but evidently missed a handful spots.\r\n\r\nIn an *ideal* world we'd make them actually immutable, as via `System.Collections.Immutable`, as I indeed did one or two places, but for the time being I think it suffices that we just make them read-only (even if the user could technically still muck with them with a cast, I'd consider fixing that problem later to be a non-breaking change in the API).\r\n\r\nI only undertook this review in the Core/Data/Transform assemblies.","Url":"https://github.com/dotnet/machinelearning/pull/2878","RelatedDescription":"Closed or merged PR \"Make array values intended to be immutable IReadOnlyList\" (#2878)"},{"Id":"418432912","IsPullRequest":false,"CreatedAt":"2019-03-07T17:39:15","Actor":"tauheedul","Number":"2879","RawContent":null,"Title":"Suggestion: Model Explainability Interpretability Visualization using Decision Tree Diagrams","State":"open","Body":"I previously logged an enhancement for #511 - \"Suggestion - Make Machine Learning Models explainable by design with ML.NET\". @rogancarr kindly broke down that request into separate new enhancements. \r\nhttps://github.com/dotnet/machinelearning/issues/511#issuecomment-448329385\r\n\r\nIn this enhancement, I am suggesting we add visualization of Machine Learning decisions using a Decision Tree within Visual Studio. Now that ML.NET supports Feature Importance (#599) this should be possible.\r\n\r\n**How it could be done.**\r\nI propose in the Visual Studio IDE Editor a new Model Visualization tab is added \r\n(Similar to the CPU Performance usage or a UML Class Diagram that shows how objects relate to each other)\r\n- The tab could show a graphical decision tree showing a path the algorithm took and why it did it\r\n- The decision tree could be derived from the feature importance metrics that are available within ML.NET\r\n- At each level of a tree, you could inspect the Data that contributed to it (an extension of IDataView?)\r\n\r\n **There have been similar issues logged, but my request is different from the following...**\r\n- Feature request: get reasons behind predictions made by Decision Trees #913\r\n- Is it possible to visualize a generated decision tree? #326\r\n- Pipeline visualization please #2478\r\n- Proof of concept for debugger visualization #847\r\n\r\n**Advanced Deep Learning Debugging / Explainability** \r\nAlso from the perspective of a Deep Learning model e.g. a TensorFlow or ONNX model, would it be possible to peek into the neural network nodes? (not only a high-level feature importance score but peek into what each node is doing e.g. you can view feature importance at each node level)\r\n\r\nIn the Visual Studio IDE we could have a Model with a tree of neurons (maybe thousands)... each neuron can be expanded and the evaluation of what each node is doing can be inspected.\r\n\r\nThis can open up the opportunity to allow developers to create custom graphing for visual feedback and monitor the progression of a decision in real-time.\r\n\r\nIt allows you to trace which neurons are fired in any given execution of the model and how a given set of data impacted the score and at what stage it changed.\r\n\r\n**Examples of how this can work**\r\n[Explaining Explanations: An Overview of Interpretability of Machine Learning](https://arxiv.org/abs/1806.00069)\r\n\r\n[Want To Simplify Neural Networks? Transform Them Into Decision Trees](https://www.analyticsindiamag.com/want-to-simplify-neural-networks-transform-them-into-decision-trees/)\r\n\r\n[\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)\r\n\r\n[A Brief History of Machine Learning Models Explainability](https://medium.com/@Zelros/a-brief-history-of-machine-learning-models-explainability-f1c3301be9dc)\r\n\r\n[Decision Trees — Understanding Explainable AI](https://towardsdatascience.com/decision-trees-understanding-explainable-ai-620fc37e598d)\r\n\r\n[How to Perform Explainable Machine Learning Classification — Without Any Trees](https://towardsdatascience.com/how-to-perform-explainable-machine-learning-classification-without-any-trees-873db4192c68)\r\n\r\n[AI for health care: tackling the issue of interpretability.](https://medium.com/@Pacmedhealth/ai-for-health-care-tackling-the-issue-of-interpretability-868be42aaf50)\r\n\r\n[What matters is what’s on the outside: model explainability using black box approaches](https://medium.com/james-blogs/what-matters-is-whats-on-the-outside-model-explainability-using-black-box-approaches-ee1c4e6d564f)\r\n\r\n[Explainable AI: P1 - The Importance of Human Interpretable Machine Learning](https://towardsdatascience.com/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476)\r\n\r\n[Explainable AI: P2 - Model Interpretation Strategies](https://towardsdatascience.com/explainable-artificial-intelligence-part-2-model-interpretation-strategies-75d4afa6b739)\r\n\r\n[Explainable AI: P3 - Hands-on Machine Learning Model Interpretation](https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608)\r\n\r\n[How to Explain the Prediction of a Machine Learning Model?](https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html)\r\n\r\n[Identifying and Correcting Label Bias in Machine Learning](https://towardsdatascience.com/identifying-and-correcting-label-bias-in-machine-learning-ed177d30349e)\r\n\r\n[Toward ethical, transparent and fair AI/ML: a critical reading list](https://medium.com/@eirinimalliaraki/toward-ethical-transparent-and-fair-ai-ml-a-critical-reading-list-d950e70a70ea)\r\n\r\nMichał Łopuszyński - Data Scientist, University of Warsaw has built up a list of excellent resources covering these topics \r\nhttps://github.com/lopusz/awesome-interpretable-machine-learning\r\n\r\nSandra Wachter discusses the benefits of offering counterfactual explanations that will be valuable to end users who are non-technical...\r\n[Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR](https://arxiv.org/abs/1711.00399)\r\n\r\ncc: @rustd @shauheen @Ivanidzo4ka","Url":"https://github.com/dotnet/machinelearning/issues/2879","RelatedDescription":"Open issue \"Suggestion: Model Explainability Interpretability Visualization using Decision Tree Diagrams\" (#2879)"},{"Id":"418034986","IsPullRequest":true,"CreatedAt":"2019-03-07T05:06:35","Actor":"Ivanidzo4ka","Number":"2872","RawContent":null,"Title":"ImageModels in tensorflow are 4 dimensional.","State":"closed","Body":"Fixes https://github.com/dotnet/machinelearning/issues/2778\r\nWell, not exactly fixes, it's more like a hack.\r\nProper solution would be to implement Reshape transform https://github.com/dotnet/machinelearning/issues/765","Url":"https://github.com/dotnet/machinelearning/pull/2872","RelatedDescription":"Closed or merged PR \"ImageModels in tensorflow are 4 dimensional.\" (#2872)"},{"Id":"418092547","IsPullRequest":true,"CreatedAt":"2019-03-07T01:57:59","Actor":"najeeb-kazmi","Number":"2875","RawContent":null,"Title":"Scrubbing image transforms","State":"open","Body":"Fixes #2833 ","Url":"https://github.com/dotnet/machinelearning/pull/2875","RelatedDescription":"Open PR \"Scrubbing image transforms\" (#2875)"},{"Id":"418035994","IsPullRequest":false,"CreatedAt":"2019-03-06T22:19:37","Actor":"wschin","Number":"2873","RawContent":null,"Title":"exampleWeightColumnName v.s. weightColumnName","State":"open","Body":"In trainers like\r\n```csharp\r\n        internal RandomizedPcaTrainer(IHostEnvironment env,\r\n            string features,\r\n            string weights = null,\r\n            string featureColumnName,\r\n            string exampleWeightColumnName = null,\r\n            int rank = Options.Defaults.NumComponents,\r\n            int oversampling = Options.Defaults.OversamplingParameters,\r\n            bool center = Options.Defaults.IsCenteredZeroMean,\r\n            bool ensureZeroMean = Options.Defaults.EnsureZeroMean,\r\n            int? seed = null)\r\n```\r\nwe have `exampleWeightColumnName` but it seems `weightColumnName` is clear enough under this context. Can we switch to `weightColumnName`?","Url":"https://github.com/dotnet/machinelearning/issues/2873","RelatedDescription":"Open issue \"exampleWeightColumnName v.s. weightColumnName\" (#2873)"},{"Id":"417980422","IsPullRequest":false,"CreatedAt":"2019-03-06T19:52:36","Actor":"daholste","Number":"2870","RawContent":null,"Title":"Update default n-gram length for Text Transform to match default text recipe","State":"open","Body":"@justinormont and the text team tuned default n-gram lengths for the default text recipe in the internal repo\r\n\r\nThese defaults are:\r\nWord -- bigrams (w/ unigrams)\r\nCharacter -- trigrams (w/o unigrams and bigrams)\r\n\r\nOne chart from his findings:\r\n![image](https://user-images.githubusercontent.com/4080826/51941076-8c8d1b80-23c8-11e9-89d5-e30b42db39d0.png)\r\n\r\nThe line w/ the light blue call-out represents current ML.NET defaults (Unigram + Trichar)\r\nThe line w/ the light green call-out is the requested change (Bigram + Trichar)\r\nThe line w/ the pink call-out shows the Trigram+Trichar is better in terms of accuracy, but with a time hit, and accuracy has a cross over at NumIterations > 8 for Averaged Perceptron learner.","Url":"https://github.com/dotnet/machinelearning/issues/2870","RelatedDescription":"Open issue \"Update default n-gram length for Text Transform to match default text recipe\" (#2870)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-03-09T05:30:32.8867585Z","RunDurationInMilliseconds":631}