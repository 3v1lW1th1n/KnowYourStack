{"Data":{"GitHub":{"Issues":[{"Id":"348128489","IsPullRequest":true,"CreatedAt":"2018-08-07T00:53:26","Actor":"GalOshri","Number":"656","RawContent":null,"Title":"Add release notes for ML.NET 0.4","State":"open","Body":"This adds release notes for ML.NET 0.4. \r\n\r\nNote that some of the documentation links are not available yet. They will start working after the official release.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/656","RelatedDescription":"Open PR \"Add release notes for ML.NET 0.4\" (#656)"},{"Id":"348126800","IsPullRequest":false,"CreatedAt":"2018-08-07T00:42:16","Actor":"codemzs","Number":"655","RawContent":null,"Title":"OpemMP support for MKL library and SymSGD.","State":"open","Body":"Current MKL library was not build with parallel option to not have dependency on OpenMP because we are still waiting for guidance from legal department on redistributing open mp binary.","Url":"https://github.com/dotnet/machinelearning/issues/655","RelatedDescription":"Open issue \"OpemMP support for MKL library and SymSGD.\" (#655)"},{"Id":"348120663","IsPullRequest":false,"CreatedAt":"2018-08-07T00:01:53","Actor":"mjmckp","Number":"654","RawContent":null,"Title":"Default value of sigmoid parameter for LightGBM","State":"open","Body":"[The default value of the `sigmoid` parameter for LightGBM is 1](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst#sigmoid), however in the ML.Net wrapper it is hardwired to 0.5:\r\nhttps://github.com/dotnet/machinelearning/blob/f9d3973a056ad26bc6cc15c2d7a09f8ae47e30da/src/Microsoft.ML.LightGBM/LightGbmArguments.cs#L404\r\n\r\nWhy is this the case? Shouldn't this parameter either be 1 or exposed on the ML.Net API instead?","Url":"https://github.com/dotnet/machinelearning/issues/654","RelatedDescription":"Open issue \"Default value of sigmoid parameter for LightGBM\" (#654)"},{"Id":"348098009","IsPullRequest":true,"CreatedAt":"2018-08-06T22:06:02","Actor":"Ivanidzo4ka","Number":"653","RawContent":null,"Title":"add examples of API scenarios","State":"open","Body":"examples for #584 ","Url":"https://github.com/dotnet/machinelearning/pull/653","RelatedDescription":"Open PR \"add examples of API scenarios\" (#653)"},{"Id":"347972660","IsPullRequest":true,"CreatedAt":"2018-08-06T20:03:10","Actor":"eerhardt","Number":"652","RawContent":null,"Title":"Fix test output during CI.","State":"closed","Body":"When tests run in CI, we are not displaying the test output to the console. So if a test fails, and for some reason the .trx file isn't parsed correctly, it is impossible to see what test failed and why.\r\n\r\nThe test output isn't being displayed because of https://github.com/Microsoft/vstest/issues/1503.\r\n\r\nTo work around the vstest bug, split CI builds into 2 separate MSBuild invocations: one to do the build (which is multi-proc) and another to run the tests (which doesn't need MSBuild node reuse).\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/652","RelatedDescription":"Closed or merged PR \"Fix test output during CI.\" (#652)"},{"Id":"347946870","IsPullRequest":true,"CreatedAt":"2018-08-06T15:25:00","Actor":"Jongkeun","Number":"651","RawContent":null,"Title":"fixed a spelling from adressing to addressing.","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nfixed #650.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/651","RelatedDescription":"Closed or merged PR \"fixed a spelling from adressing to addressing.\" (#651)"},{"Id":"347946590","IsPullRequest":false,"CreatedAt":"2018-08-06T15:25:00","Actor":"Jongkeun","Number":"650","RawContent":null,"Title":"There is a miss spelling of a `CONTRIBUTING.md` file.","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\nfixed a spelling of a `CONTRIBUTING.md` file.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/650","RelatedDescription":"Closed issue \"There is a miss spelling of a `CONTRIBUTING.md` file.\" (#650)"},{"Id":"347894183","IsPullRequest":false,"CreatedAt":"2018-08-06T12:00:02","Actor":"rauhs","Number":"649","RawContent":null,"Title":"Multi class prediction: Best score doesn't always match prediction","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**: 2.1.202\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n\r\nI wanted to get \"top-k\" or \"best predictions\" from a multi classification problem. The code:\r\n\r\n```C#\r\nmodel.TryGetScoreLabelNames(out var classMapping);\r\n        foreach (var toEval in dataTrain)\r\n        {\r\n          var prediction = model.Predict(toEval);\r\n          var sortedScores = prediction.Score.Zip(classMapping, Tuple.Create).OrderBy(sk => -sk.Item1).ToArray();\r\n          var sum = prediction.Score.Sum(); // correctly usually ~1\r\n          var topPrediction = sortedScores.First().Item2;\r\n          if (topPrediction != prediction.CarrierId)\r\n          {\r\n            Console.WriteLine(\"Dont match. Bad!\");\r\n          }\r\n        }\r\n```\r\nwhere `CarrierId` is my predicted label (a string).\r\n\r\nI'm using `SDCA` with (roughly):\r\n\r\n```C#\r\nreturn new LearningPipeline()\r\n      {\r\n        CollectionDataSource.Create(dataTrain),\r\n        new Dictionarizer((\"CarrierId\", \"Label\")),\r\n       ....\r\n    } \r\n```\r\n\r\n- **What happened?**\r\nSometimes, the predicted label doesn't match the to score in `Scores`.\r\n\r\nNote: The class in `CarrierId` is usually the correct class and the top scored class is not correct.","Url":"https://github.com/dotnet/machinelearning/issues/649","RelatedDescription":"Open issue \"Multi class prediction: Best score doesn't always match prediction\" (#649)"},{"Id":"347352033","IsPullRequest":false,"CreatedAt":"2018-08-06T07:29:14","Actor":"aho81","Number":"642","RawContent":null,"Title":"How to build transform-only pipelines","State":"closed","Body":"I found comments, that there should be a way to use transforms without the need of a trainer/learner (i.e., building a \"processing / transform - pipeline instead of an LearningPipeline, cp.  https://github.com/dotnet/machinelearning/issues/259#issuecomment-393362342). Unfourtunately, I could not find out, how to achieve this.\r\n\r\nIn my usecase, I want to determine similarity of documents with n-gram vectorization and cosine distance. The functionalty for featurization is given by the TextFeaturizer (https://docs.microsoft.com/de-de/dotnet/api/microsoft.ml.transforms.textfeaturizer). In this usecase I don't want to do a training (yet), but am interessted in the output in the result of the TextFeaturizer itself.\r\n\r\nAccessing the results of partial steps could be helpful for debugging LearningPipelines too (cp. discussion here: https://github.com/dotnet/machinelearning/issues/259).\r\n@TomFinley \r\n","Url":"https://github.com/dotnet/machinelearning/issues/642","RelatedDescription":"Closed issue \"How to build transform-only pipelines\" (#642)"},{"Id":"347801684","IsPullRequest":false,"CreatedAt":"2018-08-06T06:59:18","Actor":"codemzs","Number":"648","RawContent":null,"Title":"Pass MKL version to CMAKE from MSBUILD","State":"open","Body":"CMAKE uses MKL library to build native SymSGD library. Currently MKL version is hard-coded to 0.0.0.5 but it would be better it this version information is passed from MSBUILD to CMAKE. MSBUILD would retrieve MKL version that is being used from dependencies.prop file in build directory under root.","Url":"https://github.com/dotnet/machinelearning/issues/648","RelatedDescription":"Open issue \"Pass MKL version to CMAKE from MSBUILD\" (#648)"},{"Id":"347798420","IsPullRequest":true,"CreatedAt":"2018-08-06T06:45:27","Actor":"codemzs","Number":"647","RawContent":null,"Title":"Pass MKL version to CMAKE from MSBUILD.","State":"open","Body":"fixes #648 ","Url":"https://github.com/dotnet/machinelearning/pull/647","RelatedDescription":"Open PR \"Pass MKL version to CMAKE from MSBUILD.\" (#647)"},{"Id":"347558335","IsPullRequest":true,"CreatedAt":"2018-08-03T22:59:32","Actor":"zeahmed","Number":"646","RawContent":null,"Title":"[Part 1] Added comments/description to convenience constructors for a set of transform","State":"open","Body":"This PR partially addresses #524.\r\n\r\nInformative comments/description is added to convenience constructors of transforms so that comments/description appear in the intellisense for users.\r\n\r\nDescription/Comments are obtained from relevant `doc.xml` file and added to C# summary comments section using `<include>` tag. If  `doc.xml` does not contain the required information it is directly added to C# summary comments.\r\n\r\nFollowing is list of transforms covered in this PR.\r\n\r\n- BootstrapSampleTransform\r\n- CategoricalHashTransform\r\n- CategoricalTransform\r\n- ConcatTransform\r\n- CopyColumnsTransform\r\n- CountFeatureSelection\r\n- DropColumnsTransform\r\n- LpNormNormalizerTransform\r\n- NAFilter\r\n- NormalizeTransform\r\n","Url":"https://github.com/dotnet/machinelearning/pull/646","RelatedDescription":"Open PR \"[Part 1] Added comments/description to convenience constructors for a set of transform\" (#646)"},{"Id":"347516565","IsPullRequest":true,"CreatedAt":"2018-08-03T20:46:18","Actor":"eerhardt","Number":"645","RawContent":null,"Title":"Bump the master branch to 0.5","State":"closed","Body":"Now that we have branched for 0.4, we need to bump the master branch to the next version.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/645","RelatedDescription":"Closed or merged PR \"Bump the master branch to 0.5\" (#645)"},{"Id":"347516249","IsPullRequest":true,"CreatedAt":"2018-08-03T20:38:05","Actor":"eerhardt","Number":"644","RawContent":null,"Title":"Merge master into release/preview for 0.4","State":"closed","Body":"This is a merge of the master branch.  It is basically a straight \"accept master\" on any conflict.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/644","RelatedDescription":"Closed or merged PR \"Merge master into release/preview for 0.4\" (#644)"},{"Id":"347432074","IsPullRequest":true,"CreatedAt":"2018-08-03T15:55:11","Actor":"eerhardt","Number":"643","RawContent":null,"Title":"Fix official build failure","State":"closed","Body":"Now that the HalLearners nuget package doesn't have a PackageReference to MlNetMklDeps, the MlNetMklDeps package is no longer getting restored during the official build. Since HalLearners needs the license file from MlNetMklDeps, it is failing to build the nuget package.\r\n\r\nThe fix is to restore all project before building the packages.","Url":"https://github.com/dotnet/machinelearning/pull/643","RelatedDescription":"Closed or merged PR \"Fix official build failure\" (#643)"},{"Id":"347138582","IsPullRequest":true,"CreatedAt":"2018-08-03T13:47:57","Actor":"eerhardt","Number":"635","RawContent":null,"Title":"Copy native assemblies for packages.config","State":"closed","Body":"Whenever we have native assemblies in our nuget packages, we need to have special build logic in order for it to work on packages.config.\r\n\r\nWe already had that logic for Microsoft.ML, but were missing it for CpuMath and HalLearners.\r\n\r\nFix #633","Url":"https://github.com/dotnet/machinelearning/pull/635","RelatedDescription":"Closed or merged PR \"Copy native assemblies for packages.config\" (#635)"},{"Id":"347096233","IsPullRequest":false,"CreatedAt":"2018-08-03T13:47:57","Actor":"eerhardt","Number":"633","RawContent":null,"Title":"CpuMath and HalLearners packages don't work with packages.config","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows.  Visual Studio 15.8\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreate a new NET Framework console app.  Ensure it uses `packages.config`.\r\nInstall the `Microsoft.ML` package.\r\nTry to run through a ML.NET scenario - https://www.microsoft.com/net/learn/machine-learning-and-ai/get-started-with-ml-dotnet-tutorial\r\n\r\n- **What happened?**\r\n```\r\nUnhandled Exception: System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.DllNotFoundException: Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Runtime.Internal.CpuMath.Thunk.SumSqU(Single* ps, Int32 c)\r\n   at Microsoft.ML.Runtime.Learners.SdcaTrainerBase`1.TrainCore(IChannel ch, RoleMappedData data, LinearPredictor predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Runtime.Learners.LinearTrainerBase`1.Train(TrainContext context)\r\n   at Microsoft.ML.Runtime.Training.TrainerBase`1.Microsoft.ML.Runtime.ITrainer.Train(TrainContext context)\r\n   at Microsoft.ML.Runtime.Data.TrainUtils.TrainCore(IHostEnvironment env, IChannel ch, RoleMappedData data, ITrainer trainer, String name, RoleMappedData validData, ICalibratorTrainer calibrator, Int32 maxCalibrationExamples, Nullable`1 cacheData, IPredictor inputPredictor)\r\n   at Microsoft.ML.Runtime.EntryPoints.LearnerEntryPointsUtils.Train[TArg,TOut](IHost host, TArg input, Func`1 createTrainer, Func`1 getLabel, Func`1 getWeight, Func`1 getGroup, Func`1 getName, Func`1 getCustom, ICalibratorTrainerFactory calibrator, Int32 maxCalibrationExamples)\r\n   at Microsoft.ML.Runtime.Learners.Sdca.TrainMultiClass(IHostEnvironment env, Arguments input)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   at System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.EntryPoints.EntryPointNode.Run()\r\n```\r\n\r\n- **What did you expect?**\r\nIt should work\r\n\r\n### Notes\r\n\r\nThis is because we need the same .targets files we have in the `Microsoft.ML` package:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/f6934a0705b8ff2b7ad2d51c9cf4f82f7d1cbd94/pkg/Microsoft.ML/build/netstandard2.0/Microsoft.ML.props#L7-L15\r\n","Url":"https://github.com/dotnet/machinelearning/issues/633","RelatedDescription":"Closed issue \"CpuMath and HalLearners packages don't work with packages.config\" (#633)"},{"Id":"347270264","IsPullRequest":true,"CreatedAt":"2018-08-03T06:04:58","Actor":"codemzs","Number":"641","RawContent":null,"Title":"Make model path mandatory in export to ONNX.","State":"open","Body":"fixes #423 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/641","RelatedDescription":"Open PR \"Make model path mandatory in export to ONNX.\" (#641)"},{"Id":"347204945","IsPullRequest":false,"CreatedAt":"2018-08-03T02:00:39","Actor":"codemzs","Number":"638","RawContent":null,"Title":"Package mkl binaries with Hal Learners nuget.","State":"closed","Body":"Native SymSGD code depends on Mkl libraries during runtime hence both of them should be packaged together to prevent dependency not found issue on macOS and linux.","Url":"https://github.com/dotnet/machinelearning/issues/638","RelatedDescription":"Closed issue \"Package mkl binaries with Hal Learners nuget.\" (#638)"},{"Id":"347131475","IsPullRequest":true,"CreatedAt":"2018-08-03T02:00:39","Actor":"codemzs","Number":"634","RawContent":null,"Title":"package mkl lib with hal learners.","State":"closed","Body":"fixes #638 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/634","RelatedDescription":"Closed or merged PR \"package mkl lib with hal learners.\" (#634)"},{"Id":"347222797","IsPullRequest":true,"CreatedAt":"2018-08-03T00:58:01","Actor":"Ivanidzo4ka","Number":"640","RawContent":null,"Title":"WIP Sketch to support read-only properties","State":"open","Body":"something something #631 ","Url":"https://github.com/dotnet/machinelearning/pull/640","RelatedDescription":"Open PR \"WIP Sketch to support read-only properties\" (#640)"},{"Id":"347221914","IsPullRequest":true,"CreatedAt":"2018-08-03T00:51:52","Actor":"Zruty0","Number":"639","RawContent":null,"Title":"API 'getting started' examples","State":"open","Body":"These examples currently do not compile, they depend on both Estimators and static type checks, but let's at least agree that we can all stand behind them in terms of simplicity.\r\n\r\nDo not merge, this is a discussion-only PR.","Url":"https://github.com/dotnet/machinelearning/pull/639","RelatedDescription":"Open PR \"API 'getting started' examples\" (#639)"},{"Id":"346847604","IsPullRequest":true,"CreatedAt":"2018-08-02T22:33:10","Actor":"shauheen","Number":"629","RawContent":null,"Title":"Merge master into release/preview branch for v0.4","State":"closed","Body":"This PR is cumulatively merging master into release branch in preparation for v0.4 release.","Url":"https://github.com/dotnet/machinelearning/pull/629","RelatedDescription":"Closed or merged PR \"Merge master into release/preview branch for v0.4\" (#629)"},{"Id":"347141692","IsPullRequest":true,"CreatedAt":"2018-08-02T22:13:38","Actor":"eerhardt","Number":"636","RawContent":null,"Title":"Change the linux official build queue from test to production.","State":"closed","Body":"We were using a \"test\" build queue because of some limitations with the build lab.  Those limitations are now fixed, so we can start using the \"production\" build queue again.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/636","RelatedDescription":"Closed or merged PR \"Change the linux official build queue from test to production.\" (#636)"},{"Id":"346817676","IsPullRequest":true,"CreatedAt":"2018-08-02T21:36:20","Actor":"Ivanidzo4ka","Number":"628","RawContent":null,"Title":"Fixes in documentation for wordembedding","State":"closed","Body":"Better example, and replace html encoding to xml encoding\r\n","Url":"https://github.com/dotnet/machinelearning/pull/628","RelatedDescription":"Closed or merged PR \"Fixes in documentation for wordembedding\" (#628)"},{"Id":"347167178","IsPullRequest":false,"CreatedAt":"2018-08-02T20:43:10","Actor":"sfilipi","Number":"637","RawContent":null,"Title":"Per component examples in the repo,  to reference in the documentation","State":"open","Body":"Our examples in the documentation currently aren't very comprehensive, because they live in XML, and it is not easily maintainable to write longer code snippets embedded in XML. \r\n\r\nThe infrastructure for docs.microsoft.com supports cross-referencing other files within the XML. \r\nThose other files can be C# files and have more fully fledged examples, that compile. \r\n\r\nSetup another folder within Microsoft.ML.Tests, similar to scenarios, that will contain examples for each components. More than one component can be used for the scenario, but they should be kept simple. \r\nThose methods can be reused by the tests.\r\n\r\nThis issue will be considered resolved after  setting up one such example end-to-end. ","Url":"https://github.com/dotnet/machinelearning/issues/637","RelatedDescription":"Open issue \"Per component examples in the repo,  to reference in the documentation\" (#637)"},{"Id":"347092277","IsPullRequest":false,"CreatedAt":"2018-08-02T16:47:45","Actor":"TomFinley","Number":"632","RawContent":null,"Title":"Direct API: Static Typing of Data Pipelines","State":"open","Body":"Currently in all iterations of the pipeline concept, whether they be based on the v0.1 idiom of `LearningPipeline`, or the #371 proposal where `IDataView` is directly created, or the refinement of that in #581, or the convenience constructors, or whatever, there is always this idea of a pipeline being a runtime-checked thing, where each stage has some output schema with typed columns indexed by a string name, and all of this is known only at runtime -- at compile time, all the compiler knows is you have *some* estimator, or *some* data view, or something like that, but has no idea what is in it.\r\n\r\nThis makes sense from a practical perspective, since there are many applications where you cannot know the schema until runtime. E.g.: loading a model from a file, or loading a Parquet file, you aren't going to know anything until the code actually runs. So we want the underlying system to remain dynamically typed to serve those scenarios, and I do not propose changing that. That said, there are some definite usability costs:\r\n\r\n* Typos on those column names are found at runtime, which is unfortunate.\r\n* Application of the wrong transform or learner is found at runtime.\r\n* Discoverability is an issue. You just sort of have to know what transforms are applicable to your case, which is somewhat difficult since if we were to collect all the things you could apply to data (transform, train a learner), there are probably about 100 of these or thereabouts. Intellisense will be of no help to you here, because at compile time, the only thing the language knows is you have *some*.\r\n\r\nIt's sort of like working with `Dictionary<string, object>` as your central data structure, and an API that just takes `Dictionary<string, object>` everywhere. In a way that's arbitrarily powerful, but the language itself can give you no help at all about what you should do with it, which is kind of a pity since we have this nice statically typed language we're working in.\r\n\r\nSo: a statically typed helper API on top of this that was sufficiently powerful would help increase the confidence that if someone compiles it might run, and also give you some help in the form of proper intellisense of what you can do, while you are typing before you've run anything. Properly structured, if you had strong typing at the columnar level, nearly everything you can do can be automatically discoverable through intellisense. The documentation would correspondingly become a lot more focused.\r\n\r\nThe desire to have something like this is very old, but all prior attempts I recall ran into some serious problems sooner or later. In this issue I discuss such an API that I've been kicking around for a little bit, and at least so far it doesn't seem to have any show-stopping problems, at least so far as I've discovered in my initial implementations.\r\n\r\nThe following proposal is built on top of #581. (For those seeking actual code, the current exploratory work in progress is based out of [this branch](https://github.com/TomFinley/machinelearning/tree/tfinley/StrongPipe), which in turn is a branch based of @Zruty0's [branch here](https://github.com/Zruty0/machinelearning/tree/feature/estimators/src/Microsoft.ML.Core/Data).)\r\n\r\n# Simple Example\r\n\r\nIt may be that the easiest way to explain the proposal is to show a simple example, then explain it. This will be where we [train sentiment classification](https://github.com/dotnet/machinelearning/blob/89dfc82f5edcfe23015dc2c1291bc7a836188e80/test/Microsoft.ML.Tests/ScenariosWithDirectInstantiation/SentimentPredictionTests.cs#L24), though I've simplified the text settings to just the diacritics option\r\n\r\n```csharp\r\n// We load two columns, the boolean \"label\" and the textual \"sentimentText\".\r\nvar text = TextLoader.Create(\r\n    c => (label: c.LoadBool(0), sentimentText: c.LoadText(1)),\r\n    sep: '\\t', header: true);\r\n\r\n// We apply the text featurizer transform to \"sentimentText\" producing the column \"features\".\r\nvar transformation = text.CreateTransform(r =>\r\n    (r.label, features: r.sentimentText.TextFeaturizer(keepDiacritics: true)));\r\n\r\n// We apply a learner to learn \"label\" given \"features\", which will in turn produce\r\n// float \"score\", float \"probability\", and boolean \"predictedLabel\".\r\nvar training = transformation.CreateTransform(r =>\r\n    r.label.TrainLinearClassification(r.features))\r\n```\r\n\r\nAn alternative is we might do a continuous, non-segmented form (where they are all merged into a single thing):\r\n\r\n```csharp\r\nvar pipeline = TextLoader.Create(\r\n    c => (label: c.LoadBool(0), sentimentText: c.LoadText(1)),\r\n    sep: '\\t', header: true)\r\n    .ExtendWithTransform(r => (r.label, features: sentimentText.TextFeaturizer(keepDiacritics: true)))\r\n    .ExtendWithTransform(r => r.label.TrainLinearClassification(r.features));\r\n```\r\n\r\nor even the following:\r\n\r\n```csharp\r\nvar pipeline = TextLoader.Create(c =>\r\n    c.LoadBool(0).TrainLinearClassification(c.LoadText(1).TextFeaturizer(keepDiacritics: true)));\r\n```\r\n\r\n## Developer Story\r\n\r\nHere's how I imagine this playing out by someone maybe like me. So: first we have this `TextLoader.Create` method. (Feel free to suggest better names.)\r\n\r\n* The developer knows they have some data file, a TSV with two fields, a label, and some sentiment text. They write `TextLoader.Create`. The first argument is delegate, with a text loader context input, and is responsible for producing a tuple out of things composed out of that context. (Both the method signature, and the XML doc commentary, can explain this.) When they write `c => c.`, intellisense hits them with what they can do... `c.LoadBool`, `c.LoadDouble`, `c.LoadFloat`, etc. These methods produce things like `Scalar<bool>`, `Vector<bool>`, `Scalar<double>`, etc., depending on which is called, what overload is used, and so on. The developer ultimately creates a value-tuple out of all this stuff, with the bool and text loading values.\r\n\r\n* Then they have this object, here called `text`. So they type `text.`, and Intellisense pops up again. They know they want to do *something* with the data they've told the framework to load, and they see `CreateTransform` or `ExtendWithTransform`. Even if they haven't read a bit of documentation, that has enough of a name that they think, maybe, \"heck, maybe this is where I belong.\" So they choose that.\r\n\r\n* Again they are hit with a delegate. But this time, the input type is the value-tuple created in the loader. And they might type, `text.CreateTransform(r => r.label.TrainLinearClassification`. They try to feed in their `sentimentText`, but the compiler complains at them, saying, I want a `Vector<float>`, not a `Scalar<text>`. So maybe they now do `r.sentimentText.TextFeaturizer` as something sufficiently promising, since it has a promising sounding name and also returns the `Vector<float>` that the classifier claims to want. In VS it looks something like this (click the image to see zoomed in version, sorry that the screenshot is so wide):\r\n\r\n![image](https://user-images.githubusercontent.com/8295757/43598024-96326f6e-9638-11e8-992d-f72e882efe7d.png)\r\n\r\nGiven that setup, there is I think only one thing here that cannot be plausibly discovered via intellisense, or the XML docs that pop up with intellisense, and that is the fact that you would want to start the pipeline with something like `TextLoader.Create`. But I figure this will be so ubiquitous even in \"example 1\" that we can get away with it. There's also the detail about training happening through a \"label,\" and unless they happen to have the right type (`Scalar<bool>`) it simply won't show up for them. But someone reading documentation on the linear classifier would surely see that extension method and figure out what to do with it.\r\n\r\n# More Details\r\n\r\nNow we drill a little bit more into the shape and design of this API.\r\n\r\n## `PipelineColumn` and its subclasses\r\n\r\nAs we saw in the example, many transformations are indicated by the type of data. For this we have the abstract class `PipelineColumn`, which are manifested to the user through the following abstract subclasses.\r\n\r\n* `Scalar<>` represents a scalar-column of a particular type.\r\n* `Vector<>` represents a vector-valued column of a particular type, where the vector size will be fixed and known (though we might not know the actual size at compiled time)\r\n* `VarVector<>` is similar, but on known size.\r\n* `Key<>`, indicating a key type, which are essentially enumerations into a set.\r\n* `Key<,>`, indicating a key type with a known value, which are essentially enumerations into a set.\r\n* `VarKey<>` which is a key type of unknown cardinality. (These are fairly rare.)\r\n\r\n## `ValueTuple`s of `PipelineColumn`s\r\n\r\nThe pipeline  are the smallest granularity structures. Above that you have collections of these representing the values present at any given time, upon which you can apply more transformations. That value, as mentioned earlier, is a potentially nested value tuple. By potentially nested, what I mean is that you can have as many `ValueTuple`s as you want. So all of the following are fine, if we imagine that `a`, `b`, and `c` are each some sort of `PipelineColumn`:\r\n\r\n```csharp\r\n(a, b)\r\n(a, x: (b, c))\r\na\r\n```\r\n\r\nIn the first case the actual underlying data-view, when produced, would have two columns named `a` and `b`. In the second, there would be three columns, `a`, `x.b`, and `x.c`. In the last, since there is no way as near as I can tell to have a named `ValueTuple<>`, I just for now picked the name `Data`. (Note that in the case where value-tuples are present, the names of the items become the names of the output columns in the data-view schema.)\r\n\r\nThe reason for supporting nesting is, some estimators produce multiple columns (notably, in the example, the binary classification trainer produces three columns), and as far as I can tell there is no way to \"unpack\" a returned value-tuple into another value-tuple. Also it provides a convenient way to just bring along all the inputs, if we wanted to do so, by just assigning the input tuple itself as an item in the output tuple.\r\n\r\n## The Pipeline Components\r\n\r\nAt a higher level of the columns, and the (nested) tuples of columns, you have the objects that represent the pipeline components that describe each step of what you are actually doing with these things. That is, those objects mappings into those value tuples, or between them. To return to the example with `text` and `transformation` and `training`, these have the following types, in the sense that all the following statements in code would be true:\r\n\r\n```csharp\r\ntext is DataReaderEstimator<IMultiStreamSource,\r\n    (Scalar<bool> label, Scalar<string> sentimentText)>;\r\n\r\ntransformation is Estimator<\r\n    (Scalar<bool> label, Scalar<string> sentimentText),\r\n    (Scalar<bool> label, Scalar<float> features)>;\r\n\r\ntraining is Estimator<\r\n    (Scalar<bool> label, Scalar<float> features),\r\n    (Scalar<float> score, Scalar<float> probability, Scalar<bool> predictedLabel)>;\r\n```\r\n\r\nand also in those \"omnibus\" equivalents;\r\n\r\n```csharp\r\npipeline is DataReaderEstimator<IMultiStreamSource,\r\n    (Scalar<float> score, Scalar<float> probability, Scalar<bool> predictedLabel)>;\r\n```\r\n\r\nOne may note that the statically-typed API is strongly parallel to the structures proposed in #581. That is, for every core structure following the `IEstimator` idiom laid out in #581, I envision a strongly typed variant of each type. In the current working code, in fact, the objects actually implement those interfaces, but I might go to having them actually wrap them.\r\n\r\nLike the underlying dynamically typed objects, they can be combined in the usual way to form cohesive pipelines. So for example: one could take a `DataReaderEstimator<TIn, TA>` and an `Estimator<TA, TB>` to produce a `DataReaderEstimator<TIn, TB>`. (So for example, when I was using `ExtendWithTransform` instead of )\r\n\r\nThis duality is deliberate. While the *usage* of the static estimators will necessarily not resemble the dynamically typed estimators, based as it is on actual .NET types and identifiers, the structure that is being built up *is* an estimator based pipeline, and so will resemble it structurally. This duality enables one to use static-typing for as long as is convenient, then when done drop back down to the dynamically typed one. But you could also go in reverse, start with something dynamically typed -- perhaps a model loaded from a file -- essentially assert that this dynamically typed thing has a certain shape (which of course could only be checked at runtime), and then from then on continue with the statically-typed pipe. So as soon as the static typing stops being useful, there's no cliff -- you can just stop using it at that point, and continue dynamically.\r\n\r\nHowever if you can stay in the statically typed world, that's fine. You can fit a strongly typed `Estimator` to to get a strongly typed `Transformer`. You can then further get a strongly typed `DataView` out of a strongly typed `Transformer`. In the end this is still just a veneer, kind of like the `PredictionEngine` stuff, but it's a veneer that has a strong likelihood of working.\r\n\r\n## One or Two Implementation Details\r\n\r\nThe following is not something that most users will need to concern themselves with, and we won't go into too many details. However at least a loose idea of how the system works might help clear up some of the mystery.\r\n\r\nThe `Scalar<>`, `Vector<>`, etc. classes are abstract classes. The `PipelineColumn`s that are created from the helper extension methods have actual concrete implementations intended to be nested private classes in whatever estimator they're associated with. A user never sees those implementations. The component author is responsible for calling the `protected` constructor on those objects, so as to feed it the list of dependencies (what `PipelineColumn` it needs to exist before it would want to chain its own estimator), as well as a little factory object for now called a \"reconciler\" that the analyzer can call once it has satisfied those dependencies.\r\n\r\nThe analyzer itself takes the delegate. It constructs the input object, then pipes it thorugh the delegate. In the case of the estimator,  these are *not* the ones returned from any prior delegate (indeed we have no requirement that there *be* a prior delegate -- estimators can function as independent building blocks), but special instances made for that analysis task). The resulting output will be a value-tuple of `PipelineColumn`s, and by tracing back the dependencies, until we get the graph of dependencies.\r\n\r\nThe actual constructed inputs have no dependencies, and are assumed to just be there already. We then iteratively \"resolve\" dependencies -- we take all columns that have their dependencies resolved, and take some subset that all have the same \"reconciler.\" That reconciler is responsible for returning the actual `IEstimator`. Then anything that depends on *that* column gets resolved. And so on.\r\n\r\nIn this way these delegates are declarative structures. Each extension method provides these `PipelineColumn` implementations, which as objects, but it is the analyzer that goes ahead and figures out in what sequence those factory methods will be called, with what names, etc.\r\n\r\nIt might be more clear if we saw that actual engine.\r\n\r\nhttps://github.com/TomFinley/machinelearning/blob/8e0298f64f0a9f439bb83426b09e54967065793b/src/Microsoft.ML.Core/StrongPipe/BlockMaker.cs#L13\r\n\r\nThe system mostly has fake objects everywhere as standins right now just to validate the approach, so for example if I were to actually run the code in the first example, I get the following diagnostic output. (It should be relatively easy to trace back the diagnostic output.)\r\n\r\n```\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name sentimentText\r\nConstructing TextTransform estimator!\r\n    Will make 'features' out of 'sentimentText'\r\nExiting CreateTransform !!!\r\n\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name features\r\nConstructing LinearBinaryClassification estimator!\r\n    Will make 'score' out of 'label', 'features'\r\n    Will make 'probability' out of 'label', 'features'\r\n    Will make 'predictedLabel' out of 'label', 'features'\r\nExiting CreateTransform !!!\r\n```\r\n\r\nIf I had another example, like this:\r\n\r\n```csharp\r\nvar text = TextLoader.Create(\r\n    ctx => (\r\n    label: ctx.LoadBool(0),\r\n    text: ctx.LoadText(1),\r\n    numericFeatures: ctx.LoadFloat(2, 9)\r\n    ));\r\n\r\nvar transform = text.CreateTransform(r => (\r\n    r.label,\r\n    features: r.numericFeatures.ConcatWith(r.text.Tokenize().Dictionarize().BagVectorize())\r\n    ));\r\n\r\nvar train = transform.CreateTransform(r => (\r\n    r.label.TrainLinearClassification(r.features)\r\n```\r\n\r\nthen the output looks a little something like this:\r\n\r\n```\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name numericFeatures\r\nUsing input with name text\r\nConstructing WordTokenize estimator!\r\n    Will make '#Temp_0' out of 'text'\r\nConstructing Term estimator!\r\n    Will make '#Temp_1' out of '#Temp_0'\r\nConstructing KeyToVector estimator!\r\n    Will make '#Temp_2' out of '#Temp_1'\r\nConstructing Concat estimator!\r\n    Will make 'features' out of 'numericFeatures', '#Temp_2'\r\nExiting CreateTransform !!!\r\n\r\nCalled CreateTransform !!!\r\nUsing input with name label\r\nUsing input with name features\r\nConstructing LinearBinaryClassification estimator!\r\n    Will make 'score' out of 'label', 'features'\r\n    Will make 'probability' out of 'label', 'features'\r\n    Will make 'predictedLabel' out of 'label', 'features'\r\nExiting CreateTransform !!!\r\n```\r\n\r\nYou can sort of trace though what the analyzer is doing as it resolves dependencies, constructs `IEstimator`s, etc. etc. (Obviously the real version won't have all those little console writelines everywhere.)\r\n\r\n## Stuff Not Covered\r\n\r\nThere's a lot of stuff I haven't yet talked about. We create these blocks, how do we mix and match? What does the strongly typed `Transformer` or `DataView` look like? We talked about the text loader, what about sources that come from actual .NET objects? These we might cover in future editions on this, or in subsequent comments. But I think perhaps this writing has gone on long enough...\r\n\r\n/cc @Zruty0 , @ericstj , @eerhardt , @terrajobst , @motus ","Url":"https://github.com/dotnet/machinelearning/issues/632","RelatedDescription":"Open issue \"Direct API: Static Typing of Data Pipelines\" (#632)"},{"Id":"347079547","IsPullRequest":false,"CreatedAt":"2018-08-02T16:11:01","Actor":"Zruty0","Number":"631","RawContent":null,"Title":"Support read-only properties somehow","State":"open","Body":"As mentioned in #254 , now that we are supporting both fields and properties for the purposes of schema comprehension, it is possible to create properties that act like 'calculated fields':\r\n\r\n```c#\r\n        public class MyDataRow\r\n        {\r\n            private DateTime _dateTime;\r\n\r\n            public float Day { get { return _dateTime.Day; } }\r\n            public float DayOfWeek { get { return (float)_dateTime.DayOfWeek; } }\r\n            // etc\r\n        }\r\n```\r\nBut the above code is not sufficient, because currently we require both **getter and setter** to be present (and public). So you have to add the fake setters that throw.\r\n\r\nIs there a way to have it both ways somehow? We want to ensure that we'll be able to write to a property (in case when we use the underlying class as output), but we also want to allow read-only properties (in case when we use it as input).\r\n\r\n@TomFinley , do you have a recommendation? I am leaning towards allowing getter-only (or private-setter) properties to live, but only for input classes. This means that `SchemaDefinition` / `InternalSchemaDefinition` should have some `IsReadOnly` tracking, and corresponding error/warning messages in case we attempt to generate a 'poke' method for a read-only property .","Url":"https://github.com/dotnet/machinelearning/issues/631","RelatedDescription":"Open issue \"Support read-only properties somehow\" (#631)"},{"Id":"346850249","IsPullRequest":false,"CreatedAt":"2018-08-02T03:57:25","Actor":"MaxAkbar","Number":"630","RawContent":null,"Title":"Named Entity Recognizer","State":"open","Body":"Hello ML.NET,\r\n\r\nIs there any way I can use ML.NET to created named entities?\r\n\r\nThanks,\r\n-Max","Url":"https://github.com/dotnet/machinelearning/issues/630","RelatedDescription":"Open issue \"Named Entity Recognizer\" (#630)"},{"Id":"346789518","IsPullRequest":true,"CreatedAt":"2018-08-01T22:33:22","Actor":"shauheen","Number":"627","RawContent":null,"Title":"Merge master into release/preview branch for v0.4","State":"closed","Body":"This PR is cumulatively merging master into release branch in preparation for v0.4 release.","Url":"https://github.com/dotnet/machinelearning/pull/627","RelatedDescription":"Closed or merged PR \"Merge master into release/preview branch for v0.4\" (#627)"}],"ResultType":"GitHubIssue"}},"RunOn":"2018-08-07T05:30:32.2751845Z","RunDurationInMilliseconds":1176}