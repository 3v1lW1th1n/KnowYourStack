{"Data":{"GitHub":{"Issues":[{"Id":"446394095","IsPullRequest":false,"CreatedAt":"2019-05-26T01:26:23","Actor":"seabluescn","Number":"3752","RawContent":null,"Title":"How to get training progress info?","State":"closed","Body":"Hiï¼ŒSuppose I have 10,000 training data. When I run Fit method, it takes a long time. During this period, how can I get real-time training progress information?\r\nThank You!","Url":"https://github.com/dotnet/machinelearning/issues/3752","RelatedDescription":"Closed issue \"How to get training progress info?\" (#3752)"},{"Id":"448501311","IsPullRequest":true,"CreatedAt":"2019-05-25T20:47:57","Actor":"daholste","Number":"3776","RawContent":null,"Title":"[AutoML] Reservoir sample dataset statistics","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3776","RelatedDescription":"Open PR \"[AutoML] Reservoir sample dataset statistics\" (#3776)"},{"Id":"448402582","IsPullRequest":false,"CreatedAt":"2019-05-25T02:18:07","Actor":"seabluescn","Number":"3775","RawContent":null,"Title":"An Exception about using CustomMappingFactory","State":"open","Body":"Hello there,\r\nI am learning about CustomMappingFactory, I found the following code: \r\nmachinelearning/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/CustomMappingSaveAndLoad.cs\r\nThis code runs normally, but if I create a new MLContext before loading the model (line 36), as follows: \r\n\r\nmlContext = new MLContext();\r\nvar loadedTransform = mlContext.Model.Load(\"customTransform.zip\", out var inputSchema);\r\n\r\nThen the system will report an error: \r\nInvalidOperationException: Unable to locate an extension for the contract 'IsUnderThirty'. Ensure you have called ComponentCatalog.RegisterAssembly with the Assembly that contains a class decorated with a 'Microsoft.ML.Transforms.CustomMappingFactoryAttributeAttribute'.\r\n\r\nI think creating a new MLContext before loading the model should be a necessary operation. Is this a bug?","Url":"https://github.com/dotnet/machinelearning/issues/3775","RelatedDescription":"Open issue \"An Exception about using CustomMappingFactory\" (#3775)"},{"Id":"446566150","IsPullRequest":true,"CreatedAt":"2019-05-24T20:28:02","Actor":"justinormont","Number":"3753","RawContent":null,"Title":"Minor typos in TextClassification.cs","State":"closed","Body":"Minor typos. \r\n\r\nFeel free to merge when ready.","Url":"https://github.com/dotnet/machinelearning/pull/3753","RelatedDescription":"Closed or merged PR \"Minor typos in TextClassification.cs\" (#3753)"},{"Id":"447390298","IsPullRequest":true,"CreatedAt":"2019-05-24T20:26:00","Actor":"najeeb-kazmi","Number":"3768","RawContent":null,"Title":"Improve error message for non-vector input to TensorFlowTransform","State":"closed","Body":"Closes #1542 \r\n\r\nThe behavior is expected. TensorFlow treats all inputs as tensors. A scalar input should simply be loaded as a uni-dimensional tensor.\r\n\r\nThis PR improves the error message for the existing check for non-vector inputs to make this clear and closes the issue.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3768","RelatedDescription":"Closed or merged PR \"Improve error message for non-vector input to TensorFlowTransform\" (#3768)"},{"Id":"448327873","IsPullRequest":true,"CreatedAt":"2019-05-24T19:45:10","Actor":"yaeldekel","Number":"3774","RawContent":null,"Title":"Add load names to Platt calibrator","State":"open","Body":"The load names of the `PlattCalibratorTrainerFactory` need to match those of the `LoadableClassAttribute`.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3774","RelatedDescription":"Open PR \"Add load names to Platt calibrator\" (#3774)"},{"Id":"448145353","IsPullRequest":false,"CreatedAt":"2019-05-24T12:30:37","Actor":"drake7707","Number":"3773","RawContent":null,"Title":"Incorrect metrics when the order of labels do not correspond to the indices in multiclassification","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 2.2, ML.1.0.0\r\n\r\n### Issue\r\n\r\n- **What did you do?** Train a trainingset with LightGbm and then evaluate a test set\r\n- **What happened?** The printed metrics are incorrect if the labels are not ordered from 0 -> n\r\n- **What did you expect?** A correct confusion matrix and LogLoss, ... metrics\r\n\r\nConfusion matrix when I add the labels ascending (0 -> n)  of the samples (e.g 0,1,2,3,4,0,1,2,3,4,...). This is the correct evaluation.\r\n```\r\n          ||========================================================================================\r\nPREDICTED ||     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 | Recall\r\nTRUTH     ||========================================================================================\r\n        0 ||    58 |     0 |     1 |    19 |     0 |     0 |     1 |     1 |     2 |     0 |     2 | 0,6905\r\n        1 ||     0 |    79 |     0 |     0 |     0 |     5 |     0 |     0 |     0 |     0 |     0 | 0,9405\r\n        2 ||     0 |     0 |    79 |     3 |     0 |     0 |     0 |     0 |     2 |     0 |     0 | 0,9405\r\n        3 ||     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 1,0000\r\n        4 ||     0 |     0 |     0 |     0 |    81 |     0 |     0 |     0 |     3 |     0 |     0 | 0,9643\r\n        5 ||     0 |     8 |     0 |     0 |     0 |    71 |     5 |     0 |     0 |     0 |     0 | 0,8452\r\n        6 ||     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 | 1,0000\r\n        7 ||     0 |     0 |     0 |     0 |     0 |     2 |     0 |    82 |     0 |     0 |     0 | 0,9762\r\n        8 ||     0 |     0 |     0 |     8 |     0 |     0 |     0 |     1 |    72 |     0 |     3 | 0,8571\r\n        9 ||     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 | 1,0000\r\n       10 ||     0 |     0 |     0 |     0 |     0 |     2 |     1 |     0 |     0 |     0 |    81 | 0,9643\r\n          ||========================================================================================\r\nPrecision ||1,0000 |0,9080 |0,9875 |0,7368 |1,0000 |0,8875 |0,9231 |0,9762 |0,9114 |1,0000 |0,9419 |\r\n\r\n************************************************************\r\n```\r\nNow when I do OrderByDescending to reverse the labels and run it again, I get:\r\n\r\nConfusion matrix when I reverse the labels (n -> 0)  of the samples (e.g 4,3,2,1,0,4,3,2,1,0,...)\r\n\r\n```\r\n          ||========================================================================================\r\nPREDICTED ||     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 | Recall\r\nTRUTH     ||========================================================================================\r\n        0 ||     3 |     0 |     3 |     1 |     0 |     6 |     0 |    14 |     0 |     0 |    57 | 0,0357\r\n        1 ||     0 |     0 |     0 |     0 |     0 |     2 |     0 |     0 |     0 |    82 |     0 | 0,0000\r\n        2 ||     0 |     0 |     3 |     0 |     0 |     0 |     0 |     8 |    73 |     0 |     0 | 0,0357\r\n        3 ||     0 |     0 |     0 |     0 |     0 |     0 |     0 |    84 |     0 |     0 |     0 | 0,0000\r\n        4 ||     0 |     0 |     2 |     0 |     0 |     0 |    82 |     0 |     0 |     0 |     0 | 0,0000\r\n        5 ||     0 |     0 |     0 |     0 |     3 |    74 |     0 |     0 |     0 |     7 |     0 | 0,8810\r\n        6 ||     0 |     0 |     0 |     0 |    83 |     0 |     0 |     0 |     0 |     0 |     1 | 0,0000\r\n        7 ||     0 |     0 |     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n        8 ||     2 |     0 |    76 |     0 |     0 |     0 |     0 |     6 |     0 |     0 |     0 | 0,0000\r\n        9 ||     0 |    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n       10 ||    84 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 0,0000\r\n          ||========================================================================================\r\nPrecision ||0,0337 |0,0000 |0,0357 |0,0000 |0,0000 |0,9024 |0,0000 |0,0000 |0,0000 |0,0000 |0,0000 |\r\n```\r\n\r\nI think there is an expectation somewhere that the label == the label index.\r\n\r\n### Source code / logs\r\n```\r\n            var trainingDataView = mlContext.Data.LoadFromEnumerable(trainingDataArray, schemaDef);\r\n            var testDataView = mlContext.Data.LoadFromEnumerable(testDataArray, schemaDef);\r\n\r\n            var featureNames = typeof(RecordFeatures).GetProperties().Where(p => p.Name != nameof(RecordFeatures.Label)).Select(p => p.Name).ToArray();\r\n\r\n            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"KeyColumn\", inputColumnName: nameof(RecordFeatures.Label))\r\n                                                                       .Append(mlContext.Transforms.Concatenate(\"Features\", featureNames))\r\n                                                                       .AppendCacheCheckpoint(mlContext);\r\n\r\n            var trainer = mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName: \"KeyColumn\", featureColumnName: \"Features\");\r\n          \r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n            Console.WriteLine(\"=============== Training the model ===============\");\r\n            var trainedModel = trainingPipeline.Fit(trainingDataView);\r\n\r\n            Console.WriteLine(\"===== Evaluating Model's accuracy with Test data =====\");\r\n            var predictions = trainedModel.Transform(testDataView);\r\n            var metrics = mlContext.MulticlassClassification.Evaluate(predictions, \"Label\", \"Score\");\r\n\r\n            PrintMultiClassClassificationMetrics(trainer.ToString(), metrics);\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3773","RelatedDescription":"Open issue \"Incorrect metrics when the order of labels do not correspond to the indices in multiclassification\" (#3773)"},{"Id":"447896097","IsPullRequest":true,"CreatedAt":"2019-05-23T22:12:46","Actor":"yaeldekel","Number":"3772","RawContent":null,"Title":"Fix the user name in LoadableClassAttribute of VectorToImageTransformer","State":"open","Body":"Update user name in loadable class attribute to the right name.","Url":"https://github.com/dotnet/machinelearning/pull/3772","RelatedDescription":"Open PR \"Fix the user name in LoadableClassAttribute of VectorToImageTransformer\" (#3772)"},{"Id":"447665443","IsPullRequest":false,"CreatedAt":"2019-05-23T13:32:42","Actor":"sharpwood","Number":"3771","RawContent":null,"Title":"Are there any algorithms that are independent of native libraries and can run in xamarin forms?","State":"open","Body":"Are there any algorithms that are independent of native libraries and can run in xamarin forms?","Url":"https://github.com/dotnet/machinelearning/issues/3771","RelatedDescription":"Open issue \"Are there any algorithms that are independent of native libraries and can run in xamarin forms?\" (#3771)"},{"Id":"447593748","IsPullRequest":false,"CreatedAt":"2019-05-23T11:12:23","Actor":"PeterPann23","Number":"3770","RawContent":null,"Title":"AutoML feature request for TensorFlow","State":"open","Body":"Would be nice to see some TensorFlow integration in AutoML.\r\nOne find nice Multiclass Iris prediction with TensorFlow in Python in the web. \r\nWould be nice to see it implemented in AutoMl as I guess it's a good _bootstrap'er_  for those that would like to implement it. ","Url":"https://github.com/dotnet/machinelearning/issues/3770","RelatedDescription":"Open issue \"AutoML feature request for TensorFlow\" (#3770)"},{"Id":"447498029","IsPullRequest":false,"CreatedAt":"2019-05-23T07:42:42","Actor":"PeterPann23","Number":"3769","RawContent":null,"Title":"ConfusionMatrix.GetFormattedConfusionTable() sorts on arbitrary in order found on disk ","State":"open","Body":"\r\n[Enter feedback here]\r\nWhen training a MultiClass you will/can discover the classes in a random order.\r\nThe \"random\" order is then indexed and repeated in the labels. \r\nOne can influence the order using keyOrdinality in MlContext.Transforms.Conversion.MapValueToKey \r\n\r\n```\r\n//     How items should be ordered when vectorized. If Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByOccurrence\r\n//     chosen they will be in the order encountered. If Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByValue,\r\n```\r\n\r\nThe Y axis does map the index to a label, this helps but it would be better to allow users to sort on the label to get a consistent layout as well as allow the user to use cast the labels back to enumerable classes (if this is what is used for the labels) and sort in order of the enumerable.   \r\n\r\nTo \"fix\" report formatting one should not have to alter the learning pipeline, these are 2 separate concerns. \r\n\r\n\r\n---\r\n#### Document Details\r\n\r\nâš  *Do not edit this section. It is required for docs.microsoft.com âžŸ GitHub issue linking.*\r\n\r\n* ID: a65b98b6-bd97-8615-8f5f-827305a203c1\r\n* Version Independent ID: 6975eed6-3d30-cb7d-295d-edce198c2e43\r\n* Content: [ConfusionMatrix.GetFormattedConfusionTable Method (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.confusionmatrix.getformattedconfusiontable?f1url=https%3A%2F%2Fmsdn.microsoft.com%2Fquery%2Fdev15.query%3FappId%3DDev15IDEF1%26l%3DEN-US%26k%3Dk(Microsoft.ML.Data.ConfusionMatrix.GetFormattedConfusionTable);k(SolutionItemsProject);k(TargetFrameworkMoniker-.NETFramework,Version%3Dv4.7.2);k(DevLang-csharp)%26rd%3Dtrue&view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Data/ConfusionMatrix.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/ConfusionMatrix.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/3769","RelatedDescription":"Open issue \"ConfusionMatrix.GetFormattedConfusionTable() sorts on arbitrary in order found on disk \" (#3769)"},{"Id":"447032608","IsPullRequest":true,"CreatedAt":"2019-05-22T21:46:50","Actor":"codemzs","Number":"3763","RawContent":null,"Title":"Access indices array for VBuffer in KeyToVector transformer only when resulting vector is sparse.","State":"closed","Body":"fixes #3757\r\nfixes #1751\r\nfixes #2678","Url":"https://github.com/dotnet/machinelearning/pull/3763","RelatedDescription":"Closed or merged PR \"Access indices array for VBuffer in KeyToVector transformer only when resulting vector is sparse.\" (#3763)"},{"Id":"446813574","IsPullRequest":false,"CreatedAt":"2019-05-22T21:46:49","Actor":"lisahua","Number":"3757","RawContent":null,"Title":"KeyToVectorMappingTransformer: Index was outside the bounds of the array.","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: 1.0.0\r\n- **.NET Version (eg., dotnet --info)**: 4.6.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** Apply Normalization superviseBin and OneHot, \r\n- **What happened?** Got \"Index was outside the bounds of the array.\"\r\n- **What did you expect?** No error\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\n```\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n            var dataPath = \"test1.csv\";\r\n            var featureName = \"Features\";\r\n            var loader = mlContext.Data.CreateTextLoader(new[] \r\n            {\r\n                new TextLoader.Column(\"int1\", DataKind.Int64, 0),\r\n                new TextLoader.Column(\"int2\", DataKind.Int64, 1),\r\n                new TextLoader.Column(\"Label\", DataKind.Boolean, 2),\r\n            }, hasHeader: true, separatorChar: ',');\r\n\r\n            var data = loader.Load(dataPath);\r\n            var learningPipeline = mlContext.Transforms.Conversion.ConvertType(\"int1\", outputKind: DataKind.Single)\r\n                    .Append(mlContext.Transforms.Conversion.ConvertType(\"int2\", outputKind: DataKind.Single))\r\n                    .Append(mlContext.Transforms.Concatenate(featureName, new string[] { \"int1\", \"int2\" }))\r\n                    .Append(mlContext.Transforms.NormalizeSupervisedBinning(featureName, fixZero: false, maximumBinCount: 5, labelColumnName: \"Label\"))\r\n                    .Append(mlContext.Transforms.Categorical.OneHotEncoding(featureName, outputKind: OneHotEncodingEstimator.OutputKind.Indicator));\r\n            learningPipeline.Fit(data).Transform(data).Preview();\r\n```\r\n\r\n```\r\nint1, int2, label\r\n301, 2000, true\r\n450, 3000, true\r\n-300, 4000, true\r\n300, 2000, false\r\n115, 2000, false\r\n115, 2000, false\r\n```\r\n\r\nI think it is related to [issue 1751](https://github.com/dotnet/machinelearning/issues/1751) And based on the discussion for this issue,  I tried \r\n- adding MapKeyToValue() but no help.\r\n- OneHotEncode cannot be easily removed, we want to treat binning as categorical feature. \r\n\r\n```\r\n            MLContext mlContext = new MLContext(seed: 0);\r\n            var dataPath = \"test1.csv\";\r\n            var featureName = \"Features\";\r\n            var loader = mlContext.Data.CreateTextLoader(new[] \r\n            {\r\n                new TextLoader.Column(\"int1\", DataKind.Int64, 0),\r\n                new TextLoader.Column(\"int2\", DataKind.Int64, 1),\r\n                new TextLoader.Column(\"Label\", DataKind.Boolean, 2),\r\n            }, hasHeader: true, separatorChar: ',');\r\n\r\n            var data = loader.Load(dataPath);\r\n            var learningPipeline = mlContext.Transforms.Conversion.ConvertType(\"int1\", outputKind: DataKind.Single)\r\n                    .Append(mlContext.Transforms.Conversion.ConvertType(\"int2\", outputKind: DataKind.Single))\r\n                    .Append(mlContext.Transforms.Conversion.MapValueToKey(\"Label\"))\r\n                    .Append(mlContext.Transforms.Concatenate(featureName, new string[] { \"int1\", \"int2\" }))\r\n                    .Append(mlContext.Transforms.NormalizeSupervisedBinning(featureName, fixZero: false, maximumBinCount: 5, labelColumnName: \"Label\"))\r\n                    .Append(mlContext.Transforms.Categorical.OneHotEncoding(featureName, outputKind: OneHotEncodingEstimator.OutputKind.Indicator))\r\n                    .Append(mlContext.Transforms.Conversion.MapKeyToValue(\"Label\"));\r\n            learningPipeline.Fit(data).Transform(data).Preview();\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3757","RelatedDescription":"Closed issue \"KeyToVectorMappingTransformer: Index was outside the bounds of the array.\" (#3757)"},{"Id":"447344339","IsPullRequest":false,"CreatedAt":"2019-05-22T21:09:20","Actor":"huy302","Number":"3767","RawContent":null,"Title":"OneHotEncoder on array of strings","State":"open","Body":"I couldn't find an example to run OneHotEncoder on an array of strings. From the sample code at https://github.com/dotnet/machinelearning/issues/2678 is it just as simple as ctx.Transforms.Categorical.OneHotEncoding(\"A\")? Preview function is yet to be fixed in ml.net 1.0.0 so I can't tell if it gives the desired result.\r\n\r\nThanks","Url":"https://github.com/dotnet/machinelearning/issues/3767","RelatedDescription":"Open issue \"OneHotEncoder on array of strings\" (#3767)"},{"Id":"446852458","IsPullRequest":true,"CreatedAt":"2019-05-22T20:49:52","Actor":"zeahmed","Number":"3758","RawContent":null,"Title":"Upgraded the TensorFlow version from 1.12.0 to 1.13.1","State":"closed","Body":"Upgraded the TensorFlow version from 1.12.0 to 1.13.1. Cannot upgrade to version 2.0 as it is currently in alpha.","Url":"https://github.com/dotnet/machinelearning/pull/3758","RelatedDescription":"Closed or merged PR \"Upgraded the TensorFlow version from 1.12.0 to 1.13.1\" (#3758)"},{"Id":"446765034","IsPullRequest":false,"CreatedAt":"2019-05-22T15:33:01","Actor":"prathyusha12345","Number":"3754","RawContent":null,"Title":"some Binary Classification trainers are giving excception \"Probability column not found\"","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Winows\r\n\r\n### Issue\r\n\r\nI am trying to do binary classification on dataset  at url  \"https://archive.ics.uci.edu/ml/datasets/URL+Reputation\" to classify an URL is malicious or not.\r\nI am trying to use different binary classification trainer to see which one gives better metrics. while doing that I am getting exception **Probability column  'Probability' not found\r\nParameter name: schema**  with some trainers below.\r\n-SDCANonCalibrated\r\n-SgdNonCalibrated\r\n-AveragedPerceptron\r\n-LinearSvm\r\n\r\n![image](https://user-images.githubusercontent.com/22335043/58121421-44cf1180-7bbc-11e9-98cb-bf111af73956.png)\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\n class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            string dataReltivePath = @\"Data/url_svmlight/\";\r\n            //string dataPath = GetAbsolutePath(dataReltivePath);\r\n            string dataPath = \"../../../url_svmlight/*\";\r\n            string testDataRelativePath = @\"../../../Data/test/Day21.svm\";\r\n            string testDataPath = GetAbsolutePath(testDataRelativePath);\r\n\r\n            //STEP 1: Create MLContext to be shared across the model creation workflow objects \r\n            MLContext mlContext = new MLContext();\r\n\r\n            //STEP 2: Read the trained data using TextLoader by defining the schema for reading the product co-purchase dataset\r\n            //        Do remember to replace amazon0302.txt with dataset from https://snap.stanford.edu/data/amazon0302.html\r\n            var traindata = mlContext.Data.LoadFromTextFile(path: dataPath,\r\n                                                      columns: new[]\r\n                                                                {\r\n                                                                    new TextLoader.Column(\"Label\", DataKind.Boolean, 0),\r\n                                                                    new TextLoader.Column(name:nameof(UrlData.FeatureVector), dataKind:DataKind.Single, source: new [] { new TextLoader.Range(1, 3231961) }),\r\n                                                                },\r\n                                                      hasHeader: true,\r\n                                                      separatorChar: ' ',\r\n                                                      allowSparse:true);\r\n\r\n            var testDataView = mlContext.Data.LoadFromTextFile(testDataPath,\r\n                columns: new[]\r\n                                                                {\r\n                                                                    new TextLoader.Column(\"Label\", DataKind.Boolean, 0),\r\n                                                                    new TextLoader.Column(name:nameof(UrlData.FeatureVector), dataKind:DataKind.Single, source: new [] { new TextLoader.Range(1, 3231961) }),\r\n                                                                },\r\n\r\n                hasHeader: true, separatorChar: ' ', allowSparse: true);\r\n\r\n            var est = mlContext.BinaryClassification.Trainers.SgdCalibrated(labelColumnName: \"Label\", featureColumnName: \"FeatureVector\");\r\n         \r\n            Console.WriteLine(\"====Training the model=====\");\r\n\r\n            var model = est.Fit(traindata);\r\n   }\r\n}\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3754","RelatedDescription":"Closed issue \"some Binary Classification trainers are giving excception \"Probability column not found\"\" (#3754)"},{"Id":"445992438","IsPullRequest":false,"CreatedAt":"2019-05-22T15:31:49","Actor":"PeterPann23","Number":"3748","RawContent":null,"Title":"Add sample for use with Binary dataset","State":"closed","Body":"\r\n[Enter feedback here]\r\n\r\nWould be nice to show how a binary file can be used (and re-used) to use strong typed data\r\n---\r\n#### Document Details\r\n\r\nâš  *Do not edit this section. It is required for docs.microsoft.com âžŸ GitHub issue linking.*\r\n\r\n* ID: d77f7787-449e-9eeb-9dc8-e7ca22091538\r\n* Version Independent ID: 2dca3efe-4be8-72c3-0e71-226c2183cc89\r\n* Content: [DataOperationsCatalog.CreateEnumerable(IDataView, Boolean, Boolean, SchemaDefinition) Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.createenumerable?f1url=https%3A%2F%2Fmsdn.microsoft.com%2Fquery%2Fdev15.query%3FappId%3DDev15IDEF1%26l%3DEN-US%26k%3Dk(Microsoft.ML.DataOperationsCatalog.CreateEnumerable%60%601);k(SolutionItemsProject);k(DevLang-csharp)%26rd%3Dtrue&view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/3748","RelatedDescription":"Closed issue \"Add sample for use with Binary dataset\" (#3748)"},{"Id":"447108222","IsPullRequest":false,"CreatedAt":"2019-05-22T12:30:42","Actor":"rauhs","Number":"3766","RawContent":null,"Title":"Does GetFeatureWeights support categorical splits?","State":"open","Body":"Version: 1.0\r\n\r\nI'm training my multi class LightGBM with mostly categorical features (which works great). But when I want to get the `GetFeatureWeights` from the binary predictors I get huge values for feature of index `-1`. Though, just inspecting the models in the debugger the trees almost exclusively use categorical features for the splits. It seems that the `GainMap` doesn't actually consider any categorical splits and just assigns all those gains to the index `-1` which makes the feature weights vector completely useless in my case.\r\n\r\nIs this something that will be supported? Or am I wrong here?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3766","RelatedDescription":"Open issue \"Does GetFeatureWeights support categorical splits?\" (#3766)"},{"Id":"447097534","IsPullRequest":false,"CreatedAt":"2019-05-22T12:06:46","Actor":"rauhs","Number":"3765","RawContent":null,"Title":"How to get LightGBM multiclass calibrated","State":"open","Body":"Version: 1.0\r\n\r\nAfter training the a multi class LightGBM predictor it seems the Platt calibrator on each model has the fixed parameter of 0, and -0.5:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/3798bf8b73a2ce83a526326e05639d54a331fbdd/src/Microsoft.ML.LightGbm/LightGbmMulticlassTrainer.cs#L185-L191\r\n\r\nIs that on purpose? How can I get a calibrated predictor?","Url":"https://github.com/dotnet/machinelearning/issues/3765","RelatedDescription":"Open issue \"How to get LightGBM multiclass calibrated\" (#3765)"},{"Id":"447048620","IsPullRequest":false,"CreatedAt":"2019-05-22T10:11:21","Actor":"korneliuscode","Number":"3764","RawContent":null,"Title":"Unable to load DLL 'CpuMathNative'","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 x64 (1809 17763.503) and x86 (1809 17763.503)\r\n- **.NET Version (eg., dotnet --info)**:\r\n```\r\n.NET Core SDK (reflecting any global.json):\r\n Version:   2.1.700-preview-009597\r\n Commit:    96b18bcb5c\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.17763\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\2.1.700-preview-009597\\\r\n\r\nHost (useful for support):\r\n  Version: 2.1.9\r\n  Commit:  dcedc87d22\r\n\r\n.NET Core SDKs installed:\r\n  2.1.601 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.602 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700-preview-009597 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET Core runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.8 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**: \r\nCreated a new .net standard project, added ML.NET from nuget and added the project  to my existing solution (.net Framework 4.7.2). Both are set to Any CPU, as I [read that ML.NET also supports x86](https://devblogs.microsoft.com/dotnet/announcing-ml-net-0-7-machine-learning-net/#x86-support-in-addition-to-x64). The DLL Microsoft.ML.CpuMath.dll is present in the release folder.\r\n- **What happened?**: When creating the model I get the exception as shown below in \"logs\"\r\n- **What did you expect?**: Creating the model as expected.\r\n\r\n### Source code / logs\r\n\r\n```\r\n05/21/2019 16:15:32: Runtime terminating: True\r\n05/22/2019 11:58:37: System.InvalidOperationException: Shuffle input cursor reader failed with an exception ---> System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data ---> System.DllNotFoundException: Unable to load DLL 'CpuMathNative': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n   at Microsoft.ML.Internal.CpuMath.Thunk.SumSqU(Single* ps, Int32 c)\r\n   at Microsoft.ML.Transforms.LpNormNormalizingTransformer.Mapper.<>c__DisplayClass6_0.<MakeGetter>b__5(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.BoundColumn.<>c__DisplayClass18_0`1.<MakeGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass5_1.<ConsolidateCore>b__2()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.<LoopProducerWorker>d__31.MoveNext()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.MoveNext()\r\n   at Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.StochasticTrainerBase`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3764","RelatedDescription":"Open issue \"Unable to load DLL 'CpuMathNative'\" (#3764)"},{"Id":"447025185","IsPullRequest":false,"CreatedAt":"2019-05-22T09:22:00","Actor":"PeterPann23","Number":"3762","RawContent":null,"Title":"Perhaps not a popular question but why are you not using the sample Gighub labeler","State":"open","Body":"Hi\r\n\r\nI don't want to poke but why are the items not getting labeled by something like the [github labeler](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/end-to-end-apps/MulticlassClassification-GitHubLabeler) sample found in the samples solution?\r\n\r\nWould help finding similar issues and re-use the answers provided (if still applicable in the current API)","Url":"https://github.com/dotnet/machinelearning/issues/3762","RelatedDescription":"Open issue \"Perhaps not a popular question but why are you not using the sample Gighub labeler\" (#3762)"},{"Id":"446949741","IsPullRequest":false,"CreatedAt":"2019-05-22T06:12:18","Actor":"PeterPann23","Number":"3761","RawContent":null,"Title":"The given key 'metric' was not present in the dictionary","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\nWindows 10\r\nWindows 2012\r\nWindows 2019\r\n- **.NET Version (eg., dotnet --info)**: \r\nCore 3.0                          Version 3.0.100-preview5-011568\r\nMicrosoft.ML.LightGbm  Version 1.0.0.0, Culture=neutral\r\nMicrosoft.ML                   Version 1.0.0.0\r\n\r\n### Issue\r\n- **What did you do?**\r\nLoad csv file as and train model loading by all floats in single vector \r\nsee code bellow\r\n\r\n- **What happened?**\r\nGet error _The given key 'metric' was not present in the dictionary_ during the training \r\n\r\n- **What did you expect?**\r\nNot sure why I get the error, also I do not mention a key metric.\r\n\r\n### Source code / logs\r\nThe error:\r\n```\r\n[Source=LightGBMMulticlass; Training with LightGBM, Kind=Trace] Channel disposed. Elapsed 00:00:04.0970203\r\n.57.erLeaf = 5059.0337420.\r\nError stack    at System.Collections.Generic.Dictionary`2.get_Item(TKey key)r_6_MinTicks_In_15Sec_B_ND.tsv\r\n   at Microsoft.ML.Trainers.LightGbm.WrappedLightGbmTraining.Train(IChannel ch, IProgressChannel pch, Dictionary`2 param\r\neters, Dataset dtrain, Dataset dvalid, Int32 numIteration, Boolean verboseEval, Int32 earlyStoppingRound)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainCore(IChannel ch, IProgressChannel pch, Dataset dtrain,\r\nCategoricalMetaData catMetaData, Dataset dvalid)\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredic\r\ntor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Cats.DeepBookTrainer.Infrastructure.Trainer.ExecuteLightGbm(ITransformer& transformer, Nullable`1 maxIterations, N\r\nullable`1 maxThreads) \r\n```\r\n\r\nData Loading:\r\n```\r\npublic static IDataView GetDataViewAsVector(MLContext mlContext, FileInfo trainingFile, int labelIndex=1, char[] separators = null, long? maxRows = null, bool makeBin=false)\r\n{\r\n    if (separators is null)\r\n        separators = new[] { '|' };\r\n\r\n    var loader = mlContext.Data.CreateTextLoader(options: new TextLoader.Options()\r\n    {\r\n        Columns = new[] {\r\n            new TextLoader.Column(name:\"Label\", dataKind: DataKind.String, index: labelIndex),\r\n            new TextLoader.Column(name:\"RawFeatures\",dataKind:DataKind.Single,minIndex:2,maxIndex:40732)\r\n        },\r\n        HasHeader = false,\r\n        Separators = separators,\r\n        UseThreads = false,\r\n        MaxRows=maxRows\r\n    });\r\n    var dv = loader.Load(trainingFile.FullName);\r\n    return dv;\r\n}\r\n```\r\n\r\n\r\nPipeline:\r\n```\r\nhorizonDataset = mlContext.Data.TrainTestSplit(DataViewUtils.GetDataViewAsVector(mlContext, trainingFile, labelIndex: 1, separators: new[] {'|'}));\r\n\r\nvar options = new LightGbmMulticlassTrainer.Options\r\n{\r\n    LabelColumnName = \"KeyColumn\",\r\n    FeatureColumnName = Features,\r\n    Silent = false,\r\n    Verbose = true,\r\n    EvaluationMetric = LightGbmMulticlassTrainer.Options.EvaluateMetricType.Default,\r\n    UseSoftmax       = true,\r\n    NumberOfThreads  = 1,                \r\n};\r\n\r\nvar featureColumns = Mapper.GetFieldNames();\r\nvar pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"KeyColumn\", inputColumnName: \"Label\")\r\n        .Append(mlContext.Transforms.NormalizeMinMax(outputColumnName: \"Features\", inputColumnName: \"RawFeatures\"))\r\n        .AppendCacheCheckpoint(mlContext)\r\n        .Append(mlContext.MulticlassClassification.Trainers.LightGbm(options))\r\n        .Append(mlContext.Transforms.CopyColumns(inputColumnName: \"KeyColumn\", outputColumnName: nameof(PredictedResult.PredictedLabelIndex)))\r\n```\r\nLine throwing the error \r\n`var model = pipeline.Fit(horizonDataset.TrainSet);`","Url":"https://github.com/dotnet/machinelearning/issues/3761","RelatedDescription":"Open issue \"The given key 'metric' was not present in the dictionary\" (#3761)"},{"Id":"446911675","IsPullRequest":false,"CreatedAt":"2019-05-22T03:07:43","Actor":"yaeldekel","Number":"3760","RawContent":null,"Title":"Implement Doc2vec text featurization","State":"open","Body":"This was brought up in issue #3743 .","Url":"https://github.com/dotnet/machinelearning/issues/3760","RelatedDescription":"Open issue \"Implement Doc2vec text featurization\" (#3760)"},{"Id":"446876120","IsPullRequest":false,"CreatedAt":"2019-05-22T00:07:48","Actor":"klausmh","Number":"3759","RawContent":null,"Title":"Support custom mapping without type parameters","State":"open","Body":"ML.NET supports [custom mappings](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.custommappingcatalog.custommapping?view=ml-dotnet) if a source and destination type are specified statically.\r\n\r\nWould it also be possible to support this in a dynamic setting, i.e., doing custom mappings from IDataView to IDataView?","Url":"https://github.com/dotnet/machinelearning/issues/3759","RelatedDescription":"Open issue \"Support custom mapping without type parameters\" (#3759)"},{"Id":"446778780","IsPullRequest":false,"CreatedAt":"2019-05-21T19:09:44","Actor":"daholste","Number":"3756","RawContent":null,"Title":"Potential memory leak when training?","State":"open","Body":"I modified a project in the samples repo to repro:\r\n\r\nhttps://github.com/daholste/machinelearning-samples/commit/577946224747959759ca1b4da9fd86f77eea81a9\r\n\r\nIf breakpoint at https://github.com/daholste/machinelearning-samples/blob/577946224747959759ca1b4da9fd86f77eea81a9/samples/csharp/getting-started/BinaryClassification_SentimentAnalysis/SentimentAnalysis/SentimentAnalysisConsoleApp/Program.cs#L52 , each model that is trained, the memory usage of the process consistently increases by about 80 MB (especially after the first few iterations of the loop).\r\n\r\nWhen the model is compressed & saved to disk, the size of the model file is only about 4.5 MB.\r\n\r\nWhen loading the saved model back into memory, memory of the process appears to jump by around 50 MB. (When loading the model several times back from disk to memory in the same process, average size of the model appears to be around 40 MB in memory. Not sure why. Perhaps string pooling? Not sure.)\r\n\r\nIs this a memory leak? \r\n80 MB of memory taken up by training model - 50 MB megabytes of same model serialized / deserialized = 30 MB of leakage?\r\nOr, does serializing / deserializing the model potentially restructure the data structures to use memory more efficiently?","Url":"https://github.com/dotnet/machinelearning/issues/3756","RelatedDescription":"Open issue \"Potential memory leak when training?\" (#3756)"},{"Id":"446776675","IsPullRequest":false,"CreatedAt":"2019-05-21T19:04:21","Actor":"ganik","Number":"3755","RawContent":null,"Title":"Model summary to show tree details for FastTree","State":"open","Body":"Currently model summary doesnt show trees and split points for FastTree models.\r\nFastTree model needs to implement ICanGetSummaryAsIDataView that would dump this info.","Url":"https://github.com/dotnet/machinelearning/issues/3755","RelatedDescription":"Open issue \"Model summary to show tree details for FastTree\" (#3755)"},{"Id":"446361548","IsPullRequest":false,"CreatedAt":"2019-05-21T00:11:15","Actor":"prathyusha12345","Number":"3751","RawContent":null,"Title":"Model is predicting null when a user used CustomModel in TensorFlow Image Classification","State":"open","Body":"User has reported issue in Machine Learning samples https://github.com/dotnet/machinelearning-samples/issues/468 \r\n\r\n I have used the custom model and labels.txt provided by user in [TensorFlow image classification sample](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow) and changed the model pipeLine for Tensor input and output as shown below.\r\n\r\n```\r\nvar pipeline = mlContext.Transforms.LoadImages(outputColumnName: \"Placeholder\", imageFolder: imagesFolder, inputColumnName: nameof(ImageNetData.ImagePath))\r\n                           .Append(mlContext.Transforms.ResizeImages(outputColumnName: \"Placeholder\", imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: \"Placeholder\"))\r\n                           .Append(mlContext.Transforms.ExtractPixels(outputColumnName: \"Placeholder\", interleavePixelColors: ImageNetSettings.channelsLast, offsetImage: ImageNetSettings.mean))\r\n                           .Append(mlContext.Model.LoadTensorFlowModel(modelLocation).\r\n                           ScoreTensorFlowModel(outputColumnNames: new[] { \"loss\" },\r\n                                               inputColumnNames: new[] { \"Placeholder\" }, addBatchDimensionInput: true));\r\n```\r\n\r\nWhile predicting an image using the prediction engine, the model is not predicting anything and its giving predictedLabels value as null.\r\n\r\n`var probs = model.Predict(sample).PredictedLabels;`\r\n\r\n![image](https://user-images.githubusercontent.com/22335043/58059536-38967600-7b22-11e9-91e2-ec6263e3ceba.png)\r\n\r\n\r\nCould any one let me know why the model is not predicting any label?","Url":"https://github.com/dotnet/machinelearning/issues/3751","RelatedDescription":"Open issue \"Model is predicting null when a user used CustomModel in TensorFlow Image Classification\" (#3751)"},{"Id":"446292589","IsPullRequest":false,"CreatedAt":"2019-05-20T20:20:42","Actor":"PeterPann23","Number":"3750","RawContent":null,"Title":"AutoML Code generation generates failing code if the CSV provided have a header named Label","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\nwindows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nAutoMl Wizard Rel 0.3.0\r\n### Issue\r\n\r\n- **What did you do?**\r\nCreated a CSV file for the wizard with a column that it needed to predict with the name Label\r\n- **What happened?**\r\nThe code generation created a KeyValue mapper with Label =>Label and PredictedLabel=>PredictedLabel \r\n\r\n\r\n```\r\npublic static IEstimator<ITransformer> BuildTrainingPipeline(MLContext mlContext)\r\n{\r\n\t// Data process configuration with pipeline data transformations \r\n\tvar dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(\"Label\", \"Label\")\r\n\t\t\t\t\t\t\t  .Append(mlContext.Transforms.Concatenate(\"Features\", new[] { \"F1\", \"F2\", \"F3\"}));\r\n\r\n\t// Set the training algorithm \r\n\tvar trainer = mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName: \"Label\", featureColumnName: \"Features\")\r\n\t\t\t\t\t\t\t  .Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\", \"PredictedLabel\"));\r\n\tvar trainingPipeline = dataProcessPipeline.Append(trainer);\r\n\r\n\treturn trainingPipeline;\r\n}\r\n```\r\nWhen executing the training the code fails here\r\n\r\n![sample fails](https://user-images.githubusercontent.com/44400822/58049408-15cd8700-7b4d-11e9-989c-5d7c430f581c.PNG)\r\n\r\n\r\n\r\n- **What did you expect?**\r\nWriting code that covers all possible issues is hard however as MapValueToKey goes to an internal field and MapKeyToValue cpmes from that internal field it might help not using the same name.\r\nWould be nice if the starter project would work, gives those that give the project a spin a positive vibe.\r\n\r\nPerhaps warn the user that he may needs to change the code, if this occurs, better would be if the issue doesn't happen.\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3750","RelatedDescription":"Open issue \"AutoML Code generation generates failing code if the CSV provided have a header named Label\" (#3750)"},{"Id":"446271599","IsPullRequest":false,"CreatedAt":"2019-05-20T19:24:18","Actor":"markusmobius","Number":"3749","RawContent":null,"Title":"maxExperimentTimeInSeconds - possible to make it deterministic across machines","State":"open","Body":"We started using AutoML to classify about 15000 daily news articles into 50 topics (our early results with AutoML are excellent). We get a training set from a different pipeline that identifies with high precision topics (a community detection algorithm which works well in identifying natural daily topics but has poor recall). We use AutoML to train a multiclass classifier using the output from the first pipeline as the training set. We found that we get best recall by running AutoML a number of times (right now we use 9 times) and only use articles which are assigned to the same topic in a majority of cases with a threshold for the max score (our training set covers about 15% of articles in the daily corpus, a single run of Automl increases to about 25% and the multiple-run hack increases it to 35%).\r\n\r\nOne thing which we don't understand is the maxExperimentTimeInSeconds parameter when calling: \r\nCreateMulticlassClassificationExperiment\r\n\r\nWe are running AutoML across different machines on Windows and Linux with different cores etc. We found that the depth of the experiment pipeline varies a lot across machines - maybe because things take longer on less powerful servers.\r\n\r\nIt would be great if one could control the depth of the AutoML search by another way than maxExperimentTimeInSeconds. \r\n\r\nPossibly related issue: we found that when running AutoML as part of process that consumes about 60GB of memory the experiment take double as long as when we run it with the same data on its own. Moreover, when calling autoML successively (even when creating a new mlContext) the runtimes becomes longer and longer and the depth of the AutoML search becomes shorter (even with maxExperimentTimeInSeconds constant).\r\n\r\nWe therefore now run the AutoML pipeline in a separate child process (one run at a time, then destroy the child process and start fresh; memory consumption is about 2G per run) which produces similar runtimes and depth across runs. But it would be nice to avoid this.","Url":"https://github.com/dotnet/machinelearning/issues/3749","RelatedDescription":"Open issue \"maxExperimentTimeInSeconds - possible to make it deterministic across machines\" (#3749)"},{"Id":"445962127","IsPullRequest":false,"CreatedAt":"2019-05-20T07:28:21","Actor":"PeterPann23","Number":"3747","RawContent":null,"Title":"Feels like an endless loop","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\nWindows Server 2019, \r\nWindows Server 2012, \r\nWindows 10\r\n\r\n- **.NET Version (eg., dotnet --info)**: \r\nDot net Core 3.0\r\nML 1.0.0\r\n[Dump header.txt](https://github.com/dotnet/machinelearning/files/3196652/Dump.header.txt)\r\n\r\n\r\n\r\n### Issue\r\n- **What did you do?**\r\nApplied the following training against a binary dataset of 77.7 Gb\r\n\r\n```\r\nvar featureColumns = Mapper.GetFieldNames();\r\nvar pipeline = mlContext.Transforms.Concatenate(outputColumnName: RawFeatures, inputColumnNames: featureColumns)\r\n        .Append(mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: KeyColumn, inputColumnName: Label))\r\n        .Append(mlContext.Transforms.NormalizeMinMax(outputColumnName:Features,inputColumnName: RawFeatures))\r\n        .Append(mlContext.MulticlassClassification.Trainers.LightGbm(options))\r\n        .Append(mlContext.Transforms.CopyColumns(inputColumnName: KeyColumn, outputColumnName: nameof(PredictedResult.PredictedLabelIndex)));\r\nvar model = pipeline.Fit(horizonDataset.TrainSet);\r\n```\r\nCreated the data set from a Tab Separated file size 398 GB\r\n\r\n- **What happened?**\r\n After some time the trainer seems to loop in memory and CPU performance idles at bellow 20% \r\n![Attached Debugger](https://user-images.githubusercontent.com/44400822/58003126-6955bb80-7ae0-11e9-8f5b-d572f7f86bf2.PNG)\r\n\r\n\r\n![Attached Debugger2](https://user-images.githubusercontent.com/44400822/58003354-df5a2280-7ae0-11e9-9fc6-a36030517221.PNG)\r\n\r\n\r\n- **What did you expect?**\r\nExpect the model to train in a linear manner in the same way as a smaller dataset does, where each GB takes a approximate time, multiply the GB and you get a projected finish time.\r\n\r\nI have reported this several times already, it is hard to discover if the system is \"alive\" or looping this becomes problematic after a few days of no feedback. if you need to access my process perhaps we do a live share session\r\n\r\n### Source code / logs\r\n\r\n[MLContext Log](https://github.com/dotnet/machinelearning/files/3196620/2019.05.19.102043_log.rpt.zip)","Url":"https://github.com/dotnet/machinelearning/issues/3747","RelatedDescription":"Open issue \"Feels like an endless loop\" (#3747)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-05-26T05:30:32.8248887Z","RunDurationInMilliseconds":614}