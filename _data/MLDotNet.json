{"Data":{"GitHub":{"Issues":[{"Id":"467696100","IsPullRequest":false,"CreatedAt":"2019-07-13T09:18:27","Actor":"Suriman","Number":"3999","RawContent":null,"Title":"Possibility to specify the algorithm in AutoML","State":"open","Body":"There are scenarios where you know in advance the algorithms that will work better under certain data. In these cases, it would be very useful to specify through parameters what algorithms we want to test AutoML with different configuration parameters, so the time spent would be used to find better configurations of the specified algorithms, instead of trying algorithms that are known in advance to be to give worse results.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3999","RelatedDescription":"Open issue \"Possibility to specify the algorithm in AutoML\" (#3999)"},{"Id":"467636492","IsPullRequest":false,"CreatedAt":"2019-07-12T23:34:09","Actor":"pieths","Number":"3998","RawContent":null,"Title":"Support saving to ONNX for the OptionalColumnCreator transform","State":"open","Body":"When NimbusML creates pipelines for regressors, classifiers and rankers, it prepends an OptionalColumnCreator transform to the pipeline. These pipelines can not be exported in their entirety in the ONNX format because the OptionalColumnCreator is not exportable to ONNX.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3998","RelatedDescription":"Open issue \"Support saving to ONNX for the OptionalColumnCreator transform\" (#3998)"},{"Id":"467541066","IsPullRequest":false,"CreatedAt":"2019-07-12T18:18:16","Actor":"pieths","Number":"3997","RawContent":null,"Title":"Misleading error message when using Global Contrast Normalizer","State":"open","Body":"When attempting to fit a global contrast normalizer using NimbusML and providing a column of type float32 produces this error message:\r\n\r\n> Expected Single or known-size vector of Single, got Single\r\n\r\nThis error message seems to imply that using a column of type Single (float32) is valid. There are two places in `src\\Microsoft.ML.Transforms\\GcnTransform.cs` where this message is used. In either case a column of type vector is expected.\r\n\r\nShould this message be updated to be more clear about requiring a vector column?","Url":"https://github.com/dotnet/machinelearning/issues/3997","RelatedDescription":"Open issue \"Misleading error message when using Global Contrast Normalizer\" (#3997)"},{"Id":"467385182","IsPullRequest":false,"CreatedAt":"2019-07-12T16:56:33","Actor":"nighotatul","Number":"3996","RawContent":null,"Title":"How we load data in ml.net from sql server table?","State":"closed","Body":"right now, we are loading data in ml.net from csv file. but we want to load data in ml.net through sql server table or how we load data from datatable in ml.net. ","Url":"https://github.com/dotnet/machinelearning/issues/3996","RelatedDescription":"Closed issue \"How we load data in ml.net from sql server table?\" (#3996)"},{"Id":"467200962","IsPullRequest":false,"CreatedAt":"2019-07-12T03:19:02","Actor":"nicolehaugen","Number":"3995","RawContent":null,"Title":"Exception messages need to be richer\\clearer","State":"open","Body":"Many exception messages thrown are unclear - as a result, when an exception occurs, it's challenging to identify whether the issue in with the ML.NET code, with the underlying data, with how the algorithm is being applied, etc.  Often it takes stepping through the ML.NET fwk in attempt to get further context.\r\n\r\nI logged this as a single issue because I think there would be benefit in looking at all places where exceptions are being thrown\\rethrown to ensure that default exception messages aren't provided and that the messages are as clear\\rich as possible.  Let me know if you would like these broken into separate issues rather than having them combined in one.  \r\n\r\nHere are some specific examples:\r\n\r\n\r\n  | Trainer | Scenario | Actual Message | Suggested   Message\r\n-- | -- | -- | -- | --\r\n|1. | N/A | Occurs when invalid field index is provided to the LoadColumn   attribute.         For example:<br>``` [LoadColumn(100)]   public uint Label { get; set; }```<br>In the above code, the value of 100 is an invalid index value since   the underlying data has less than 100 columns. | System.ArgumentNullException: 'Value cannot be null.   Parameter   name: items' | Message should indicate which column has the issue; the reference to   parameter ‘items’ is unclear.|\r\n|2. | N/A | Occurs when Feature column is of some other type than float\\single.        For example: <br>``` [ColumnName(\"Test\"), LoadColumn(135)]   public uint Test { get; set; }``` | System.InvalidOperationException:   'Column ‘Test’ has values of UInt32, which is not the same as earlier   observed type of Single.' | It’s unclear what “same as earlier observed type” means.  Consider rewording to state that the   Feature columns must all be of a certain type (e.g. Single).\r\n|3. | LightGbm | Occurs when custom gains are specified without providing a group id   column.       For example:<br>```var customGains = new LightGbmRankingTrainer.Options();             customGains.CustomGains = new int[] { 0,   1, 2, 3 };IEstimator<ITransformer> trainer = mlContext.Ranking.Trainers.LightGbm(customGains);IEstimator<ITransformer> trainerPipeline =   dataPipeline.Append(trainer);```<br>Notice that in the above code, the Group Id isn’t being explicitly   set as follows:<br> ```customGains.RowGroupColumnName = \"GroupId\";``` | System.ArgumentOutOfRangeException: 'Need a group column.   Parameter   name: data' | ArgumentOutOfRangeException is confusing; instead, throw ArgumentNullException   or InvalidOperationException.       Message should also indicate the ‘Group Id’ column is missing\\null;   the reference to parameter ‘data’ is unclear.\r\n|4. | LightGbm | Occurs when custom gains cardinality doesn’t match the cardinality of  the relevance label values.         For example:<br>```var customGains = new LightGbmRankingTrainer.Options(); customGains.CustomGains  = new int[] { 0, 1, 2 };                customGains.RowGroupColumnName = \"GroupId\";```<br>In the underlying data, the relevance label values are: {0, 1, 2, 3,   4 } – in other words, the cardinality of the relevance label values is   greater than the specified custom gains. | System.InvalidOperationException:   'LightGBM Error, code is -1, error message is 'label (0) excel the max range   3'.' | There appears to be a typo – “excel” should say “exceeds”.  Also, the message should state that the   cardinality of the relevance label values must less than or equal to the   cardinality of the custom gains.       Note: Refer to similar issue logged directly against LightGBM: https://github.com/Microsoft/LightGBM/issues/1090\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3995","RelatedDescription":"Open issue \"Exception messages need to be richer\\clearer\" (#3995)"},{"Id":"467191139","IsPullRequest":false,"CreatedAt":"2019-07-12T02:34:56","Actor":"nicolehaugen","Number":"3994","RawContent":null,"Title":"Docs show using VectorType instead of concatenating features","State":"open","Body":"Numerous places in the docs, we show to store features as a VectorType.  However, this isn't ideal because it doesn't allow you to easily do feature engineering where you pick\\choose the most influential features to include when training a model.  Instead, to easily support feature engineering, it's recommended to concatenate your features as part of the pipeline. \r\n\r\nFor example, here are a few places where we show using a VectorType:\r\n1.) https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/load-data-ml-net#create-the-data-model\r\n2.) https://github.com/dotnet/machinelearning/blob/master/docs/code/MlNetCookBook.md#how-do-i-load-data-from-a-text-file\r\n\r\nInstead, we should show feature concatenation and explain why this is a preferred approach - for example:\r\n```\r\n   IEstimator<ITransformer> dataPipeline = mlContext.Transforms.Concatenate(FeaturesVectorName, featureCols)\r\n                .Append(mlContext.Transforms.Conversion.MapValueToKey(nameof(SearchResultData.Label)))\r\n                .Append(mlContext.Transforms.Conversion.Hash(nameof(SearchResultData.GroupId), nameof(SearchResultData.GroupId), numberOfBits: 20));\r\n```\r\nAlso, why is there a VectorType attribute?  Are there ever benefits to using this?  If not, we should consider removing.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3994","RelatedDescription":"Open issue \"Docs show using VectorType instead of concatenating features\" (#3994)"},{"Id":"467170942","IsPullRequest":false,"CreatedAt":"2019-07-12T01:02:33","Actor":"nicolehaugen","Number":"3993","RawContent":null,"Title":"Exception is thrown if NDCG > 10 is used with LightGbm for evaluating ranking","State":"open","Body":"- Version: ML.NET 1.2.0\r\n\r\nThe current code in the RankingEvaluator.cs file has the MaxTruncationLevel for NDCG (Normalized Cumulative Gain Metric) set to 10.  Also, the code currently throws an exception if the NDCG is set to a value > 10.  This is a blocking issue for ranking because it prevents the ability to measure the quality of ranking with result sets > 10.  For example, if you were attempting to rank a group of 100 results, with the MaxTruncationLevel of 10, you could only measure whether the first 10 results were ranked correctly.\r\n\r\nHere's the code:\r\n\r\n```\r\n         public RankingEvaluator(IHostEnvironment env, Arguments args)\r\n            : base(env, LoadName)\r\n        {\r\n            // REVIEW: What kind of checking should be applied to labelGains?\r\n            if (args.DcgTruncationLevel <= 0 || args.DcgTruncationLevel > Aggregator.Counters.MaxTruncationLevel)\r\n                throw Host.ExceptUserArg(nameof(args.DcgTruncationLevel), \"DCG Truncation Level must be between 1 and {0}\", Aggregator.Counters.MaxTruncationLevel);\r\n            Host.CheckUserArg(args.LabelGains != null, nameof(args.LabelGains), \"Label gains cannot be null\");\r\n...\r\n}\r\n```\r\nIt appears from the //Review comment in the above code that this functionality hasn't been fully completed.  \r\n\r\nWhile I'm unsure what the MaxTruncationLevel value should be, I have seen on a ranking contest\\example on Kaggle.com where one contest was measuring NDCG with a truncation level of up to 38.  \r\n\r\nI also noticed that in other parts of this file, the code indicates that a value between 0-100 should be allowed:\r\n\r\n```\r\n public Transform(IHostEnvironment env, IDataView input, string labelCol, string scoreCol, string groupCol,\r\n                int truncationLevel, Double[] labelGains)\r\n                : base(env, input, labelCol, scoreCol, groupCol, RegistrationName)\r\n            {\r\n                Host.CheckParam(0 < truncationLevel && truncationLevel < 100, nameof(truncationLevel),\r\n                    \"Truncation level must be between 1 and 99\");\r\n...\r\n}\r\n```\r\n\r\nAlso, refer to the linked bug since it is related to this scenario: [Ranker Evaluate doesn't allow you specify metric parameters.] (https://github.com/dotnet/machinelearning/issues/2728)","Url":"https://github.com/dotnet/machinelearning/issues/3993","RelatedDescription":"Open issue \"Exception is thrown if NDCG > 10 is used with LightGbm for evaluating ranking\" (#3993)"},{"Id":"467103110","IsPullRequest":false,"CreatedAt":"2019-07-11T20:57:22","Actor":"artidoro","Number":"3992","RawContent":null,"Title":"FeaturizeText should allow only outputColumnName to be defined","State":"open","Body":"One of the extension methods for `FeaturizeText` needs both the `outputColumnName` and the `inputColumnNames` to be provided.\r\n\r\nThere is no compile error if `inputColumnNames` is not provided, only a runtime error.\r\n\r\nWe should fix the error so that when `inputColumnNames` is not provided, it is set to `new[] { outputColumnName }` as we do everywhere else in the code base.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c3bdaaa2a29f88a85dd91cde3fbb805001011903/src/Microsoft.ML.Transforms/Text/TextCatalog.cs#L60-L65","Url":"https://github.com/dotnet/machinelearning/issues/3992","RelatedDescription":"Open issue \"FeaturizeText should allow only outputColumnName to be defined\" (#3992)"},{"Id":"467100591","IsPullRequest":false,"CreatedAt":"2019-07-11T20:51:18","Actor":"nicolehaugen","Number":"3991","RawContent":null,"Title":"Need advanced filtering for downsampling","State":"open","Body":"- Version: ML.NET 1.2.1\r\n\r\nTo filter rows in a performance-friendly way and load the data into an IDataView, I attempted to use:\r\n```\r\n mlContext.Data.FilterRowsByColumn(...)\r\n```\r\nHowever, this method only supports the ability to filter on the values of a single column.  There are cases where you need to do more advanced filtering scenarios - for example, filter based on multiple column values, nest queries, etc.  It would be helpful in general to have the ability to provide a linq expression to support a variety of filtering scenarios.\r\n\r\nHere's more information on my specific scenario - as I said, it would be helpful to have advanced filtering capabilities provided since this is a useful way to do down-sampling before training on the data.\r\n\r\n-----------------------------------------------------------------------\r\n**Scenario:**\r\n\r\nMy scenario uses a large hotel result dataset for ranking (1,000,000+ records).  \r\nHere is simple example of the data:\r\n\r\nGroupId | HotelId | Srch_Result_Clicked | Srch_Result_Booked\r\n----------|----------|----------------------|-------------------------|\r\n1 | 12 | 0 | 0 |\r\n1           |       24     |              1                 |             0 |\r\n1           |       45     |              1                 |             1 |\r\n1           |       55     |              0                 |             0 |\r\n\r\nNotice that in the above data, the GroupId corresponds to the query or search id.  There are multiple hotel results then tied to the GroupId since these are the results corresponding to a given query.  Each hotel result may have the following values:\r\n* Srch_Result_Clicked == 1 if the user clicked the hotel search result\r\n* Srch_Result_Booked == 1 if the user both clicked and booked the hotel search result\r\n* Or, the above values are 0 if the user neither clicked nor booked the result\r\n\r\nIn this scenario, I needed to perform down-sampling so that I only trained on hotel search queries where that had been either clicked or booked.  Here's an example of the type of query that I was trying to achieve:\r\n\r\n```\r\n//Get those group\\query ids that have at least one hotel result that was either clicked or booked\r\nvar groupIds = hotelData.Where(h => h.Srch_Result_Clicked == 1 || h.Srch_Result_Booked == 1).Select(h => h.GroupId).Distinct();\r\n\r\n//Down sample retrieve all hotel results for a group\\query matching the above criteria\r\nIDataView downSampleData = hotelData.Where(h => groupIds.Contains(h.GroupId));\r\n\r\n//Train the model\r\n var model = trainingPipeline.Fit(downSampleData);\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3991","RelatedDescription":"Open issue \"Need advanced filtering for downsampling\" (#3991)"},{"Id":"467076166","IsPullRequest":false,"CreatedAt":"2019-07-11T19:51:08","Actor":"colbylwilliams","Number":"3990","RawContent":null,"Title":"PredictedLabel is always true for Anomaly Detection","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: macOS & Windows\r\n- **.NET Version (eg., dotnet --info)**:  .Net Core\r\n\r\n### Issue: PredictedLabel is always true for Anomaly Detection\r\n\r\nIn my experience, and as demonstrated by [this sample](https://github.com/dotnet/machinelearning-samples/tree/AnomalyDetection_FraudDetection/samples/csharp/getting-started/AnomalyDetection_CreditCardFraudDetection), predictions from models trained with the `RandomizedPcaTrainer` always set the value for `PredictedLabel` to `true`.\r\n\r\n_Note: I’m very new to machine learning, I am not a data scientist, nor am I very familiar with this code base, but I’ve taken a crack at figuring out why..._\r\n\r\nThe `BinaryClassifierScorer` is [used for scoring anomaly detection models](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L295-L297), specifically those trained using the `RandomizedPcaTrainer`. Which I _think_ makes sense, as with binary classification the `PredictedLabel` in anomaly detection will be one of two values, `true` or `false`.  \r\n\r\nHowever, when using binary classification, `PredictiveLabel` is set to `true` if the prediction's `Score` is a positive value and set to `false` if the `Score` is negative. This is one place it seems to break down with anomaly detection, as the `Score` is going to be a value between one and zero.  So, the current implementation of `BinaryClassifierScorer` is going to return a value of true for any prediction that does not have a `Score` of zero or NAN.\r\n\r\nAdditionally, it’s my understanding that in anomaly detection it is up to the user to set the threshold of the model that indicates whether a `Score` is considered an anomaly or a normal value.  (Or at least this is the case for supervised training).  From what I can tell, the implementation of `BinaryClassifierScorer` used by anomaly detection, does have a `Threshold` property which [it compares the `Score` value to, to get the value for `PredictedLabel`](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/BinaryClassifierScorer.cs#L259-L263).  It would seem the `BinaryClassifierScorer` could be used for anomaly detection if the user was able to manually set a value for `Threshold`, or if the scorer could intelligently set the value based on the distribution of `Score`s.  However, the [`Threshold` property is by default set to zero](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Scorers/PredictionTransformer.cs#L270), with no public way of changing its value.\r\n\r\nThus, based on my understanding, the Scorer compares the prediction’s `Score` to zero, and the value for `PredictedLabel` will always be set to `true`, with the exception of the edge case where score is zero or NAN.\r\n\r\nDuring my research, I did find that `BinaryClassificationCatalog` has a method [`ChangeModelThreshold`](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/TrainCatalog.cs#L261-L267) to manually override the value of the scorer’s `Threshold` property.  Unfortunately, this functionality is is not exposed on the `AnomalyDetectionCatalog`, so can’t be used with anomaly detection.\r\n\r\n---\r\n\r\nFinally, and this may need to be moved to a separate issue, but I've found contradictory information on how to interpret the `Score` value of an anomaly detection prediction.  For example [this sample](https://github.com/dotnet/machinelearning/blob/master/docs/samples/Microsoft.ML.Samples/Dynamic/Trainers/AnomalyDetection/RandomizedPcaSample.cs#L92) indicates that outliers (or anomalies) will have a **smaller** value for `Score` than will normal values.  However, [this documentation](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.randomizedpcatrainer?view=ml-dotnet#training-algorithm-details) states _\"If the error is close to 0, the instance is considered normal (non-anomaly).\"_  This matches the results I'm getting from [my sample](https://github.com/dotnet/machinelearning-samples/tree/AnomalyDetection_FraudDetection/samples/csharp/getting-started/AnomalyDetection_CreditCardFraudDetection), where anomalies have a **higher** value for `Score` than normal values.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3990","RelatedDescription":"Open issue \"PredictedLabel is always true for Anomaly Detection\" (#3990)"},{"Id":"466937119","IsPullRequest":false,"CreatedAt":"2019-07-11T14:44:09","Actor":"ganzikk02","Number":"3989","RawContent":null,"Title":"Multiple trainers in one pipeline","State":"open","Body":"First of all, I would like to thank you for ML.NET as I have waited for **the** C# machine learning library for such a long time (been using Accord.NET and CNTK) and right now I am having a great time with ML.NET.\r\n\r\nAs for my question, I am trying to create a strong classifier for multiclass classification consisting of more weaker classifiers, to do this I need to train different models. Is it possible to train multiple models in one pipeline? Or do I need to create separate pipelines and then even predictor engines for each model?\r\n\r\n```\r\nvar estimatorChain = mlContext.Transforms.Conversion.MapValueToKey(\"Label\")\r\n                .Append(mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy())\r\n                .Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\"));\r\n\r\nvar transformerChain = estimatorChain.Fit(trainDataMemory);\r\n\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<DataItem, DataItemPrediction>(transformerChain, inputSchemaDefinition: inputSchemaDefinition);\r\n```\r\n\r\nI would like to append more trainers into the pipeline which is actually possible to do, but I have no idea what it does because the result of training and of prediction is not very transparent in this regard... Also did not find anything about this in the documentation.\r\n\r\nSo is it possible or do I have to create multiple pipelines which need to be used separately?","Url":"https://github.com/dotnet/machinelearning/issues/3989","RelatedDescription":"Open issue \"Multiple trainers in one pipeline\" (#3989)"},{"Id":"466926699","IsPullRequest":false,"CreatedAt":"2019-07-11T14:26:22","Actor":"SkinnyMan32","Number":"3988","RawContent":null,"Title":"Troubles with CustomMappingEstimator after save/load","State":"open","Body":"### System information\r\n\r\n- **ML.Net v1.2.0**\r\n\r\n### Issue\r\nI try to use CustomMapping with specified column names. It works fine, but after save/load model I get exception:\r\n**System.ArgumentOutOfRangeException: \"Could not find  column 'Words'\".** \r\n'Words' - the original name of property, not specified by me.\r\n\r\nWhat am i doing wrong?\r\n\r\nI can fix it by using only original names, it is not comfortable in some cases.\r\n\r\n### Source code\r\n```C#\r\n// --- Test method ---\r\nvar ml = new MLContext();\r\nvar descriptions = new[]\r\n{\r\n\tnew { Description = \"Painted, Painting, Painter\" }\r\n};\r\nvar dataView = ml.Data.LoadFromEnumerable(descriptions);\r\n\r\nvar pipeline = ml.Transforms.Text.NormalizeText(\"Normalized\", \"Description\")\r\n\t.Append(ml.Transforms.Text.TokenizeIntoWords(\"Tokens\", \"Normalized\"))\r\n     // (Extension method) CustomMapping with specified column names\r\n\t.Append(ml.Transforms.StemText(\"Stemmed\", \"Tokens\"));\r\n\r\nvar model = pipeline.Fit(dataView);\r\nvar preview = model.Transform(dataView).Preview();  // everything is ok\r\n\r\n// Save model\r\nMemoryStream stream = new MemoryStream();\r\nml.Model.Save(model, dataView.Schema, stream);\r\nstream.Position = 0;\r\n\r\n// Load model in the new context\r\nvar ml2 = new MLContext();\r\n// Register custom action\r\nml2.ComponentCatalog.RegisterAssembly(typeof(StemmerCustomAction).Assembly);\r\nvar loadedModel = ml2.Model.Load(stream, out var schema);\r\n\r\n// Exception:\r\n// System.ArgumentOutOfRangeException: \"Could not find  column 'Words'\r\nvar preview2 = loadedModel.Transform(dataView).Preview();\r\n\r\n\r\n//--- Classes ---\r\n\r\npublic class StemmerInput\r\n{\r\n\tpublic string[] Words { get; set; }\r\n}\r\n\r\npublic class StemmerOutput\r\n{\r\n\tpublic string[] Stemmed { get; set; }\r\n}\r\n\r\n[CustomMappingFactoryAttribute(\"StemText\")]\r\npublic class StemmerCustomAction : CustomMappingFactory<StemmerInput, StemmerOutput>\r\n{\r\n\tpublic static void StemAction(StemmerInput input, StemmerOutput output)\r\n\t{\r\n\t\tvar stemmer = new EnglishStemmer();\r\n\t\toutput.Stemmed = new string[input.Words.Length];\r\n\t\tfor (int i = 0; i < input.Words.Length; i++)\r\n\t\t{\r\n\t\t\toutput.Stemmed[i] = stemmer.Stem(input.Words[i]);\r\n\t\t}\r\n\t}\r\n\r\n\tpublic override Action<StemmerInput, StemmerOutput> GetMapping() => StemAction;\r\n}\r\n\r\nstatic class StemmerTransformHelper\r\n{\r\n\tpublic static CustomMappingEstimator<StemmerInput, StemmerOutput> StemText(this TransformsCatalog catalog,\r\n\t\tstring outputColumnName, string inputColumnName = null)\r\n\t{\r\n\t\tvar inputSchema = SchemaDefinition.Create(typeof(StemmerInput), SchemaDefinition.Direction.Read);\t\t\r\n\t\tvar outSchema = SchemaDefinition.Create(typeof(StemmerOutput), SchemaDefinition.Direction.Write);\t\t\r\n\t\t// specify column names\r\n\t\tinputSchema[0].ColumnName = inputColumnName ?? outputColumnName;\r\n\t\toutSchema[0].ColumnName = outputColumnName;\r\n\t\treturn catalog.CustomMapping(new StemmerCustomAction().GetMapping(), \"StemText\", inputSchema, outSchema);\r\n\t}\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/3988","RelatedDescription":"Open issue \"Troubles with CustomMappingEstimator after save/load\" (#3988)"},{"Id":"466727956","IsPullRequest":false,"CreatedAt":"2019-07-11T07:59:59","Actor":"mani009","Number":"3987","RawContent":null,"Title":"After packing and install ML.NET Project with Setup installer throws exceptions","State":"open","Body":"### System information\r\n\r\n-Windows 10(18362)\r\n- NET Framework 4.6.1: \r\n\r\n### Issue\r\n\r\n- Try Pack ML.NET Project with Windows Setup Installer\r\n- Installed and run Program throw an exception\r\n\r\n\r\nSimple Example:\r\n```\r\n    public partial class Form1 : Form\r\n    {\r\n        public Form1()\r\n        {\r\n            InitializeComponent();\r\n        }\r\n\r\n        private void button1_Click(object sender, EventArgs e)\r\n        {\r\n                try\r\n                {\r\n                    HousingData[] inMemoryCollection = new HousingData[]\r\n                    {\r\n                new HousingData\r\n                {\r\n                    Size =700f,\r\n                    HistoricalPrices = new float[]\r\n                    {\r\n                        100000f, 3000000f, 250000f\r\n                    },\r\n                    CurrentPrice = 500000f\r\n                },\r\n                new HousingData\r\n                {\r\n                    Size =1000f,\r\n                    HistoricalPrices = new float[]\r\n                    {\r\n                        600000f, 400000f, 650000f\r\n                    },\r\n                    CurrentPrice=700000f\r\n                }\r\n                    };\r\n\r\n                    MLContext mlContext = new MLContext();\r\n\r\n                    IDataView data = mlContext.Data.LoadFromEnumerable<HousingData>(inMemoryCollection);\r\n                }\r\n                catch (Exception ex)\r\n                {\r\n                    MessageBox.Show(ex.Message);\r\n                }\r\n            }\r\n\r\n        }\r\n```\r\nIf i Run the program and push the button it throws that exception:\r\n\r\n![Exception](https://user-images.githubusercontent.com/13287806/61032695-3635f700-a3c2-11e9-9107-7f150e33cd8c.png)\r\n\r\nAnd if i attach the process with VS 2017 it throws that exception\r\n\r\nException thrown: 'System.BadImageFormatException' in Microsoft.ML.Data.dll","Url":"https://github.com/dotnet/machinelearning/issues/3987","RelatedDescription":"Open issue \"After packing and install ML.NET Project with Setup installer throws exceptions\" (#3987)"},{"Id":"466568495","IsPullRequest":true,"CreatedAt":"2019-07-10T23:12:06","Actor":"wschin","Number":"3986","RawContent":null,"Title":"Allow user to save PredictorTransform in file and then convert it to …","State":"open","Body":"…ONNX via entry point APIs\r\n\r\nFix #3974. The model type in `Microsoft.ML.Model.OnnxConverter.SaveOnnxCommand.Arguments` is `TransformModel` as shown below.\r\n```c#\r\n...\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.CmdLineOnly, HelpText = \"Comma delimited list of output column names to drop\", ShortName = \"odrop\", SortOrder = 7)]\r\n            public string OutputsToDrop;\r\n\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.EntryPointsOnly, HelpText = \"Array of output column names to drop\", Name = nameof(OutputsToDrop), SortOrder = 8)]\r\n            public string[] OutputsToDropArray;\r\n\r\n            [Argument(ArgumentType.AtMostOnce, Visibility = ArgumentAttribute.VisibilityType.CmdLineOnly, HelpText = \"Whether we should attempt to load the predictor and attach the scorer to the pipeline if one is present.\", ShortName = \"pred\", SortOrder = 9)]\r\n            public bool? LoadPredictor;\r\n\r\n            /// <summary>\r\n            /// Entry point API can save either <see cref=\"TransformModel\"/> or <see cref=\"PredictorModel\"/>.\r\n            /// <see cref=\"Model\"/> is used when the saved model is typed to <see cref=\"TransformModel\"/>.\r\n            /// </summary>\r\n            [Argument(ArgumentType.Required, Visibility = ArgumentAttribute.VisibilityType.EntryPointsOnly, HelpText = \"Model that needs to be converted to ONNX format.\", SortOrder = 10)]\r\n            public TransformModel Model;\r\n...\r\n```\r\nThus, model typed to `PredictorModel` (created by entry point APIs) won't be loaded. To support both of `TransformModel` and `PredictorModel`, we add one extra field (called `PredictiveModel`) in parallel to `Model` and some if-else blocks.","Url":"https://github.com/dotnet/machinelearning/pull/3986","RelatedDescription":"Open PR \"Allow user to save PredictorTransform in file and then convert it to …\" (#3986)"},{"Id":"466093013","IsPullRequest":true,"CreatedAt":"2019-07-10T22:30:23","Actor":"harishsk","Number":"3983","RawContent":null,"Title":"TF package size fix","State":"closed","Body":"The Tensorflow tar files contain libtensorflow.so, libtensorflow.so.$(MajorVersion) and libtensorflow.so.$(Version). Of these, the first two are symlinked to the third. When these files get copied over to the nuget package, they are copied as files and not as symlinks which causes the package size to almost triple. \r\nThis fix reduces the copied files to only libtensorflow.so and libtensorflow_framework.so.$(MajorVersion).\r\n","Url":"https://github.com/dotnet/machinelearning/pull/3983","RelatedDescription":"Closed or merged PR \"TF package size fix\" (#3983)"},{"Id":"466474428","IsPullRequest":false,"CreatedAt":"2019-07-10T19:17:26","Actor":"justinormont","Number":"3985","RawContent":null,"Title":"Add FieldAwareFactorizationMachine to AutoML","State":"open","Body":"FieldAwareFactorizationMachine is good for large dataset like the Criteo 1TB dataset. \r\n\r\nCurrently FieldAwareFactorizationMachine is not swept over in AutoML. \r\n\r\nTask:\r\n* Add trainer to default list of binary learners to try\r\n* Add sweep range\r\n* Add to CLI's C# CodeGen\r\n\r\nShould be easy to just replicate an existing trainer like SDCA:\r\nhttps://github.com/dotnet/machinelearning/blob/d518b587b06ac3896a48646622b0f2169a230855/src/Microsoft.ML.AutoML/TrainerExtensions/BinaryTrainerExtensions.cs#L150-L169","Url":"https://github.com/dotnet/machinelearning/issues/3985","RelatedDescription":"Open issue \"Add FieldAwareFactorizationMachine to AutoML\" (#3985)"},{"Id":"466435561","IsPullRequest":false,"CreatedAt":"2019-07-10T17:40:58","Actor":"baruchiro","Number":"3984","RawContent":null,"Title":"Renaming column","State":"open","Body":"### Issue\r\n\r\nI try to convert column type to another type by using [ConversionsExtensionsCatalog.ConvertType](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.conversionsextensionscatalog.converttype). After the transform, I have duplicated columns with the same name but another type. I want to keep with the same name.\r\n\r\nSo, I convert to a new name, drop the old name, copy the new name to the old name and drop the new name.\r\n\r\nWAT???\r\n\r\nWhy it is so complicated?\r\n\r\nI think we need to add an option to transform \"inplace\", or combine `Drop` & `Copy` to `Rename`.\r\n\r\n### Source code / logs\r\n\r\n```csharp\r\nvar intTypes = new[]\r\n{\r\n        DataKind.Int16,\r\n        DataKind.Int32,\r\n        DataKind.Int64\r\n};\r\nvar intColumnsNames = columns\r\n    .Where(c => intTypes.Contains(c.DataKind))\r\n    .Select(c => c.Name).ToList();\r\nconst string addedName = \"single_\";\r\n\r\nAddPipelineStage(_mlContext.Transforms.Conversion.ConvertType(\r\n    intColumnsNames.Select(c =>\r\n        new InputOutputColumnPair(addedName + c, c)).ToArray(),\r\n    DataKind.Single));\r\nAddPipelineStage(_mlContext.Transforms.DropColumns(intColumnsNames.ToArray()));\r\nintColumnsNames.ForEach(c => AddPipelineStage(_mlContext.Transforms.CopyColumns(c, addedName + c)));\r\nAddPipelineStage(_mlContext.Transforms.DropColumns(intColumnsNames.Select(c => addedName + c).ToArray()));\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3984","RelatedDescription":"Open issue \"Renaming column\" (#3984)"},{"Id":"465819663","IsPullRequest":false,"CreatedAt":"2019-07-10T17:08:41","Actor":"darren-zdc","Number":"3977","RawContent":null,"Title":"[AutoML/CLI] Error in running a multiClass training for a datasets","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  3.0.0-preview6-27804-01\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRunning the command `mlnet auto-train --task multiclass-classification --dataset \"SampleTrainDataset.txt\" --label-column-name \"label\" --has-header true --max-exploration-time 60 -V diag` for this \r\n[dataset](https://github.com/dotnet/machinelearning/files/3373418/SampleTrainDataset.txt)\r\n- **What happened?**\r\n![image](https://user-images.githubusercontent.com/36833304/60896587-9ac34b80-a234-11e9-8804-da562ba5d093.png)\r\nThe ColumnConcatenating set only contains 4 columns. It ignores the first \"dataValue\" column for no reason. \r\n- **What did you expect?**\r\nI tried to debug it by the source code. I found out that after the `mlContext.Auto().InferColumns(SampleTrainDatasetPath, \"label\", separatorChar: '\\t')` function, the first column (\"dataValue\") went into the `IgnoredColumnNames` collection. I want to know why,,,\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n[debug_log.txt](https://github.com/dotnet/machinelearning/files/3373536/debug_log.txt)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3977","RelatedDescription":"Closed issue \"[AutoML/CLI] Error in running a multiClass training for a datasets\" (#3977)"},{"Id":"465922355","IsPullRequest":false,"CreatedAt":"2019-07-09T23:24:31","Actor":"artidoro","Number":"3980","RawContent":null,"Title":"Update API Compat after 1.2 release","State":"closed","Body":"We should update the API Compat tool after the 1.2 release. There are two updates that need to be made.\r\n\r\n1. Update the current projects to point to point to the 1.2 nugets\r\nhttps://github.com/dotnet/machinelearning/blob/78bfecb4c5999e1d675255544e2032f29c5fd621/tools-local/Microsoft.ML.StableApi/Microsoft.ML.StableApi.csproj#L10-L16\r\n\r\n2. Activate API Compat on the new stable projects (Onnx, TensorFlow and TimeSeries) and make the stable version point to the 1.2 nugets.","Url":"https://github.com/dotnet/machinelearning/issues/3980","RelatedDescription":"Closed issue \"Update API Compat after 1.2 release\" (#3980)"},{"Id":"465943872","IsPullRequest":false,"CreatedAt":"2019-07-09T19:18:05","Actor":"nighotatul","Number":"3982","RawContent":null,"Title":"Need More Detail regarding feature","State":"open","Body":"\r\nis feature columns consider as complex variable that means all are consider as object when processes in ml.net?\r\n\r\nex.\r\nif consider label is Purchased Bike\r\nand feature are Commute Distance,Gender,Age,Cars.\r\n\r\nso all feature columns consider as object in ml.net?\r\n\r\nmeans like all column data convert into vector array.\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3982","RelatedDescription":"Open issue \"Need More Detail regarding feature\" (#3982)"},{"Id":"465931398","IsPullRequest":true,"CreatedAt":"2019-07-09T18:51:20","Actor":"artidoro","Number":"3981","RawContent":null,"Title":"Update Api Compat after 1.2 release","State":"closed","Body":"Fixes #3980 \r\n\r\nI update the package version number for the stable projects and I activate the API Compat tool for Onnx, TimeSeries and TensorFlow packages which became stable in the last release.  \r\n","Url":"https://github.com/dotnet/machinelearning/pull/3981","RelatedDescription":"Closed or merged PR \"Update Api Compat after 1.2 release\" (#3981)"},{"Id":"465905104","IsPullRequest":true,"CreatedAt":"2019-07-09T17:39:45","Actor":"artidoro","Number":"3979","RawContent":null,"Title":"Internalizing Static API code","State":"open","Body":"Related to #3952.\r\n\r\nIn this PR I internalize the static API code and do some clean up:\r\n1. Everything in the StaticPipe assembly is made internal\r\n2. The Static API samples have been removed\r\n3. The packaging step does not produce StaticPipe nuget\r\n\r\nNotice that this is the first of a three step process which will end up removing the static API code from the repository.","Url":"https://github.com/dotnet/machinelearning/pull/3979","RelatedDescription":"Open PR \"Internalizing Static API code\" (#3979)"},{"Id":"465852280","IsPullRequest":false,"CreatedAt":"2019-07-09T15:37:15","Actor":"famschopman","Number":"3978","RawContent":null,"Title":"AutoML, How can I identify dropped features ","State":"open","Body":"Based on the documentation AutoML automatically drops features during training where needed.\r\n\r\nIs there a way to retrieve the actual list of features that was included in the final model, e.g. determine which features were dropped and didn't improve the accuracy of the model?\r\n\r\nWhen I inspect the final model, the OutputSchema tends to always include all the features based on the initial training data.","Url":"https://github.com/dotnet/machinelearning/issues/3978","RelatedDescription":"Open issue \"AutoML, How can I identify dropped features \" (#3978)"},{"Id":"465783476","IsPullRequest":false,"CreatedAt":"2019-07-09T13:32:40","Actor":"fwaris","Number":"3976","RawContent":null,"Title":"IPredictorProducing 'internal' is causing issues with F# type resolution","State":"open","Body":"I am trying to use PermutationFeatureImportance (PFI)  with F# but the F# type system is not resolving ITransformer to ISingleFeaturePredictionTransformer - which is required by PFI.\r\n\r\nI believe it is due to  IPredictorProducing (and related interfaces) being marked as \"internal\".\r\n\r\nF# supports explicit interfaces and maybe that is the reason for this issue.\r\n\r\nHere is a snippet of code that shows what I am trying to do\r\n(I am using the latest bits - v 1.2.0 at the time of this post)\r\n\r\n```F#\r\nlet mutable schema = null\r\nlet mdl = ctx.Model.Load(@\"F:\\fwaris\\data\\t\\analysis\\model_cv_LightGbmBinary.bin\", &schema) \r\nlet mdlt =  mdl :?> TransformerChain<ITransformer>\r\nlet m1 =  mdlt.LastTransformer //debugger shows it is Microsoft.ML.Data.BinaryPredictionTransformer<Microsoft.ML.IPredictorProducing<float>>\r\nlet scored = mdl.Transform(trainView)\r\nscored.Preview()\r\nctx.BinaryClassification.PermutationFeatureImportance(m1 :?> _,scored)\r\n```\r\n\r\n@dsyme \r\n","Url":"https://github.com/dotnet/machinelearning/issues/3976","RelatedDescription":"Open issue \"IPredictorProducing 'internal' is causing issues with F# type resolution\" (#3976)"},{"Id":"465620979","IsPullRequest":false,"CreatedAt":"2019-07-09T07:37:41","Actor":"wovas","Number":"3975","RawContent":null,"Title":"Add Product recommendation sample that will suggest k best related products to subject product","State":"open","Body":"Provided sample it's not quite useful in real word scenarios. As basically the problem stated as pick k best-suited products to the subject product. Using the current approach I should recalculate scoring for all universe of products from N total products. So to form recommendations for whole store I should recalculate n*n scores and sort to pick the best recommendation, which looks too compute intensive even if this is quite parallelizable computations for several thousand products it's quite expensive.\r\n\r\nAs per @wschin suggestion, we can try and implement \r\n\r\n> There are some approximated solutions (**approximated maximum inner product search and approximated nearest neighbor search usually via K-D tree**) but ML.NET doesn't support any of them.","Url":"https://github.com/dotnet/machinelearning/issues/3975","RelatedDescription":"Open issue \"Add Product recommendation sample that will suggest k best related products to subject product\" (#3975)"},{"Id":"465476473","IsPullRequest":false,"CreatedAt":"2019-07-08T21:54:57","Actor":"pieths","Number":"3974","RawContent":null,"Title":"SaveOnnxCommand appears to ignore predictors when saving a model to ONNX format.","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n\r\n### Steps To Recreate The Issue\r\n\r\n1. Create and save a PredictorModel to disk using the entry point api.\r\n2. Try and convert the model to ONNX format using the entry point api.\r\n3. Notice that `SaveOnnxCommand.GetPipe` only cycles through the transforms and never encounters the logistic regression node.\r\n\r\n    This might be happening because `ExecuteGraphCommand.GetOutputToPath` saves a `TlcModule.DataKind.PredictorModel` to disk in step (1). And then, `ExecuteGraphCommand.SetInputFromPath` loads a `TlcModule.DataKind.TransformModel` from disk in step (2) (apparently a consequence of `SaveOnnxCommand.Arguments.Model` being of type `TransformModel`). `PredictorModelImpl` and `TransformModelImpl` don't appear to be compatible from a serialization point of view.\r\n\r\n### Source code / logs\r\n\r\nSee [here](https://github.com/pieths/dotnet_machinelearning/commit/1058abc7086d58a76000717b284a5b115931c70e) for an ml.net test which demonstrates the issue.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3974","RelatedDescription":"Open issue \"SaveOnnxCommand appears to ignore predictors when saving a model to ONNX format.\" (#3974)"},{"Id":"465466145","IsPullRequest":false,"CreatedAt":"2019-07-08T21:23:42","Actor":"pieths","Number":"3973","RawContent":null,"Title":"Converting from ml.net pipeline to ONNX fails.","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n\r\n### Issue\r\n\r\nI created an ml.net pipeline using onnx exportable transforms and a logistic regression node. It trains and predicts as expected but exporting the pipeline using `ConvertToOnnxProtobuf` fails with the following error:\r\n\r\n```console\r\nSystem.InvalidOperationException : The targeted pipeline can not be fully converted into\r\na well-defined ONNX model. Please check if all steps in that pipeline are convertible\r\nto ONNX and all necessary variables are not dropped (via command line arguments).\r\n```\r\n\r\n### Source code / logs\r\n\r\nSee [here](https://github.com/pieths/dotnet_machinelearning/commit/5335349756c50e54b8cb221484f6c56fd9805d49) for an ml.net test which demonstrates the issue.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/3973","RelatedDescription":"Open issue \"Converting from ml.net pipeline to ONNX fails.\" (#3973)"},{"Id":"465433267","IsPullRequest":true,"CreatedAt":"2019-07-08T21:02:10","Actor":"PranovD","Number":"3971","RawContent":null,"Title":"[WIP] NO MERGE.","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/3971","RelatedDescription":"Closed or merged PR \"[WIP] NO MERGE.\" (#3971)"},{"Id":"465458248","IsPullRequest":false,"CreatedAt":"2019-07-08T21:01:50","Actor":"famschopman","Number":"3972","RawContent":null,"Title":"Using PFI with AutoML, possible?","State":"open","Body":"Playing with AutoML and so far having much fun with it. \r\n\r\nI have a trained model and now trying to retrieve the feature weights. None of the objects returned expose a LastTransformer object that I need to \r\n\r\nCode snippet:\r\n\r\n```\r\nvar mlContext = new MLContext();\r\nvar _appPath = AppDomain.CurrentDomain.BaseDirectory;\r\n var _dataPath = Path.Combine(_appPath, \"Datasets\", \"dataset.csv\");\r\nvar _modelPath = Path.Combine(_appPath, \"Datasets\", \"TrainedModels\");\r\n\r\n\r\nColumnInferenceResults columnInference = mlContext.Auto().InferColumns(_dataPath, LabelColumnName, groupColumns: false);\r\n            ColumnInformation columnInformation = columnInference.ColumnInformation;\r\n\r\n            TextLoader textLoader = mlContext.Data.CreateTextLoader(columnInference.TextLoaderOptions);\r\n            IDataView data = textLoader.Load(_dataPath);\r\n\r\n            DataOperationsCatalog.TrainTestData dataSplit = mlContext.Data.TrainTestSplit(data, testFraction: 0.2);\r\n            IDataView trainData = dataSplit.TrainSet;\r\n            IDataView testData = dataSplit.TestSet;\r\n\r\n            var cts = new CancellationTokenSource();\r\n            var experimentSettings = CreateExperimentSettings(mlContext, cts);\r\n\r\n            var progressHandler = new BinaryExperimentProgressHandler();\r\n\r\n            ExperimentResult<BinaryClassificationMetrics> experimentResult = mlContext.Auto()\r\n                .CreateBinaryClassificationExperiment(experimentSettings)\r\n                .Execute(trainData, labelColumnName: \"Attrition\", progressHandler: new BinaryExperimentProgressHandler());\r\n\r\n            RunDetail<BinaryClassificationMetrics> bestRun = experimentResult.BestRun;\r\n            ITransformer trainedModel = bestRun.Model;\r\n            var predictions = trainedModel.Transform(testData);\r\n            var metrics = mlContext.BinaryClassification.EvaluateNonCalibrated(data: predictions, labelColumnName: \"Attrition\", scoreColumnName: \"Score\");\r\n\r\n            mlContext.Model.Save(trainedModel, trainData.Schema, _modelPath);\r\n```\r\n\r\nThen I want to get the PFI information and I get stuck. There appears no way to get the LastTransformer object from the trainedModel.\r\n\r\n\r\n```\r\n            var transformedData = trainedModel.Transform(trainData);\r\n            var linearPredictor = model.LastTransformer; \r\n\r\n            var permutationMetrics = mlContext.BinaryClassification.PermutationFeatureImportance(\r\n                linearPredictor, transformedData, permutationCount: 30);\r\n```\r\n\r\nHope someone can help me with some guidance.","Url":"https://github.com/dotnet/machinelearning/issues/3972","RelatedDescription":"Open issue \"Using PFI with AutoML, possible?\" (#3972)"},{"Id":"465138521","IsPullRequest":false,"CreatedAt":"2019-07-08T16:22:02","Actor":"baruchiro","Number":"3970","RawContent":null,"Title":"What about the constructors?","State":"closed","Body":"How can I initialize this type?\n\n---\n#### Document Details\n\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\n\n* ID: 7366dd71-3899-63fb-690e-5e0d11a5bf13\n* Version Independent ID: 4e44da94-51eb-2617-135a-eb71186b4da9\n* Content: [TensorFlowEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowestimator?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/TensorFlowEstimator.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/3970","RelatedDescription":"Closed issue \"What about the constructors?\" (#3970)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-07-14T05:30:42.5587914Z","RunDurationInMilliseconds":664}