{"Data":{"GitHub":{"Issues":[{"Id":"474882562","IsPullRequest":false,"CreatedAt":"2019-07-31T00:42:48","Actor":"justinormont","Number":"4049","RawContent":null,"Title":"AutoML CLI ignores the normalized column name","State":"open","Body":"In the normalization function for column names, we call the Sanitize() function, then ignore its result (besides the 1st letter).\r\n\r\nThis line:\r\nhttps://github.com/dotnet/machinelearning/blob/a15aaa73ffa3798d4ab6c79672a7d3859d36030b/src/mlnet/Utilities/Utils.cs#L81\r\n\r\nShould be:\r\n```C#\r\nreturn sanitizedInput.First().ToString().ToUpper() + sanitizedInput.Substring(1);\r\n```\r\n\r\nNoted as something to fix after https://github.com/dotnet/machinelearning/pull/3882 is merged into master.","Url":"https://github.com/dotnet/machinelearning/issues/4049","RelatedDescription":"Open issue \"AutoML CLI ignores the normalized column name\" (#4049)"},{"Id":"469934177","IsPullRequest":false,"CreatedAt":"2019-07-30T14:26:42","Actor":"cookt","Number":"4020","RawContent":null,"Title":"What is TModel?","State":"closed","Body":"Given that the examples do not use type parameters, it would extremely helpful to include documentation of TModel especially for creating a function. \n\n---\n#### Document Details\n\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\n\n* ID: 5ec45442-8e5f-a544-cc9a-58483a383513\n* Version Independent ID: 040169f9-d169-cbbd-099e-f04a7a5a6b3f\n* Content: [PermutationFeatureImportanceExtensions.PermutationFeatureImportance Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions.permutationfeatureimportance?view=ml-dotnet#Microsoft_ML_PermutationFeatureImportanceExtensions_PermutationFeatureImportance__1_Microsoft_ML_MulticlassClassificationCatalog_Microsoft_ML_ISingleFeaturePredictionTransformer___0__Microsoft_ML_IDataView_System_String_System_Boolean_System_Nullable_System_Int32__System_Int32_)\n* Content Source: [dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/PermutationFeatureImportanceExtensions.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/4020","RelatedDescription":"Closed issue \"What is TModel?\" (#4020)"},{"Id":"474568845","IsPullRequest":false,"CreatedAt":"2019-07-30T12:55:59","Actor":"acrigney","Number":"4048","RawContent":null,"Title":"System.ArgumentOutOfRangeException : Could not find input column 'SamplingKeyColumn'","State":"open","Body":"### System information\r\n\r\n- **Win10/distro**:\r\n- **.NET Version Core 2.1**: \r\n\r\n### Issue\r\n\r\nWhen I am running my RefitBestPipeline function. i.e my function to run my model over the entire data I got this error.\r\n\r\nMessage: System.ArgumentOutOfRangeException : Could not find input column 'SamplingKeyColumn'\r\nParameter name: inputSchema\r\n\r\nThis is some internal error I am calling the same load and transfer function that I used to build my model.\r\n\r\n### Source code / logs\r\nprivate ITransformer RefitBestPipeline(ExperimentResult<RegressionMetrics> experimentResult)\r\n        {\r\n            DebugHelper.WriteHeader(\"=============== Re-fitting best pipeline ===============\");\r\n            //var textLoader = mlContext.Data.CreateTextLoader(columnInference.TextLoaderOptions);\r\n            //_trainDataView = _mlContext.Data.LoadFromEnumerable<T>(trainingCollection);\r\n            //_testDataView = _mlContext.Data.LoadFromEnumerable<T>(testCollection);\r\n\r\n            //IEnumerable<T> allData = trainingCollection.Concat(testCollection);\r\n            //IDataView allDataView = _mlContext.Data.LoadFromEnumerable<T>(testCollection);          \r\n            // Generate the dataview for all of the data\r\n            LoadData(_modelInput.TrainingCollection);\r\n            TransformData();\r\n\r\n            //var combinedDataView = textLoader.Load(new MultiFileSource(TrainDataPath, TestDataPath));\r\n            RunDetail<RegressionMetrics> bestRun = experimentResult.BestRun;\r\n\r\n            return bestRun.Estimator.Fit(_trainDataView); // pass in the data view for all of the data.\r\n        }\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4048","RelatedDescription":"Open issue \"System.ArgumentOutOfRangeException : Could not find input column 'SamplingKeyColumn'\" (#4048)"},{"Id":"474287345","IsPullRequest":false,"CreatedAt":"2019-07-29T22:36:20","Actor":"justinormont","Number":"4047","RawContent":null,"Title":"Improve \"Invalid TValue\" error message","State":"open","Body":"When throwing \"Invalid TValue\" runtime errors, we tell users which type they entered, but don't tell the user the type that is needed. We tell them their current type is wrong, but not the right type.\r\n\r\nThere are current [23 places](https://github.com/dotnet/machinelearning/search?q=%22Invalid+TValue%22&unscoped_q=%22Invalid+TValue%22) we throw this error. Our most common is when calling a `GetGetter()`.\r\n\r\nThe one I'm hitting at the moment:\r\nhttps://github.com/dotnet/machinelearning/blob/45b6c43387294d19cad843a21e87539213e8d34c/src/Microsoft.ML.Data/Data/DataViewUtils.cs#L1128\r\n\r\n## Task:\r\nTo make this more actionable, we should tell the user which type is needed for the column type.","Url":"https://github.com/dotnet/machinelearning/issues/4047","RelatedDescription":"Open issue \"Improve \"Invalid TValue\" error message\" (#4047)"},{"Id":"474172450","IsPullRequest":false,"CreatedAt":"2019-07-29T17:36:52","Actor":"NeoXtreem","Number":"4046","RawContent":null,"Title":"Path error on mkllibpath parameter running build.cmd","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10.0.17134\r\n- **.NET Version (eg., dotnet --info)**: 2.2.102\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nRan **build.cmd** in root folder in a VS 2019 developer command prompt.\r\n\r\n- **What happened?**\r\nBuild failed with error: `The system cannot find the path specified.`\r\nIt occurs when running the command:\r\n`C:\\Users\\micro\\OneDrive - X-treem Software\\Development\\Repos\\General\\Frameworks\\ML.NET\\src\\Native\\build.cmd Debug x64 --mkllibpath C:\\Users\\micro\\OneDrive - X-treem Software\\Development\\Repos\\General\\Frameworks\\ML.NET\\packages/mlnetmkldeps\\0.0.0.9\\runtimes\\win-x64\\native`\r\nIt appears that the mixture of forward slashes and backslashes may be causing the error as the path does exist. Only one of these slash types should be used in the path after `--mkllibpath`.\r\n\r\n- **What did you expect?**\r\nBuild succeed.  #3336 is a similar issue that was closed on the basis the issue was fixed, but it clearly isn't.\r\n\r\n### Source code / logs\r\n[msbuild.log](https://github.com/dotnet/machinelearning/files/3439365/msbuild.log)","Url":"https://github.com/dotnet/machinelearning/issues/4046","RelatedDescription":"Open issue \"Path error on mkllibpath parameter running build.cmd\" (#4046)"},{"Id":"474128196","IsPullRequest":false,"CreatedAt":"2019-07-29T15:53:19","Actor":"acrigney","Number":"4045","RawContent":null,"Title":"Common issue Only supported feature column types are Boolean, Single, and String. ","State":"open","Body":"### System information\r\n\r\n\r\n- **OS version Windows 10 /distro**:\r\n- **.NET Version (.NET Core 2.1)**: \r\n\r\n### Issue\r\nI have removed the unsupported column types in my data but I am still getting this message\r\n\r\nMessage: System.ArgumentException : Only supported feature column types are Boolean, Single, and String. Please change the feature column IntMonth of type Int32 to one of the supported types.\r\nParameter name: trainData\r\nThe problem is that the conversions and drop columns are not converting and dropping the columns as they are not operating on the correct object.\r\nHow can I get the int32 and double columns removed?\r\nHow can I do this please?\r\nHere is some example code that \r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nprivate void TransformData()\r\n        {\r\n            var dataProcessPipeline = _mlContext.Transforms.DropColumns(_modelInput.KeyFeatureToIgnore);\r\n            PropertyInfo propertyInfo;\r\n\r\n            foreach (string feature in _includedFeatureNames)\r\n            {\r\n                propertyInfo = _allFeaturesPropertyInfo.Find(x => x.Name == feature);\r\n                if (typeof(Double) == propertyInfo.PropertyType)\r\n                {\r\n                    dataProcessPipeline.Append(_mlContext.Transforms.Conversion.ConvertType(feature, feature, DataKind.Single));\r\n                }\r\nelse if (typeof(Int32) == propertyInfo.PropertyType)\r\n                {\r\n                    dataProcessPipeline.Append(_mlContext.Transforms.Conversion.ConvertType(feature, feature, DataKind.Single));\r\n                }\r\n                dataProcessPipeline.Append(_mlContext.Transforms.NormalizeMeanVariance(feature, useCdf: false));\r\n            }\r\n\r\n            // Now we can transform the data and look at the output to confirm the\r\n            // behavior of the estimator. This operation doesn't actually evaluate\r\n            // data until we read the data below.\r\n            var tansformer = dataProcessPipeline.Fit(_trainDataView);\r\n\r\n            _trainDataView = tansformer.Transform(_trainDataView);\r\n\r\n            var trainDataViewSchemaTest = _trainDataView.Schema;\r\n            \r\n            \r\n        }\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4045","RelatedDescription":"Open issue \"Common issue Only supported feature column types are Boolean, Single, and String. \" (#4045)"},{"Id":"473719092","IsPullRequest":false,"CreatedAt":"2019-07-28T08:23:28","Actor":"baruchiro","Number":"4044","RawContent":null,"Title":"AutoML execute with preFeaturizer should accept Int32 and so","State":"open","Body":"### System information\r\n\r\nMicrosoft.ML.AutoML (0.14.0)\r\n\r\n### Issue\r\n\r\n**TL;DR:** `ExperimentBase.Execute` with non-null `preFeaturizer` argument should check the schema types **after** transforming the `preFeaturizer`.\r\n\r\n----\r\n\r\nI have a flattened object with `long` and `int` fields that I load it to an `IDataView`.\r\nIf I want to `Execute` an experiment for this `dataView`, I get this expeption:\r\n\r\n> **System.ArgumentException:** 'Only supported feature column types are Boolean, Single, and String. Please change the feature column Feature1 of type Int64 to one of the supported types.\r\nParameter name: trainData'\r\n\r\nSo, I have to create an `EstimatorChain` to `ConvertType` from `long` to `Single`, and `Fit` then `Transform` the `dataView`.\r\n\r\nLet's say I have this `EstimatorChain` to transform these types. Now I have two options:\r\n\r\n 1. Transform the `dataView` **before** passing it to the `Execute` method.  \r\nWith this option, the problem is that I have to create a class that fit to the new schema, if I want to save the model and use it latter.  \r\n(The first generic type in `CreatePredictionEngine` must be appropriated to the `inputSchema`)\r\n 2. Pass this `EstimatorChain` as `preFeaturizer` argument in the `Execute` method.  \r\nBut this is not a real solution because the `Execute` method **still throws the exception above!**","Url":"https://github.com/dotnet/machinelearning/issues/4044","RelatedDescription":"Open issue \"AutoML execute with preFeaturizer should accept Int32 and so\" (#4044)"},{"Id":"473548438","IsPullRequest":true,"CreatedAt":"2019-07-26T21:49:36","Actor":"LittleLittleCloud","Number":"4043","RawContent":null,"Title":"[AutoML] WIP - Pull out Code Gen as separate library","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n### See this [Issue](https://github.com/dotnet/machinelearning-modelbuilder/issues/128) for detailed Information","Url":"https://github.com/dotnet/machinelearning/pull/4043","RelatedDescription":"Open PR \"[AutoML] WIP - Pull out Code Gen as separate library\" (#4043)"},{"Id":"473464013","IsPullRequest":false,"CreatedAt":"2019-07-26T17:37:00","Actor":"colbylwilliams","Number":"4042","RawContent":null,"Title":"Consider adding machinelearning-samples ConsoleHelper funcitonality ","State":"open","Body":"Several of the samples in the [machinelearning-samples](https://github.com/dotnet/machinelearning-samples) repo make extensive use of a shared [ConsoleHelper](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/common/ConsoleHelper.cs) to visualize the data or metrics.  Consider exposing the functionality provided by the ConsoleHelper class inside ML.NET itself.  For example, expose as static methods on the corresponding metrics objects returned by Evaluate, as well as IDataView and Preview.","Url":"https://github.com/dotnet/machinelearning/issues/4042","RelatedDescription":"Open issue \"Consider adding machinelearning-samples ConsoleHelper funcitonality \" (#4042)"},{"Id":"473460332","IsPullRequest":false,"CreatedAt":"2019-07-26T17:30:29","Actor":"nicolehaugen","Number":"4041","RawContent":null,"Title":"Need clarity on concept of key type, including info on using Hashing to create the key type","State":"closed","Body":"When learning about machine learning in general, I didn't see reference to a 'key type' outside of ML.NET - as a result, this concept was difficult for me to understand from the current description provided in the docs.\r\n\r\nIt would be better to provide an example that clarifies how and why a key type is needed.  The example that someone shared with me and that I found to be helpful, is this:\r\n* When you use MapValueToKey, it \"learns\" the keys based on the training set.\r\n* Using the U.S. States as an example, it \"learns\" that ND maps to 1, MN to 2, SD to 3, etc.\r\n* And, when you see a new value in the test set that isn't in the training set, it will map it to an \"unknown\" key (e.g. 0)\r\n\r\nAnother way to make a KeyType is to use Hashing.  This should also be mentioned and explained in the docs alongside the description of KeyTypes.","Url":"https://github.com/dotnet/machinelearning/issues/4041","RelatedDescription":"Closed issue \"Need clarity on concept of key type, including info on using Hashing to create the key type\" (#4041)"},{"Id":"473455181","IsPullRequest":false,"CreatedAt":"2019-07-26T17:11:32","Actor":"nicolehaugen","Number":"4040","RawContent":null,"Title":"Consider making model builder's code generation 'ala carte'","State":"open","Body":"ML .NET 1.2.0\r\n\r\nModel Builder’s code generation functionality is useful for generating large data structures that contain many columns\\properties; however, this functionality is currently tied to only a few trainers that are currently supported by Model Builder.\r\n\r\nYou can still use the code generation portion with other models, which is what I did for the recent Ranking sample. \r\n\r\nWe should surface the code generation functionality so that it can be used selectively with other trainers.  Today, it's not clear that you can use the code generation piece with other trainers like this.","Url":"https://github.com/dotnet/machinelearning/issues/4040","RelatedDescription":"Open issue \"Consider making model builder's code generation 'ala carte'\" (#4040)"},{"Id":"473108066","IsPullRequest":true,"CreatedAt":"2019-07-25T23:14:04","Actor":"artidoro","Number":"4039","RawContent":null,"Title":"PCA Anomaly Detection Threshold","State":"open","Body":"Fixes #3990 \r\n\r\nIn this PR I change the default threshold for PCA anomaly detection to 0.5 (see the issue for discussion on what that means).\r\n\r\nI also add a method to change the threshold from MlContext in the same spirit as the BinaryClassification ChangeThreshold method.\r\n\r\nI update the samples and add a test for the new method.","Url":"https://github.com/dotnet/machinelearning/pull/4039","RelatedDescription":"Open PR \"PCA Anomaly Detection Threshold\" (#4039)"},{"Id":"472768699","IsPullRequest":false,"CreatedAt":"2019-07-25T09:45:45","Actor":"TannerGilbert","Number":"4038","RawContent":null,"Title":"Microsoft.ML.Transforms.TensorFlow.TFException: \"Expected image (JPEG, PNG, or GIF), got unknown format starting with '2552162552240167' \t [[{{node map/while/DecodePng}}]]\" when trying to use Attention-OCR model","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n\r\n### Issue\r\n\r\nGetting `Microsoft.ML.Transforms.TensorFlow.TFException: \"Expected image (JPEG, PNG, or GIF)` error when trying to predict with OCR model created with the [Attention-OCR Github Repository](https://github.com/emedvedev/attention-ocr) (written in Tensorflow).\r\n\r\n### Source code / logs\r\n\r\nModelUtils.cs:\r\n```\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing OCRWithMLNET.ImageDataStructures;\r\nusing System.Diagnostics;\r\nusing System.IO;\r\nusing System.Drawing;\r\nusing System.Drawing.Imaging;\r\n\r\nnamespace OCRWithMLNET\r\n{\r\n    public static class ModelUtils\r\n    {\r\n\r\n        public struct ImageSettings\r\n        {\r\n            public const int imageHeight = 224;\r\n            public const int imageWidth = 224;\r\n            public const float mean = 117;\r\n            public const bool channelsLast = true;\r\n        }\r\n\r\n        public struct TensorFlowModelSettings\r\n        {\r\n            // input tensor name\r\n            public const string inputTensorName = \"input_image_as_bytes\";\r\n\r\n            // output tensor name\r\n            public const string outputTensorName = \"prediction\";\r\n        }\r\n\r\n        public static PredictionEngine<ImageInputData, ImageLabelPredictions> loadModel(string modelLocation)\r\n        {\r\n            MLContext mlContext = new MLContext();\r\n            var data = CreateEmptyDataView(mlContext);\r\n\r\n            var pipeline = mlContext.Transforms.Concatenate(\"input_image_as_bytes\", new string[] { \"input_image\" })\r\n                            .Append(mlContext.Model.LoadTensorFlowModel(modelLocation).\r\n                            ScoreTensorFlowModel(outputColumnNames: new[] { \"prediction\" },\r\n                                                inputColumnNames: new[] { \"input_image_as_bytes\" }, addBatchDimensionInput: false));\r\n\r\n            ITransformer model = pipeline.Fit(data);\r\n\r\n            var predictionEngine = mlContext.Model.CreatePredictionEngine<ImageInputData, ImageLabelPredictions>(model);\r\n\r\n            return predictionEngine;\r\n        }\r\n\r\n        private static IDataView CreateEmptyDataView(MLContext mlContext)\r\n        {\r\n            //Create empty DataView. We just need the schema to call fit()\r\n            List<ImageInputData> list = new List<ImageInputData>();\r\n            IEnumerable<ImageInputData> enumerableData = list;\r\n            var dv = mlContext.Data.LoadFromEnumerable(enumerableData);\r\n            return dv;\r\n        }\r\n\r\n        public static void makePredictions(PredictionEngine<ImageInputData, ImageLabelPredictions> model, string[] imgPaths)\r\n        {\r\n            int i = 0;\r\n            foreach (var path in imgPaths)\r\n            {\r\n                ImageInputData sample = new ImageInputData()\r\n                {\r\n                    input_image = string.Join(\"\", File.ReadAllBytes(path))\r\n                    //input_image = Convert.ToBase64String(File.ReadAllBytes(path))\r\n                };\r\n                Stopwatch sw = new Stopwatch();\r\n                sw.Start();\r\n                model.Predict(sample);\r\n\r\n                //Console.WriteLine(prediction.PredictedLabels);\r\n\r\n                i++;\r\n\r\n                sw.Stop();\r\n\r\n                Console.WriteLine(\"Elapsed={0}\", sw.Elapsed.TotalMilliseconds);\r\n            }\r\n        }\r\n\r\n        public static string ImageToString(this Image image)\r\n        {\r\n            if (image == null)\r\n                return String.Empty;\r\n\r\n            var stream = new MemoryStream();\r\n            image.Save(stream, image.RawFormat);\r\n            var bytes = stream.ToArray();\r\n\r\n            return Convert.ToBase64String(bytes);\r\n        }\r\n    }\r\n}\r\n```\r\nImageInputData.cs:\r\n```\r\nusing Microsoft.ML.Data;\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.IO;\r\nusing System.Linq;\r\n\r\nnamespace OCRWithMLNET.ImageDataStructures\r\n{\r\n    public class ImageInputData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string input_image;\r\n    }\r\n}\r\n```\r\n\r\nImageLabelPredictions.cs\r\n```\r\nusing Microsoft.ML.Data;\r\n\r\nnamespace OCRWithMLNET.ImageDataStructures\r\n{\r\n    public class ImageLabelPredictions\r\n    {\r\n        [ColumnName(ModelUtils.TensorFlowModelSettings.outputTensorName)]\r\n        public string[] PredictedLabels;\r\n    }\r\n}\r\n```\r\n\r\nProgramm.cs\r\n```\r\nusing System;\r\nusing Microsoft.ML;\r\nusing OCRWithMLNET.ImageDataStructures;\r\n\r\nnamespace OCRWithMLNET\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n            PredictionEngine<ImageInputData, ImageLabelPredictions>  model = ModelUtils.loadModel(\"<path>/frozen_graph.pb\");\r\n\r\n            string[] inputArr = new string[1] { \"img.png\" };\r\n\r\n            ModelUtils.makePredictions(model, inputArr);\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n### Additional Information\r\n\r\nIt suspect that it has to do with the way I load in the image. I also tried loading it in with base64 encoding but this didn't work either.\r\n\r\nIn Python I can load the image in like this:\r\n```\r\nwith open(filename, 'rb') as img_file:\r\n    img_file_data = img_file.read()\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4038","RelatedDescription":"Open issue \"Microsoft.ML.Transforms.TensorFlow.TFException: \"Expected image (JPEG, PNG, or GIF), got unknown format starting with '2552162552240167' \t [[{{node map/while/DecodePng}}]]\" when trying to use Attention-OCR model\" (#4038)"},{"Id":"472711097","IsPullRequest":true,"CreatedAt":"2019-07-25T07:35:28","Actor":"codemzs","Number":"4037","RawContent":null,"Title":"[WIP] Initial draft of tensorflow dnn API for training.","State":"open","Body":"This spec is till in progress, please hold off until WIP tag is removed.","Url":"https://github.com/dotnet/machinelearning/pull/4037","RelatedDescription":"Open PR \"[WIP] Initial draft of tensorflow dnn API for training.\" (#4037)"},{"Id":"472378150","IsPullRequest":false,"CreatedAt":"2019-07-24T16:22:58","Actor":"eerhardt","Number":"4036","RawContent":null,"Title":"Need to explicitly call out that the IEnumerable needs to be thread-safe","State":"open","Body":"See the conversation starting at https://github.com/dotnet/machinelearning/issues/2159#issuecomment-513271843 and continuing from there.\n\nML.NET supports multiple threads reading from the same IDataView instance. For example, when using an SDCA trainer, by default it will train on multiple threads on a machine with more than 2 processors. When using `LoadFromEnumerable` on an IEnumerable that doesn't support multiple threads (like in the issue - using an EF query), ML.NET will still try to access the IDataView from multiple threads, and the underlying IEnumerable can throw, or have some other undefined behavior.\n\nWe should explicitly call this limitation out in the docs, and inform users of this method that the IEnumerable being returned needs to be thread-safe.\n\n---\n#### Document Details\n\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\n\n* ID: 10e8d5aa-2038-a382-ec86-cf8ad031f996\n* Version Independent ID: 81198dc9-ddf4-cef1-c178-82f50f0e7a46\n* Content: [DataOperationsCatalog.LoadFromEnumerable Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataoperationscatalog.loadfromenumerable?view=ml-dotnet)\n* Content Source: [dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/DataOperationsCatalog.xml)\n* Product: **dotnet-ml-api**\n* GitHub Login: @sfilipi\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/4036","RelatedDescription":"Open issue \"Need to explicitly call out that the IEnumerable needs to be thread-safe\" (#4036)"},{"Id":"471602591","IsPullRequest":false,"CreatedAt":"2019-07-24T10:38:00","Actor":"LetterFirst","Number":"4033","RawContent":null,"Title":"Unable to infer column types of the file provided","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 / Visual Studio Professinal 2017 15.9.14\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.1\r\n\r\n### Issue\r\nI would like to thank all of you for your excellent work\r\n\r\n- **What did you do?** I'm trying to load a csv file from my desktop to ML Model Builder\r\n- **What happened?** An error appears (snapshot attached)\r\n- **What did you expect?** I loaded the csv file correctly from RStudio (snapshot attached)\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are \r\n![0](https://user-images.githubusercontent.com/53216682/61702396-041c8180-ad40-11e9-93e3-de705569cd62.PNG)\r\n![1](https://user-images.githubusercontent.com/53216682/61702398-041c8180-ad40-11e9-8803-e4213f2e5945.PNG)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4033","RelatedDescription":"Closed issue \"Unable to infer column types of the file provided\" (#4033)"},{"Id":"471967973","IsPullRequest":true,"CreatedAt":"2019-07-23T21:39:07","Actor":"tannergooding","Number":"4035","RawContent":null,"Title":"Adding the initial prototype of a DatabaseLoader","State":"open","Body":"This adds the initial barebones prototype for DatabaseLoader to the Microsot.ML.Experimental project.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4035","RelatedDescription":"Open PR \"Adding the initial prototype of a DatabaseLoader\" (#4035)"},{"Id":"471710154","IsPullRequest":false,"CreatedAt":"2019-07-23T13:51:20","Actor":"hobbsa","Number":"4034","RawContent":null,"Title":"Onnx Support for String Tensors?","State":"open","Body":"### System information\r\n\r\nWindows 10 - \r\n.NET Core 2 - ML.NET 1.2\r\n\r\n### Issue\r\n\r\nIs there any timeline for allowing string tensors to be used in Onnx models within ML.NET?  Tried both InferenceSession and pipeline ApplyOnnxModel and keep hitting in the \r\n\r\npublic static NamedOnnxValue CreateNamedOnnxValue<T>(string name, ReadOnlySpan<T> data, OnnxShape shape)\r\n        {\r\n            if (!_onnxTypeMap.Contains(typeof(T)))\r\n                throw new NotImplementedException($\"Not implemented type {typeof(T)}\");\r\n            return NamedOnnxValue.CreateFromTensor<T>(name, new DenseTensor<T>(data.ToArray(), shape.Select(x => (int)x).ToArray()));\r\n        }\r\n\r\nBecause onnxTypeMap does not support string.\r\n\r\nMy OnnxModel takes input of string and output of long+float.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4034","RelatedDescription":"Open issue \"Onnx Support for String Tensors?\" (#4034)"},{"Id":"471033680","IsPullRequest":false,"CreatedAt":"2019-07-22T11:09:14","Actor":"yaeldekel","Number":"4032","RawContent":null,"Title":"Integrate with LibSVM","State":"open","Body":"The LibSVM library supports multiple kinds of SVMs, including anomaly detection, binary and multiclass classification, and regression.\r\nhttps://www.csie.ntu.edu.tw/~cjlin/libsvm/\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4032","RelatedDescription":"Open issue \"Integrate with LibSVM\" (#4032)"},{"Id":"471032313","IsPullRequest":false,"CreatedAt":"2019-07-22T11:05:53","Actor":"yaeldekel","Number":"4031","RawContent":null,"Title":"Add a Local Deep Kernel Learning trainer","State":"open","Body":"http://manikvarma.org/pubs/jose13.pdf\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4031","RelatedDescription":"Open issue \"Add a Local Deep Kernel Learning trainer\" (#4031)"},{"Id":"471031438","IsPullRequest":false,"CreatedAt":"2019-07-22T11:03:51","Actor":"yaeldekel","Number":"4030","RawContent":null,"Title":"Integrate with Bonsai/ProtoNN","State":"open","Body":"Integrate with the EdgeML package:\r\nhttps://github.com/microsoft/EdgeML\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4030","RelatedDescription":"Open issue \"Integrate with Bonsai/ProtoNN\" (#4030)"},{"Id":"470710437","IsPullRequest":false,"CreatedAt":"2019-07-20T20:12:59","Actor":"famschopman","Number":"4029","RawContent":null,"Title":"AutoML API model incompatible with AutoML CLI?","State":"open","Body":"When I train and save a model with the ModelBuilder from Visual Studio, and inspect the model that is loaded to predict I get a TrainSchema with all columns, and the last column is the Features column.\r\n\r\nWhen I train and save a model with the AutoML API, it received an exception where it tries to find a SamplingKeyColumn. After inspection AutoML has saved the model with an additional column just before the Features column. This is different compared to the ModelBuilder behavior.\r\n\r\nSo I have to extend me model with the following lines to make sure I can run a prediction (I have 34 columns in my dataset).\r\n\r\n            [ColumnName(\"SamplingKeyColumn\"), LoadColumn(35)]\r\n            public float SamplingKeyColumn { get; set; }\r\n\r\nIs this expected behavior? It feels very inconsistent and quite confusing behavior. I couldn't find any documentation about this either.","Url":"https://github.com/dotnet/machinelearning/issues/4029","RelatedDescription":"Open issue \"AutoML API model incompatible with AutoML CLI?\" (#4029)"},{"Id":"470509330","IsPullRequest":false,"CreatedAt":"2019-07-20T14:43:25","Actor":"famschopman","Number":"4026","RawContent":null,"Title":"Getting bestfit hyper-parameters from AutoML","State":"closed","Body":"When using the model builder, the generated code contains interesting hyper-parameters. \r\n\r\nIs there a way to get these when using the AutoML API? I debugged the bestfit but couldnt find anything that resembles this.\r\n\r\nExample:\r\nvar trainer = mlContext.BinaryClassification.Trainers.SdcaLogisticRegression(new SdcaLogisticRegressionBinaryTrainer.Options() { **L2Regularization = 0.0001f, L1Regularization = 1f, ConvergenceTolerance = 0.2f, MaximumNumberOfIterations = 20, Shuffle = false, BiasLearningRate = 0f**, LabelColumnName = \"Attrition\", FeatureColumnName = \"Features\" });\r\n            var trainingPipeline = dataProcessPipeline.Append(trainer);\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4026","RelatedDescription":"Closed issue \"Getting bestfit hyper-parameters from AutoML\" (#4026)"},{"Id":"470680797","IsPullRequest":false,"CreatedAt":"2019-07-20T14:32:38","Actor":"nick-ganju","Number":"4028","RawContent":null,"Title":"Upsampling with IDataView","State":"open","Body":"Upsampling is a common practice for unbalanced data sets. The best practice for upsampling is to upsample the training set AFTER splitting into train and test sets, because if you duplicate rows before splitting, you'll get identical rows in the train and test set.  This is data leakage from the train to the test set, and if you overfit the training set it will be partially hidden by the identical rows in the test set pumping up the scores.\r\n\r\nThere is no Upsampling transformer, so far as I can find.  If I use the built-in TrainTestSplit method, I get two IDataViews back.  Now I can't upsample by adding/duplicating rows in the training set because IDataView is immutable.\r\n\r\nSo basically I have to load from text file myself, because if I use TextLoader I get an IDataView which puts me in the same predicament.  Next, I have to reproduce the functionality in TrainTestSplit(), in order to split my original dataset myself into train and test split.  Next, I have to upsample the training set myself, and then remember to separately run both the train and test split through the regular data pipeline I've created.  \r\n\r\nI can't see how the CustomTransform can be used to Upsample.  How would you suggest is the correct way to upsample a data set with ML.Net?  Like a nice, convenient way.  Not an arduous solution like I mentioned above, which will just drive people back to python instead.","Url":"https://github.com/dotnet/machinelearning/issues/4028","RelatedDescription":"Open issue \"Upsampling with IDataView\" (#4028)"},{"Id":"470679264","IsPullRequest":false,"CreatedAt":"2019-07-20T14:17:33","Actor":"jonathan-taina","Number":"4027","RawContent":null,"Title":"InvalidProtocolBufferException: Protocol message was too large.","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 Pro v1803, build 17134.885\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 2.2.108\r\n\r\n### Issue\r\n\r\n- **What did you do?** Attempted to load an ONNX model\r\n- **What happened?** It failed: InvalidProtocolBufferException: Protocol message was too large. May be malicious. Use CodedInputStream.SetSizeLimit() to increase the size limit.\r\n- **What did you expect?** For the model to load successfully.\r\n\r\n### Source code / logs\r\n\r\nThe model is a pre-trained resnet34 trained on the MNIST handwritten digits database. The model was exported from pytorch.\r\n\r\nI assume the .onnx file is valid, as I can view it without any issues at https://lutzroeder.github.io/netron/\r\n\r\nI'd attach the file itself but github won't allow me, the filesize is 83.3MB; 73MB zipped.\r\n\r\n`var modelPath = $\"{Directory.GetCurrentDirectory()}/Models/mnist_digits.onnx\";`\r\n`var pipeline = mlContext.Transforms.LoadImages(\"image\", \"\", nameof(ImageNetData.ImagePath));`\r\n`pipeline.Append(mlContext.Transforms.ResizeImages(\"image\", ImageNetSettings.imageWidth, ImageNetSettings.imageHeight, \"image\"));`\r\n`pipeline.Append(mlContext.Transforms.ExtractPixels(\"image\"));`\r\n`pipeline.Append(mlContext.Transforms.ApplyOnnxModel(modelPath));`\r\n\r\nException occurs on the final line above.\r\n\r\n### Stacktrace\r\n\r\nInvalidProtocolBufferException: Protocol message was too large. May be malicious. Use CodedInputStream.SetSizeLimit() to increase the size limit.\r\nGoogle.Protobuf.CodedInputStream.RefillBuffer(bool mustSucceed)\r\nGoogle.Protobuf.CodedInputStream.get_IsAtEnd()\r\nGoogle.Protobuf.CodedInputStream.ReadTag()\r\nGoogle.Protobuf.CodedInputStream.PeekTag()\r\nGoogle.Protobuf.Collections.RepeatedField<T>.AddEntriesFrom(CodedInputStream input, FieldCodec<T> codec)\r\nMicrosoft.ML.Model.OnnxConverter.OnnxCSharpToProtoWrapper+GraphProto.MergeFrom(CodedInputStream input)\r\nGoogle.Protobuf.CodedInputStream.ReadMessage(IMessage builder)\r\nMicrosoft.ML.Model.OnnxConverter.OnnxCSharpToProtoWrapper+ModelProto.MergeFrom(CodedInputStream input)\r\nGoogle.Protobuf.MessageExtensions.MergeFrom(IMessage message, Stream input)\r\nGoogle.Protobuf.MessageParser<T>.ParseFrom(Stream input)\r\nMicrosoft.ML.Transforms.Onnx.OnnxModel..ctor(string modelFile, Nullable<int> gpuDeviceId, bool fallbackToCpu, bool ownModelFile)\r\nMicrosoft.ML.Transforms.Onnx.OnnxTransformer..ctor(IHostEnvironment env, Options options, byte[] modelBytes)\r\nMicrosoft.ML.Transforms.Onnx.OnnxScoringEstimator..ctor(IHostEnvironment env, string modelFile, Nullable<int> gpuDeviceId, bool fallbackToCpu)\r\nMicrosoft.ML.OnnxCatalog.ApplyOnnxModel(TransformsCatalog catalog, string modelFile, Nullable<int> gpuDeviceId, bool fallbackToCpu)\r\nONNX_backend.Services.OnnxService.LoadHandwrittenDigitsModel(MLContext mlContext) in OnnxService.cs\r\n+\r\n            pipeline.Append(mlContext.Transforms.ApplyOnnxModel(modelPath));\r\nONNX_backend.Services.OnnxService.Start() in OnnxService.cs\r\n+\r\n            var model = LoadHandwrittenDigitsModel(_mlContext);\r\nONNX_backend.Controllers.ValuesController.Get() in ValuesController.cs\r\n+\r\n            _onnxService.Start();\r\nlambda_method(Closure , object , object[] )\r\nMicrosoft.Extensions.Internal.ObjectMethodExecutor.Execute(object target, object[] parameters)\r\nMicrosoft.AspNetCore.Mvc.Internal.ActionMethodExecutor+SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, object controller, object[] arguments)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(ref State next, ref Scope scope, ref object state, ref bool isCompleted)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextResourceFilter()\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.Rethrow(ResourceExecutedContext context)\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.Next(ref State next, ref Scope scope, ref object state, ref bool isCompleted)\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeFilterPipelineAsync()\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeAsync()\r\nMicrosoft.AspNetCore.Routing.EndpointMiddleware.Invoke(HttpContext httpContext)\r\nMicrosoft.AspNetCore.Routing.EndpointRoutingMiddleware.Invoke(HttpContext httpContext)\r\nMicrosoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)","Url":"https://github.com/dotnet/machinelearning/issues/4027","RelatedDescription":"Open issue \"InvalidProtocolBufferException: Protocol message was too large.\" (#4027)"},{"Id":"470507435","IsPullRequest":false,"CreatedAt":"2019-07-19T19:42:19","Actor":"famschopman","Number":"4025","RawContent":null,"Title":"Getting algorithm","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4025","RelatedDescription":"Closed issue \"Getting algorithm\" (#4025)"},{"Id":"470383482","IsPullRequest":false,"CreatedAt":"2019-07-19T15:27:34","Actor":"colbylwilliams","Number":"4024","RawContent":null,"Title":"Anomaly Detection Task output should include PredictedLabel","State":"open","Body":"\r\nThe [Inputs and Output Columns](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.randomizedpcatrainer?view=ml-dotnet#input-and-output-columns) section should have [`PredictedLabel` in addition to `Score`](https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.PCA/PcaTrainer.cs#L381-L385).  Note: There is an [issue](https://github.com/dotnet/machinelearning/issues/3990) with the current release of ML.NET where `PredictedLabel` always evaluates to `true`.\r\n\r\nAdditionally, the description for `Score` reads:\r\n> The non-negative, unbounded score that was calculated by the anomaly detection model.\r\n\r\nThis does not indicate how the value returned by the model for `Score` should be interpreted.  Should higher scores be interpreted as anomalies, or scores closer to zero?\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 8b318bcc-48ff-eb63-9952-e811a283eb90\r\n* Version Independent ID: 1810a47c-da4c-8a3a-f5a0-61b31069f083\r\n* Content: [RandomizedPcaTrainer Class (Microsoft.ML.Trainers)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.randomizedpcatrainer?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers/RandomizedPcaTrainer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers/RandomizedPcaTrainer.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @sfilipi\r\n* Microsoft Alias: **johalex**","Url":"https://github.com/dotnet/machinelearning/issues/4024","RelatedDescription":"Open issue \"Anomaly Detection Task output should include PredictedLabel\" (#4024)"},{"Id":"470369216","IsPullRequest":false,"CreatedAt":"2019-07-19T14:57:04","Actor":"nick-ganju","Number":"4023","RawContent":null,"Title":"Interpreting a pipeline's resulting Schema and/or .Preview()","State":"open","Body":"\r\nGoing over this article to be able to inspect data after the preprocessing pipeline:\r\nhttps://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/inspect-intermediate-data-ml-net\r\n\r\nComing from python where you have a dataframe and you can just do dataframe.show(), this is quite an ordeal.  The CreateEnumerable() is pretty impractical because your original POCO won't fit the schema any more if you've done one-hot-encoding etc.  The one-hot-encoding creates multiple columns with the same name, how can that ever map back to a POCO? \r\n\r\nAnd there's a mandatory Features column at the end of the row, that repeats all the values in the row.  And if you then NormalizeMinMax the Features column, you get ANOTHER Features column with the same name.  Then you're trying to look at that in a Preview() and it's very confusing to see what's going on. \r\n\r\nThen there's DataViewRowCursor, where you need to specify reflection-style getters for each column.  So each time you tweak the pipeline you have to rewrite the code that lets you see the results of your pipeline?  It defeats the ability to quickly tweak and look, tweak and look, in the way that python does it so simply with dataframe.show().\r\n\r\nSo assuming this is how we have to inspect our data, I've got two questions:\r\n\r\n1) When a Transform (like OneHotEncoding) creates multiple columns with the same name, what's going on?  Is the training algorithm going to look at all of them?  Is the IsHidden how it's deciding what to use?  If so, can there be some official documentation on how all of this works?\r\n\r\n2) Why is it our responsibility to create a Features column at all?  Can't the algorithms just run on the IDataView we created, like in python?  It seems like a complicated and unnecessary step.  Also does it seem like good OO design to have a Features field at the end of a row that repeats all the values in said row? If you need to make this Features vector for performance reasons, why not create it once Fit() is called, keep it out of our data table, and hide this implementation detail from the user?\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/4023","RelatedDescription":"Open issue \"Interpreting a pipeline's resulting Schema and/or .Preview()\" (#4023)"},{"Id":"470128230","IsPullRequest":true,"CreatedAt":"2019-07-19T04:11:33","Actor":"PranovD","Number":"4022","RawContent":null,"Title":"Dnn","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4022","RelatedDescription":"Open PR \"Dnn\" (#4022)"},{"Id":"469957216","IsPullRequest":true,"CreatedAt":"2019-07-18T23:14:13","Actor":"CESARDELATORRE","Number":"4021","RawContent":null,"Title":"DatabaseLoader specs: Update on NuGet and Class library design","State":"closed","Body":"Minor update so we are more explicit about the NuGet and Class library design for this feature.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/4021","RelatedDescription":"Closed or merged PR \"DatabaseLoader specs: Update on NuGet and Class library design\" (#4021)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-07-31T05:30:42.9656794Z","RunDurationInMilliseconds":823}